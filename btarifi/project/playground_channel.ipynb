{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model_name = \"toy_convnet\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_1_0\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0281, -0.0582, -0.0371],\n",
      "          [-0.1579,  0.0132, -0.0916],\n",
      "          [-0.1409, -0.0279,  0.0260]],\n",
      "\n",
      "         [[-0.0331,  0.1588,  0.0091],\n",
      "          [ 0.1361, -0.0194,  0.0423],\n",
      "          [-0.0636, -0.1731, -0.0179]],\n",
      "\n",
      "         [[-0.1212,  0.1039, -0.1320],\n",
      "          [-0.1762,  0.1007, -0.1141],\n",
      "          [ 0.1080, -0.0230, -0.0278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0323, -0.0230,  0.1359],\n",
      "          [-0.0833,  0.1698, -0.0782],\n",
      "          [-0.1471, -0.1869,  0.1094]],\n",
      "\n",
      "         [[-0.0801,  0.0152,  0.0724],\n",
      "          [ 0.0146,  0.0003, -0.0094],\n",
      "          [-0.1833,  0.0050,  0.0855]],\n",
      "\n",
      "         [[ 0.0945, -0.0190,  0.0050],\n",
      "          [ 0.1021,  0.1551,  0.0910],\n",
      "          [-0.1895, -0.1132, -0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-0.0246, -0.0291,  0.1384],\n",
      "          [ 0.1425, -0.1888,  0.1047],\n",
      "          [ 0.0226, -0.0433,  0.1525]],\n",
      "\n",
      "         [[-0.1333,  0.0212,  0.1316],\n",
      "          [-0.1676, -0.0624,  0.0050],\n",
      "          [-0.0123, -0.1813, -0.1231]],\n",
      "\n",
      "         [[ 0.1192, -0.0281,  0.0213],\n",
      "          [-0.1387, -0.1433, -0.0901],\n",
      "          [-0.0120, -0.1786, -0.1341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0388,  0.0215, -0.0140],\n",
      "          [-0.0646,  0.0772, -0.0620],\n",
      "          [-0.1702,  0.1200,  0.0992]],\n",
      "\n",
      "         [[-0.0456,  0.1566, -0.1053],\n",
      "          [ 0.1025, -0.1557, -0.1612],\n",
      "          [ 0.0185,  0.0244,  0.0629]],\n",
      "\n",
      "         [[-0.0415,  0.1572, -0.1861],\n",
      "          [-0.0559, -0.0251,  0.0135],\n",
      "          [-0.1409,  0.0945, -0.0916]]],\n",
      "\n",
      "\n",
      "        [[[-0.0358, -0.0166, -0.1808],\n",
      "          [-0.1462,  0.0410, -0.1780],\n",
      "          [-0.1294, -0.1415,  0.0672]],\n",
      "\n",
      "         [[ 0.0717, -0.0766, -0.1496],\n",
      "          [-0.0873,  0.0201, -0.1688],\n",
      "          [ 0.0117, -0.1336, -0.1572]],\n",
      "\n",
      "         [[ 0.0082, -0.0865, -0.0872],\n",
      "          [-0.0791,  0.0603, -0.1893],\n",
      "          [-0.1515, -0.1540,  0.1534]]],\n",
      "\n",
      "\n",
      "        [[[-0.1032,  0.0052, -0.1522],\n",
      "          [ 0.0596,  0.0488,  0.1130],\n",
      "          [-0.0443,  0.0843,  0.1565]],\n",
      "\n",
      "         [[-0.0957,  0.0796,  0.1682],\n",
      "          [-0.0779, -0.0751, -0.1459],\n",
      "          [-0.1088,  0.0034, -0.0063]],\n",
      "\n",
      "         [[-0.1716,  0.1457,  0.1211],\n",
      "          [-0.1615,  0.0933,  0.1331],\n",
      "          [-0.1742, -0.0264, -0.1103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1299,  0.1591,  0.1104],\n",
      "          [-0.1777,  0.0813,  0.0555],\n",
      "          [ 0.0875,  0.1530,  0.1006]],\n",
      "\n",
      "         [[ 0.0911, -0.1370,  0.0769],\n",
      "          [ 0.1230, -0.0951,  0.0309],\n",
      "          [-0.0020, -0.0136,  0.0172]],\n",
      "\n",
      "         [[ 0.0174,  0.1471,  0.1669],\n",
      "          [-0.1216, -0.1433, -0.0996],\n",
      "          [-0.0346,  0.0805, -0.1108]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470, -0.0613,  0.1496],\n",
      "          [-0.0450,  0.1105,  0.0757],\n",
      "          [ 0.1122, -0.0148, -0.0836]],\n",
      "\n",
      "         [[ 0.1298, -0.1689, -0.0546],\n",
      "          [-0.0775,  0.1205,  0.1637],\n",
      "          [ 0.1796,  0.1915,  0.0197]],\n",
      "\n",
      "         [[ 0.1052, -0.1128,  0.0655],\n",
      "          [ 0.1414,  0.1597, -0.0725],\n",
      "          [-0.1131,  0.0336, -0.0099]]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[-0.0281, -0.0582, -0.0371],\n",
      "          [-0.1579,  0.0132, -0.0916],\n",
      "          [-0.1409, -0.0279,  0.0260]],\n",
      "\n",
      "         [[-0.0331,  0.1588,  0.0091],\n",
      "          [ 0.1361, -0.0194,  0.0423],\n",
      "          [-0.0636, -0.1731, -0.0179]],\n",
      "\n",
      "         [[-0.1212,  0.1039, -0.1320],\n",
      "          [-0.1762,  0.1007, -0.1141],\n",
      "          [ 0.1080, -0.0230, -0.0278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0323, -0.0230,  0.1359],\n",
      "          [-0.0833,  0.1698, -0.0782],\n",
      "          [-0.1471, -0.1869,  0.1094]],\n",
      "\n",
      "         [[-0.0801,  0.0152,  0.0724],\n",
      "          [ 0.0146,  0.0003, -0.0094],\n",
      "          [-0.1833,  0.0050,  0.0855]],\n",
      "\n",
      "         [[ 0.0945, -0.0190,  0.0050],\n",
      "          [ 0.1021,  0.1551,  0.0910],\n",
      "          [-0.1895, -0.1132, -0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-0.0246, -0.0291,  0.1384],\n",
      "          [ 0.1425, -0.1888,  0.1047],\n",
      "          [ 0.0226, -0.0433,  0.1525]],\n",
      "\n",
      "         [[-0.1333,  0.0212,  0.1316],\n",
      "          [-0.1676, -0.0624,  0.0050],\n",
      "          [-0.0123, -0.1813, -0.1231]],\n",
      "\n",
      "         [[ 0.1192, -0.0281,  0.0213],\n",
      "          [-0.1387, -0.1433, -0.0901],\n",
      "          [-0.0120, -0.1786, -0.1341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0388,  0.0215, -0.0140],\n",
      "          [-0.0646,  0.0772, -0.0620],\n",
      "          [-0.1702,  0.1200,  0.0992]],\n",
      "\n",
      "         [[-0.0456,  0.1566, -0.1053],\n",
      "          [ 0.1025, -0.1557, -0.1612],\n",
      "          [ 0.0185,  0.0244,  0.0629]],\n",
      "\n",
      "         [[-0.0415,  0.1572, -0.1861],\n",
      "          [-0.0559, -0.0251,  0.0135],\n",
      "          [-0.1409,  0.0945, -0.0916]]],\n",
      "\n",
      "\n",
      "        [[[-0.0358, -0.0166, -0.1808],\n",
      "          [-0.1462,  0.0410, -0.1780],\n",
      "          [-0.1294, -0.1415,  0.0672]],\n",
      "\n",
      "         [[ 0.0717, -0.0766, -0.1496],\n",
      "          [-0.0873,  0.0201, -0.1688],\n",
      "          [ 0.0117, -0.1336, -0.1572]],\n",
      "\n",
      "         [[ 0.0082, -0.0865, -0.0872],\n",
      "          [-0.0791,  0.0603, -0.1893],\n",
      "          [-0.1515, -0.1540,  0.1534]]],\n",
      "\n",
      "\n",
      "        [[[-0.1032,  0.0052, -0.1522],\n",
      "          [ 0.0596,  0.0488,  0.1130],\n",
      "          [-0.0443,  0.0843,  0.1565]],\n",
      "\n",
      "         [[-0.0957,  0.0796,  0.1682],\n",
      "          [-0.0779, -0.0751, -0.1459],\n",
      "          [-0.1088,  0.0034, -0.0063]],\n",
      "\n",
      "         [[-0.1716,  0.1457,  0.1211],\n",
      "          [-0.1615,  0.0933,  0.1331],\n",
      "          [-0.1742, -0.0264, -0.1103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1299,  0.1591,  0.1104],\n",
      "          [-0.1777,  0.0813,  0.0555],\n",
      "          [ 0.0875,  0.1530,  0.1006]],\n",
      "\n",
      "         [[ 0.0911, -0.1370,  0.0769],\n",
      "          [ 0.1230, -0.0951,  0.0309],\n",
      "          [-0.0020, -0.0136,  0.0172]],\n",
      "\n",
      "         [[ 0.0174,  0.1471,  0.1669],\n",
      "          [-0.1216, -0.1433, -0.0996],\n",
      "          [-0.0346,  0.0805, -0.1108]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470, -0.0613,  0.1496],\n",
      "          [-0.0450,  0.1105,  0.0757],\n",
      "          [ 0.1122, -0.0148, -0.0836]],\n",
      "\n",
      "         [[ 0.1298, -0.1689, -0.0546],\n",
      "          [-0.0775,  0.1205,  0.1637],\n",
      "          [ 0.1796,  0.1915,  0.0197]],\n",
      "\n",
      "         [[ 0.1052, -0.1128,  0.0655],\n",
      "          [ 0.1414,  0.1597, -0.0725],\n",
      "          [-0.1131,  0.0336, -0.0099]]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.0581, -0.1654, -0.1093, -0.0078, -0.0281, -0.1812, -0.0995, -0.0212]))])\n",
      "--------------------------------------------------\n",
      "block_2_0\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0596, -0.0875,  0.0476],\n",
      "          [-0.0365, -0.1032,  0.0094],\n",
      "          [ 0.0261, -0.0170, -0.0172]],\n",
      "\n",
      "         [[-0.0382, -0.0939, -0.1078],\n",
      "          [-0.0156, -0.0526, -0.0604],\n",
      "          [ 0.0932, -0.0227,  0.1047]],\n",
      "\n",
      "         [[-0.0091, -0.0926,  0.1150],\n",
      "          [ 0.0752,  0.0721, -0.1087],\n",
      "          [-0.0664,  0.1070,  0.0600]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1078, -0.0985, -0.0785],\n",
      "          [ 0.0428, -0.0222, -0.1045],\n",
      "          [-0.1009, -0.0900, -0.0588]],\n",
      "\n",
      "         [[ 0.0508, -0.0773,  0.0361],\n",
      "          [ 0.0582, -0.1089,  0.1133],\n",
      "          [ 0.0926, -0.0273,  0.0611]],\n",
      "\n",
      "         [[ 0.0501, -0.0282,  0.0956],\n",
      "          [ 0.0752,  0.0743, -0.0127],\n",
      "          [ 0.0484,  0.0273,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0674, -0.0254,  0.0535],\n",
      "          [-0.0291,  0.0914, -0.0815],\n",
      "          [-0.1006,  0.0794, -0.0939]],\n",
      "\n",
      "         [[ 0.1072,  0.0983,  0.0033],\n",
      "          [ 0.0995,  0.0336,  0.0705],\n",
      "          [-0.0851, -0.0121, -0.1073]],\n",
      "\n",
      "         [[ 0.0823,  0.1116,  0.0432],\n",
      "          [ 0.0847,  0.0571,  0.0561],\n",
      "          [ 0.0845,  0.1007, -0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1028, -0.0511,  0.0339],\n",
      "          [-0.0309,  0.0465,  0.0748],\n",
      "          [ 0.0375,  0.0016,  0.0234]],\n",
      "\n",
      "         [[ 0.0200,  0.1162, -0.0746],\n",
      "          [ 0.0323,  0.0382, -0.0532],\n",
      "          [ 0.0018,  0.1120,  0.0635]],\n",
      "\n",
      "         [[-0.0559, -0.1024, -0.0014],\n",
      "          [-0.0612,  0.1089, -0.0595],\n",
      "          [ 0.0894, -0.0961,  0.0489]]],\n",
      "\n",
      "\n",
      "        [[[-0.0339, -0.0094,  0.0812],\n",
      "          [ 0.0574, -0.0567,  0.1112],\n",
      "          [ 0.0741, -0.0671, -0.0715]],\n",
      "\n",
      "         [[-0.0719,  0.0981,  0.0644],\n",
      "          [-0.0326, -0.0022, -0.0769],\n",
      "          [ 0.0494, -0.0056, -0.0676]],\n",
      "\n",
      "         [[ 0.0943, -0.0431, -0.0135],\n",
      "          [-0.0334, -0.1086, -0.0668],\n",
      "          [ 0.0871,  0.0335,  0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0783, -0.0962, -0.0887],\n",
      "          [ 0.0200, -0.1048,  0.1062],\n",
      "          [ 0.0985, -0.1136, -0.0910]],\n",
      "\n",
      "         [[-0.0103,  0.0190,  0.0287],\n",
      "          [ 0.0229,  0.0080, -0.0192],\n",
      "          [-0.0947,  0.1093,  0.0466]],\n",
      "\n",
      "         [[ 0.0701,  0.0776, -0.0818],\n",
      "          [-0.0544, -0.0652, -0.0046],\n",
      "          [ 0.0091,  0.1091, -0.0164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1108,  0.0437,  0.0885],\n",
      "          [ 0.0368,  0.0278, -0.1073],\n",
      "          [ 0.0280,  0.0425,  0.1060]],\n",
      "\n",
      "         [[ 0.0674, -0.0610,  0.0578],\n",
      "          [ 0.0383,  0.0874, -0.0150],\n",
      "          [ 0.0550,  0.0654,  0.0950]],\n",
      "\n",
      "         [[-0.0842, -0.0888, -0.0826],\n",
      "          [-0.0258, -0.0271,  0.0476],\n",
      "          [-0.0879,  0.0962, -0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161, -0.0774, -0.0436],\n",
      "          [ 0.0274,  0.0617, -0.0436],\n",
      "          [ 0.0645,  0.1001,  0.0709]],\n",
      "\n",
      "         [[-0.0332, -0.0703,  0.0374],\n",
      "          [ 0.0791,  0.0801,  0.1043],\n",
      "          [-0.0903,  0.0275, -0.0864]],\n",
      "\n",
      "         [[ 0.0198,  0.0705,  0.0244],\n",
      "          [ 0.0181, -0.0652,  0.0100],\n",
      "          [-0.0482,  0.0683, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.1143, -0.0299,  0.0207],\n",
      "          [ 0.0898,  0.0824,  0.0892],\n",
      "          [-0.0534,  0.0803,  0.0363]],\n",
      "\n",
      "         [[ 0.0663,  0.0086, -0.0991],\n",
      "          [ 0.0858,  0.0761,  0.0711],\n",
      "          [ 0.1016, -0.0749,  0.0748]],\n",
      "\n",
      "         [[ 0.0343,  0.0539, -0.1150],\n",
      "          [ 0.0733,  0.0621, -0.0680],\n",
      "          [ 0.0439,  0.0956, -0.0327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0822, -0.1176, -0.0535],\n",
      "          [ 0.1119, -0.0932,  0.0493],\n",
      "          [-0.0484, -0.1010, -0.0124]],\n",
      "\n",
      "         [[ 0.0456,  0.0963, -0.0413],\n",
      "          [ 0.1107, -0.1017, -0.0885],\n",
      "          [-0.0423,  0.0104, -0.0072]],\n",
      "\n",
      "         [[ 0.0071,  0.0636, -0.0601],\n",
      "          [ 0.0475,  0.0615, -0.0321],\n",
      "          [ 0.1114,  0.0611,  0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0716,  0.0727, -0.0890],\n",
      "          [-0.0349, -0.0882, -0.1096],\n",
      "          [-0.0773,  0.0900, -0.0068]],\n",
      "\n",
      "         [[-0.0798,  0.0989, -0.1112],\n",
      "          [ 0.0889,  0.0375, -0.0443],\n",
      "          [-0.0928, -0.0475,  0.0469]],\n",
      "\n",
      "         [[-0.0055, -0.0073,  0.0975],\n",
      "          [-0.0471,  0.0789,  0.0345],\n",
      "          [-0.0696, -0.0959, -0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0008,  0.0041,  0.0502],\n",
      "          [ 0.0588,  0.0806,  0.0062],\n",
      "          [ 0.0587, -0.0384,  0.0294]],\n",
      "\n",
      "         [[ 0.0297,  0.0202,  0.1005],\n",
      "          [ 0.0867, -0.0717, -0.0795],\n",
      "          [-0.0349, -0.0062,  0.0557]],\n",
      "\n",
      "         [[ 0.0949,  0.1112, -0.0870],\n",
      "          [ 0.1066, -0.0233, -0.0375],\n",
      "          [-0.1044,  0.0916,  0.0663]]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[-0.0596, -0.0875,  0.0476],\n",
      "          [-0.0365, -0.1032,  0.0094],\n",
      "          [ 0.0261, -0.0170, -0.0172]],\n",
      "\n",
      "         [[-0.0382, -0.0939, -0.1078],\n",
      "          [-0.0156, -0.0526, -0.0604],\n",
      "          [ 0.0932, -0.0227,  0.1047]],\n",
      "\n",
      "         [[-0.0091, -0.0926,  0.1150],\n",
      "          [ 0.0752,  0.0721, -0.1087],\n",
      "          [-0.0664,  0.1070,  0.0600]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1078, -0.0985, -0.0785],\n",
      "          [ 0.0428, -0.0222, -0.1045],\n",
      "          [-0.1009, -0.0900, -0.0588]],\n",
      "\n",
      "         [[ 0.0508, -0.0773,  0.0361],\n",
      "          [ 0.0582, -0.1089,  0.1133],\n",
      "          [ 0.0926, -0.0273,  0.0611]],\n",
      "\n",
      "         [[ 0.0501, -0.0282,  0.0956],\n",
      "          [ 0.0752,  0.0743, -0.0127],\n",
      "          [ 0.0484,  0.0273,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0674, -0.0254,  0.0535],\n",
      "          [-0.0291,  0.0914, -0.0815],\n",
      "          [-0.1006,  0.0794, -0.0939]],\n",
      "\n",
      "         [[ 0.1072,  0.0983,  0.0033],\n",
      "          [ 0.0995,  0.0336,  0.0705],\n",
      "          [-0.0851, -0.0121, -0.1073]],\n",
      "\n",
      "         [[ 0.0823,  0.1116,  0.0432],\n",
      "          [ 0.0847,  0.0571,  0.0561],\n",
      "          [ 0.0845,  0.1007, -0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1028, -0.0511,  0.0339],\n",
      "          [-0.0309,  0.0465,  0.0748],\n",
      "          [ 0.0375,  0.0016,  0.0234]],\n",
      "\n",
      "         [[ 0.0200,  0.1162, -0.0746],\n",
      "          [ 0.0323,  0.0382, -0.0532],\n",
      "          [ 0.0018,  0.1120,  0.0635]],\n",
      "\n",
      "         [[-0.0559, -0.1024, -0.0014],\n",
      "          [-0.0612,  0.1089, -0.0595],\n",
      "          [ 0.0894, -0.0961,  0.0489]]],\n",
      "\n",
      "\n",
      "        [[[-0.0339, -0.0094,  0.0812],\n",
      "          [ 0.0574, -0.0567,  0.1112],\n",
      "          [ 0.0741, -0.0671, -0.0715]],\n",
      "\n",
      "         [[-0.0719,  0.0981,  0.0644],\n",
      "          [-0.0326, -0.0022, -0.0769],\n",
      "          [ 0.0494, -0.0056, -0.0676]],\n",
      "\n",
      "         [[ 0.0943, -0.0431, -0.0135],\n",
      "          [-0.0334, -0.1086, -0.0668],\n",
      "          [ 0.0871,  0.0335,  0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0783, -0.0962, -0.0887],\n",
      "          [ 0.0200, -0.1048,  0.1062],\n",
      "          [ 0.0985, -0.1136, -0.0910]],\n",
      "\n",
      "         [[-0.0103,  0.0190,  0.0287],\n",
      "          [ 0.0229,  0.0080, -0.0192],\n",
      "          [-0.0947,  0.1093,  0.0466]],\n",
      "\n",
      "         [[ 0.0701,  0.0776, -0.0818],\n",
      "          [-0.0544, -0.0652, -0.0046],\n",
      "          [ 0.0091,  0.1091, -0.0164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1108,  0.0437,  0.0885],\n",
      "          [ 0.0368,  0.0278, -0.1073],\n",
      "          [ 0.0280,  0.0425,  0.1060]],\n",
      "\n",
      "         [[ 0.0674, -0.0610,  0.0578],\n",
      "          [ 0.0383,  0.0874, -0.0150],\n",
      "          [ 0.0550,  0.0654,  0.0950]],\n",
      "\n",
      "         [[-0.0842, -0.0888, -0.0826],\n",
      "          [-0.0258, -0.0271,  0.0476],\n",
      "          [-0.0879,  0.0962, -0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161, -0.0774, -0.0436],\n",
      "          [ 0.0274,  0.0617, -0.0436],\n",
      "          [ 0.0645,  0.1001,  0.0709]],\n",
      "\n",
      "         [[-0.0332, -0.0703,  0.0374],\n",
      "          [ 0.0791,  0.0801,  0.1043],\n",
      "          [-0.0903,  0.0275, -0.0864]],\n",
      "\n",
      "         [[ 0.0198,  0.0705,  0.0244],\n",
      "          [ 0.0181, -0.0652,  0.0100],\n",
      "          [-0.0482,  0.0683, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.1143, -0.0299,  0.0207],\n",
      "          [ 0.0898,  0.0824,  0.0892],\n",
      "          [-0.0534,  0.0803,  0.0363]],\n",
      "\n",
      "         [[ 0.0663,  0.0086, -0.0991],\n",
      "          [ 0.0858,  0.0761,  0.0711],\n",
      "          [ 0.1016, -0.0749,  0.0748]],\n",
      "\n",
      "         [[ 0.0343,  0.0539, -0.1150],\n",
      "          [ 0.0733,  0.0621, -0.0680],\n",
      "          [ 0.0439,  0.0956, -0.0327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0822, -0.1176, -0.0535],\n",
      "          [ 0.1119, -0.0932,  0.0493],\n",
      "          [-0.0484, -0.1010, -0.0124]],\n",
      "\n",
      "         [[ 0.0456,  0.0963, -0.0413],\n",
      "          [ 0.1107, -0.1017, -0.0885],\n",
      "          [-0.0423,  0.0104, -0.0072]],\n",
      "\n",
      "         [[ 0.0071,  0.0636, -0.0601],\n",
      "          [ 0.0475,  0.0615, -0.0321],\n",
      "          [ 0.1114,  0.0611,  0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0716,  0.0727, -0.0890],\n",
      "          [-0.0349, -0.0882, -0.1096],\n",
      "          [-0.0773,  0.0900, -0.0068]],\n",
      "\n",
      "         [[-0.0798,  0.0989, -0.1112],\n",
      "          [ 0.0889,  0.0375, -0.0443],\n",
      "          [-0.0928, -0.0475,  0.0469]],\n",
      "\n",
      "         [[-0.0055, -0.0073,  0.0975],\n",
      "          [-0.0471,  0.0789,  0.0345],\n",
      "          [-0.0696, -0.0959, -0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0008,  0.0041,  0.0502],\n",
      "          [ 0.0588,  0.0806,  0.0062],\n",
      "          [ 0.0587, -0.0384,  0.0294]],\n",
      "\n",
      "         [[ 0.0297,  0.0202,  0.1005],\n",
      "          [ 0.0867, -0.0717, -0.0795],\n",
      "          [-0.0349, -0.0062,  0.0557]],\n",
      "\n",
      "         [[ 0.0949,  0.1112, -0.0870],\n",
      "          [ 0.1066, -0.0233, -0.0375],\n",
      "          [-0.1044,  0.0916,  0.0663]]]])),\n",
      "             ('bias',\n",
      "              tensor([-0.0129, -0.0635,  0.1079, -0.0312, -0.0897,  0.0984, -0.0563,  0.0653,\n",
      "         0.0155,  0.0256,  0.0391, -0.0085,  0.1097, -0.1032,  0.0863,  0.1127]))])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv2d':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        pprint(mg.modules[node.target].state_dict())\n",
    "        print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried\n",
      "Reached3\n",
      "Mask3\n",
      "tensor([[[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]]])\n",
      "Tensor3\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0281, -0.0582, -0.0371],\n",
      "          [-0.1579,  0.0132, -0.0916],\n",
      "          [-0.1409, -0.0279,  0.0260]],\n",
      "\n",
      "         [[-0.0331,  0.1588,  0.0091],\n",
      "          [ 0.1361, -0.0194,  0.0423],\n",
      "          [-0.0636, -0.1731, -0.0179]],\n",
      "\n",
      "         [[-0.1212,  0.1039, -0.1320],\n",
      "          [-0.1762,  0.1007, -0.1141],\n",
      "          [ 0.1080, -0.0230, -0.0278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0323, -0.0230,  0.1359],\n",
      "          [-0.0833,  0.1698, -0.0782],\n",
      "          [-0.1471, -0.1869,  0.1094]],\n",
      "\n",
      "         [[-0.0801,  0.0152,  0.0724],\n",
      "          [ 0.0146,  0.0003, -0.0094],\n",
      "          [-0.1833,  0.0050,  0.0855]],\n",
      "\n",
      "         [[ 0.0945, -0.0190,  0.0050],\n",
      "          [ 0.1021,  0.1551,  0.0910],\n",
      "          [-0.1895, -0.1132, -0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-0.0246, -0.0291,  0.1384],\n",
      "          [ 0.1425, -0.1888,  0.1047],\n",
      "          [ 0.0226, -0.0433,  0.1525]],\n",
      "\n",
      "         [[-0.1333,  0.0212,  0.1316],\n",
      "          [-0.1676, -0.0624,  0.0050],\n",
      "          [-0.0123, -0.1813, -0.1231]],\n",
      "\n",
      "         [[ 0.1192, -0.0281,  0.0213],\n",
      "          [-0.1387, -0.1433, -0.0901],\n",
      "          [-0.0120, -0.1786, -0.1341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0388,  0.0215, -0.0140],\n",
      "          [-0.0646,  0.0772, -0.0620],\n",
      "          [-0.1702,  0.1200,  0.0992]],\n",
      "\n",
      "         [[-0.0456,  0.1566, -0.1053],\n",
      "          [ 0.1025, -0.1557, -0.1612],\n",
      "          [ 0.0185,  0.0244,  0.0629]],\n",
      "\n",
      "         [[-0.0415,  0.1572, -0.1861],\n",
      "          [-0.0559, -0.0251,  0.0135],\n",
      "          [-0.1409,  0.0945, -0.0916]]],\n",
      "\n",
      "\n",
      "        [[[-0.0358, -0.0166, -0.1808],\n",
      "          [-0.1462,  0.0410, -0.1780],\n",
      "          [-0.1294, -0.1415,  0.0672]],\n",
      "\n",
      "         [[ 0.0717, -0.0766, -0.1496],\n",
      "          [-0.0873,  0.0201, -0.1688],\n",
      "          [ 0.0117, -0.1336, -0.1572]],\n",
      "\n",
      "         [[ 0.0082, -0.0865, -0.0872],\n",
      "          [-0.0791,  0.0603, -0.1893],\n",
      "          [-0.1515, -0.1540,  0.1534]]],\n",
      "\n",
      "\n",
      "        [[[-0.1032,  0.0052, -0.1522],\n",
      "          [ 0.0596,  0.0488,  0.1130],\n",
      "          [-0.0443,  0.0843,  0.1565]],\n",
      "\n",
      "         [[-0.0957,  0.0796,  0.1682],\n",
      "          [-0.0779, -0.0751, -0.1459],\n",
      "          [-0.1088,  0.0034, -0.0063]],\n",
      "\n",
      "         [[-0.1716,  0.1457,  0.1211],\n",
      "          [-0.1615,  0.0933,  0.1331],\n",
      "          [-0.1742, -0.0264, -0.1103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1299,  0.1591,  0.1104],\n",
      "          [-0.1777,  0.0813,  0.0555],\n",
      "          [ 0.0875,  0.1530,  0.1006]],\n",
      "\n",
      "         [[ 0.0911, -0.1370,  0.0769],\n",
      "          [ 0.1230, -0.0951,  0.0309],\n",
      "          [-0.0020, -0.0136,  0.0172]],\n",
      "\n",
      "         [[ 0.0174,  0.1471,  0.1669],\n",
      "          [-0.1216, -0.1433, -0.0996],\n",
      "          [-0.0346,  0.0805, -0.1108]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470, -0.0613,  0.1496],\n",
      "          [-0.0450,  0.1105,  0.0757],\n",
      "          [ 0.1122, -0.0148, -0.0836]],\n",
      "\n",
      "         [[ 0.1298, -0.1689, -0.0546],\n",
      "          [-0.0775,  0.1205,  0.1637],\n",
      "          [ 0.1796,  0.1915,  0.0197]],\n",
      "\n",
      "         [[ 0.1052, -0.1128,  0.0655],\n",
      "          [ 0.1414,  0.1597, -0.0725],\n",
      "          [-0.1131,  0.0336, -0.0099]]]], requires_grad=True)\n",
      "Reached3\n",
      "Mask3\n",
      "tensor([[[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]]])\n",
      "Tensor3\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0596, -0.0875,  0.0476],\n",
      "          [-0.0365, -0.1032,  0.0094],\n",
      "          [ 0.0261, -0.0170, -0.0172]],\n",
      "\n",
      "         [[-0.0382, -0.0939, -0.1078],\n",
      "          [-0.0156, -0.0526, -0.0604],\n",
      "          [ 0.0932, -0.0227,  0.1047]],\n",
      "\n",
      "         [[-0.0091, -0.0926,  0.1150],\n",
      "          [ 0.0752,  0.0721, -0.1087],\n",
      "          [-0.0664,  0.1070,  0.0600]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1078, -0.0985, -0.0785],\n",
      "          [ 0.0428, -0.0222, -0.1045],\n",
      "          [-0.1009, -0.0900, -0.0588]],\n",
      "\n",
      "         [[ 0.0508, -0.0773,  0.0361],\n",
      "          [ 0.0582, -0.1089,  0.1133],\n",
      "          [ 0.0926, -0.0273,  0.0611]],\n",
      "\n",
      "         [[ 0.0501, -0.0282,  0.0956],\n",
      "          [ 0.0752,  0.0743, -0.0127],\n",
      "          [ 0.0484,  0.0273,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[-0.0674, -0.0254,  0.0535],\n",
      "          [-0.0291,  0.0914, -0.0815],\n",
      "          [-0.1006,  0.0794, -0.0939]],\n",
      "\n",
      "         [[ 0.1072,  0.0983,  0.0033],\n",
      "          [ 0.0995,  0.0336,  0.0705],\n",
      "          [-0.0851, -0.0121, -0.1073]],\n",
      "\n",
      "         [[ 0.0823,  0.1116,  0.0432],\n",
      "          [ 0.0847,  0.0571,  0.0561],\n",
      "          [ 0.0845,  0.1007, -0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1028, -0.0511,  0.0339],\n",
      "          [-0.0309,  0.0465,  0.0748],\n",
      "          [ 0.0375,  0.0016,  0.0234]],\n",
      "\n",
      "         [[ 0.0200,  0.1162, -0.0746],\n",
      "          [ 0.0323,  0.0382, -0.0532],\n",
      "          [ 0.0018,  0.1120,  0.0635]],\n",
      "\n",
      "         [[-0.0559, -0.1024, -0.0014],\n",
      "          [-0.0612,  0.1089, -0.0595],\n",
      "          [ 0.0894, -0.0961,  0.0489]]],\n",
      "\n",
      "\n",
      "        [[[-0.0339, -0.0094,  0.0812],\n",
      "          [ 0.0574, -0.0567,  0.1112],\n",
      "          [ 0.0741, -0.0671, -0.0715]],\n",
      "\n",
      "         [[-0.0719,  0.0981,  0.0644],\n",
      "          [-0.0326, -0.0022, -0.0769],\n",
      "          [ 0.0494, -0.0056, -0.0676]],\n",
      "\n",
      "         [[ 0.0943, -0.0431, -0.0135],\n",
      "          [-0.0334, -0.1086, -0.0668],\n",
      "          [ 0.0871,  0.0335,  0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0783, -0.0962, -0.0887],\n",
      "          [ 0.0200, -0.1048,  0.1062],\n",
      "          [ 0.0985, -0.1136, -0.0910]],\n",
      "\n",
      "         [[-0.0103,  0.0190,  0.0287],\n",
      "          [ 0.0229,  0.0080, -0.0192],\n",
      "          [-0.0947,  0.1093,  0.0466]],\n",
      "\n",
      "         [[ 0.0701,  0.0776, -0.0818],\n",
      "          [-0.0544, -0.0652, -0.0046],\n",
      "          [ 0.0091,  0.1091, -0.0164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1108,  0.0437,  0.0885],\n",
      "          [ 0.0368,  0.0278, -0.1073],\n",
      "          [ 0.0280,  0.0425,  0.1060]],\n",
      "\n",
      "         [[ 0.0674, -0.0610,  0.0578],\n",
      "          [ 0.0383,  0.0874, -0.0150],\n",
      "          [ 0.0550,  0.0654,  0.0950]],\n",
      "\n",
      "         [[-0.0842, -0.0888, -0.0826],\n",
      "          [-0.0258, -0.0271,  0.0476],\n",
      "          [-0.0879,  0.0962, -0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161, -0.0774, -0.0436],\n",
      "          [ 0.0274,  0.0617, -0.0436],\n",
      "          [ 0.0645,  0.1001,  0.0709]],\n",
      "\n",
      "         [[-0.0332, -0.0703,  0.0374],\n",
      "          [ 0.0791,  0.0801,  0.1043],\n",
      "          [-0.0903,  0.0275, -0.0864]],\n",
      "\n",
      "         [[ 0.0198,  0.0705,  0.0244],\n",
      "          [ 0.0181, -0.0652,  0.0100],\n",
      "          [-0.0482,  0.0683, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.1143, -0.0299,  0.0207],\n",
      "          [ 0.0898,  0.0824,  0.0892],\n",
      "          [-0.0534,  0.0803,  0.0363]],\n",
      "\n",
      "         [[ 0.0663,  0.0086, -0.0991],\n",
      "          [ 0.0858,  0.0761,  0.0711],\n",
      "          [ 0.1016, -0.0749,  0.0748]],\n",
      "\n",
      "         [[ 0.0343,  0.0539, -0.1150],\n",
      "          [ 0.0733,  0.0621, -0.0680],\n",
      "          [ 0.0439,  0.0956, -0.0327]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0822, -0.1176, -0.0535],\n",
      "          [ 0.1119, -0.0932,  0.0493],\n",
      "          [-0.0484, -0.1010, -0.0124]],\n",
      "\n",
      "         [[ 0.0456,  0.0963, -0.0413],\n",
      "          [ 0.1107, -0.1017, -0.0885],\n",
      "          [-0.0423,  0.0104, -0.0072]],\n",
      "\n",
      "         [[ 0.0071,  0.0636, -0.0601],\n",
      "          [ 0.0475,  0.0615, -0.0321],\n",
      "          [ 0.1114,  0.0611,  0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0716,  0.0727, -0.0890],\n",
      "          [-0.0349, -0.0882, -0.1096],\n",
      "          [-0.0773,  0.0900, -0.0068]],\n",
      "\n",
      "         [[-0.0798,  0.0989, -0.1112],\n",
      "          [ 0.0889,  0.0375, -0.0443],\n",
      "          [-0.0928, -0.0475,  0.0469]],\n",
      "\n",
      "         [[-0.0055, -0.0073,  0.0975],\n",
      "          [-0.0471,  0.0789,  0.0345],\n",
      "          [-0.0696, -0.0959, -0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0008,  0.0041,  0.0502],\n",
      "          [ 0.0588,  0.0806,  0.0062],\n",
      "          [ 0.0587, -0.0384,  0.0294]],\n",
      "\n",
      "         [[ 0.0297,  0.0202,  0.1005],\n",
      "          [ 0.0867, -0.0717, -0.0795],\n",
      "          [-0.0349, -0.0062,  0.0557]],\n",
      "\n",
      "         [[ 0.0949,  0.1112, -0.0870],\n",
      "          [ 0.1066, -0.0233, -0.0375],\n",
      "          [-0.1044,  0.0916,  0.0663]]]], requires_grad=True)\n",
      "Reached\n",
      "Mask\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True]])\n",
      "Tensor\n",
      "Parameter containing:\n",
      "tensor([[-2.8795e-02, -2.2573e-02,  1.3991e-02,  2.0430e-02,  1.1819e-01,\n",
      "          1.1692e-01,  1.2147e-01,  9.5639e-03, -8.3923e-02,  1.3923e-02,\n",
      "         -1.1151e-01,  1.1233e-01, -4.5217e-02, -9.5822e-02,  1.1495e-01,\n",
      "          1.0942e-01, -2.0367e-02,  1.2415e-01,  7.6994e-02,  8.6115e-02,\n",
      "          6.0341e-02, -7.6021e-02,  3.8945e-02, -8.7525e-02, -8.8008e-02,\n",
      "         -1.0779e-01,  5.1936e-02,  3.8997e-02, -1.0901e-01, -1.2435e-01,\n",
      "          5.4153e-02, -3.3609e-02,  1.7459e-02, -5.3404e-02,  1.2800e-02,\n",
      "         -8.2249e-02,  1.1606e-01,  5.9796e-02,  2.1196e-02,  9.3116e-02,\n",
      "         -8.7785e-02,  9.3755e-02,  1.0039e-01,  4.1993e-02, -3.3545e-02,\n",
      "          7.8646e-02,  5.4443e-02, -3.8970e-02, -1.0430e-01,  8.5263e-03,\n",
      "         -2.5452e-02,  8.4323e-02, -1.0554e-01,  3.3927e-02,  4.5700e-02,\n",
      "         -7.4499e-02,  1.9439e-02, -4.4171e-02, -6.3155e-02, -9.7151e-02,\n",
      "          8.4275e-02,  6.3965e-02,  1.0162e-01, -6.6406e-02],\n",
      "        [-1.4952e-02,  6.4024e-02,  9.1461e-02, -5.0661e-02,  1.0589e-01,\n",
      "         -2.7298e-02,  6.2761e-02,  5.2542e-02,  4.9060e-02, -9.5782e-02,\n",
      "          7.0030e-03,  5.5767e-02, -7.0466e-02, -9.0439e-02,  2.8438e-02,\n",
      "         -4.8691e-02,  5.2405e-02, -1.0528e-01,  7.1523e-02,  6.4141e-02,\n",
      "          6.4039e-02, -7.6433e-02, -6.6487e-02, -4.4141e-02,  8.8393e-02,\n",
      "         -8.2018e-02, -1.0745e-01, -4.6423e-03,  9.4494e-02, -3.3140e-02,\n",
      "         -1.0566e-02,  1.2374e-01,  1.2493e-01,  5.5766e-02, -6.1162e-02,\n",
      "          8.2458e-02,  4.6842e-02, -2.6224e-02,  5.7545e-02,  8.9950e-02,\n",
      "         -6.8425e-02, -8.9023e-03, -4.7329e-02, -8.6904e-02,  6.4965e-02,\n",
      "          9.7322e-02,  1.0497e-02, -1.4934e-02,  2.6205e-02,  4.0909e-02,\n",
      "         -7.8219e-02,  2.4099e-02,  5.2508e-03, -2.2646e-02,  5.0036e-02,\n",
      "          2.1389e-03,  7.6325e-02,  3.1856e-02,  1.0736e-03, -9.4000e-02,\n",
      "         -9.8632e-03, -4.3213e-02,  1.2365e-01, -1.0895e-01],\n",
      "        [-5.9096e-02,  9.0406e-02,  2.7270e-02, -9.9658e-02, -4.3271e-02,\n",
      "          2.4611e-02, -1.0524e-01,  5.8882e-02,  9.0602e-02, -4.7332e-02,\n",
      "          4.9465e-02, -6.1459e-02, -1.2388e-01,  8.9581e-02,  6.8641e-02,\n",
      "         -1.2294e-01, -9.0106e-02,  1.2746e-03,  1.0185e-01, -1.1027e-02,\n",
      "         -6.9049e-02, -3.7524e-03,  1.2077e-01,  5.8443e-02, -1.8015e-03,\n",
      "          1.2022e-01,  4.5139e-02,  1.8998e-02, -4.2562e-02,  8.1744e-02,\n",
      "         -1.7213e-02, -3.3361e-02,  4.8648e-03, -1.8100e-02,  2.5474e-02,\n",
      "          3.7568e-02,  1.9062e-02,  1.3696e-02,  8.9122e-03,  6.8267e-02,\n",
      "          4.4633e-02, -9.4372e-03,  1.2204e-01,  9.7019e-02, -4.3299e-02,\n",
      "         -1.2494e-01, -5.0262e-02,  3.8921e-02,  7.0751e-02, -1.3734e-02,\n",
      "         -2.6946e-02,  1.1165e-01, -6.4191e-03,  1.2194e-01, -1.0239e-01,\n",
      "         -6.5486e-02, -1.0396e-01,  2.9457e-02, -5.4241e-02,  6.3224e-02,\n",
      "          1.1711e-01, -8.0725e-02, -1.1627e-02, -1.3741e-02],\n",
      "        [ 1.0149e-01,  4.0493e-02,  6.5083e-02,  5.7649e-02, -6.5466e-02,\n",
      "         -8.6148e-02, -4.0036e-02,  4.5085e-02,  3.5409e-02,  6.2983e-02,\n",
      "          3.9491e-02,  1.2355e-01, -6.2135e-02, -7.0426e-02,  7.6144e-02,\n",
      "         -8.8005e-02,  1.1255e-02,  2.8952e-02, -7.2352e-02,  1.1856e-01,\n",
      "          1.1411e-01, -1.1339e-01, -2.4995e-02,  2.4079e-02, -5.1122e-03,\n",
      "          1.6228e-02,  4.6184e-02,  4.8946e-02, -7.3140e-02,  1.2162e-01,\n",
      "          1.1963e-01, -2.3390e-02,  7.3519e-02, -1.8804e-02, -7.7355e-02,\n",
      "         -1.1010e-01,  1.2488e-01, -1.0254e-01,  2.1962e-02,  5.8237e-02,\n",
      "         -7.2457e-03,  4.1231e-02,  4.4185e-03, -1.2378e-01,  9.7255e-02,\n",
      "          7.1576e-02, -4.0911e-03, -5.6224e-02,  2.6134e-02, -1.1109e-01,\n",
      "         -2.9911e-02, -1.0149e-01,  1.1865e-01,  1.2458e-01, -3.1492e-03,\n",
      "          7.1064e-02, -3.6944e-02,  1.2079e-01,  7.4461e-02, -1.9323e-02,\n",
      "          9.8188e-02, -2.9794e-02,  1.1473e-01,  2.3497e-02],\n",
      "        [ 8.8360e-02,  3.4085e-02,  1.0830e-01, -2.2365e-02,  3.2506e-02,\n",
      "          1.2158e-02, -9.8459e-02,  2.3367e-02, -1.0618e-01, -3.0845e-02,\n",
      "         -1.7975e-03,  1.3163e-02, -1.1058e-01,  1.1356e-01,  8.5676e-03,\n",
      "         -3.9584e-02, -3.8692e-02,  9.9262e-02, -8.9216e-02, -3.6747e-02,\n",
      "          1.2036e-01, -6.7535e-02,  1.1250e-01,  3.4372e-02,  2.4689e-02,\n",
      "         -9.5375e-02, -1.0029e-01,  7.5316e-02,  1.1539e-02,  5.2656e-02,\n",
      "         -5.4259e-02,  1.2236e-01, -2.9759e-02, -1.2435e-01, -9.4015e-02,\n",
      "          7.1864e-02,  5.1828e-02, -7.6786e-05, -1.5573e-02, -6.1166e-02,\n",
      "          9.0314e-02,  7.2907e-02, -2.6129e-02, -4.7211e-02, -5.9974e-02,\n",
      "         -4.5797e-02,  8.2774e-02, -5.9000e-02,  5.6422e-02,  4.7560e-02,\n",
      "         -7.4830e-02, -4.0216e-02, -9.1867e-02, -1.5416e-02,  7.8083e-02,\n",
      "         -4.1542e-02,  6.4142e-02, -5.4337e-02,  1.0901e-01,  4.9692e-03,\n",
      "          4.9815e-02,  4.9689e-02,  5.0177e-02,  3.2074e-02],\n",
      "        [ 7.1593e-03,  8.6023e-02,  3.5670e-02, -2.1374e-03,  5.5175e-02,\n",
      "         -2.6731e-02, -2.6673e-02,  3.4383e-02,  6.2512e-02,  8.6046e-02,\n",
      "         -7.8034e-02, -2.0149e-02,  1.0724e-01, -9.8996e-02,  9.0045e-02,\n",
      "          1.1334e-01, -9.7700e-03,  7.8057e-02,  5.8602e-02, -6.2122e-02,\n",
      "         -6.9584e-02, -1.1103e-01, -8.3712e-03, -1.1647e-01, -3.2930e-02,\n",
      "         -3.7882e-03,  3.7130e-02,  6.1323e-02,  7.3872e-02,  1.0227e-01,\n",
      "         -1.1971e-01, -6.8224e-02,  6.0328e-02, -5.9144e-02,  8.5306e-02,\n",
      "         -5.9575e-02,  1.2882e-02, -3.4358e-02, -1.5689e-02, -9.3303e-02,\n",
      "          1.1690e-01,  6.8985e-02, -1.0289e-01, -3.1126e-02, -8.3317e-03,\n",
      "          7.3819e-02, -5.3189e-02,  7.8451e-02,  8.2772e-02,  7.4532e-02,\n",
      "         -7.2249e-02,  5.0445e-02, -9.2203e-02, -3.2746e-02, -7.5307e-02,\n",
      "          5.9146e-02, -1.1670e-01, -1.0347e-01, -7.7607e-02,  6.1218e-02,\n",
      "         -6.9080e-02, -1.9620e-02, -1.2095e-01,  5.1069e-02],\n",
      "        [-1.1265e-01, -1.2440e-01, -2.1309e-02,  2.5996e-02, -2.7872e-02,\n",
      "          1.2489e-01, -1.1632e-01,  9.1129e-03, -7.5444e-02, -1.1472e-01,\n",
      "          6.8527e-02, -7.9066e-02, -5.5541e-02,  1.0527e-02,  1.2858e-02,\n",
      "          1.0956e-01,  5.0118e-03, -6.8608e-02, -7.7325e-02, -4.6751e-02,\n",
      "          1.0032e-01, -1.8373e-03,  1.2170e-01,  1.1137e-01,  9.7893e-03,\n",
      "         -2.4682e-02,  8.5380e-02,  4.2485e-03,  7.6333e-02, -1.0772e-01,\n",
      "          7.2724e-02, -2.8854e-02, -2.0732e-04, -5.7280e-02,  3.3387e-02,\n",
      "         -3.4480e-02,  1.0427e-01,  2.4778e-02, -8.8337e-04,  7.4688e-02,\n",
      "         -1.2276e-01, -5.8891e-02,  6.5596e-03, -2.4169e-02, -9.6784e-02,\n",
      "          1.8783e-02, -1.1807e-01,  4.1273e-02,  3.0435e-02,  1.6675e-02,\n",
      "         -2.5853e-03,  7.0596e-02, -1.1811e-01,  6.5545e-02,  6.3089e-02,\n",
      "         -1.2200e-01, -4.2128e-02,  2.0266e-02,  1.1917e-02,  5.5410e-02,\n",
      "         -1.1850e-01, -2.7762e-02,  4.0063e-02, -6.3892e-03],\n",
      "        [ 8.6512e-02, -4.4207e-02, -8.8412e-02, -4.6021e-03, -1.0902e-01,\n",
      "         -2.9137e-02,  1.1387e-01,  3.0610e-03,  8.5655e-02, -6.7575e-02,\n",
      "          3.6638e-02,  6.7365e-02,  9.6171e-02, -1.1657e-01,  7.6008e-02,\n",
      "          1.7717e-02, -7.2963e-02, -2.5728e-02, -8.3898e-02, -1.1915e-01,\n",
      "          7.8728e-03,  8.3563e-02, -3.5542e-02, -5.8265e-02,  1.7798e-04,\n",
      "          4.2507e-03,  6.4458e-02,  6.0668e-02, -1.2142e-01,  1.3789e-02,\n",
      "         -8.4741e-02, -9.1037e-02, -1.2193e-01, -7.7559e-02,  1.2466e-03,\n",
      "         -6.1099e-02,  1.2323e-02, -1.1432e-01,  7.6727e-02, -4.7729e-02,\n",
      "          4.1339e-02, -1.1351e-01, -6.5004e-02,  4.5968e-02,  1.2239e-02,\n",
      "          1.2633e-02,  5.3487e-02, -1.0512e-01,  6.5261e-04,  4.3317e-02,\n",
      "          1.0495e-01, -3.7885e-02, -4.4484e-02, -4.3106e-02,  1.2386e-01,\n",
      "         -5.6415e-02, -1.6410e-02, -3.3650e-02,  4.8381e-03,  1.1736e-01,\n",
      "         -3.7628e-03,  2.6272e-02, -5.8922e-02, -1.1933e-01],\n",
      "        [-5.0661e-02, -4.7558e-02, -7.4874e-02,  2.8085e-03,  2.1130e-02,\n",
      "          3.3459e-02, -9.0123e-02,  9.4546e-02,  9.3282e-02,  8.8094e-02,\n",
      "         -9.9304e-02, -7.6031e-02,  1.1074e-01, -2.7546e-03, -2.1387e-02,\n",
      "         -9.4563e-02,  1.2078e-02,  4.6511e-02, -1.0801e-02,  2.6855e-02,\n",
      "         -4.0597e-02,  8.3578e-02, -8.2591e-04, -5.2960e-02, -5.9866e-02,\n",
      "         -1.9702e-02,  5.8392e-02, -7.5661e-02,  2.8587e-02, -6.9314e-02,\n",
      "         -1.0855e-01,  6.9535e-02, -7.7688e-02, -1.1016e-01, -8.1111e-02,\n",
      "          1.1725e-01, -1.0582e-01, -1.0376e-01,  7.0284e-02, -5.3246e-02,\n",
      "          6.7161e-02,  4.4224e-02,  1.0759e-01, -2.1990e-02, -1.2110e-01,\n",
      "         -1.0802e-01, -7.8824e-02,  3.4742e-02,  2.7426e-04,  9.5223e-02,\n",
      "          1.0873e-01,  8.8262e-02,  8.1014e-02, -1.1657e-01, -1.0721e-01,\n",
      "         -7.4696e-02,  1.0057e-02,  8.6590e-02,  7.7870e-02,  4.8819e-02,\n",
      "         -9.8435e-02, -3.2347e-02,  3.2442e-02,  9.1571e-02],\n",
      "        [-1.1203e-01, -2.5193e-02,  7.5642e-02, -6.0626e-02,  5.4579e-02,\n",
      "          1.4915e-02, -3.2161e-03, -1.6375e-02, -1.1724e-01,  1.3762e-02,\n",
      "         -1.2060e-01,  8.3200e-02,  1.2117e-01, -1.7899e-02, -7.6822e-02,\n",
      "         -3.9369e-02,  8.7880e-03,  1.1317e-01, -8.6554e-02, -6.2620e-02,\n",
      "          1.0736e-01, -5.2994e-02,  1.0251e-01,  1.0375e-01, -9.5814e-02,\n",
      "         -5.8796e-03,  9.9064e-02, -1.0896e-01, -8.0973e-02, -6.7111e-02,\n",
      "          1.2045e-01, -8.3496e-02,  3.3379e-02,  1.0400e-02,  9.2393e-02,\n",
      "          9.3417e-02,  6.0682e-03,  5.7256e-02,  9.8608e-02,  1.1502e-01,\n",
      "         -7.3001e-02,  7.1948e-02, -5.9099e-02,  5.9832e-02, -5.8955e-02,\n",
      "          8.1563e-02,  3.4793e-02,  1.1310e-01,  5.3684e-02,  1.7758e-02,\n",
      "          1.1336e-01,  1.0070e-01,  5.0223e-02,  1.0143e-01, -2.0465e-02,\n",
      "         -1.2261e-01,  2.8167e-02, -8.1115e-02,  1.1299e-01, -1.7430e-02,\n",
      "         -8.6500e-02, -9.5841e-02, -4.5259e-02,  8.4332e-02]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"channel\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block_3_0\n",
      "Parameter containing:\n",
      "tensor([[[-0.1409, -0.0761, -0.0573],\n",
      "         [ 0.0117,  0.0768,  0.0178],\n",
      "         [-0.1305,  0.0202, -0.0235],\n",
      "         ...,\n",
      "         [ 0.0556,  0.1262, -0.0789],\n",
      "         [ 0.0327, -0.1376, -0.0521],\n",
      "         [-0.0638,  0.0398, -0.0657]],\n",
      "\n",
      "        [[-0.0781, -0.0895,  0.0452],\n",
      "         [-0.1205,  0.0272, -0.0688],\n",
      "         [-0.1330,  0.1047,  0.1162],\n",
      "         ...,\n",
      "         [-0.0790,  0.0293, -0.1086],\n",
      "         [ 0.0287, -0.0769,  0.0658],\n",
      "         [-0.1197,  0.0678, -0.0213]],\n",
      "\n",
      "        [[ 0.0731, -0.1045, -0.0855],\n",
      "         [ 0.0911, -0.0642,  0.0982],\n",
      "         [-0.1269,  0.0221,  0.1263],\n",
      "         ...,\n",
      "         [-0.0627, -0.0403, -0.0903],\n",
      "         [ 0.0504, -0.0632,  0.0472],\n",
      "         [-0.1148, -0.0394,  0.0852]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0984, -0.0615, -0.1379],\n",
      "         [-0.0083,  0.0268, -0.1374],\n",
      "         [ 0.0584,  0.1286,  0.0790],\n",
      "         ...,\n",
      "         [-0.0658,  0.1130,  0.0417],\n",
      "         [-0.0559,  0.1345,  0.1233],\n",
      "         [ 0.1255,  0.0110, -0.0715]],\n",
      "\n",
      "        [[-0.1062, -0.1011,  0.0615],\n",
      "         [-0.0565,  0.1179, -0.1246],\n",
      "         [ 0.1149,  0.0417,  0.0974],\n",
      "         ...,\n",
      "         [ 0.0192,  0.1248,  0.0889],\n",
      "         [ 0.0330, -0.0290,  0.0897],\n",
      "         [ 0.0069,  0.1153, -0.0025]],\n",
      "\n",
      "        [[-0.0461,  0.0618, -0.0512],\n",
      "         [ 0.1222, -0.1377,  0.0637],\n",
      "         [ 0.0154,  0.0501,  0.0517],\n",
      "         ...,\n",
      "         [-0.1282,  0.0495,  0.0808],\n",
      "         [-0.1401,  0.0346,  0.0249],\n",
      "         [-0.0522, -0.0689, -0.1250]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[-0.1409, -0.0761, -0.0573],\n",
      "         [ 0.0117,  0.0768,  0.0178],\n",
      "         [-0.1305,  0.0202, -0.0235],\n",
      "         ...,\n",
      "         [ 0.0556,  0.1262, -0.0789],\n",
      "         [ 0.0327, -0.1376, -0.0521],\n",
      "         [-0.0638,  0.0398, -0.0657]],\n",
      "\n",
      "        [[-0.0781, -0.0895,  0.0452],\n",
      "         [-0.1205,  0.0272, -0.0688],\n",
      "         [-0.1330,  0.1047,  0.1162],\n",
      "         ...,\n",
      "         [-0.0790,  0.0293, -0.1086],\n",
      "         [ 0.0287, -0.0769,  0.0658],\n",
      "         [-0.1197,  0.0678, -0.0213]],\n",
      "\n",
      "        [[ 0.0731, -0.1045, -0.0855],\n",
      "         [ 0.0911, -0.0642,  0.0982],\n",
      "         [-0.1269,  0.0221,  0.1263],\n",
      "         ...,\n",
      "         [-0.0627, -0.0403, -0.0903],\n",
      "         [ 0.0504, -0.0632,  0.0472],\n",
      "         [-0.1148, -0.0394,  0.0852]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0984, -0.0615, -0.1379],\n",
      "         [-0.0083,  0.0268, -0.1374],\n",
      "         [ 0.0584,  0.1286,  0.0790],\n",
      "         ...,\n",
      "         [-0.0658,  0.1130,  0.0417],\n",
      "         [-0.0559,  0.1345,  0.1233],\n",
      "         [ 0.1255,  0.0110, -0.0715]],\n",
      "\n",
      "        [[-0.1062, -0.1011,  0.0615],\n",
      "         [-0.0565,  0.1179, -0.1246],\n",
      "         [ 0.1149,  0.0417,  0.0974],\n",
      "         ...,\n",
      "         [ 0.0192,  0.1248,  0.0889],\n",
      "         [ 0.0330, -0.0290,  0.0897],\n",
      "         [ 0.0069,  0.1153, -0.0025]],\n",
      "\n",
      "        [[-0.0461,  0.0618, -0.0512],\n",
      "         [ 0.1222, -0.1377,  0.0637],\n",
      "         [ 0.0154,  0.0501,  0.0517],\n",
      "         ...,\n",
      "         [-0.1282,  0.0495,  0.0808],\n",
      "         [-0.1401,  0.0346,  0.0249],\n",
      "         [-0.0522, -0.0689, -0.1250]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.1049,  0.1385, -0.0758, -0.0294, -0.0389,  0.1069, -0.0040,  0.0159,\n",
      "        -0.0589, -0.1264,  0.0667,  0.0964, -0.0228, -0.0181, -0.0002, -0.0801,\n",
      "         0.1289, -0.0789, -0.1206, -0.0538, -0.1124, -0.1276, -0.1400,  0.1021,\n",
      "        -0.0246, -0.0867, -0.0950,  0.1128,  0.0538,  0.0629, -0.0601,  0.0764]))])\n",
      "Pruned percent: -1.0\n",
      "--------------------------------------------------\n",
      "Layer: block_4_0\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0759,  0.0188, -0.0441],\n",
      "         [-0.0122,  0.0823, -0.0373],\n",
      "         [-0.0532, -0.0628,  0.0593],\n",
      "         ...,\n",
      "         [ 0.1004, -0.0447,  0.0147],\n",
      "         [-0.0120,  0.0925,  0.0844],\n",
      "         [ 0.0743, -0.0749, -0.0459]],\n",
      "\n",
      "        [[ 0.0688, -0.0515, -0.0109],\n",
      "         [ 0.0488,  0.0773, -0.0397],\n",
      "         [ 0.1006, -0.0106, -0.0919],\n",
      "         ...,\n",
      "         [ 0.0504,  0.0629, -0.0726],\n",
      "         [-0.0321, -0.0714,  0.0304],\n",
      "         [-0.0805,  0.0023, -0.0410]],\n",
      "\n",
      "        [[-0.0939,  0.1017, -0.0362],\n",
      "         [-0.0965,  0.0964,  0.0927],\n",
      "         [-0.0341, -0.0345,  0.0932],\n",
      "         ...,\n",
      "         [-0.0212, -0.0560, -0.0657],\n",
      "         [-0.0873, -0.0557,  0.0357],\n",
      "         [-0.0155,  0.0060, -0.0890]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0837, -0.0666, -0.0180],\n",
      "         [ 0.0886, -0.0823,  0.0238],\n",
      "         [-0.0485,  0.0338,  0.0988],\n",
      "         ...,\n",
      "         [ 0.0353,  0.0131,  0.0144],\n",
      "         [ 0.0867, -0.0394,  0.0691],\n",
      "         [-0.0602, -0.0674, -0.0038]],\n",
      "\n",
      "        [[-0.0454,  0.0712,  0.0190],\n",
      "         [-0.0738, -0.0835,  0.0778],\n",
      "         [-0.0526,  0.0491, -0.0506],\n",
      "         ...,\n",
      "         [ 0.0853, -0.0609,  0.0728],\n",
      "         [-0.1014, -0.0359, -0.0983],\n",
      "         [-0.0127,  0.0021, -0.0442]],\n",
      "\n",
      "        [[ 0.0158,  0.0400, -0.0981],\n",
      "         [-0.0130,  0.0185, -0.0801],\n",
      "         [-0.0842, -0.0649, -0.0365],\n",
      "         ...,\n",
      "         [-0.0614,  0.0979,  0.0929],\n",
      "         [ 0.0375,  0.0991, -0.0384],\n",
      "         [ 0.0047, -0.0965,  0.0027]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[ 0.0759,  0.0188, -0.0441],\n",
      "         [-0.0122,  0.0823, -0.0373],\n",
      "         [-0.0532, -0.0628,  0.0593],\n",
      "         ...,\n",
      "         [ 0.1004, -0.0447,  0.0147],\n",
      "         [-0.0120,  0.0925,  0.0844],\n",
      "         [ 0.0743, -0.0749, -0.0459]],\n",
      "\n",
      "        [[ 0.0688, -0.0515, -0.0109],\n",
      "         [ 0.0488,  0.0773, -0.0397],\n",
      "         [ 0.1006, -0.0106, -0.0919],\n",
      "         ...,\n",
      "         [ 0.0504,  0.0629, -0.0726],\n",
      "         [-0.0321, -0.0714,  0.0304],\n",
      "         [-0.0805,  0.0023, -0.0410]],\n",
      "\n",
      "        [[-0.0939,  0.1017, -0.0362],\n",
      "         [-0.0965,  0.0964,  0.0927],\n",
      "         [-0.0341, -0.0345,  0.0932],\n",
      "         ...,\n",
      "         [-0.0212, -0.0560, -0.0657],\n",
      "         [-0.0873, -0.0557,  0.0357],\n",
      "         [-0.0155,  0.0060, -0.0890]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0837, -0.0666, -0.0180],\n",
      "         [ 0.0886, -0.0823,  0.0238],\n",
      "         [-0.0485,  0.0338,  0.0988],\n",
      "         ...,\n",
      "         [ 0.0353,  0.0131,  0.0144],\n",
      "         [ 0.0867, -0.0394,  0.0691],\n",
      "         [-0.0602, -0.0674, -0.0038]],\n",
      "\n",
      "        [[-0.0454,  0.0712,  0.0190],\n",
      "         [-0.0738, -0.0835,  0.0778],\n",
      "         [-0.0526,  0.0491, -0.0506],\n",
      "         ...,\n",
      "         [ 0.0853, -0.0609,  0.0728],\n",
      "         [-0.1014, -0.0359, -0.0983],\n",
      "         [-0.0127,  0.0021, -0.0442]],\n",
      "\n",
      "        [[ 0.0158,  0.0400, -0.0981],\n",
      "         [-0.0130,  0.0185, -0.0801],\n",
      "         [-0.0842, -0.0649, -0.0365],\n",
      "         ...,\n",
      "         [-0.0614,  0.0979,  0.0929],\n",
      "         [ 0.0375,  0.0991, -0.0384],\n",
      "         [ 0.0047, -0.0965,  0.0027]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.0942,  0.0828, -0.0789,  0.0115,  0.0304,  0.0215, -0.0437,  0.0213,\n",
      "         0.0096, -0.0733, -0.0952,  0.0427, -0.0512,  0.0370, -0.0224, -0.0859,\n",
      "        -0.0712, -0.0806, -0.0624, -0.0398, -0.0390, -0.0203,  0.0458, -0.0848,\n",
      "        -0.0607,  0.0211, -0.0932, -0.0667, -0.0048,  0.0427,  0.0827, -0.0928,\n",
      "        -0.0429, -0.0079, -0.0891,  0.0082, -0.0339,  0.0117,  0.0510,  0.0417,\n",
      "        -0.0981,  0.0570, -0.0167, -0.0802,  0.0429,  0.0767,  0.0628,  0.0437,\n",
      "         0.0931, -0.0377, -0.0576,  0.0607, -0.0452, -0.0889, -0.0527,  0.0366,\n",
      "        -0.0408,  0.0253,  0.0909, -0.0816, -0.0775, -0.0595, -0.0238, -0.0489]))])\n",
      "Pruned percent: -1.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv1d':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        pprint(mg.modules[node.target].state_dict())\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        w = mg.modules[node.target].weight\n",
    "        for s in w:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "# for node in mg.fx_graph.nodes:\n",
    "#     if get_mase_op(node) == 'linear':\n",
    "#         print(f\"Layer: {node.name}\")\n",
    "#         # pprint(node.meta['mase'].parameters['common'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "#         pprint(mg.modules[node.target].weight)\n",
    "#         # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "#         # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "#         total_w = 0\n",
    "#         pruned_w = 0\n",
    "#         mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "#         for s in mask_2:\n",
    "#             total_w += s.numel()\n",
    "#             pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "#         pruned_percent = pruned_w / total_w\n",
    "#         print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "#         print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "# for node in mg.fx_graph.nodes:\n",
    "#     if get_mase_op(node) == 'linear':\n",
    "#         print(node.name)\n",
    "#         print(50*'-')\n",
    "#         # pprint(node.meta['mase'].parameters['common'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "#         pprint(mg.modules[node.target].weight)\n",
    "#         pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "#         # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "#         print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
