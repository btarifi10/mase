{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model_name = \"toy_convnet\"\n",
    "dataset_name = \"Cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "{'': GraphModule(\n",
      "  (block_1): Module(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (block_2): Module(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (block_3): Module(\n",
      "    (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (block_4): Module(\n",
      "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      "), 'block_1': Module(\n",
      "  (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "), 'block_1.0': Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), 'block_1.1': ReLU(), 'maxpool': MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 'block_2': Module(\n",
      "  (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "), 'block_2.0': Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), 'block_2.1': ReLU(), 'block_3': Module(\n",
      "  (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (1): ReLU()\n",
      "), 'block_3.0': Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,)), 'block_3.1': ReLU(), 'block_4': Module(\n",
      "  (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (1): ReLU()\n",
      "), 'block_4.0': Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,)), 'block_4.1': ReLU(), 'avgpool': AdaptiveAvgPool1d(output_size=1), 'linear': Linear(in_features=64, out_features=10, bias=True)}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'conv2d':\n",
    "    if node.op == \"call_module\":\n",
    "        #print(node.name)\n",
    "        #print(50*'-')\n",
    "        #print(node.target)\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].state_dict())\n",
    "        #pprint(mg.mo)\n",
    "        print(50*'-')\n",
    "print(mg.modules)\n",
    "#print(type(mg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     prune_transform_pass,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m pass_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscope\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     },\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprune_transform_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/pruning/prune.py:192\u001b[0m, in \u001b[0;36mprune_transform_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprune_transform_pass\u001b[39m(graph, pass_args: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {}):\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Apply pruning transformation to the given graph.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    This is achieved by adding a register_parametrization hook to weights\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    :rtype: tuple\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mprune_graph_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, {}\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/pruning/prune.py:139\u001b[0m, in \u001b[0;36mprune_graph_iterator\u001b[0;34m(graph, config)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprune_graph_iterator\u001b[39m(graph, config: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Setup all pruning-related parameters (incl. basic validation)\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     w_config \u001b[38;5;241m=\u001b[39m load_weight_prune_config(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, graph)\n\u001b[1;32m    140\u001b[0m     a_config \u001b[38;5;241m=\u001b[39m load_activation_prune_config(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m], graph)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# we need to loop twice, the first time is to fetch all necessary information\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# first sloop\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight'"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    "    activation_pruning_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block_1.0.bias', tensor([-0.0150,  0.1194, -0.0869,  0.1154, -0.1577, -0.0850,  0.0252,  0.1689])), ('block_1.0.parametrizations.weight.original', tensor([[[[ 0.0482, -0.1878,  0.1399],\n",
      "          [-0.0447, -0.1207,  0.0728],\n",
      "          [ 0.1810,  0.1505, -0.0590]],\n",
      "\n",
      "         [[ 0.0790,  0.0771,  0.1427],\n",
      "          [-0.0824,  0.0353,  0.0553],\n",
      "          [ 0.1773, -0.0354, -0.0334]],\n",
      "\n",
      "         [[ 0.0501,  0.1248,  0.1277],\n",
      "          [ 0.0594,  0.0126, -0.0937],\n",
      "          [ 0.1721,  0.0603,  0.1783]]],\n",
      "\n",
      "\n",
      "        [[[-0.1910,  0.0375, -0.1549],\n",
      "          [-0.1783,  0.1765, -0.1179],\n",
      "          [-0.1074,  0.0089, -0.0264]],\n",
      "\n",
      "         [[ 0.0115, -0.1628,  0.0479],\n",
      "          [ 0.1017,  0.1554,  0.1056],\n",
      "          [ 0.0324, -0.0862, -0.0767]],\n",
      "\n",
      "         [[ 0.0320, -0.1785,  0.0332],\n",
      "          [-0.1306,  0.0354,  0.1682],\n",
      "          [-0.0375,  0.0699,  0.1177]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0533,  0.0707, -0.1811],\n",
      "          [ 0.0834,  0.0610, -0.0461],\n",
      "          [ 0.0318, -0.0468, -0.0558]],\n",
      "\n",
      "         [[-0.1492, -0.1507, -0.1335],\n",
      "          [ 0.1556, -0.1650,  0.0681],\n",
      "          [-0.1720, -0.0592,  0.1443]],\n",
      "\n",
      "         [[ 0.1144,  0.0282,  0.0255],\n",
      "          [ 0.0072, -0.1592,  0.1490],\n",
      "          [-0.0806, -0.0816,  0.1889]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1372, -0.0015,  0.1747],\n",
      "          [ 0.1662,  0.1222,  0.1376],\n",
      "          [ 0.0438, -0.1225, -0.0558]],\n",
      "\n",
      "         [[ 0.0859,  0.1583, -0.0952],\n",
      "          [ 0.0552, -0.0827, -0.1789],\n",
      "          [-0.0847, -0.0393,  0.0409]],\n",
      "\n",
      "         [[ 0.0853, -0.0500, -0.0621],\n",
      "          [-0.0242, -0.0368, -0.0848],\n",
      "          [-0.0821, -0.1868, -0.1163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1098, -0.0516, -0.0927],\n",
      "          [-0.1351,  0.1254, -0.1793],\n",
      "          [-0.1417,  0.1095, -0.1807]],\n",
      "\n",
      "         [[ 0.1692,  0.0284, -0.1439],\n",
      "          [-0.1344, -0.0125, -0.1628],\n",
      "          [ 0.1394,  0.1148,  0.0548]],\n",
      "\n",
      "         [[ 0.1052, -0.1389, -0.0091],\n",
      "          [ 0.0414,  0.1159,  0.0400],\n",
      "          [ 0.1353, -0.1280, -0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.1091,  0.1622, -0.0223],\n",
      "          [-0.0250,  0.1361, -0.0692],\n",
      "          [ 0.0560,  0.1055, -0.1218]],\n",
      "\n",
      "         [[ 0.1718,  0.0455,  0.1047],\n",
      "          [ 0.0265, -0.1897,  0.0900],\n",
      "          [-0.0968, -0.0677,  0.0797]],\n",
      "\n",
      "         [[ 0.1742,  0.1691, -0.1905],\n",
      "          [ 0.0279, -0.1319,  0.1491],\n",
      "          [ 0.0227,  0.1762, -0.0797]]],\n",
      "\n",
      "\n",
      "        [[[-0.1599,  0.0872,  0.0988],\n",
      "          [-0.1566,  0.1369,  0.1657],\n",
      "          [-0.1378,  0.1902,  0.0396]],\n",
      "\n",
      "         [[-0.1657,  0.0108,  0.0075],\n",
      "          [ 0.1565, -0.1112, -0.1592],\n",
      "          [-0.0101, -0.0271, -0.0948]],\n",
      "\n",
      "         [[-0.0766,  0.0704,  0.0535],\n",
      "          [-0.0574,  0.0132,  0.0885],\n",
      "          [ 0.1017, -0.1076,  0.1387]]],\n",
      "\n",
      "\n",
      "        [[[-0.0366, -0.1487,  0.1734],\n",
      "          [-0.0564,  0.1104, -0.0360],\n",
      "          [-0.0056,  0.1768,  0.1271]],\n",
      "\n",
      "         [[ 0.0180, -0.0707,  0.1378],\n",
      "          [-0.0553,  0.0366, -0.0708],\n",
      "          [ 0.0396, -0.0658,  0.0549]],\n",
      "\n",
      "         [[ 0.0755, -0.1423, -0.1889],\n",
      "          [ 0.1051, -0.1273,  0.0122],\n",
      "          [ 0.0670, -0.1653, -0.0353]]]])), ('block_1.0.parametrizations.weight.0.mask', tensor([[[[False,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False]]]])), ('block_2.0.bias', tensor([-0.0873,  0.0853, -0.0529, -0.0211, -0.0257, -0.0613,  0.0628,  0.1111,\n",
      "        -0.0658,  0.0443,  0.0983,  0.0057,  0.0704,  0.0325,  0.0384,  0.0273])), ('block_2.0.parametrizations.weight.original', tensor([[[[-7.3164e-02, -3.5792e-02,  6.2530e-02],\n",
      "          [ 1.1180e-01,  5.5126e-03, -5.2311e-02],\n",
      "          [-8.7217e-03,  5.5034e-02, -1.0775e-02]],\n",
      "\n",
      "         [[ 1.7260e-02,  8.1440e-03, -6.2507e-02],\n",
      "          [-3.9982e-02,  7.2046e-02,  1.5615e-02],\n",
      "          [ 5.0020e-02,  1.8362e-02, -1.0248e-01]],\n",
      "\n",
      "         [[ 1.0516e-01, -1.1496e-03,  5.7527e-02],\n",
      "          [ 1.0161e-01, -2.6610e-02,  9.2292e-02],\n",
      "          [ 4.8030e-02,  6.9393e-02, -3.9050e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7844e-02,  2.9254e-02, -6.9710e-02],\n",
      "          [ 8.0607e-02, -9.5377e-02, -5.3852e-04],\n",
      "          [-1.0632e-01, -5.5983e-02,  1.1649e-01]],\n",
      "\n",
      "         [[ 4.9026e-02,  1.1381e-01, -1.0847e-01],\n",
      "          [-8.7854e-03,  1.0446e-01, -2.9343e-02],\n",
      "          [-3.7824e-02,  7.4768e-02, -7.8245e-02]],\n",
      "\n",
      "         [[-4.7404e-02,  1.9228e-02,  9.2781e-02],\n",
      "          [-1.0608e-01, -5.5542e-02,  1.0501e-01],\n",
      "          [ 2.5595e-02, -4.7634e-02, -7.3433e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8188e-03,  8.8838e-02,  3.5333e-02],\n",
      "          [ 5.4889e-02, -3.7048e-02,  8.7602e-02],\n",
      "          [-4.0893e-02,  5.1910e-02, -9.7804e-02]],\n",
      "\n",
      "         [[-4.4325e-02,  1.9604e-03, -1.7291e-03],\n",
      "          [ 1.0679e-01,  5.5831e-02, -9.7520e-02],\n",
      "          [ 9.3985e-02, -5.7197e-03, -9.9021e-03]],\n",
      "\n",
      "         [[-4.4307e-02, -9.1681e-02,  9.0561e-02],\n",
      "          [-6.1748e-02,  2.8704e-02,  2.5783e-02],\n",
      "          [ 8.0566e-02, -5.0144e-02,  1.0203e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2944e-02,  5.8891e-02, -7.5695e-02],\n",
      "          [-4.5107e-02,  5.5784e-02, -7.3049e-02],\n",
      "          [-3.2986e-02,  5.8733e-02, -9.1544e-02]],\n",
      "\n",
      "         [[ 5.2507e-03, -8.3595e-02,  1.0369e-01],\n",
      "          [ 9.9381e-02,  1.1036e-01, -6.2576e-02],\n",
      "          [-6.4921e-02,  2.6826e-02,  5.7940e-02]],\n",
      "\n",
      "         [[ 1.0781e-01, -1.0896e-01,  7.5756e-02],\n",
      "          [ 2.3827e-02,  7.7318e-02, -1.1537e-01],\n",
      "          [ 4.6751e-02,  1.1054e-02, -5.6416e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6792e-02,  1.1156e-01, -7.6322e-02],\n",
      "          [ 2.2198e-02,  3.4144e-02, -1.5733e-02],\n",
      "          [-1.0491e-02,  8.8053e-02, -6.2106e-02]],\n",
      "\n",
      "         [[-4.3911e-02, -6.2618e-04, -1.1040e-01],\n",
      "          [-4.3996e-02,  6.1727e-02, -3.7053e-02],\n",
      "          [-6.4065e-02,  1.1613e-02, -7.9569e-02]],\n",
      "\n",
      "         [[ 4.3577e-02, -7.9689e-02, -7.5668e-02],\n",
      "          [ 1.1068e-01, -3.1105e-03,  1.1086e-01],\n",
      "          [ 2.3632e-02,  2.5888e-02, -1.1741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8868e-02,  1.0238e-02, -4.1204e-02],\n",
      "          [ 1.0477e-01, -1.4142e-02, -7.8157e-02],\n",
      "          [-3.7035e-02, -1.8862e-02, -2.2064e-02]],\n",
      "\n",
      "         [[-6.4384e-04,  2.4001e-02, -3.0005e-02],\n",
      "          [-2.6286e-02, -5.1973e-02,  1.0618e-02],\n",
      "          [ 9.2148e-02,  3.5244e-02, -8.3853e-02]],\n",
      "\n",
      "         [[-2.8725e-02,  1.1052e-01,  2.8106e-02],\n",
      "          [ 8.5162e-02, -7.8291e-02, -7.2436e-02],\n",
      "          [ 2.2685e-03,  4.7023e-02,  4.9981e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1337e-01,  6.2873e-02, -5.1491e-02],\n",
      "          [-2.6755e-02, -1.0510e-02,  6.0088e-02],\n",
      "          [ 4.0170e-02,  7.1250e-02,  9.6053e-02]],\n",
      "\n",
      "         [[-5.1337e-02, -1.9477e-02,  9.2799e-02],\n",
      "          [-6.3104e-02, -1.1582e-01, -8.1200e-02],\n",
      "          [ 6.2329e-02, -1.0168e-01, -1.1237e-01]],\n",
      "\n",
      "         [[-3.8252e-02, -1.0675e-01,  9.7299e-03],\n",
      "          [-7.7501e-02,  1.0701e-01,  3.6289e-03],\n",
      "          [-4.1225e-02, -3.6578e-02,  7.1382e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5911e-02,  2.4986e-02, -5.7031e-02],\n",
      "          [-5.5507e-03, -6.9505e-02, -3.0977e-02],\n",
      "          [ 2.9424e-02, -6.8944e-02,  7.1138e-02]],\n",
      "\n",
      "         [[ 6.1547e-02, -1.1177e-01,  8.5836e-02],\n",
      "          [-2.2554e-02,  6.2181e-02,  9.5262e-03],\n",
      "          [-4.3724e-02,  8.1902e-02,  2.7412e-02]],\n",
      "\n",
      "         [[ 2.9208e-02, -7.7896e-02, -7.6193e-02],\n",
      "          [-7.6798e-02, -9.8470e-02,  1.0433e-01],\n",
      "          [ 1.1376e-01,  1.0434e-02, -3.0982e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1364e-02,  3.6460e-02,  1.9660e-04],\n",
      "          [-4.5688e-02,  3.5868e-02, -4.4238e-02],\n",
      "          [ 8.3863e-02, -8.7230e-02, -7.4176e-02]],\n",
      "\n",
      "         [[ 6.6078e-02, -8.1642e-02, -2.4147e-02],\n",
      "          [ 5.9180e-02, -9.1912e-02, -1.0531e-01],\n",
      "          [ 4.2441e-02, -1.0209e-01,  4.9050e-02]],\n",
      "\n",
      "         [[ 4.1745e-02,  1.0967e-01, -8.3971e-02],\n",
      "          [ 6.1120e-02, -3.6559e-02,  1.0551e-01],\n",
      "          [-1.0333e-01, -8.0555e-02, -9.2520e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0039e-01,  7.8183e-02, -5.6101e-02],\n",
      "          [-1.7231e-02, -1.5447e-02,  1.5240e-02],\n",
      "          [ 8.7997e-02,  5.9031e-02, -2.4858e-02]],\n",
      "\n",
      "         [[ 8.8515e-02, -1.1368e-01, -3.9590e-03],\n",
      "          [ 9.2562e-02,  7.9570e-02,  1.1721e-01],\n",
      "          [-6.7500e-02, -8.9282e-02,  6.9140e-02]],\n",
      "\n",
      "         [[ 8.9193e-03,  8.9558e-03,  2.9366e-02],\n",
      "          [ 2.0069e-02, -9.8191e-02, -6.7588e-02],\n",
      "          [-9.3216e-02, -4.3536e-03, -8.8818e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9310e-02,  8.2291e-02,  1.4515e-02],\n",
      "          [-4.8546e-02,  7.9303e-02,  7.4954e-02],\n",
      "          [ 4.5168e-02,  7.3695e-02, -8.1811e-02]],\n",
      "\n",
      "         [[ 9.3572e-03, -4.9404e-02,  1.1674e-01],\n",
      "          [-1.1648e-01,  6.6193e-02,  3.9933e-02],\n",
      "          [-8.3907e-02, -3.0829e-02, -2.4208e-02]],\n",
      "\n",
      "         [[ 6.6340e-02, -1.1352e-01,  7.6282e-02],\n",
      "          [-4.6117e-02,  4.7454e-02,  7.3671e-02],\n",
      "          [ 6.2023e-02,  7.4238e-02, -4.9420e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8108e-02,  3.1631e-02, -5.1316e-02],\n",
      "          [ 3.2496e-02,  7.1109e-03, -6.3822e-02],\n",
      "          [-6.8870e-02,  1.1360e-01, -1.6819e-02]],\n",
      "\n",
      "         [[-2.6419e-02,  3.1337e-03,  7.5734e-02],\n",
      "          [ 8.4328e-02,  2.4305e-05,  2.7967e-02],\n",
      "          [ 7.5876e-02,  6.8452e-03,  8.6770e-02]],\n",
      "\n",
      "         [[-2.5564e-02, -6.2881e-02,  5.4439e-02],\n",
      "          [-4.3468e-02, -4.4770e-02,  1.1253e-01],\n",
      "          [ 6.7794e-02, -4.6720e-02,  5.8572e-02]]]])), ('block_2.0.parametrizations.weight.0.mask', tensor([[[[ True, False,  True],\n",
      "          [ True, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [False, False, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True, False,  True],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [False, False,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False,  True,  True],\n",
      "          [ True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [ True, False,  True]]]])), ('block_3.0.bias', tensor([-0.0632,  0.0645, -0.0901, -0.0578, -0.0520,  0.0589, -0.1231,  0.0708,\n",
      "        -0.0869, -0.0087, -0.0029,  0.1425, -0.0953, -0.0415, -0.0927, -0.0512,\n",
      "         0.0057, -0.0287,  0.1319, -0.0534,  0.1061,  0.0093,  0.0650,  0.0640,\n",
      "         0.0171, -0.1191,  0.1019, -0.0473,  0.0376,  0.0182, -0.0409, -0.1077])), ('block_3.0.parametrizations.weight.original', tensor([[[ 0.0372, -0.1421, -0.0459],\n",
      "         [ 0.1442, -0.0439,  0.0497],\n",
      "         [ 0.1122, -0.0019, -0.0465],\n",
      "         ...,\n",
      "         [ 0.0746, -0.0231,  0.0299],\n",
      "         [ 0.0434, -0.0480,  0.1070],\n",
      "         [-0.1312, -0.1347,  0.1389]],\n",
      "\n",
      "        [[ 0.0172,  0.1348, -0.0856],\n",
      "         [ 0.0843,  0.1095, -0.1190],\n",
      "         [-0.1419, -0.0830,  0.0173],\n",
      "         ...,\n",
      "         [-0.0576, -0.0884, -0.1222],\n",
      "         [ 0.0742, -0.1127, -0.0616],\n",
      "         [ 0.1203, -0.0162, -0.0494]],\n",
      "\n",
      "        [[-0.0238,  0.0717,  0.0509],\n",
      "         [-0.0462,  0.0552, -0.0111],\n",
      "         [ 0.0453, -0.0947, -0.1331],\n",
      "         ...,\n",
      "         [-0.0003,  0.0142, -0.1064],\n",
      "         [ 0.1042,  0.0756, -0.0319],\n",
      "         [ 0.0325, -0.0543,  0.0926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0371, -0.0879, -0.0678],\n",
      "         [-0.1158, -0.0005,  0.0081],\n",
      "         [ 0.0695,  0.1177,  0.0216],\n",
      "         ...,\n",
      "         [ 0.1187,  0.0831,  0.0773],\n",
      "         [ 0.0377,  0.1285,  0.1051],\n",
      "         [-0.0216,  0.1393,  0.0031]],\n",
      "\n",
      "        [[ 0.1316, -0.1382,  0.1278],\n",
      "         [ 0.1406,  0.0589, -0.1405],\n",
      "         [-0.0716, -0.0221, -0.1019],\n",
      "         ...,\n",
      "         [ 0.1045,  0.0998,  0.0127],\n",
      "         [ 0.0898, -0.1021,  0.0630],\n",
      "         [ 0.0714,  0.1071, -0.0985]],\n",
      "\n",
      "        [[-0.0506,  0.1424, -0.1245],\n",
      "         [ 0.0700,  0.0229,  0.1130],\n",
      "         [-0.1303, -0.0371,  0.0275],\n",
      "         ...,\n",
      "         [ 0.0524, -0.1011,  0.0293],\n",
      "         [ 0.0695, -0.1102,  0.0516],\n",
      "         [ 0.0233,  0.0951, -0.0730]]])), ('block_3.0.parametrizations.weight.0.mask', tensor([[[False,  True, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [ True, False, False],\n",
      "         [False, False,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [False, False, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False, False,  True],\n",
      "         [ True,  True, False],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False, False],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True],\n",
      "         [False,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [False,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [False,  True,  True]]])), ('block_4.0.bias', tensor([ 0.0243,  0.0212,  0.0532,  0.0477, -0.0931,  0.0876,  0.0066, -0.0931,\n",
      "         0.0162, -0.0065,  0.0788, -0.0448,  0.0009, -0.0486, -0.0444,  0.0028,\n",
      "         0.0192, -0.0439, -0.0477,  0.0416,  0.0967,  0.0497,  0.0955,  0.0836,\n",
      "        -0.0047, -0.0496,  0.0161, -0.0375,  0.0408, -0.0364, -0.0286,  0.0066,\n",
      "         0.1005,  0.0129,  0.0928,  0.0919, -0.0044, -0.0349,  0.0600, -0.0720,\n",
      "        -0.0792,  0.0307, -0.0052, -0.0365,  0.0521, -0.0975, -0.0394,  0.0890,\n",
      "         0.0160,  0.0235, -0.0520,  0.0140, -0.0041, -0.0246, -0.1003, -0.0654,\n",
      "         0.0874,  0.0306,  0.0553, -0.0623, -0.0613, -0.0183,  0.0444,  0.0857])), ('block_4.0.parametrizations.weight.original', tensor([[[ 0.0542, -0.0099, -0.0512],\n",
      "         [ 0.0539, -0.0178,  0.0612],\n",
      "         [-0.0954,  0.0357,  0.0328],\n",
      "         ...,\n",
      "         [-0.0899,  0.0845,  0.0136],\n",
      "         [ 0.0739,  0.0013,  0.0422],\n",
      "         [ 0.0919, -0.0724,  0.0522]],\n",
      "\n",
      "        [[ 0.0884,  0.0876, -0.0260],\n",
      "         [ 0.0236,  0.0734, -0.0471],\n",
      "         [-0.0274,  0.0030, -0.0919],\n",
      "         ...,\n",
      "         [ 0.0769, -0.0393, -0.0541],\n",
      "         [-0.0770, -0.0166,  0.0468],\n",
      "         [ 0.0947, -0.0206, -0.0922]],\n",
      "\n",
      "        [[ 0.0064,  0.0705, -0.0688],\n",
      "         [ 0.0312,  0.0805,  0.0013],\n",
      "         [-0.0080, -0.0211, -0.0727],\n",
      "         ...,\n",
      "         [-0.0150, -0.0303, -0.0324],\n",
      "         [-0.0184,  0.0331,  0.0476],\n",
      "         [ 0.1016, -0.1000, -0.0375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0065,  0.0914, -0.0253],\n",
      "         [ 0.0682,  0.0809,  0.0321],\n",
      "         [ 0.0365, -0.0770, -0.0693],\n",
      "         ...,\n",
      "         [-0.0265,  0.0719,  0.0583],\n",
      "         [ 0.0820,  0.0425, -0.0899],\n",
      "         [-0.0440, -0.0805, -0.0815]],\n",
      "\n",
      "        [[ 0.0882, -0.0511,  0.0053],\n",
      "         [-0.0558,  0.0011,  0.0542],\n",
      "         [ 0.0367,  0.0522, -0.0979],\n",
      "         ...,\n",
      "         [-0.0815,  0.0221,  0.0615],\n",
      "         [-0.0427,  0.1012,  0.0583],\n",
      "         [-0.0932, -0.0546, -0.0815]],\n",
      "\n",
      "        [[ 0.0568,  0.0330,  0.0514],\n",
      "         [-0.0652, -0.0572, -0.0913],\n",
      "         [-0.0379,  0.0251,  0.0679],\n",
      "         ...,\n",
      "         [ 0.0127,  0.0012, -0.0135],\n",
      "         [-0.0445, -0.0669,  0.0543],\n",
      "         [ 0.0879, -0.0368, -0.0559]]])), ('block_4.0.parametrizations.weight.0.mask', tensor([[[False, False, False],\n",
      "         [False, False,  True],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True, False, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[ True,  True, False],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [ True, False, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [False,  True,  True],\n",
      "         [ True, False,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [ True,  True,  True],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False,  True, False],\n",
      "         [ True, False, False]]])), ('linear.bias', tensor([ 0.1015, -0.0603, -0.1208, -0.0205,  0.0865,  0.0243, -0.0639, -0.0232,\n",
      "         0.0621,  0.0614])), ('linear.parametrizations.weight.original', tensor([[-0.0305, -0.1249, -0.0250, -0.0066,  0.1101, -0.1192, -0.0567,  0.1167,\n",
      "         -0.0117, -0.0792,  0.0802, -0.0242,  0.0132,  0.1125,  0.0541,  0.1193,\n",
      "         -0.0320,  0.0606, -0.0033,  0.0063, -0.0799, -0.0009, -0.1026,  0.0924,\n",
      "         -0.0100,  0.0095,  0.0075,  0.0250,  0.0294,  0.0659,  0.0638, -0.0863,\n",
      "          0.0894,  0.0472,  0.1228, -0.0490,  0.0817,  0.1119,  0.0616,  0.0227,\n",
      "          0.0870, -0.0899, -0.0463,  0.1199, -0.0707, -0.0470,  0.0313,  0.1222,\n",
      "         -0.1060, -0.0777,  0.0585,  0.1225,  0.0879, -0.0823,  0.1219, -0.0608,\n",
      "         -0.0357, -0.0518, -0.0641,  0.0708, -0.0375, -0.0786, -0.1033, -0.0672],\n",
      "        [-0.0518, -0.0111, -0.0859,  0.0105, -0.0430, -0.0366, -0.0081, -0.0481,\n",
      "         -0.0094, -0.0896,  0.0636,  0.0834,  0.0291,  0.0397,  0.0091,  0.0655,\n",
      "         -0.0245,  0.0517, -0.0797, -0.0586,  0.0143, -0.0479, -0.0039, -0.0946,\n",
      "         -0.0880,  0.0094, -0.0381,  0.1002, -0.0291,  0.0634,  0.1136,  0.0449,\n",
      "         -0.0979, -0.1236,  0.0002, -0.1040,  0.0900,  0.0394, -0.0793, -0.1208,\n",
      "          0.0804, -0.1134, -0.1022,  0.1176,  0.0187, -0.0395,  0.0036,  0.0525,\n",
      "          0.1228,  0.1034, -0.0718,  0.1078, -0.0706, -0.0868, -0.0718, -0.0656,\n",
      "         -0.0418,  0.0394, -0.1239, -0.0680,  0.0649,  0.0439, -0.1093, -0.0990],\n",
      "        [ 0.0796, -0.0468, -0.1168,  0.0924,  0.1067, -0.0999,  0.0691,  0.1055,\n",
      "          0.0672,  0.0963,  0.1074,  0.0392, -0.0639,  0.0775,  0.0903,  0.0376,\n",
      "         -0.0508, -0.0262,  0.0371,  0.1027,  0.0512, -0.0568, -0.0024, -0.0496,\n",
      "         -0.0531, -0.0719,  0.1026, -0.0616, -0.0406,  0.1120, -0.0686, -0.1079,\n",
      "         -0.1135,  0.0418,  0.0085, -0.0667,  0.1022, -0.0452, -0.0240, -0.1242,\n",
      "          0.0178, -0.0391, -0.0008, -0.0943,  0.0855,  0.0839,  0.0258, -0.0295,\n",
      "          0.0969,  0.0097, -0.0487, -0.0782,  0.0017, -0.0918, -0.1112, -0.0236,\n",
      "         -0.0943, -0.0382,  0.0270,  0.0932, -0.0933, -0.0082,  0.0383,  0.0712],\n",
      "        [ 0.0315,  0.0899, -0.1056,  0.1178,  0.0594, -0.0490,  0.1029, -0.0590,\n",
      "          0.0432,  0.0047,  0.0280, -0.0408,  0.0076,  0.0604, -0.1039, -0.0594,\n",
      "          0.0949,  0.0638, -0.0221, -0.0865,  0.1090,  0.0981, -0.0991,  0.0188,\n",
      "          0.0742,  0.1212,  0.0214,  0.0149,  0.0519,  0.0207,  0.0492,  0.0971,\n",
      "         -0.0742, -0.0483, -0.0756,  0.0872,  0.0375, -0.0763,  0.0664, -0.0996,\n",
      "         -0.0852,  0.0598, -0.0740, -0.0206,  0.0690, -0.1130, -0.0051,  0.0858,\n",
      "         -0.0175,  0.0803, -0.0396, -0.1026, -0.0679,  0.0469, -0.0008,  0.0329,\n",
      "          0.1061,  0.1132,  0.1028,  0.0213,  0.0172, -0.0638,  0.0790,  0.0371],\n",
      "        [ 0.1067, -0.0995, -0.0347,  0.0068,  0.0163,  0.0711, -0.1242, -0.0620,\n",
      "         -0.0373,  0.0256,  0.0116, -0.0887,  0.1187,  0.0617,  0.0185,  0.0242,\n",
      "          0.1014,  0.0407, -0.1067, -0.0636,  0.0834,  0.0795,  0.0579, -0.0992,\n",
      "         -0.0506, -0.0844, -0.0479, -0.0250, -0.1021,  0.0717,  0.0866, -0.0033,\n",
      "          0.0148,  0.0119, -0.1211, -0.0586, -0.0765, -0.0673, -0.0722, -0.0274,\n",
      "         -0.0493,  0.0445, -0.1005,  0.1065,  0.0591,  0.0998, -0.0062, -0.1039,\n",
      "          0.0015,  0.0606,  0.1087, -0.1079, -0.0609,  0.0301, -0.0971,  0.0815,\n",
      "         -0.0571,  0.0360,  0.0361,  0.0892, -0.0242,  0.1019,  0.0111,  0.1193],\n",
      "        [-0.0751,  0.1161,  0.0793,  0.1139,  0.0720,  0.0903,  0.0717, -0.0843,\n",
      "          0.1096, -0.1029,  0.1095, -0.0607, -0.0066,  0.1032,  0.0744,  0.0712,\n",
      "         -0.0222,  0.0558,  0.1005, -0.1206,  0.0551, -0.0197,  0.0200, -0.0997,\n",
      "         -0.0685,  0.0740, -0.0433, -0.0515,  0.0032,  0.1070, -0.0327, -0.0049,\n",
      "          0.1229,  0.0888,  0.0764,  0.0815,  0.1044, -0.0096,  0.1020,  0.0195,\n",
      "         -0.0409,  0.1154, -0.1239, -0.0261,  0.1226,  0.0213,  0.0804,  0.0827,\n",
      "          0.0248,  0.0703,  0.0775,  0.0488,  0.1137, -0.0075, -0.0577,  0.0760,\n",
      "         -0.0806, -0.0713,  0.0440,  0.0105,  0.0393, -0.0105,  0.0832, -0.0833],\n",
      "        [-0.0932,  0.0699,  0.0114, -0.0823,  0.0928, -0.0212,  0.0542, -0.0006,\n",
      "          0.0407,  0.0205, -0.0276,  0.0745, -0.1231, -0.0190, -0.0273,  0.0119,\n",
      "         -0.0821, -0.0752, -0.1196, -0.1073,  0.1070,  0.1143,  0.0815,  0.0268,\n",
      "          0.0913, -0.0573,  0.0530, -0.1025, -0.1177,  0.1004, -0.0287,  0.0028,\n",
      "          0.1182,  0.0651,  0.0295, -0.0865,  0.0994, -0.0648, -0.1058,  0.1042,\n",
      "         -0.1238,  0.1107,  0.0417, -0.1176, -0.0537, -0.0271,  0.0282, -0.0706,\n",
      "         -0.0020, -0.0114,  0.0894,  0.0946,  0.0255,  0.0618, -0.0074, -0.0661,\n",
      "         -0.0201, -0.1066,  0.1073, -0.0201,  0.0790,  0.0373, -0.0872,  0.0669],\n",
      "        [-0.0200, -0.1013,  0.1021,  0.1004, -0.1207, -0.1121, -0.0852, -0.0818,\n",
      "          0.0959,  0.1220,  0.0122, -0.0013, -0.0238, -0.0842,  0.0380,  0.0133,\n",
      "          0.0822, -0.0004, -0.0777, -0.0006, -0.1081,  0.0122, -0.0402,  0.0630,\n",
      "          0.0430, -0.0520, -0.0895, -0.0072,  0.0540,  0.0797,  0.1083, -0.1244,\n",
      "          0.1041,  0.0813,  0.0362, -0.1030,  0.0804, -0.0258,  0.0850,  0.0583,\n",
      "         -0.1210, -0.0521,  0.0912,  0.0013,  0.0869,  0.0165,  0.0902,  0.0358,\n",
      "         -0.0243, -0.1175,  0.0964, -0.0201,  0.0570, -0.0913,  0.0404,  0.0893,\n",
      "         -0.0419, -0.0613,  0.0785, -0.0845,  0.1035, -0.0634,  0.0175, -0.0493],\n",
      "        [ 0.0388, -0.0753, -0.1036, -0.0512, -0.0078, -0.1128, -0.1167,  0.1079,\n",
      "         -0.0255,  0.0243,  0.0449, -0.0670, -0.1237, -0.0102, -0.0635,  0.1225,\n",
      "          0.0443, -0.1126, -0.0015, -0.0533,  0.1142, -0.0192,  0.0076,  0.0846,\n",
      "         -0.0915,  0.1137,  0.0703,  0.0469, -0.0645,  0.0119, -0.0699, -0.1047,\n",
      "         -0.0350,  0.0749,  0.0763, -0.0440,  0.0839,  0.1152, -0.0354,  0.0434,\n",
      "         -0.1028, -0.0113,  0.0044,  0.0996,  0.0210,  0.0431, -0.0318, -0.0325,\n",
      "         -0.0930, -0.0049, -0.0234, -0.0534,  0.1081, -0.0817,  0.0610,  0.0971,\n",
      "          0.0748,  0.0814,  0.1016,  0.0274,  0.0165, -0.0218, -0.0295, -0.0570],\n",
      "        [ 0.0792, -0.0282, -0.0505, -0.0764, -0.0447, -0.0543, -0.1059,  0.0090,\n",
      "         -0.0753,  0.0234, -0.0836,  0.0617, -0.1249, -0.0309, -0.0148, -0.0891,\n",
      "          0.1081, -0.0224, -0.1231, -0.0089,  0.0523,  0.0211, -0.0144,  0.1027,\n",
      "          0.0285,  0.1040, -0.0108, -0.0526, -0.1016,  0.0051, -0.0232,  0.1078,\n",
      "          0.0514, -0.0586, -0.0378,  0.1012, -0.1089,  0.0674,  0.1109, -0.0039,\n",
      "          0.0280, -0.0743,  0.0260, -0.0203, -0.0993,  0.0533,  0.0363,  0.1013,\n",
      "          0.0535,  0.0293,  0.0484, -0.0590,  0.0899,  0.0576,  0.0930, -0.0037,\n",
      "          0.1187,  0.0870, -0.0086, -0.1009, -0.0745, -0.0309,  0.0918,  0.0785]])), ('linear.parametrizations.weight.0.mask', tensor([[False,  True, False, False,  True,  True,  True,  True, False,  True,\n",
      "          True, False, False,  True, False,  True, False,  True, False, False,\n",
      "          True, False,  True,  True, False, False, False, False, False,  True,\n",
      "          True,  True,  True, False,  True, False,  True,  True,  True, False,\n",
      "          True,  True, False,  True,  True, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
      "         False,  True,  True,  True],\n",
      "        [False, False,  True, False, False, False, False, False, False,  True,\n",
      "          True,  True, False, False, False,  True, False, False,  True,  True,\n",
      "         False, False, False,  True,  True, False, False,  True, False,  True,\n",
      "          True, False,  True,  True, False,  True,  True, False,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
      "          True, False,  True,  True],\n",
      "        [ True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False,  True,  True,  True, False, False, False, False,  True,\n",
      "         False,  True, False, False, False,  True,  True,  True, False,  True,\n",
      "          True,  True,  True, False, False,  True,  True, False, False,  True,\n",
      "         False, False, False,  True,  True,  True, False, False,  True, False,\n",
      "         False,  True, False,  True,  True, False,  True, False, False,  True,\n",
      "          True, False, False,  True],\n",
      "        [False,  True,  True,  True,  True, False,  True,  True, False, False,\n",
      "         False, False, False,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "         False,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True, False,  True, False,  True,\n",
      "         False,  True,  True, False, False, False,  True,  True,  True, False,\n",
      "         False,  True,  True, False],\n",
      "        [ True,  True, False, False, False,  True,  True,  True, False, False,\n",
      "         False,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "          True,  True,  True,  True, False,  True, False, False,  True,  True,\n",
      "          True, False, False, False,  True,  True,  True,  True,  True, False,\n",
      "         False, False,  True,  True,  True,  True, False,  True, False,  True,\n",
      "          True,  True,  True, False,  True,  True,  True, False, False,  True,\n",
      "         False,  True, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
      "         False, False, False,  True,  True,  True, False, False, False,  True,\n",
      "         False, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         False,  True,  True, False,  True, False,  True,  True, False,  True,\n",
      "          True, False,  True, False,  True,  True,  True,  True, False, False,\n",
      "         False, False,  True,  True],\n",
      "        [ True,  True, False,  True,  True, False, False, False, False, False,\n",
      "         False,  True,  True, False, False, False,  True,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
      "         False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True, False, False, False,  True, False, False,\n",
      "          True,  True, False,  True, False,  True, False,  True,  True, False,\n",
      "          True, False,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False,  True, False, False,  True, False,  True, False,\n",
      "          True, False, False,  True, False, False,  True, False, False,  True,\n",
      "          True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
      "          True, False,  True, False,  True, False,  True, False, False,  True,\n",
      "          True, False,  True,  True, False,  True, False,  True,  True,  True,\n",
      "          True,  True, False, False],\n",
      "        [False,  True,  True, False, False,  True,  True,  True, False, False,\n",
      "         False,  True,  True, False,  True,  True, False,  True, False, False,\n",
      "          True, False, False,  True,  True,  True,  True, False,  True, False,\n",
      "          True,  True, False,  True,  True, False,  True,  True, False, False,\n",
      "          True, False, False,  True, False, False, False, False,  True, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False,  True],\n",
      "        [ True, False, False,  True, False, False,  True, False,  True, False,\n",
      "          True,  True,  True, False, False,  True,  True, False,  True, False,\n",
      "         False, False, False,  True, False,  True, False, False,  True, False,\n",
      "         False,  True, False,  True, False,  True,  True,  True,  True, False,\n",
      "         False,  True, False, False,  True, False, False,  True, False, False,\n",
      "         False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
      "          True, False,  True,  True]]))])\n"
     ]
    }
   ],
   "source": [
    "print(mg.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_items([(10, <function get_activation_hook.<locals>.sparsify_input at 0x7f651a1e97e0>)])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([(11, <function get_activation_hook.<locals>.sparsify_input at 0x7f651544e8c0>)])\n",
      "odict_items([])\n",
      "odict_items([(12, <function get_activation_hook.<locals>.sparsify_input at 0x7f651544f2e0>)])\n",
      "odict_items([])\n",
      "odict_items([(13, <function get_activation_hook.<locals>.sparsify_input at 0x7f651544f910>)])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([(14, <function get_activation_hook.<locals>.sparsify_input at 0x7f651544f880>)])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'linear':\n",
    "    if node.op == \"call_module\":\n",
    "        #print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        #pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        pprint(mg.modules[node.target]._forward_pre_hooks.items())\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "       # print(mg.model.state_dict())\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # w = mg.modules[node.target].weight\n",
    "        # for s in w:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        # print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_blocks_2\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [5],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330], requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 16],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0000, 0.6918, 0.1922,  ..., 0.0000, 0.2194, 0.4817],\n",
      "        [0.0000, 0.3129, 0.0933,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5225, 0.2079, 0.1787,  ..., 0.0000, 0.1940, 0.0000],\n",
      "        ...,\n",
      "        [0.4002, 0.3301, 1.0308,  ..., 0.0000, 1.3613, 0.0000],\n",
      "        [0.0000, 0.4540, 0.2304,  ..., 0.0000, 0.1260, 0.0000],\n",
      "        [0.0000, 0.6719, 1.6635,  ..., 0.5214, 1.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [5, 16],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]],\n",
      "       requires_grad=True)}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "        # for s in mask_2:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n",
    "#print(mg.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('seq_blocks.0.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('seq_blocks.0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('seq_blocks.0.running_mean', tensor([-0.0050, -0.0008,  0.0117,  0.0123,  0.0122,  0.0126,  0.0009,  0.0042,\n",
      "         0.0009,  0.0062,  0.0059,  0.0099,  0.0060,  0.0104,  0.0113,  0.0112])), ('seq_blocks.0.running_var', tensor([1.0098, 1.0104, 1.0108, 1.0118, 1.0102, 1.0118, 0.9849, 0.9822, 0.9849,\n",
      "        0.9984, 1.0017, 1.0007, 0.9980, 0.9983, 1.0123, 1.0123])), ('seq_blocks.0.num_batches_tracked', tensor(2)), ('seq_blocks.2.bias', tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330])), ('seq_blocks.2.parametrizations.weight.original', tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]])), ('seq_blocks.2.parametrizations.weight.0.mask', tensor([[False,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
      "          True,  True, False, False, False, False],\n",
      "        [ True, False, False, False,  True, False,  True, False, False, False,\n",
      "          True, False, False, False,  True,  True],\n",
      "        [False,  True,  True, False, False,  True,  True, False, False, False,\n",
      "          True, False,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False,  True,  True,  True,  True, False,\n",
      "          True, False, False, False,  True,  True],\n",
      "        [ True,  True, False, False, False,  True,  True, False,  True,  True,\n",
      "         False, False,  True, False,  True, False]]))])\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block_1.0.bias', tensor([-0.0150,  0.1194, -0.0869,  0.1154, -0.1577, -0.0850,  0.0252,  0.1689])), ('block_1.0.parametrizations.weight.original', tensor([[[[ 0.0482, -0.1878,  0.1399],\n",
      "          [-0.0447, -0.1207,  0.0728],\n",
      "          [ 0.1810,  0.1505, -0.0590]],\n",
      "\n",
      "         [[ 0.0790,  0.0771,  0.1427],\n",
      "          [-0.0824,  0.0353,  0.0553],\n",
      "          [ 0.1773, -0.0354, -0.0334]],\n",
      "\n",
      "         [[ 0.0501,  0.1248,  0.1277],\n",
      "          [ 0.0594,  0.0126, -0.0937],\n",
      "          [ 0.1721,  0.0603,  0.1783]]],\n",
      "\n",
      "\n",
      "        [[[-0.1910,  0.0375, -0.1549],\n",
      "          [-0.1783,  0.1765, -0.1179],\n",
      "          [-0.1074,  0.0089, -0.0264]],\n",
      "\n",
      "         [[ 0.0115, -0.1628,  0.0479],\n",
      "          [ 0.1017,  0.1554,  0.1056],\n",
      "          [ 0.0324, -0.0862, -0.0767]],\n",
      "\n",
      "         [[ 0.0320, -0.1785,  0.0332],\n",
      "          [-0.1306,  0.0354,  0.1682],\n",
      "          [-0.0375,  0.0699,  0.1177]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0533,  0.0707, -0.1811],\n",
      "          [ 0.0834,  0.0610, -0.0461],\n",
      "          [ 0.0318, -0.0468, -0.0558]],\n",
      "\n",
      "         [[-0.1492, -0.1507, -0.1335],\n",
      "          [ 0.1556, -0.1650,  0.0681],\n",
      "          [-0.1720, -0.0592,  0.1443]],\n",
      "\n",
      "         [[ 0.1144,  0.0282,  0.0255],\n",
      "          [ 0.0072, -0.1592,  0.1490],\n",
      "          [-0.0806, -0.0816,  0.1889]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1372, -0.0015,  0.1747],\n",
      "          [ 0.1662,  0.1222,  0.1376],\n",
      "          [ 0.0438, -0.1225, -0.0558]],\n",
      "\n",
      "         [[ 0.0859,  0.1583, -0.0952],\n",
      "          [ 0.0552, -0.0827, -0.1789],\n",
      "          [-0.0847, -0.0393,  0.0409]],\n",
      "\n",
      "         [[ 0.0853, -0.0500, -0.0621],\n",
      "          [-0.0242, -0.0368, -0.0848],\n",
      "          [-0.0821, -0.1868, -0.1163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1098, -0.0516, -0.0927],\n",
      "          [-0.1351,  0.1254, -0.1793],\n",
      "          [-0.1417,  0.1095, -0.1807]],\n",
      "\n",
      "         [[ 0.1692,  0.0284, -0.1439],\n",
      "          [-0.1344, -0.0125, -0.1628],\n",
      "          [ 0.1394,  0.1148,  0.0548]],\n",
      "\n",
      "         [[ 0.1052, -0.1389, -0.0091],\n",
      "          [ 0.0414,  0.1159,  0.0400],\n",
      "          [ 0.1353, -0.1280, -0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.1091,  0.1622, -0.0223],\n",
      "          [-0.0250,  0.1361, -0.0692],\n",
      "          [ 0.0560,  0.1055, -0.1218]],\n",
      "\n",
      "         [[ 0.1718,  0.0455,  0.1047],\n",
      "          [ 0.0265, -0.1897,  0.0900],\n",
      "          [-0.0968, -0.0677,  0.0797]],\n",
      "\n",
      "         [[ 0.1742,  0.1691, -0.1905],\n",
      "          [ 0.0279, -0.1319,  0.1491],\n",
      "          [ 0.0227,  0.1762, -0.0797]]],\n",
      "\n",
      "\n",
      "        [[[-0.1599,  0.0872,  0.0988],\n",
      "          [-0.1566,  0.1369,  0.1657],\n",
      "          [-0.1378,  0.1902,  0.0396]],\n",
      "\n",
      "         [[-0.1657,  0.0108,  0.0075],\n",
      "          [ 0.1565, -0.1112, -0.1592],\n",
      "          [-0.0101, -0.0271, -0.0948]],\n",
      "\n",
      "         [[-0.0766,  0.0704,  0.0535],\n",
      "          [-0.0574,  0.0132,  0.0885],\n",
      "          [ 0.1017, -0.1076,  0.1387]]],\n",
      "\n",
      "\n",
      "        [[[-0.0366, -0.1487,  0.1734],\n",
      "          [-0.0564,  0.1104, -0.0360],\n",
      "          [-0.0056,  0.1768,  0.1271]],\n",
      "\n",
      "         [[ 0.0180, -0.0707,  0.1378],\n",
      "          [-0.0553,  0.0366, -0.0708],\n",
      "          [ 0.0396, -0.0658,  0.0549]],\n",
      "\n",
      "         [[ 0.0755, -0.1423, -0.1889],\n",
      "          [ 0.1051, -0.1273,  0.0122],\n",
      "          [ 0.0670, -0.1653, -0.0353]]]])), ('block_1.0.parametrizations.weight.0.mask', tensor([[[[False,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False]]]])), ('block_2.0.bias', tensor([-0.0873,  0.0853, -0.0529, -0.0211, -0.0257, -0.0613,  0.0628,  0.1111,\n",
      "        -0.0658,  0.0443,  0.0983,  0.0057,  0.0704,  0.0325,  0.0384,  0.0273])), ('block_2.0.parametrizations.weight.original', tensor([[[[-7.3164e-02, -3.5792e-02,  6.2530e-02],\n",
      "          [ 1.1180e-01,  5.5126e-03, -5.2311e-02],\n",
      "          [-8.7217e-03,  5.5034e-02, -1.0775e-02]],\n",
      "\n",
      "         [[ 1.7260e-02,  8.1440e-03, -6.2507e-02],\n",
      "          [-3.9982e-02,  7.2046e-02,  1.5615e-02],\n",
      "          [ 5.0020e-02,  1.8362e-02, -1.0248e-01]],\n",
      "\n",
      "         [[ 1.0516e-01, -1.1496e-03,  5.7527e-02],\n",
      "          [ 1.0161e-01, -2.6610e-02,  9.2292e-02],\n",
      "          [ 4.8030e-02,  6.9393e-02, -3.9050e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7844e-02,  2.9254e-02, -6.9710e-02],\n",
      "          [ 8.0607e-02, -9.5377e-02, -5.3852e-04],\n",
      "          [-1.0632e-01, -5.5983e-02,  1.1649e-01]],\n",
      "\n",
      "         [[ 4.9026e-02,  1.1381e-01, -1.0847e-01],\n",
      "          [-8.7854e-03,  1.0446e-01, -2.9343e-02],\n",
      "          [-3.7824e-02,  7.4768e-02, -7.8245e-02]],\n",
      "\n",
      "         [[-4.7404e-02,  1.9228e-02,  9.2781e-02],\n",
      "          [-1.0608e-01, -5.5542e-02,  1.0501e-01],\n",
      "          [ 2.5595e-02, -4.7634e-02, -7.3433e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8188e-03,  8.8838e-02,  3.5333e-02],\n",
      "          [ 5.4889e-02, -3.7048e-02,  8.7602e-02],\n",
      "          [-4.0893e-02,  5.1910e-02, -9.7804e-02]],\n",
      "\n",
      "         [[-4.4325e-02,  1.9604e-03, -1.7291e-03],\n",
      "          [ 1.0679e-01,  5.5831e-02, -9.7520e-02],\n",
      "          [ 9.3985e-02, -5.7197e-03, -9.9021e-03]],\n",
      "\n",
      "         [[-4.4307e-02, -9.1681e-02,  9.0561e-02],\n",
      "          [-6.1748e-02,  2.8704e-02,  2.5783e-02],\n",
      "          [ 8.0566e-02, -5.0144e-02,  1.0203e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2944e-02,  5.8891e-02, -7.5695e-02],\n",
      "          [-4.5107e-02,  5.5784e-02, -7.3049e-02],\n",
      "          [-3.2986e-02,  5.8733e-02, -9.1544e-02]],\n",
      "\n",
      "         [[ 5.2507e-03, -8.3595e-02,  1.0369e-01],\n",
      "          [ 9.9381e-02,  1.1036e-01, -6.2576e-02],\n",
      "          [-6.4921e-02,  2.6826e-02,  5.7940e-02]],\n",
      "\n",
      "         [[ 1.0781e-01, -1.0896e-01,  7.5756e-02],\n",
      "          [ 2.3827e-02,  7.7318e-02, -1.1537e-01],\n",
      "          [ 4.6751e-02,  1.1054e-02, -5.6416e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6792e-02,  1.1156e-01, -7.6322e-02],\n",
      "          [ 2.2198e-02,  3.4144e-02, -1.5733e-02],\n",
      "          [-1.0491e-02,  8.8053e-02, -6.2106e-02]],\n",
      "\n",
      "         [[-4.3911e-02, -6.2618e-04, -1.1040e-01],\n",
      "          [-4.3996e-02,  6.1727e-02, -3.7053e-02],\n",
      "          [-6.4065e-02,  1.1613e-02, -7.9569e-02]],\n",
      "\n",
      "         [[ 4.3577e-02, -7.9689e-02, -7.5668e-02],\n",
      "          [ 1.1068e-01, -3.1105e-03,  1.1086e-01],\n",
      "          [ 2.3632e-02,  2.5888e-02, -1.1741e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8868e-02,  1.0238e-02, -4.1204e-02],\n",
      "          [ 1.0477e-01, -1.4142e-02, -7.8157e-02],\n",
      "          [-3.7035e-02, -1.8862e-02, -2.2064e-02]],\n",
      "\n",
      "         [[-6.4384e-04,  2.4001e-02, -3.0005e-02],\n",
      "          [-2.6286e-02, -5.1973e-02,  1.0618e-02],\n",
      "          [ 9.2148e-02,  3.5244e-02, -8.3853e-02]],\n",
      "\n",
      "         [[-2.8725e-02,  1.1052e-01,  2.8106e-02],\n",
      "          [ 8.5162e-02, -7.8291e-02, -7.2436e-02],\n",
      "          [ 2.2685e-03,  4.7023e-02,  4.9981e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1337e-01,  6.2873e-02, -5.1491e-02],\n",
      "          [-2.6755e-02, -1.0510e-02,  6.0088e-02],\n",
      "          [ 4.0170e-02,  7.1250e-02,  9.6053e-02]],\n",
      "\n",
      "         [[-5.1337e-02, -1.9477e-02,  9.2799e-02],\n",
      "          [-6.3104e-02, -1.1582e-01, -8.1200e-02],\n",
      "          [ 6.2329e-02, -1.0168e-01, -1.1237e-01]],\n",
      "\n",
      "         [[-3.8252e-02, -1.0675e-01,  9.7299e-03],\n",
      "          [-7.7501e-02,  1.0701e-01,  3.6289e-03],\n",
      "          [-4.1225e-02, -3.6578e-02,  7.1382e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5911e-02,  2.4986e-02, -5.7031e-02],\n",
      "          [-5.5507e-03, -6.9505e-02, -3.0977e-02],\n",
      "          [ 2.9424e-02, -6.8944e-02,  7.1138e-02]],\n",
      "\n",
      "         [[ 6.1547e-02, -1.1177e-01,  8.5836e-02],\n",
      "          [-2.2554e-02,  6.2181e-02,  9.5262e-03],\n",
      "          [-4.3724e-02,  8.1902e-02,  2.7412e-02]],\n",
      "\n",
      "         [[ 2.9208e-02, -7.7896e-02, -7.6193e-02],\n",
      "          [-7.6798e-02, -9.8470e-02,  1.0433e-01],\n",
      "          [ 1.1376e-01,  1.0434e-02, -3.0982e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1364e-02,  3.6460e-02,  1.9660e-04],\n",
      "          [-4.5688e-02,  3.5868e-02, -4.4238e-02],\n",
      "          [ 8.3863e-02, -8.7230e-02, -7.4176e-02]],\n",
      "\n",
      "         [[ 6.6078e-02, -8.1642e-02, -2.4147e-02],\n",
      "          [ 5.9180e-02, -9.1912e-02, -1.0531e-01],\n",
      "          [ 4.2441e-02, -1.0209e-01,  4.9050e-02]],\n",
      "\n",
      "         [[ 4.1745e-02,  1.0967e-01, -8.3971e-02],\n",
      "          [ 6.1120e-02, -3.6559e-02,  1.0551e-01],\n",
      "          [-1.0333e-01, -8.0555e-02, -9.2520e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0039e-01,  7.8183e-02, -5.6101e-02],\n",
      "          [-1.7231e-02, -1.5447e-02,  1.5240e-02],\n",
      "          [ 8.7997e-02,  5.9031e-02, -2.4858e-02]],\n",
      "\n",
      "         [[ 8.8515e-02, -1.1368e-01, -3.9590e-03],\n",
      "          [ 9.2562e-02,  7.9570e-02,  1.1721e-01],\n",
      "          [-6.7500e-02, -8.9282e-02,  6.9140e-02]],\n",
      "\n",
      "         [[ 8.9193e-03,  8.9558e-03,  2.9366e-02],\n",
      "          [ 2.0069e-02, -9.8191e-02, -6.7588e-02],\n",
      "          [-9.3216e-02, -4.3536e-03, -8.8818e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9310e-02,  8.2291e-02,  1.4515e-02],\n",
      "          [-4.8546e-02,  7.9303e-02,  7.4954e-02],\n",
      "          [ 4.5168e-02,  7.3695e-02, -8.1811e-02]],\n",
      "\n",
      "         [[ 9.3572e-03, -4.9404e-02,  1.1674e-01],\n",
      "          [-1.1648e-01,  6.6193e-02,  3.9933e-02],\n",
      "          [-8.3907e-02, -3.0829e-02, -2.4208e-02]],\n",
      "\n",
      "         [[ 6.6340e-02, -1.1352e-01,  7.6282e-02],\n",
      "          [-4.6117e-02,  4.7454e-02,  7.3671e-02],\n",
      "          [ 6.2023e-02,  7.4238e-02, -4.9420e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8108e-02,  3.1631e-02, -5.1316e-02],\n",
      "          [ 3.2496e-02,  7.1109e-03, -6.3822e-02],\n",
      "          [-6.8870e-02,  1.1360e-01, -1.6819e-02]],\n",
      "\n",
      "         [[-2.6419e-02,  3.1337e-03,  7.5734e-02],\n",
      "          [ 8.4328e-02,  2.4305e-05,  2.7967e-02],\n",
      "          [ 7.5876e-02,  6.8452e-03,  8.6770e-02]],\n",
      "\n",
      "         [[-2.5564e-02, -6.2881e-02,  5.4439e-02],\n",
      "          [-4.3468e-02, -4.4770e-02,  1.1253e-01],\n",
      "          [ 6.7794e-02, -4.6720e-02,  5.8572e-02]]]])), ('block_2.0.parametrizations.weight.0.mask', tensor([[[[ True, False,  True],\n",
      "          [ True, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [False, False, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True, False,  True],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [False, False,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False,  True,  True],\n",
      "          [ True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [ True, False,  True]]]])), ('block_3.0.bias', tensor([-0.0632,  0.0645, -0.0901, -0.0578, -0.0520,  0.0589, -0.1231,  0.0708,\n",
      "        -0.0869, -0.0087, -0.0029,  0.1425, -0.0953, -0.0415, -0.0927, -0.0512,\n",
      "         0.0057, -0.0287,  0.1319, -0.0534,  0.1061,  0.0093,  0.0650,  0.0640,\n",
      "         0.0171, -0.1191,  0.1019, -0.0473,  0.0376,  0.0182, -0.0409, -0.1077])), ('block_3.0.parametrizations.weight.original', tensor([[[ 0.0372, -0.1421, -0.0459],\n",
      "         [ 0.1442, -0.0439,  0.0497],\n",
      "         [ 0.1122, -0.0019, -0.0465],\n",
      "         ...,\n",
      "         [ 0.0746, -0.0231,  0.0299],\n",
      "         [ 0.0434, -0.0480,  0.1070],\n",
      "         [-0.1312, -0.1347,  0.1389]],\n",
      "\n",
      "        [[ 0.0172,  0.1348, -0.0856],\n",
      "         [ 0.0843,  0.1095, -0.1190],\n",
      "         [-0.1419, -0.0830,  0.0173],\n",
      "         ...,\n",
      "         [-0.0576, -0.0884, -0.1222],\n",
      "         [ 0.0742, -0.1127, -0.0616],\n",
      "         [ 0.1203, -0.0162, -0.0494]],\n",
      "\n",
      "        [[-0.0238,  0.0717,  0.0509],\n",
      "         [-0.0462,  0.0552, -0.0111],\n",
      "         [ 0.0453, -0.0947, -0.1331],\n",
      "         ...,\n",
      "         [-0.0003,  0.0142, -0.1064],\n",
      "         [ 0.1042,  0.0756, -0.0319],\n",
      "         [ 0.0325, -0.0543,  0.0926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0371, -0.0879, -0.0678],\n",
      "         [-0.1158, -0.0005,  0.0081],\n",
      "         [ 0.0695,  0.1177,  0.0216],\n",
      "         ...,\n",
      "         [ 0.1187,  0.0831,  0.0773],\n",
      "         [ 0.0377,  0.1285,  0.1051],\n",
      "         [-0.0216,  0.1393,  0.0031]],\n",
      "\n",
      "        [[ 0.1316, -0.1382,  0.1278],\n",
      "         [ 0.1406,  0.0589, -0.1405],\n",
      "         [-0.0716, -0.0221, -0.1019],\n",
      "         ...,\n",
      "         [ 0.1045,  0.0998,  0.0127],\n",
      "         [ 0.0898, -0.1021,  0.0630],\n",
      "         [ 0.0714,  0.1071, -0.0985]],\n",
      "\n",
      "        [[-0.0506,  0.1424, -0.1245],\n",
      "         [ 0.0700,  0.0229,  0.1130],\n",
      "         [-0.1303, -0.0371,  0.0275],\n",
      "         ...,\n",
      "         [ 0.0524, -0.1011,  0.0293],\n",
      "         [ 0.0695, -0.1102,  0.0516],\n",
      "         [ 0.0233,  0.0951, -0.0730]]])), ('block_3.0.parametrizations.weight.0.mask', tensor([[[False,  True, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [ True, False, False],\n",
      "         [False, False,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [False, False, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False, False,  True],\n",
      "         [ True,  True, False],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False, False],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True],\n",
      "         [False,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [False,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [False,  True,  True]]])), ('block_4.0.bias', tensor([ 0.0243,  0.0212,  0.0532,  0.0477, -0.0931,  0.0876,  0.0066, -0.0931,\n",
      "         0.0162, -0.0065,  0.0788, -0.0448,  0.0009, -0.0486, -0.0444,  0.0028,\n",
      "         0.0192, -0.0439, -0.0477,  0.0416,  0.0967,  0.0497,  0.0955,  0.0836,\n",
      "        -0.0047, -0.0496,  0.0161, -0.0375,  0.0408, -0.0364, -0.0286,  0.0066,\n",
      "         0.1005,  0.0129,  0.0928,  0.0919, -0.0044, -0.0349,  0.0600, -0.0720,\n",
      "        -0.0792,  0.0307, -0.0052, -0.0365,  0.0521, -0.0975, -0.0394,  0.0890,\n",
      "         0.0160,  0.0235, -0.0520,  0.0140, -0.0041, -0.0246, -0.1003, -0.0654,\n",
      "         0.0874,  0.0306,  0.0553, -0.0623, -0.0613, -0.0183,  0.0444,  0.0857])), ('block_4.0.parametrizations.weight.original', tensor([[[ 0.0542, -0.0099, -0.0512],\n",
      "         [ 0.0539, -0.0178,  0.0612],\n",
      "         [-0.0954,  0.0357,  0.0328],\n",
      "         ...,\n",
      "         [-0.0899,  0.0845,  0.0136],\n",
      "         [ 0.0739,  0.0013,  0.0422],\n",
      "         [ 0.0919, -0.0724,  0.0522]],\n",
      "\n",
      "        [[ 0.0884,  0.0876, -0.0260],\n",
      "         [ 0.0236,  0.0734, -0.0471],\n",
      "         [-0.0274,  0.0030, -0.0919],\n",
      "         ...,\n",
      "         [ 0.0769, -0.0393, -0.0541],\n",
      "         [-0.0770, -0.0166,  0.0468],\n",
      "         [ 0.0947, -0.0206, -0.0922]],\n",
      "\n",
      "        [[ 0.0064,  0.0705, -0.0688],\n",
      "         [ 0.0312,  0.0805,  0.0013],\n",
      "         [-0.0080, -0.0211, -0.0727],\n",
      "         ...,\n",
      "         [-0.0150, -0.0303, -0.0324],\n",
      "         [-0.0184,  0.0331,  0.0476],\n",
      "         [ 0.1016, -0.1000, -0.0375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0065,  0.0914, -0.0253],\n",
      "         [ 0.0682,  0.0809,  0.0321],\n",
      "         [ 0.0365, -0.0770, -0.0693],\n",
      "         ...,\n",
      "         [-0.0265,  0.0719,  0.0583],\n",
      "         [ 0.0820,  0.0425, -0.0899],\n",
      "         [-0.0440, -0.0805, -0.0815]],\n",
      "\n",
      "        [[ 0.0882, -0.0511,  0.0053],\n",
      "         [-0.0558,  0.0011,  0.0542],\n",
      "         [ 0.0367,  0.0522, -0.0979],\n",
      "         ...,\n",
      "         [-0.0815,  0.0221,  0.0615],\n",
      "         [-0.0427,  0.1012,  0.0583],\n",
      "         [-0.0932, -0.0546, -0.0815]],\n",
      "\n",
      "        [[ 0.0568,  0.0330,  0.0514],\n",
      "         [-0.0652, -0.0572, -0.0913],\n",
      "         [-0.0379,  0.0251,  0.0679],\n",
      "         ...,\n",
      "         [ 0.0127,  0.0012, -0.0135],\n",
      "         [-0.0445, -0.0669,  0.0543],\n",
      "         [ 0.0879, -0.0368, -0.0559]]])), ('block_4.0.parametrizations.weight.0.mask', tensor([[[False, False, False],\n",
      "         [False, False,  True],\n",
      "         [ True, False, False],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True, False, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[ True,  True, False],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [ True, False, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False,  True]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [False,  True,  True],\n",
      "         [ True, False,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [ True,  True,  True],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False,  True, False],\n",
      "         [ True, False, False]]])), ('linear.bias', tensor([ 0.1015, -0.0603, -0.1208, -0.0205,  0.0865,  0.0243, -0.0639, -0.0232,\n",
      "         0.0621,  0.0614])), ('linear.parametrizations.weight.original', tensor([[-0.0305, -0.1249, -0.0250, -0.0066,  0.1101, -0.1192, -0.0567,  0.1167,\n",
      "         -0.0117, -0.0792,  0.0802, -0.0242,  0.0132,  0.1125,  0.0541,  0.1193,\n",
      "         -0.0320,  0.0606, -0.0033,  0.0063, -0.0799, -0.0009, -0.1026,  0.0924,\n",
      "         -0.0100,  0.0095,  0.0075,  0.0250,  0.0294,  0.0659,  0.0638, -0.0863,\n",
      "          0.0894,  0.0472,  0.1228, -0.0490,  0.0817,  0.1119,  0.0616,  0.0227,\n",
      "          0.0870, -0.0899, -0.0463,  0.1199, -0.0707, -0.0470,  0.0313,  0.1222,\n",
      "         -0.1060, -0.0777,  0.0585,  0.1225,  0.0879, -0.0823,  0.1219, -0.0608,\n",
      "         -0.0357, -0.0518, -0.0641,  0.0708, -0.0375, -0.0786, -0.1033, -0.0672],\n",
      "        [-0.0518, -0.0111, -0.0859,  0.0105, -0.0430, -0.0366, -0.0081, -0.0481,\n",
      "         -0.0094, -0.0896,  0.0636,  0.0834,  0.0291,  0.0397,  0.0091,  0.0655,\n",
      "         -0.0245,  0.0517, -0.0797, -0.0586,  0.0143, -0.0479, -0.0039, -0.0946,\n",
      "         -0.0880,  0.0094, -0.0381,  0.1002, -0.0291,  0.0634,  0.1136,  0.0449,\n",
      "         -0.0979, -0.1236,  0.0002, -0.1040,  0.0900,  0.0394, -0.0793, -0.1208,\n",
      "          0.0804, -0.1134, -0.1022,  0.1176,  0.0187, -0.0395,  0.0036,  0.0525,\n",
      "          0.1228,  0.1034, -0.0718,  0.1078, -0.0706, -0.0868, -0.0718, -0.0656,\n",
      "         -0.0418,  0.0394, -0.1239, -0.0680,  0.0649,  0.0439, -0.1093, -0.0990],\n",
      "        [ 0.0796, -0.0468, -0.1168,  0.0924,  0.1067, -0.0999,  0.0691,  0.1055,\n",
      "          0.0672,  0.0963,  0.1074,  0.0392, -0.0639,  0.0775,  0.0903,  0.0376,\n",
      "         -0.0508, -0.0262,  0.0371,  0.1027,  0.0512, -0.0568, -0.0024, -0.0496,\n",
      "         -0.0531, -0.0719,  0.1026, -0.0616, -0.0406,  0.1120, -0.0686, -0.1079,\n",
      "         -0.1135,  0.0418,  0.0085, -0.0667,  0.1022, -0.0452, -0.0240, -0.1242,\n",
      "          0.0178, -0.0391, -0.0008, -0.0943,  0.0855,  0.0839,  0.0258, -0.0295,\n",
      "          0.0969,  0.0097, -0.0487, -0.0782,  0.0017, -0.0918, -0.1112, -0.0236,\n",
      "         -0.0943, -0.0382,  0.0270,  0.0932, -0.0933, -0.0082,  0.0383,  0.0712],\n",
      "        [ 0.0315,  0.0899, -0.1056,  0.1178,  0.0594, -0.0490,  0.1029, -0.0590,\n",
      "          0.0432,  0.0047,  0.0280, -0.0408,  0.0076,  0.0604, -0.1039, -0.0594,\n",
      "          0.0949,  0.0638, -0.0221, -0.0865,  0.1090,  0.0981, -0.0991,  0.0188,\n",
      "          0.0742,  0.1212,  0.0214,  0.0149,  0.0519,  0.0207,  0.0492,  0.0971,\n",
      "         -0.0742, -0.0483, -0.0756,  0.0872,  0.0375, -0.0763,  0.0664, -0.0996,\n",
      "         -0.0852,  0.0598, -0.0740, -0.0206,  0.0690, -0.1130, -0.0051,  0.0858,\n",
      "         -0.0175,  0.0803, -0.0396, -0.1026, -0.0679,  0.0469, -0.0008,  0.0329,\n",
      "          0.1061,  0.1132,  0.1028,  0.0213,  0.0172, -0.0638,  0.0790,  0.0371],\n",
      "        [ 0.1067, -0.0995, -0.0347,  0.0068,  0.0163,  0.0711, -0.1242, -0.0620,\n",
      "         -0.0373,  0.0256,  0.0116, -0.0887,  0.1187,  0.0617,  0.0185,  0.0242,\n",
      "          0.1014,  0.0407, -0.1067, -0.0636,  0.0834,  0.0795,  0.0579, -0.0992,\n",
      "         -0.0506, -0.0844, -0.0479, -0.0250, -0.1021,  0.0717,  0.0866, -0.0033,\n",
      "          0.0148,  0.0119, -0.1211, -0.0586, -0.0765, -0.0673, -0.0722, -0.0274,\n",
      "         -0.0493,  0.0445, -0.1005,  0.1065,  0.0591,  0.0998, -0.0062, -0.1039,\n",
      "          0.0015,  0.0606,  0.1087, -0.1079, -0.0609,  0.0301, -0.0971,  0.0815,\n",
      "         -0.0571,  0.0360,  0.0361,  0.0892, -0.0242,  0.1019,  0.0111,  0.1193],\n",
      "        [-0.0751,  0.1161,  0.0793,  0.1139,  0.0720,  0.0903,  0.0717, -0.0843,\n",
      "          0.1096, -0.1029,  0.1095, -0.0607, -0.0066,  0.1032,  0.0744,  0.0712,\n",
      "         -0.0222,  0.0558,  0.1005, -0.1206,  0.0551, -0.0197,  0.0200, -0.0997,\n",
      "         -0.0685,  0.0740, -0.0433, -0.0515,  0.0032,  0.1070, -0.0327, -0.0049,\n",
      "          0.1229,  0.0888,  0.0764,  0.0815,  0.1044, -0.0096,  0.1020,  0.0195,\n",
      "         -0.0409,  0.1154, -0.1239, -0.0261,  0.1226,  0.0213,  0.0804,  0.0827,\n",
      "          0.0248,  0.0703,  0.0775,  0.0488,  0.1137, -0.0075, -0.0577,  0.0760,\n",
      "         -0.0806, -0.0713,  0.0440,  0.0105,  0.0393, -0.0105,  0.0832, -0.0833],\n",
      "        [-0.0932,  0.0699,  0.0114, -0.0823,  0.0928, -0.0212,  0.0542, -0.0006,\n",
      "          0.0407,  0.0205, -0.0276,  0.0745, -0.1231, -0.0190, -0.0273,  0.0119,\n",
      "         -0.0821, -0.0752, -0.1196, -0.1073,  0.1070,  0.1143,  0.0815,  0.0268,\n",
      "          0.0913, -0.0573,  0.0530, -0.1025, -0.1177,  0.1004, -0.0287,  0.0028,\n",
      "          0.1182,  0.0651,  0.0295, -0.0865,  0.0994, -0.0648, -0.1058,  0.1042,\n",
      "         -0.1238,  0.1107,  0.0417, -0.1176, -0.0537, -0.0271,  0.0282, -0.0706,\n",
      "         -0.0020, -0.0114,  0.0894,  0.0946,  0.0255,  0.0618, -0.0074, -0.0661,\n",
      "         -0.0201, -0.1066,  0.1073, -0.0201,  0.0790,  0.0373, -0.0872,  0.0669],\n",
      "        [-0.0200, -0.1013,  0.1021,  0.1004, -0.1207, -0.1121, -0.0852, -0.0818,\n",
      "          0.0959,  0.1220,  0.0122, -0.0013, -0.0238, -0.0842,  0.0380,  0.0133,\n",
      "          0.0822, -0.0004, -0.0777, -0.0006, -0.1081,  0.0122, -0.0402,  0.0630,\n",
      "          0.0430, -0.0520, -0.0895, -0.0072,  0.0540,  0.0797,  0.1083, -0.1244,\n",
      "          0.1041,  0.0813,  0.0362, -0.1030,  0.0804, -0.0258,  0.0850,  0.0583,\n",
      "         -0.1210, -0.0521,  0.0912,  0.0013,  0.0869,  0.0165,  0.0902,  0.0358,\n",
      "         -0.0243, -0.1175,  0.0964, -0.0201,  0.0570, -0.0913,  0.0404,  0.0893,\n",
      "         -0.0419, -0.0613,  0.0785, -0.0845,  0.1035, -0.0634,  0.0175, -0.0493],\n",
      "        [ 0.0388, -0.0753, -0.1036, -0.0512, -0.0078, -0.1128, -0.1167,  0.1079,\n",
      "         -0.0255,  0.0243,  0.0449, -0.0670, -0.1237, -0.0102, -0.0635,  0.1225,\n",
      "          0.0443, -0.1126, -0.0015, -0.0533,  0.1142, -0.0192,  0.0076,  0.0846,\n",
      "         -0.0915,  0.1137,  0.0703,  0.0469, -0.0645,  0.0119, -0.0699, -0.1047,\n",
      "         -0.0350,  0.0749,  0.0763, -0.0440,  0.0839,  0.1152, -0.0354,  0.0434,\n",
      "         -0.1028, -0.0113,  0.0044,  0.0996,  0.0210,  0.0431, -0.0318, -0.0325,\n",
      "         -0.0930, -0.0049, -0.0234, -0.0534,  0.1081, -0.0817,  0.0610,  0.0971,\n",
      "          0.0748,  0.0814,  0.1016,  0.0274,  0.0165, -0.0218, -0.0295, -0.0570],\n",
      "        [ 0.0792, -0.0282, -0.0505, -0.0764, -0.0447, -0.0543, -0.1059,  0.0090,\n",
      "         -0.0753,  0.0234, -0.0836,  0.0617, -0.1249, -0.0309, -0.0148, -0.0891,\n",
      "          0.1081, -0.0224, -0.1231, -0.0089,  0.0523,  0.0211, -0.0144,  0.1027,\n",
      "          0.0285,  0.1040, -0.0108, -0.0526, -0.1016,  0.0051, -0.0232,  0.1078,\n",
      "          0.0514, -0.0586, -0.0378,  0.1012, -0.1089,  0.0674,  0.1109, -0.0039,\n",
      "          0.0280, -0.0743,  0.0260, -0.0203, -0.0993,  0.0533,  0.0363,  0.1013,\n",
      "          0.0535,  0.0293,  0.0484, -0.0590,  0.0899,  0.0576,  0.0930, -0.0037,\n",
      "          0.1187,  0.0870, -0.0086, -0.1009, -0.0745, -0.0309,  0.0918,  0.0785]])), ('linear.parametrizations.weight.0.mask', tensor([[False,  True, False, False,  True,  True,  True,  True, False,  True,\n",
      "          True, False, False,  True, False,  True, False,  True, False, False,\n",
      "          True, False,  True,  True, False, False, False, False, False,  True,\n",
      "          True,  True,  True, False,  True, False,  True,  True,  True, False,\n",
      "          True,  True, False,  True,  True, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
      "         False,  True,  True,  True],\n",
      "        [False, False,  True, False, False, False, False, False, False,  True,\n",
      "          True,  True, False, False, False,  True, False, False,  True,  True,\n",
      "         False, False, False,  True,  True, False, False,  True, False,  True,\n",
      "          True, False,  True,  True, False,  True,  True, False,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
      "          True, False,  True,  True],\n",
      "        [ True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False,  True,  True,  True, False, False, False, False,  True,\n",
      "         False,  True, False, False, False,  True,  True,  True, False,  True,\n",
      "          True,  True,  True, False, False,  True,  True, False, False,  True,\n",
      "         False, False, False,  True,  True,  True, False, False,  True, False,\n",
      "         False,  True, False,  True,  True, False,  True, False, False,  True,\n",
      "          True, False, False,  True],\n",
      "        [False,  True,  True,  True,  True, False,  True,  True, False, False,\n",
      "         False, False, False,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "         False,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True, False,  True, False,  True,\n",
      "         False,  True,  True, False, False, False,  True,  True,  True, False,\n",
      "         False,  True,  True, False],\n",
      "        [ True,  True, False, False, False,  True,  True,  True, False, False,\n",
      "         False,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "          True,  True,  True,  True, False,  True, False, False,  True,  True,\n",
      "          True, False, False, False,  True,  True,  True,  True,  True, False,\n",
      "         False, False,  True,  True,  True,  True, False,  True, False,  True,\n",
      "          True,  True,  True, False,  True,  True,  True, False, False,  True,\n",
      "         False,  True, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
      "         False, False, False,  True,  True,  True, False, False, False,  True,\n",
      "         False, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         False,  True,  True, False,  True, False,  True,  True, False,  True,\n",
      "          True, False,  True, False,  True,  True,  True,  True, False, False,\n",
      "         False, False,  True,  True],\n",
      "        [ True,  True, False,  True,  True, False, False, False, False, False,\n",
      "         False,  True,  True, False, False, False,  True,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
      "         False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True, False, False, False,  True, False, False,\n",
      "          True,  True, False,  True, False,  True, False,  True,  True, False,\n",
      "          True, False,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False,  True, False, False,  True, False,  True, False,\n",
      "          True, False, False,  True, False, False,  True, False, False,  True,\n",
      "          True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
      "          True, False,  True, False,  True, False,  True, False, False,  True,\n",
      "          True, False,  True,  True, False,  True, False,  True,  True,  True,\n",
      "          True,  True, False, False],\n",
      "        [False,  True,  True, False, False,  True,  True,  True, False, False,\n",
      "         False,  True,  True, False,  True,  True, False,  True, False, False,\n",
      "          True, False, False,  True,  True,  True,  True, False,  True, False,\n",
      "          True,  True, False,  True,  True, False,  True,  True, False, False,\n",
      "          True, False, False,  True, False, False, False, False,  True, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False,  True],\n",
      "        [ True, False, False,  True, False, False,  True, False,  True, False,\n",
      "          True,  True,  True, False, False,  True,  True, False,  True, False,\n",
      "         False, False, False,  True, False,  True, False, False,  True, False,\n",
      "         False,  True, False,  True, False,  True,  True,  True,  True, False,\n",
      "         False,  True, False, False,  True, False, False,  True, False, False,\n",
      "         False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
      "          True, False,  True,  True]]))])\n"
     ]
    }
   ],
   "source": [
    "print(mg.model.state_dict())\n",
    "#print(node.meta['mase'].parameters['common']['args']['weight']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_2\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
