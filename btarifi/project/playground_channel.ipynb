{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model_name = \"toy_convnet\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_1_0\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0406,  0.1007,  0.1421],\n",
      "          [-0.0221, -0.1440, -0.0653],\n",
      "          [-0.1475,  0.1540,  0.1288]],\n",
      "\n",
      "         [[ 0.1485,  0.1614, -0.1640],\n",
      "          [ 0.1323, -0.0085, -0.1097],\n",
      "          [-0.1292,  0.1169,  0.0516]],\n",
      "\n",
      "         [[ 0.1849,  0.0419, -0.1325],\n",
      "          [-0.0087,  0.1468,  0.1605],\n",
      "          [ 0.0924,  0.1582, -0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1416,  0.1599, -0.1145],\n",
      "          [-0.0103,  0.1711,  0.0970],\n",
      "          [-0.0603,  0.1344, -0.1182]],\n",
      "\n",
      "         [[-0.1316, -0.0681, -0.1880],\n",
      "          [-0.0262, -0.0429,  0.1686],\n",
      "          [-0.1269, -0.1366, -0.1418]],\n",
      "\n",
      "         [[ 0.0225, -0.1792,  0.1807],\n",
      "          [ 0.0951,  0.0091, -0.1411],\n",
      "          [ 0.0601,  0.1470, -0.1021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0810, -0.1291,  0.0744],\n",
      "          [ 0.1471,  0.0882, -0.0180],\n",
      "          [-0.1234,  0.0954, -0.0194]],\n",
      "\n",
      "         [[ 0.1366, -0.1777, -0.0891],\n",
      "          [-0.0346,  0.1356, -0.0091],\n",
      "          [ 0.1674, -0.1539,  0.0350]],\n",
      "\n",
      "         [[ 0.0273,  0.1130, -0.0673],\n",
      "          [-0.1461,  0.1065, -0.0848],\n",
      "          [ 0.1857, -0.1824,  0.0763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0598,  0.0963, -0.1213],\n",
      "          [ 0.1782, -0.1071, -0.0746],\n",
      "          [ 0.0090,  0.1170,  0.0135]],\n",
      "\n",
      "         [[ 0.1506, -0.0696,  0.0609],\n",
      "          [-0.1584, -0.1119, -0.1438],\n",
      "          [-0.1626, -0.1916,  0.0362]],\n",
      "\n",
      "         [[-0.1192, -0.1208, -0.0578],\n",
      "          [ 0.1442,  0.0219,  0.1712],\n",
      "          [-0.1368,  0.1336, -0.1064]]],\n",
      "\n",
      "\n",
      "        [[[-0.0817, -0.0773, -0.0628],\n",
      "          [ 0.1299,  0.0479,  0.0830],\n",
      "          [ 0.1074, -0.0844, -0.0222]],\n",
      "\n",
      "         [[ 0.1194,  0.0104, -0.0993],\n",
      "          [-0.1139,  0.0847, -0.1772],\n",
      "          [ 0.1733,  0.0849, -0.0012]],\n",
      "\n",
      "         [[-0.0200,  0.1010,  0.0856],\n",
      "          [ 0.1123,  0.0974,  0.1572],\n",
      "          [-0.1208,  0.0224, -0.1695]]],\n",
      "\n",
      "\n",
      "        [[[-0.0486,  0.1279,  0.0149],\n",
      "          [-0.1167, -0.0106,  0.0712],\n",
      "          [-0.1151,  0.1651, -0.1414]],\n",
      "\n",
      "         [[-0.1388, -0.1870, -0.0405],\n",
      "          [-0.1244,  0.1355, -0.1445],\n",
      "          [-0.0775, -0.1158,  0.1870]],\n",
      "\n",
      "         [[-0.0934,  0.0885,  0.0277],\n",
      "          [ 0.1747,  0.1426,  0.0251],\n",
      "          [ 0.0107,  0.1865,  0.0817]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1580, -0.1199, -0.0287],\n",
      "          [ 0.0092,  0.0841, -0.1081],\n",
      "          [ 0.1268, -0.1224, -0.1264]],\n",
      "\n",
      "         [[ 0.0032,  0.0649, -0.0257],\n",
      "          [ 0.0736, -0.1194,  0.0965],\n",
      "          [ 0.1304, -0.1857,  0.1024]],\n",
      "\n",
      "         [[-0.1260,  0.1910,  0.0116],\n",
      "          [-0.0586, -0.0959,  0.0670],\n",
      "          [-0.0405,  0.0341,  0.1897]]],\n",
      "\n",
      "\n",
      "        [[[-0.1750, -0.0832,  0.0673],\n",
      "          [-0.1837,  0.1514,  0.0399],\n",
      "          [-0.1817, -0.0467, -0.1066]],\n",
      "\n",
      "         [[-0.0891, -0.1119,  0.0654],\n",
      "          [ 0.0618, -0.0191,  0.0971],\n",
      "          [ 0.1671,  0.1923,  0.1600]],\n",
      "\n",
      "         [[-0.1406,  0.0052, -0.1565],\n",
      "          [-0.1563,  0.0059,  0.1823],\n",
      "          [-0.1120,  0.0636,  0.0079]]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[ 0.0406,  0.1007,  0.1421],\n",
      "          [-0.0221, -0.1440, -0.0653],\n",
      "          [-0.1475,  0.1540,  0.1288]],\n",
      "\n",
      "         [[ 0.1485,  0.1614, -0.1640],\n",
      "          [ 0.1323, -0.0085, -0.1097],\n",
      "          [-0.1292,  0.1169,  0.0516]],\n",
      "\n",
      "         [[ 0.1849,  0.0419, -0.1325],\n",
      "          [-0.0087,  0.1468,  0.1605],\n",
      "          [ 0.0924,  0.1582, -0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1416,  0.1599, -0.1145],\n",
      "          [-0.0103,  0.1711,  0.0970],\n",
      "          [-0.0603,  0.1344, -0.1182]],\n",
      "\n",
      "         [[-0.1316, -0.0681, -0.1880],\n",
      "          [-0.0262, -0.0429,  0.1686],\n",
      "          [-0.1269, -0.1366, -0.1418]],\n",
      "\n",
      "         [[ 0.0225, -0.1792,  0.1807],\n",
      "          [ 0.0951,  0.0091, -0.1411],\n",
      "          [ 0.0601,  0.1470, -0.1021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0810, -0.1291,  0.0744],\n",
      "          [ 0.1471,  0.0882, -0.0180],\n",
      "          [-0.1234,  0.0954, -0.0194]],\n",
      "\n",
      "         [[ 0.1366, -0.1777, -0.0891],\n",
      "          [-0.0346,  0.1356, -0.0091],\n",
      "          [ 0.1674, -0.1539,  0.0350]],\n",
      "\n",
      "         [[ 0.0273,  0.1130, -0.0673],\n",
      "          [-0.1461,  0.1065, -0.0848],\n",
      "          [ 0.1857, -0.1824,  0.0763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0598,  0.0963, -0.1213],\n",
      "          [ 0.1782, -0.1071, -0.0746],\n",
      "          [ 0.0090,  0.1170,  0.0135]],\n",
      "\n",
      "         [[ 0.1506, -0.0696,  0.0609],\n",
      "          [-0.1584, -0.1119, -0.1438],\n",
      "          [-0.1626, -0.1916,  0.0362]],\n",
      "\n",
      "         [[-0.1192, -0.1208, -0.0578],\n",
      "          [ 0.1442,  0.0219,  0.1712],\n",
      "          [-0.1368,  0.1336, -0.1064]]],\n",
      "\n",
      "\n",
      "        [[[-0.0817, -0.0773, -0.0628],\n",
      "          [ 0.1299,  0.0479,  0.0830],\n",
      "          [ 0.1074, -0.0844, -0.0222]],\n",
      "\n",
      "         [[ 0.1194,  0.0104, -0.0993],\n",
      "          [-0.1139,  0.0847, -0.1772],\n",
      "          [ 0.1733,  0.0849, -0.0012]],\n",
      "\n",
      "         [[-0.0200,  0.1010,  0.0856],\n",
      "          [ 0.1123,  0.0974,  0.1572],\n",
      "          [-0.1208,  0.0224, -0.1695]]],\n",
      "\n",
      "\n",
      "        [[[-0.0486,  0.1279,  0.0149],\n",
      "          [-0.1167, -0.0106,  0.0712],\n",
      "          [-0.1151,  0.1651, -0.1414]],\n",
      "\n",
      "         [[-0.1388, -0.1870, -0.0405],\n",
      "          [-0.1244,  0.1355, -0.1445],\n",
      "          [-0.0775, -0.1158,  0.1870]],\n",
      "\n",
      "         [[-0.0934,  0.0885,  0.0277],\n",
      "          [ 0.1747,  0.1426,  0.0251],\n",
      "          [ 0.0107,  0.1865,  0.0817]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1580, -0.1199, -0.0287],\n",
      "          [ 0.0092,  0.0841, -0.1081],\n",
      "          [ 0.1268, -0.1224, -0.1264]],\n",
      "\n",
      "         [[ 0.0032,  0.0649, -0.0257],\n",
      "          [ 0.0736, -0.1194,  0.0965],\n",
      "          [ 0.1304, -0.1857,  0.1024]],\n",
      "\n",
      "         [[-0.1260,  0.1910,  0.0116],\n",
      "          [-0.0586, -0.0959,  0.0670],\n",
      "          [-0.0405,  0.0341,  0.1897]]],\n",
      "\n",
      "\n",
      "        [[[-0.1750, -0.0832,  0.0673],\n",
      "          [-0.1837,  0.1514,  0.0399],\n",
      "          [-0.1817, -0.0467, -0.1066]],\n",
      "\n",
      "         [[-0.0891, -0.1119,  0.0654],\n",
      "          [ 0.0618, -0.0191,  0.0971],\n",
      "          [ 0.1671,  0.1923,  0.1600]],\n",
      "\n",
      "         [[-0.1406,  0.0052, -0.1565],\n",
      "          [-0.1563,  0.0059,  0.1823],\n",
      "          [-0.1120,  0.0636,  0.0079]]]])),\n",
      "             ('bias',\n",
      "              tensor([-0.1864, -0.0948,  0.1576,  0.0204,  0.0939,  0.0537, -0.0333,  0.0869]))])\n",
      "--------------------------------------------------\n",
      "block_2_0\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0611,  0.0164,  0.1130],\n",
      "          [-0.0371,  0.0624,  0.0826],\n",
      "          [ 0.0718, -0.0182,  0.0154]],\n",
      "\n",
      "         [[-0.0287,  0.0853,  0.0014],\n",
      "          [-0.0274,  0.0515, -0.0554],\n",
      "          [-0.0579,  0.0320,  0.0008]],\n",
      "\n",
      "         [[-0.0296,  0.0570,  0.0622],\n",
      "          [ 0.0526, -0.0176, -0.0089],\n",
      "          [-0.0179,  0.0131,  0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1138, -0.0908, -0.0329],\n",
      "          [-0.0067, -0.1145,  0.0122],\n",
      "          [ 0.0287,  0.0965, -0.0784]],\n",
      "\n",
      "         [[ 0.0062,  0.0421,  0.1090],\n",
      "          [ 0.0736,  0.0586,  0.0290],\n",
      "          [ 0.0191, -0.0848, -0.0078]],\n",
      "\n",
      "         [[-0.1152, -0.0443,  0.0509],\n",
      "          [ 0.1034, -0.0729, -0.0561],\n",
      "          [ 0.1080, -0.0946,  0.0326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0070, -0.1118, -0.0661],\n",
      "          [-0.0120,  0.0321, -0.1147],\n",
      "          [-0.0968,  0.0658, -0.0577]],\n",
      "\n",
      "         [[-0.0476,  0.0913,  0.0538],\n",
      "          [-0.0688, -0.1113,  0.0271],\n",
      "          [-0.0276,  0.0268,  0.0719]],\n",
      "\n",
      "         [[-0.0045, -0.0481, -0.0247],\n",
      "          [ 0.0384,  0.0567,  0.0864],\n",
      "          [-0.0800,  0.0653, -0.0172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473,  0.0766,  0.1104],\n",
      "          [ 0.0868, -0.1010, -0.0890],\n",
      "          [-0.0535,  0.0543, -0.0734]],\n",
      "\n",
      "         [[-0.0918,  0.0879, -0.0543],\n",
      "          [-0.0655,  0.0471, -0.0266],\n",
      "          [ 0.0050,  0.0833,  0.1167]],\n",
      "\n",
      "         [[-0.1031, -0.0737, -0.0711],\n",
      "          [-0.0475, -0.1030,  0.0766],\n",
      "          [-0.0751,  0.0110,  0.1053]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305, -0.0760,  0.0492],\n",
      "          [-0.0758,  0.0152,  0.0184],\n",
      "          [ 0.0723, -0.1092, -0.0260]],\n",
      "\n",
      "         [[ 0.0735, -0.0106, -0.0632],\n",
      "          [ 0.0307,  0.0681, -0.0954],\n",
      "          [-0.0106, -0.0574, -0.1169]],\n",
      "\n",
      "         [[ 0.0367, -0.1056, -0.0850],\n",
      "          [ 0.0761,  0.0666, -0.0217],\n",
      "          [ 0.0418,  0.0414, -0.0929]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0464, -0.0872, -0.0223],\n",
      "          [ 0.0944,  0.0671, -0.0512],\n",
      "          [ 0.0983, -0.0897,  0.0658]],\n",
      "\n",
      "         [[ 0.0106,  0.1177, -0.0287],\n",
      "          [-0.1165,  0.1025,  0.0934],\n",
      "          [ 0.0167,  0.0274,  0.0527]],\n",
      "\n",
      "         [[-0.1158, -0.0558,  0.0898],\n",
      "          [ 0.0322, -0.0041,  0.0737],\n",
      "          [ 0.0700,  0.0941, -0.1168]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0650,  0.0072,  0.0063],\n",
      "          [-0.1058,  0.0621,  0.0030],\n",
      "          [ 0.0538, -0.0489,  0.0346]],\n",
      "\n",
      "         [[-0.0906,  0.1165, -0.0432],\n",
      "          [-0.1060, -0.0420, -0.0935],\n",
      "          [ 0.0982,  0.0706, -0.1168]],\n",
      "\n",
      "         [[ 0.1039,  0.0222,  0.0852],\n",
      "          [-0.0435, -0.0578,  0.0255],\n",
      "          [ 0.0421, -0.0516, -0.0621]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0984, -0.0287,  0.0116],\n",
      "          [ 0.0590,  0.0524, -0.0611],\n",
      "          [ 0.0448,  0.0037,  0.0849]],\n",
      "\n",
      "         [[ 0.0473, -0.1120, -0.0469],\n",
      "          [-0.1079,  0.0507,  0.0954],\n",
      "          [-0.0556,  0.1080,  0.0293]],\n",
      "\n",
      "         [[ 0.0602, -0.0662,  0.0321],\n",
      "          [-0.0780,  0.0770,  0.0580],\n",
      "          [ 0.0168, -0.0566, -0.0645]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1048, -0.0489,  0.0952],\n",
      "          [-0.0925, -0.0539, -0.0379],\n",
      "          [ 0.0835, -0.0801,  0.0607]],\n",
      "\n",
      "         [[-0.1097, -0.1081, -0.0405],\n",
      "          [-0.0429, -0.0999,  0.0429],\n",
      "          [ 0.0950,  0.0661, -0.0161]],\n",
      "\n",
      "         [[-0.0819,  0.0986, -0.0913],\n",
      "          [-0.0309,  0.0272,  0.0791],\n",
      "          [-0.0991, -0.0275,  0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0170, -0.1023, -0.0328],\n",
      "          [ 0.0220,  0.0184,  0.0522],\n",
      "          [ 0.0339,  0.0847, -0.0344]],\n",
      "\n",
      "         [[-0.0698,  0.0153,  0.0023],\n",
      "          [-0.0586,  0.0906,  0.0257],\n",
      "          [ 0.0823, -0.0116, -0.0053]],\n",
      "\n",
      "         [[-0.0683, -0.0525, -0.0624],\n",
      "          [ 0.0301,  0.0775,  0.0243],\n",
      "          [ 0.0196,  0.0876,  0.0641]]],\n",
      "\n",
      "\n",
      "        [[[-0.1083, -0.0719, -0.0998],\n",
      "          [-0.0950, -0.0540,  0.0690],\n",
      "          [-0.0727,  0.0403, -0.1131]],\n",
      "\n",
      "         [[-0.1166,  0.0886,  0.0706],\n",
      "          [ 0.0294, -0.0450, -0.1098],\n",
      "          [ 0.1116, -0.0764,  0.0377]],\n",
      "\n",
      "         [[-0.1072,  0.0018, -0.0024],\n",
      "          [ 0.0553,  0.0664,  0.0258],\n",
      "          [-0.0281,  0.0803,  0.0737]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1102, -0.1079, -0.0080],\n",
      "          [-0.0862,  0.0080,  0.0242],\n",
      "          [-0.0850, -0.0713, -0.0010]],\n",
      "\n",
      "         [[-0.0416,  0.0175,  0.1119],\n",
      "          [ 0.0563,  0.0239, -0.0980],\n",
      "          [-0.0943, -0.0897, -0.0107]],\n",
      "\n",
      "         [[-0.0694, -0.0834,  0.0876],\n",
      "          [-0.1129, -0.0245, -0.0993],\n",
      "          [ 0.0053,  0.1030,  0.0687]]]], requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[-0.0611,  0.0164,  0.1130],\n",
      "          [-0.0371,  0.0624,  0.0826],\n",
      "          [ 0.0718, -0.0182,  0.0154]],\n",
      "\n",
      "         [[-0.0287,  0.0853,  0.0014],\n",
      "          [-0.0274,  0.0515, -0.0554],\n",
      "          [-0.0579,  0.0320,  0.0008]],\n",
      "\n",
      "         [[-0.0296,  0.0570,  0.0622],\n",
      "          [ 0.0526, -0.0176, -0.0089],\n",
      "          [-0.0179,  0.0131,  0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1138, -0.0908, -0.0329],\n",
      "          [-0.0067, -0.1145,  0.0122],\n",
      "          [ 0.0287,  0.0965, -0.0784]],\n",
      "\n",
      "         [[ 0.0062,  0.0421,  0.1090],\n",
      "          [ 0.0736,  0.0586,  0.0290],\n",
      "          [ 0.0191, -0.0848, -0.0078]],\n",
      "\n",
      "         [[-0.1152, -0.0443,  0.0509],\n",
      "          [ 0.1034, -0.0729, -0.0561],\n",
      "          [ 0.1080, -0.0946,  0.0326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0070, -0.1118, -0.0661],\n",
      "          [-0.0120,  0.0321, -0.1147],\n",
      "          [-0.0968,  0.0658, -0.0577]],\n",
      "\n",
      "         [[-0.0476,  0.0913,  0.0538],\n",
      "          [-0.0688, -0.1113,  0.0271],\n",
      "          [-0.0276,  0.0268,  0.0719]],\n",
      "\n",
      "         [[-0.0045, -0.0481, -0.0247],\n",
      "          [ 0.0384,  0.0567,  0.0864],\n",
      "          [-0.0800,  0.0653, -0.0172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473,  0.0766,  0.1104],\n",
      "          [ 0.0868, -0.1010, -0.0890],\n",
      "          [-0.0535,  0.0543, -0.0734]],\n",
      "\n",
      "         [[-0.0918,  0.0879, -0.0543],\n",
      "          [-0.0655,  0.0471, -0.0266],\n",
      "          [ 0.0050,  0.0833,  0.1167]],\n",
      "\n",
      "         [[-0.1031, -0.0737, -0.0711],\n",
      "          [-0.0475, -0.1030,  0.0766],\n",
      "          [-0.0751,  0.0110,  0.1053]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305, -0.0760,  0.0492],\n",
      "          [-0.0758,  0.0152,  0.0184],\n",
      "          [ 0.0723, -0.1092, -0.0260]],\n",
      "\n",
      "         [[ 0.0735, -0.0106, -0.0632],\n",
      "          [ 0.0307,  0.0681, -0.0954],\n",
      "          [-0.0106, -0.0574, -0.1169]],\n",
      "\n",
      "         [[ 0.0367, -0.1056, -0.0850],\n",
      "          [ 0.0761,  0.0666, -0.0217],\n",
      "          [ 0.0418,  0.0414, -0.0929]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0464, -0.0872, -0.0223],\n",
      "          [ 0.0944,  0.0671, -0.0512],\n",
      "          [ 0.0983, -0.0897,  0.0658]],\n",
      "\n",
      "         [[ 0.0106,  0.1177, -0.0287],\n",
      "          [-0.1165,  0.1025,  0.0934],\n",
      "          [ 0.0167,  0.0274,  0.0527]],\n",
      "\n",
      "         [[-0.1158, -0.0558,  0.0898],\n",
      "          [ 0.0322, -0.0041,  0.0737],\n",
      "          [ 0.0700,  0.0941, -0.1168]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0650,  0.0072,  0.0063],\n",
      "          [-0.1058,  0.0621,  0.0030],\n",
      "          [ 0.0538, -0.0489,  0.0346]],\n",
      "\n",
      "         [[-0.0906,  0.1165, -0.0432],\n",
      "          [-0.1060, -0.0420, -0.0935],\n",
      "          [ 0.0982,  0.0706, -0.1168]],\n",
      "\n",
      "         [[ 0.1039,  0.0222,  0.0852],\n",
      "          [-0.0435, -0.0578,  0.0255],\n",
      "          [ 0.0421, -0.0516, -0.0621]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0984, -0.0287,  0.0116],\n",
      "          [ 0.0590,  0.0524, -0.0611],\n",
      "          [ 0.0448,  0.0037,  0.0849]],\n",
      "\n",
      "         [[ 0.0473, -0.1120, -0.0469],\n",
      "          [-0.1079,  0.0507,  0.0954],\n",
      "          [-0.0556,  0.1080,  0.0293]],\n",
      "\n",
      "         [[ 0.0602, -0.0662,  0.0321],\n",
      "          [-0.0780,  0.0770,  0.0580],\n",
      "          [ 0.0168, -0.0566, -0.0645]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1048, -0.0489,  0.0952],\n",
      "          [-0.0925, -0.0539, -0.0379],\n",
      "          [ 0.0835, -0.0801,  0.0607]],\n",
      "\n",
      "         [[-0.1097, -0.1081, -0.0405],\n",
      "          [-0.0429, -0.0999,  0.0429],\n",
      "          [ 0.0950,  0.0661, -0.0161]],\n",
      "\n",
      "         [[-0.0819,  0.0986, -0.0913],\n",
      "          [-0.0309,  0.0272,  0.0791],\n",
      "          [-0.0991, -0.0275,  0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0170, -0.1023, -0.0328],\n",
      "          [ 0.0220,  0.0184,  0.0522],\n",
      "          [ 0.0339,  0.0847, -0.0344]],\n",
      "\n",
      "         [[-0.0698,  0.0153,  0.0023],\n",
      "          [-0.0586,  0.0906,  0.0257],\n",
      "          [ 0.0823, -0.0116, -0.0053]],\n",
      "\n",
      "         [[-0.0683, -0.0525, -0.0624],\n",
      "          [ 0.0301,  0.0775,  0.0243],\n",
      "          [ 0.0196,  0.0876,  0.0641]]],\n",
      "\n",
      "\n",
      "        [[[-0.1083, -0.0719, -0.0998],\n",
      "          [-0.0950, -0.0540,  0.0690],\n",
      "          [-0.0727,  0.0403, -0.1131]],\n",
      "\n",
      "         [[-0.1166,  0.0886,  0.0706],\n",
      "          [ 0.0294, -0.0450, -0.1098],\n",
      "          [ 0.1116, -0.0764,  0.0377]],\n",
      "\n",
      "         [[-0.1072,  0.0018, -0.0024],\n",
      "          [ 0.0553,  0.0664,  0.0258],\n",
      "          [-0.0281,  0.0803,  0.0737]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1102, -0.1079, -0.0080],\n",
      "          [-0.0862,  0.0080,  0.0242],\n",
      "          [-0.0850, -0.0713, -0.0010]],\n",
      "\n",
      "         [[-0.0416,  0.0175,  0.1119],\n",
      "          [ 0.0563,  0.0239, -0.0980],\n",
      "          [-0.0943, -0.0897, -0.0107]],\n",
      "\n",
      "         [[-0.0694, -0.0834,  0.0876],\n",
      "          [-0.1129, -0.0245, -0.0993],\n",
      "          [ 0.0053,  0.1030,  0.0687]]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.0648, -0.0901, -0.1004, -0.0257,  0.0434, -0.0964,  0.0967, -0.0084,\n",
      "         0.0550, -0.1066,  0.0467,  0.0750, -0.0154, -0.0640,  0.1017, -0.0980]))])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv2d':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        pprint(mg.modules[node.target].state_dict())\n",
    "        print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried\n",
      "Reached3\n",
      "Mask3\n",
      "tensor([[[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]]])\n",
      "Tensor3\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0406,  0.1007,  0.1421],\n",
      "          [-0.0221, -0.1440, -0.0653],\n",
      "          [-0.1475,  0.1540,  0.1288]],\n",
      "\n",
      "         [[ 0.1485,  0.1614, -0.1640],\n",
      "          [ 0.1323, -0.0085, -0.1097],\n",
      "          [-0.1292,  0.1169,  0.0516]],\n",
      "\n",
      "         [[ 0.1849,  0.0419, -0.1325],\n",
      "          [-0.0087,  0.1468,  0.1605],\n",
      "          [ 0.0924,  0.1582, -0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1416,  0.1599, -0.1145],\n",
      "          [-0.0103,  0.1711,  0.0970],\n",
      "          [-0.0603,  0.1344, -0.1182]],\n",
      "\n",
      "         [[-0.1316, -0.0681, -0.1880],\n",
      "          [-0.0262, -0.0429,  0.1686],\n",
      "          [-0.1269, -0.1366, -0.1418]],\n",
      "\n",
      "         [[ 0.0225, -0.1792,  0.1807],\n",
      "          [ 0.0951,  0.0091, -0.1411],\n",
      "          [ 0.0601,  0.1470, -0.1021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0810, -0.1291,  0.0744],\n",
      "          [ 0.1471,  0.0882, -0.0180],\n",
      "          [-0.1234,  0.0954, -0.0194]],\n",
      "\n",
      "         [[ 0.1366, -0.1777, -0.0891],\n",
      "          [-0.0346,  0.1356, -0.0091],\n",
      "          [ 0.1674, -0.1539,  0.0350]],\n",
      "\n",
      "         [[ 0.0273,  0.1130, -0.0673],\n",
      "          [-0.1461,  0.1065, -0.0848],\n",
      "          [ 0.1857, -0.1824,  0.0763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0598,  0.0963, -0.1213],\n",
      "          [ 0.1782, -0.1071, -0.0746],\n",
      "          [ 0.0090,  0.1170,  0.0135]],\n",
      "\n",
      "         [[ 0.1506, -0.0696,  0.0609],\n",
      "          [-0.1584, -0.1119, -0.1438],\n",
      "          [-0.1626, -0.1916,  0.0362]],\n",
      "\n",
      "         [[-0.1192, -0.1208, -0.0578],\n",
      "          [ 0.1442,  0.0219,  0.1712],\n",
      "          [-0.1368,  0.1336, -0.1064]]],\n",
      "\n",
      "\n",
      "        [[[-0.0817, -0.0773, -0.0628],\n",
      "          [ 0.1299,  0.0479,  0.0830],\n",
      "          [ 0.1074, -0.0844, -0.0222]],\n",
      "\n",
      "         [[ 0.1194,  0.0104, -0.0993],\n",
      "          [-0.1139,  0.0847, -0.1772],\n",
      "          [ 0.1733,  0.0849, -0.0012]],\n",
      "\n",
      "         [[-0.0200,  0.1010,  0.0856],\n",
      "          [ 0.1123,  0.0974,  0.1572],\n",
      "          [-0.1208,  0.0224, -0.1695]]],\n",
      "\n",
      "\n",
      "        [[[-0.0486,  0.1279,  0.0149],\n",
      "          [-0.1167, -0.0106,  0.0712],\n",
      "          [-0.1151,  0.1651, -0.1414]],\n",
      "\n",
      "         [[-0.1388, -0.1870, -0.0405],\n",
      "          [-0.1244,  0.1355, -0.1445],\n",
      "          [-0.0775, -0.1158,  0.1870]],\n",
      "\n",
      "         [[-0.0934,  0.0885,  0.0277],\n",
      "          [ 0.1747,  0.1426,  0.0251],\n",
      "          [ 0.0107,  0.1865,  0.0817]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1580, -0.1199, -0.0287],\n",
      "          [ 0.0092,  0.0841, -0.1081],\n",
      "          [ 0.1268, -0.1224, -0.1264]],\n",
      "\n",
      "         [[ 0.0032,  0.0649, -0.0257],\n",
      "          [ 0.0736, -0.1194,  0.0965],\n",
      "          [ 0.1304, -0.1857,  0.1024]],\n",
      "\n",
      "         [[-0.1260,  0.1910,  0.0116],\n",
      "          [-0.0586, -0.0959,  0.0670],\n",
      "          [-0.0405,  0.0341,  0.1897]]],\n",
      "\n",
      "\n",
      "        [[[-0.1750, -0.0832,  0.0673],\n",
      "          [-0.1837,  0.1514,  0.0399],\n",
      "          [-0.1817, -0.0467, -0.1066]],\n",
      "\n",
      "         [[-0.0891, -0.1119,  0.0654],\n",
      "          [ 0.0618, -0.0191,  0.0971],\n",
      "          [ 0.1671,  0.1923,  0.1600]],\n",
      "\n",
      "         [[-0.1406,  0.0052, -0.1565],\n",
      "          [-0.1563,  0.0059,  0.1823],\n",
      "          [-0.1120,  0.0636,  0.0079]]]], requires_grad=True)\n",
      "Reached3\n",
      "Mask3\n",
      "tensor([[[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]]])\n",
      "Tensor3\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0611,  0.0164,  0.1130],\n",
      "          [-0.0371,  0.0624,  0.0826],\n",
      "          [ 0.0718, -0.0182,  0.0154]],\n",
      "\n",
      "         [[-0.0287,  0.0853,  0.0014],\n",
      "          [-0.0274,  0.0515, -0.0554],\n",
      "          [-0.0579,  0.0320,  0.0008]],\n",
      "\n",
      "         [[-0.0296,  0.0570,  0.0622],\n",
      "          [ 0.0526, -0.0176, -0.0089],\n",
      "          [-0.0179,  0.0131,  0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1138, -0.0908, -0.0329],\n",
      "          [-0.0067, -0.1145,  0.0122],\n",
      "          [ 0.0287,  0.0965, -0.0784]],\n",
      "\n",
      "         [[ 0.0062,  0.0421,  0.1090],\n",
      "          [ 0.0736,  0.0586,  0.0290],\n",
      "          [ 0.0191, -0.0848, -0.0078]],\n",
      "\n",
      "         [[-0.1152, -0.0443,  0.0509],\n",
      "          [ 0.1034, -0.0729, -0.0561],\n",
      "          [ 0.1080, -0.0946,  0.0326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0070, -0.1118, -0.0661],\n",
      "          [-0.0120,  0.0321, -0.1147],\n",
      "          [-0.0968,  0.0658, -0.0577]],\n",
      "\n",
      "         [[-0.0476,  0.0913,  0.0538],\n",
      "          [-0.0688, -0.1113,  0.0271],\n",
      "          [-0.0276,  0.0268,  0.0719]],\n",
      "\n",
      "         [[-0.0045, -0.0481, -0.0247],\n",
      "          [ 0.0384,  0.0567,  0.0864],\n",
      "          [-0.0800,  0.0653, -0.0172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473,  0.0766,  0.1104],\n",
      "          [ 0.0868, -0.1010, -0.0890],\n",
      "          [-0.0535,  0.0543, -0.0734]],\n",
      "\n",
      "         [[-0.0918,  0.0879, -0.0543],\n",
      "          [-0.0655,  0.0471, -0.0266],\n",
      "          [ 0.0050,  0.0833,  0.1167]],\n",
      "\n",
      "         [[-0.1031, -0.0737, -0.0711],\n",
      "          [-0.0475, -0.1030,  0.0766],\n",
      "          [-0.0751,  0.0110,  0.1053]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305, -0.0760,  0.0492],\n",
      "          [-0.0758,  0.0152,  0.0184],\n",
      "          [ 0.0723, -0.1092, -0.0260]],\n",
      "\n",
      "         [[ 0.0735, -0.0106, -0.0632],\n",
      "          [ 0.0307,  0.0681, -0.0954],\n",
      "          [-0.0106, -0.0574, -0.1169]],\n",
      "\n",
      "         [[ 0.0367, -0.1056, -0.0850],\n",
      "          [ 0.0761,  0.0666, -0.0217],\n",
      "          [ 0.0418,  0.0414, -0.0929]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0464, -0.0872, -0.0223],\n",
      "          [ 0.0944,  0.0671, -0.0512],\n",
      "          [ 0.0983, -0.0897,  0.0658]],\n",
      "\n",
      "         [[ 0.0106,  0.1177, -0.0287],\n",
      "          [-0.1165,  0.1025,  0.0934],\n",
      "          [ 0.0167,  0.0274,  0.0527]],\n",
      "\n",
      "         [[-0.1158, -0.0558,  0.0898],\n",
      "          [ 0.0322, -0.0041,  0.0737],\n",
      "          [ 0.0700,  0.0941, -0.1168]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0650,  0.0072,  0.0063],\n",
      "          [-0.1058,  0.0621,  0.0030],\n",
      "          [ 0.0538, -0.0489,  0.0346]],\n",
      "\n",
      "         [[-0.0906,  0.1165, -0.0432],\n",
      "          [-0.1060, -0.0420, -0.0935],\n",
      "          [ 0.0982,  0.0706, -0.1168]],\n",
      "\n",
      "         [[ 0.1039,  0.0222,  0.0852],\n",
      "          [-0.0435, -0.0578,  0.0255],\n",
      "          [ 0.0421, -0.0516, -0.0621]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0984, -0.0287,  0.0116],\n",
      "          [ 0.0590,  0.0524, -0.0611],\n",
      "          [ 0.0448,  0.0037,  0.0849]],\n",
      "\n",
      "         [[ 0.0473, -0.1120, -0.0469],\n",
      "          [-0.1079,  0.0507,  0.0954],\n",
      "          [-0.0556,  0.1080,  0.0293]],\n",
      "\n",
      "         [[ 0.0602, -0.0662,  0.0321],\n",
      "          [-0.0780,  0.0770,  0.0580],\n",
      "          [ 0.0168, -0.0566, -0.0645]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1048, -0.0489,  0.0952],\n",
      "          [-0.0925, -0.0539, -0.0379],\n",
      "          [ 0.0835, -0.0801,  0.0607]],\n",
      "\n",
      "         [[-0.1097, -0.1081, -0.0405],\n",
      "          [-0.0429, -0.0999,  0.0429],\n",
      "          [ 0.0950,  0.0661, -0.0161]],\n",
      "\n",
      "         [[-0.0819,  0.0986, -0.0913],\n",
      "          [-0.0309,  0.0272,  0.0791],\n",
      "          [-0.0991, -0.0275,  0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0170, -0.1023, -0.0328],\n",
      "          [ 0.0220,  0.0184,  0.0522],\n",
      "          [ 0.0339,  0.0847, -0.0344]],\n",
      "\n",
      "         [[-0.0698,  0.0153,  0.0023],\n",
      "          [-0.0586,  0.0906,  0.0257],\n",
      "          [ 0.0823, -0.0116, -0.0053]],\n",
      "\n",
      "         [[-0.0683, -0.0525, -0.0624],\n",
      "          [ 0.0301,  0.0775,  0.0243],\n",
      "          [ 0.0196,  0.0876,  0.0641]]],\n",
      "\n",
      "\n",
      "        [[[-0.1083, -0.0719, -0.0998],\n",
      "          [-0.0950, -0.0540,  0.0690],\n",
      "          [-0.0727,  0.0403, -0.1131]],\n",
      "\n",
      "         [[-0.1166,  0.0886,  0.0706],\n",
      "          [ 0.0294, -0.0450, -0.1098],\n",
      "          [ 0.1116, -0.0764,  0.0377]],\n",
      "\n",
      "         [[-0.1072,  0.0018, -0.0024],\n",
      "          [ 0.0553,  0.0664,  0.0258],\n",
      "          [-0.0281,  0.0803,  0.0737]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1102, -0.1079, -0.0080],\n",
      "          [-0.0862,  0.0080,  0.0242],\n",
      "          [-0.0850, -0.0713, -0.0010]],\n",
      "\n",
      "         [[-0.0416,  0.0175,  0.1119],\n",
      "          [ 0.0563,  0.0239, -0.0980],\n",
      "          [-0.0943, -0.0897, -0.0107]],\n",
      "\n",
      "         [[-0.0694, -0.0834,  0.0876],\n",
      "          [-0.1129, -0.0245, -0.0993],\n",
      "          [ 0.0053,  0.1030,  0.0687]]]], requires_grad=True)\n",
      "Reached\n",
      "Mask\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True]])\n",
      "Tensor\n",
      "Parameter containing:\n",
      "tensor([[-4.8201e-02, -1.0803e-01,  5.7866e-02,  1.1544e-01, -9.2786e-02,\n",
      "          9.0190e-02,  2.8168e-02, -2.8635e-02, -6.8646e-02,  8.8577e-02,\n",
      "         -8.5208e-03, -1.2988e-02,  3.1546e-02, -5.1661e-02, -1.2005e-02,\n",
      "          6.0037e-02, -1.4635e-02,  1.0171e-01,  5.3320e-02, -4.5243e-02,\n",
      "          1.2074e-01, -1.0907e-01, -6.5843e-02,  3.8781e-02,  9.1482e-02,\n",
      "         -2.5041e-02, -1.0091e-01, -5.3196e-02, -8.7143e-02,  5.0399e-02,\n",
      "          1.4316e-02,  5.0463e-02, -8.8563e-02, -6.3780e-02, -8.0072e-02,\n",
      "         -7.3948e-02, -3.2215e-02,  2.4076e-02, -7.9060e-02, -4.5274e-02,\n",
      "          1.1971e-01, -1.0358e-01,  9.3591e-02,  3.6492e-02, -1.2128e-01,\n",
      "          6.0816e-02, -3.8068e-02,  1.0095e-01,  2.0844e-02,  1.0283e-01,\n",
      "          9.4581e-02,  8.6537e-02, -5.1049e-02,  3.2523e-02, -7.2838e-02,\n",
      "          7.2268e-02, -2.8714e-03, -6.2139e-02, -3.7265e-03, -3.7994e-02,\n",
      "          1.1517e-01, -4.4166e-02,  2.8543e-02,  1.1928e-02],\n",
      "        [ 7.6112e-02,  3.9591e-02, -2.4907e-03,  8.0970e-02,  6.6201e-02,\n",
      "          6.0673e-02,  7.7706e-02, -4.2389e-02,  7.2179e-02,  3.5909e-02,\n",
      "          1.2102e-02, -7.8323e-02,  4.6085e-02, -7.7517e-02, -1.0939e-01,\n",
      "         -1.2785e-02,  6.8200e-02,  1.0468e-01, -1.1151e-01, -1.3258e-03,\n",
      "         -5.3389e-02,  6.6359e-03, -8.6888e-03, -6.5885e-02, -6.1034e-02,\n",
      "         -7.8829e-02,  6.8032e-02,  8.4880e-02,  3.2136e-02, -1.2199e-01,\n",
      "          7.7070e-02,  8.6124e-02, -3.2679e-02,  8.2483e-02,  4.4718e-02,\n",
      "         -1.0065e-01,  3.4948e-02,  3.4493e-02, -9.6622e-02,  8.7380e-02,\n",
      "         -5.2037e-02, -4.7558e-02, -9.8364e-02, -9.9789e-02, -5.1759e-02,\n",
      "         -7.3258e-02,  5.8640e-02,  1.2516e-02, -6.9559e-02,  8.9025e-02,\n",
      "          1.2286e-01,  7.6484e-02,  1.2339e-01,  3.9132e-02, -6.2697e-02,\n",
      "          6.4772e-02, -2.6371e-02, -1.1040e-01, -4.9226e-02, -4.4053e-02,\n",
      "          5.3685e-02, -9.9500e-02,  9.4699e-02,  6.0605e-02],\n",
      "        [ 9.7951e-02, -7.7009e-02,  5.0135e-02,  5.6851e-02, -9.7103e-02,\n",
      "         -5.8599e-02,  7.7499e-02,  4.8778e-02,  2.7622e-02,  1.2356e-02,\n",
      "          7.9460e-02, -1.0172e-01,  1.0906e-01,  5.7346e-02, -1.3156e-02,\n",
      "         -1.0788e-01, -9.1864e-02,  9.0140e-02,  6.1932e-02,  8.1343e-02,\n",
      "          1.0063e-01, -2.4107e-02,  6.1494e-03,  1.3887e-02,  8.5270e-02,\n",
      "          1.1375e-01, -6.3828e-02, -9.5504e-02, -7.9790e-02,  6.8119e-02,\n",
      "          5.2077e-02, -8.9024e-02, -3.5065e-03, -1.9178e-02, -4.5671e-02,\n",
      "          3.4772e-02,  6.7608e-02,  4.2664e-02, -5.1461e-02,  4.9812e-02,\n",
      "          1.1258e-01, -1.0213e-01,  9.3802e-02,  1.0727e-01, -4.3542e-03,\n",
      "          1.1772e-01, -2.7905e-02,  1.2074e-01, -8.7402e-02,  3.6960e-02,\n",
      "          5.8793e-03,  1.2881e-02,  6.3559e-02,  5.5295e-02, -1.8792e-02,\n",
      "         -1.2345e-01,  7.5327e-02,  8.0845e-02,  6.5420e-02,  9.9366e-02,\n",
      "         -1.1475e-01, -1.0007e-01, -8.8089e-02, -5.6082e-02],\n",
      "        [-8.7500e-02, -8.8389e-02,  6.7117e-02,  9.2439e-02, -7.3756e-03,\n",
      "         -1.0539e-01, -2.9931e-02, -7.3663e-02, -4.5705e-02,  9.3262e-02,\n",
      "         -7.3219e-02,  1.1209e-01,  1.2278e-01,  1.2417e-01,  5.3584e-03,\n",
      "          4.1025e-02,  9.3742e-02, -2.3397e-02, -5.7166e-02,  3.8508e-02,\n",
      "         -2.0990e-02, -1.2453e-01, -1.4958e-02,  7.4648e-03, -1.3473e-02,\n",
      "          1.1469e-01,  5.6061e-02, -4.4218e-02, -5.4267e-02,  9.6993e-02,\n",
      "          4.1442e-03, -2.8109e-02, -3.6084e-02, -1.0364e-01, -1.2035e-01,\n",
      "          1.0525e-01,  2.6379e-02, -5.8889e-02, -1.1716e-01, -4.4370e-02,\n",
      "         -5.1254e-02, -6.2077e-02, -7.9264e-02, -2.7148e-02,  1.0785e-01,\n",
      "          2.1252e-02,  1.0596e-02, -6.8258e-02,  8.2549e-02,  6.1315e-02,\n",
      "          1.0622e-01, -7.2483e-02,  6.0430e-02,  1.2003e-01,  1.7518e-02,\n",
      "         -7.5416e-03,  4.8732e-02, -9.3969e-02, -1.2380e-01, -5.0136e-02,\n",
      "         -1.1976e-01, -7.6041e-02, -3.9589e-02,  9.3550e-02],\n",
      "        [-8.8994e-02, -3.4767e-02,  7.2195e-02,  1.0003e-01, -1.1516e-01,\n",
      "          4.9092e-03, -1.9090e-02, -1.0206e-01, -8.5008e-03,  9.2852e-02,\n",
      "          8.6345e-02,  6.1163e-02,  1.9570e-02,  1.1451e-01, -1.1124e-01,\n",
      "         -7.4631e-02,  4.4171e-02,  9.4061e-02, -4.2972e-02, -6.8167e-02,\n",
      "          5.5119e-02, -1.0920e-01,  7.8102e-02,  9.5255e-03, -9.3380e-02,\n",
      "          7.6664e-02, -1.0054e-01, -3.2814e-02, -4.9778e-02, -1.0141e-01,\n",
      "          9.8787e-02,  4.2379e-02,  6.6936e-02,  1.1529e-01, -3.2500e-02,\n",
      "          6.3765e-02,  1.1440e-01, -1.9355e-02,  5.1689e-02,  3.3290e-02,\n",
      "          5.2421e-02, -6.2230e-02, -4.6464e-02, -1.5923e-02, -1.5564e-02,\n",
      "          4.7837e-02,  1.9394e-02, -9.9256e-02,  4.7398e-02, -4.5648e-02,\n",
      "          5.4166e-03, -5.1193e-02, -9.0644e-02,  9.1530e-02,  2.5919e-02,\n",
      "         -1.0117e-01, -1.4482e-02, -5.0125e-04, -1.4567e-02, -1.1311e-01,\n",
      "         -3.7106e-02,  9.5344e-02, -7.9514e-02, -5.2848e-02],\n",
      "        [-1.9937e-02,  3.3007e-02, -7.9067e-02, -4.1971e-02, -1.6298e-02,\n",
      "          6.1228e-02, -9.3453e-02, -4.8093e-02,  1.1882e-01, -1.2241e-01,\n",
      "         -3.4717e-02,  8.2318e-02, -2.0127e-02,  8.7271e-02,  1.7560e-02,\n",
      "         -2.7521e-02, -6.4131e-02, -2.3677e-02,  1.0938e-01,  7.6069e-02,\n",
      "         -9.8785e-02,  5.8483e-02, -1.1884e-02, -4.8775e-02, -2.3683e-02,\n",
      "         -8.6211e-02, -1.0331e-01, -9.5245e-03, -1.0230e-01,  1.4677e-02,\n",
      "         -6.6984e-02,  7.8525e-02, -6.4518e-02, -9.1696e-02, -6.6677e-02,\n",
      "         -1.1343e-01, -1.3388e-02, -8.9934e-02,  8.1098e-02,  6.2936e-02,\n",
      "          2.1712e-02,  1.0122e-01,  1.4876e-03,  9.6532e-02,  5.4042e-02,\n",
      "          3.6718e-02,  1.5179e-02,  7.1631e-02, -1.5566e-02, -3.5643e-02,\n",
      "         -6.8959e-02,  8.8801e-02, -1.2341e-01,  1.6960e-02, -1.1762e-01,\n",
      "          7.1051e-02, -9.0173e-02, -1.0377e-01,  9.2894e-02, -2.2938e-02,\n",
      "          9.8212e-02, -8.9787e-02,  6.0418e-03,  4.4958e-03],\n",
      "        [ 8.2451e-02,  1.0463e-01, -1.0976e-01, -4.3238e-02,  4.9660e-02,\n",
      "          1.2042e-01, -9.1940e-02, -1.0642e-02,  4.0129e-02,  9.5438e-02,\n",
      "         -1.8171e-02, -1.2131e-02,  3.7032e-02, -9.7467e-02, -1.0037e-01,\n",
      "         -8.6764e-02,  1.2139e-01, -2.7383e-02, -5.3299e-02, -1.1839e-01,\n",
      "         -1.0176e-01, -1.1035e-01,  3.9169e-02,  6.3959e-02,  1.2126e-01,\n",
      "          3.7874e-02, -4.9160e-02,  1.4485e-02, -7.5302e-02, -4.3732e-02,\n",
      "         -4.6790e-02, -4.7568e-02, -1.2551e-02, -2.7910e-02, -4.9136e-02,\n",
      "         -4.3903e-03, -6.7730e-02, -4.0762e-03, -2.2666e-02,  8.6000e-02,\n",
      "          8.6366e-02, -7.3053e-02, -1.1449e-01,  1.0465e-01,  2.8519e-02,\n",
      "         -7.0050e-02, -9.2366e-02,  1.2490e-01,  1.0737e-02,  6.8666e-02,\n",
      "          1.0373e-01, -6.7416e-02, -3.9131e-02,  3.4472e-03,  5.6715e-02,\n",
      "         -5.2534e-02,  7.0037e-02, -7.3492e-02, -4.3846e-02,  1.6121e-02,\n",
      "          5.6667e-02,  8.7105e-02,  9.0337e-02, -9.3523e-02],\n",
      "        [ 1.0646e-01, -4.8922e-02, -1.0260e-01, -1.0462e-01, -1.0347e-01,\n",
      "          5.2739e-02,  1.0033e-01, -5.9750e-02, -8.2598e-02, -9.9156e-02,\n",
      "         -1.1406e-01,  4.6614e-02, -8.7958e-02, -1.1672e-01,  7.7012e-02,\n",
      "          7.0451e-03, -2.1407e-02,  1.2146e-01, -9.1721e-02, -7.2758e-02,\n",
      "          1.2415e-01, -5.2180e-02,  1.0885e-01, -7.7082e-02,  1.0999e-01,\n",
      "          7.5235e-03,  7.3830e-02,  1.1559e-01, -5.5470e-03,  3.1876e-02,\n",
      "         -8.1453e-02,  1.3925e-02,  6.3702e-02, -2.6965e-02, -6.6298e-02,\n",
      "         -6.8653e-02, -1.2226e-04,  6.7174e-02,  4.2651e-02, -3.5758e-02,\n",
      "          4.2113e-02,  1.2087e-01, -6.7463e-03,  1.0080e-01,  3.3762e-02,\n",
      "          9.4801e-02, -9.3525e-02,  1.2379e-01,  2.2500e-02, -9.9234e-03,\n",
      "          1.0114e-02,  6.0549e-02,  1.0459e-01,  5.7232e-02,  1.1301e-01,\n",
      "         -9.6098e-02, -1.0785e-01, -2.3443e-02,  5.2796e-02, -1.1496e-01,\n",
      "         -2.7110e-02,  1.0570e-01,  2.6056e-02,  1.1880e-01],\n",
      "        [ 3.7734e-02,  1.1908e-02, -5.8381e-02, -4.2262e-02,  5.1793e-02,\n",
      "          1.0337e-01,  1.4150e-03, -1.7658e-02,  1.2414e-01, -6.5537e-02,\n",
      "          6.4812e-03,  1.4260e-02,  1.0811e-01,  1.0361e-02,  8.2116e-02,\n",
      "          1.9860e-02, -1.1320e-01, -8.3800e-02,  9.8788e-02, -8.5841e-02,\n",
      "          1.4188e-02, -1.7119e-02,  3.0170e-02, -1.2362e-01,  6.5915e-02,\n",
      "         -1.5457e-03, -2.1241e-02,  8.2518e-02,  2.5372e-02,  6.7234e-02,\n",
      "         -9.6861e-02,  1.2550e-02,  1.5431e-03, -6.5858e-02, -1.4018e-02,\n",
      "          3.5531e-02, -7.4515e-02,  6.7227e-02,  8.0973e-02, -7.6559e-02,\n",
      "          5.5174e-02,  6.7300e-02, -6.2702e-02, -1.7568e-02,  1.1331e-01,\n",
      "         -3.4744e-02,  4.6742e-02, -3.4539e-02, -6.5540e-03,  1.6317e-02,\n",
      "          1.0604e-01, -5.1617e-02,  1.1507e-01,  1.0876e-01,  2.5852e-02,\n",
      "         -5.1019e-02, -1.0965e-01,  8.7513e-02, -4.9147e-02, -1.4507e-02,\n",
      "          1.1383e-01,  8.3477e-02, -1.1176e-01, -6.4335e-02],\n",
      "        [ 5.3884e-02,  7.5282e-02, -4.2355e-02,  1.1948e-01, -1.2120e-01,\n",
      "          1.1774e-01, -1.7802e-03,  6.0138e-02, -7.9861e-02, -5.6894e-02,\n",
      "         -1.7802e-02,  5.9781e-02,  6.9047e-02, -4.2301e-02, -3.7708e-02,\n",
      "         -6.1264e-03,  3.8162e-03,  4.3895e-03, -9.6657e-02,  3.2445e-02,\n",
      "          6.0198e-02, -3.8816e-02, -1.2198e-01,  1.1241e-01, -2.4095e-02,\n",
      "          5.8252e-02,  1.1147e-01,  9.2614e-02, -3.2723e-02, -1.0604e-01,\n",
      "         -7.5044e-02, -1.2477e-01,  1.0884e-01,  1.0675e-01, -4.9125e-02,\n",
      "          7.6597e-02, -1.0528e-01, -7.7216e-02,  8.8213e-02,  6.6932e-02,\n",
      "          3.3651e-02, -1.0848e-01,  2.1666e-02,  1.0261e-01,  7.4611e-02,\n",
      "         -7.8261e-02,  6.4374e-02,  8.2337e-02,  6.7030e-02,  1.7528e-02,\n",
      "          1.1247e-01, -1.1242e-01, -9.0461e-03,  1.0915e-01, -3.1844e-02,\n",
      "          2.4605e-02, -3.8112e-02,  2.6953e-02, -1.3701e-02,  4.1193e-02,\n",
      "          4.3957e-02, -8.6924e-02,  6.0375e-02, -1.1439e-01]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"channel\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: block_1_0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ParametrizedConv2d' object has no attribute 'data_out_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# pprint(node.meta['mase'].parameters['common'])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m pprint(\u001b[43mmg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_out_0\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m pprint(mg\u001b[38;5;241m.\u001b[39mmodules[node\u001b[38;5;241m.\u001b[39mtarget]\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParametrizedConv2d' object has no attribute 'data_out_0'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv2d':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        pprint(mg.modules[node.target].data_out_0)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        pprint(mg.modules[node.target].state_dict())\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        w = mg.modules[node.target].weight\n",
    "        for s in w:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "# for node in mg.fx_graph.nodes:\n",
    "#     if get_mase_op(node) == 'linear':\n",
    "#         print(f\"Layer: {node.name}\")\n",
    "#         # pprint(node.meta['mase'].parameters['common'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "#         pprint(mg.modules[node.target].weight)\n",
    "#         # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "#         # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "#         total_w = 0\n",
    "#         pruned_w = 0\n",
    "#         mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "#         for s in mask_2:\n",
    "#             total_w += s.numel()\n",
    "#             pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "#         pruned_percent = pruned_w / total_w\n",
    "#         print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "#         print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "# for node in mg.fx_graph.nodes:\n",
    "#     if get_mase_op(node) == 'linear':\n",
    "#         print(node.name)\n",
    "#         print(50*'-')\n",
    "#         # pprint(node.meta['mase'].parameters['common'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "#         # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "#         pprint(mg.modules[node.target].weight)\n",
    "#         pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "#         # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "#         print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
