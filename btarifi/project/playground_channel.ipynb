{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_0\n",
      "--------------------------------------------------\n",
      "seq_blocks.0\n",
      "--------------------------------------------------\n",
      "seq_blocks_1\n",
      "--------------------------------------------------\n",
      "seq_blocks.1\n",
      "--------------------------------------------------\n",
      "seq_blocks_2\n",
      "--------------------------------------------------\n",
      "seq_blocks.2\n",
      "--------------------------------------------------\n",
      "seq_blocks_3\n",
      "--------------------------------------------------\n",
      "seq_blocks.3\n",
      "--------------------------------------------------\n",
      "<class 'dict'>\n",
      "<class 'torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl'>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'conv2d':\n",
    "    if node.op == \"call_module\":\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        print(node.target)\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].state_dict())\n",
    "        #pprint(mg.mo)\n",
    "        print(50*'-')\n",
    "print(type(mg.modules[\"seq_blocks.\" +2]))\n",
    "print(type(mg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('seq_blocks.0.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('seq_blocks.0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('seq_blocks.0.running_mean', tensor([-0.0050, -0.0008,  0.0117,  0.0123,  0.0122,  0.0126,  0.0009,  0.0042,\n",
      "         0.0009,  0.0062,  0.0059,  0.0099,  0.0060,  0.0104,  0.0113,  0.0112])), ('seq_blocks.0.running_var', tensor([1.0098, 1.0104, 1.0108, 1.0118, 1.0102, 1.0118, 0.9849, 0.9822, 0.9849,\n",
      "        0.9984, 1.0017, 1.0007, 0.9980, 0.9983, 1.0123, 1.0123])), ('seq_blocks.0.num_batches_tracked', tensor(2)), ('seq_blocks.2.weight', tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]])), ('seq_blocks.2.bias', tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330]))])\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_blocks_0\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [16],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 16],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[-0.7474,  0.7055,  0.2588,  ..., -0.1582,  0.2858,  0.5553],\n",
      "        [-0.1004,  0.3167,  0.1572,  ..., -0.1375, -0.0600, -0.0717],\n",
      "        [ 0.5088,  0.2090,  0.2449,  ..., -1.2359,  0.2597, -1.0364],\n",
      "        ...,\n",
      "        [ 0.3835,  0.3343,  1.1200,  ..., -0.3493,  1.4631, -1.0364],\n",
      "        [-0.1051,  0.4615,  0.2981,  ..., -0.7702,  0.1896, -0.4094],\n",
      "        [-0.4591,  0.6851,  1.7697,  ...,  0.5731,  1.7593, -0.0717]])},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [16],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)}}\n",
      "Layer: seq_blocks_1\n",
      "{'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 16],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0000, 0.6918, 0.1922,  ..., 0.0000, 0.2194, 0.4817],\n",
      "        [0.0000, 0.3129, 0.0933,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5225, 0.2079, 0.1787,  ..., 0.0000, 0.1940, 0.0000],\n",
      "        ...,\n",
      "        [0.4002, 0.3301, 1.0308,  ..., 0.0000, 1.3613, 0.0000],\n",
      "        [0.0000, 0.4540, 0.2304,  ..., 0.0000, 0.1260, 0.0000],\n",
      "        [0.0000, 0.6719, 1.6635,  ..., 0.5214, 1.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)}}\n",
      "Layer: seq_blocks_2\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [5],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330], requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 16],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0000, 0.6918, 0.1922,  ..., 0.0000, 0.2194, 0.4817],\n",
      "        [0.0000, 0.3129, 0.0933,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5225, 0.2079, 0.1787,  ..., 0.0000, 0.1940, 0.0000],\n",
      "        ...,\n",
      "        [0.4002, 0.3301, 1.0308,  ..., 0.0000, 1.3613, 0.0000],\n",
      "        [0.0000, 0.4540, 0.2304,  ..., 0.0000, 0.1260, 0.0000],\n",
      "        [0.0000, 0.6719, 1.6635,  ..., 0.5214, 1.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [5, 16],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]],\n",
      "       requires_grad=True)}}\n",
      "Layer: seq_blocks_3\n",
      "{'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 5],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0000, 0.3233, 0.1376, 0.1816, 0.0000],\n",
      "        [0.0000, 0.0992, 0.2402, 0.1623, 0.0000],\n",
      "        [0.0000, 0.0385, 0.1568, 0.0732, 0.0000],\n",
      "        ...,\n",
      "        [0.5673, 0.8087, 0.8252, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1803, 0.1735, 0.1018, 0.0000],\n",
      "        [0.4246, 0.8724, 0.5164, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'linear':\n",
    "    if node.op == \"call_module\":\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        #pprint(mg.modules[node.target])\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "       # print(mg.model.state_dict())\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # w = mg.modules[node.target].weight\n",
    "        # for s in w:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        # print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_blocks_2\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [5],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330], requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 16],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0000, 0.6918, 0.1922,  ..., 0.0000, 0.2194, 0.4817],\n",
      "        [0.0000, 0.3129, 0.0933,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5225, 0.2079, 0.1787,  ..., 0.0000, 0.1940, 0.0000],\n",
      "        ...,\n",
      "        [0.4002, 0.3301, 1.0308,  ..., 0.0000, 1.3613, 0.0000],\n",
      "        [0.0000, 0.4540, 0.2304,  ..., 0.0000, 0.1260, 0.0000],\n",
      "        [0.0000, 0.6719, 1.6635,  ..., 0.5214, 1.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [5, 16],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]],\n",
      "       requires_grad=True)}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "        # for s in mask_2:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n",
    "#print(mg.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('seq_blocks.0.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('seq_blocks.0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('seq_blocks.0.running_mean', tensor([-0.0050, -0.0008,  0.0117,  0.0123,  0.0122,  0.0126,  0.0009,  0.0042,\n",
      "         0.0009,  0.0062,  0.0059,  0.0099,  0.0060,  0.0104,  0.0113,  0.0112])), ('seq_blocks.0.running_var', tensor([1.0098, 1.0104, 1.0108, 1.0118, 1.0102, 1.0118, 0.9849, 0.9822, 0.9849,\n",
      "        0.9984, 1.0017, 1.0007, 0.9980, 0.9983, 1.0123, 1.0123])), ('seq_blocks.0.num_batches_tracked', tensor(2)), ('seq_blocks.2.bias', tensor([-0.2035,  0.1072,  0.2207,  0.2167,  0.0330])), ('seq_blocks.2.parametrizations.weight.original', tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]])), ('seq_blocks.2.parametrizations.weight.0.mask', tensor([[False,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
      "          True,  True, False, False, False, False],\n",
      "        [ True, False, False, False,  True, False,  True, False, False, False,\n",
      "          True, False, False, False,  True,  True],\n",
      "        [False,  True,  True, False, False,  True,  True, False, False, False,\n",
      "          True, False,  True,  True,  True, False],\n",
      "        [ True,  True, False, False, False,  True,  True,  True,  True, False,\n",
      "          True, False, False, False,  True,  True],\n",
      "        [ True,  True, False, False, False,  True,  True, False,  True,  True,\n",
      "         False, False,  True, False,  True, False]]))])\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mg.model.state_dict())\n",
    "#print(node.meta['mase'].parameters['common']['args']['weight']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_2\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[ 0.0280,  0.1994,  0.1990, -0.0459,  0.1669,  0.2383,  0.2267, -0.1722,\n",
      "          0.2401,  0.0899,  0.2032, -0.2431, -0.0539,  0.0350, -0.0878,  0.0864],\n",
      "        [-0.2471,  0.1335, -0.0760,  0.0635,  0.2423,  0.0355,  0.1517,  0.0415,\n",
      "         -0.1401,  0.0164, -0.2077,  0.0701,  0.0952, -0.0982,  0.2382,  0.1787],\n",
      "        [-0.0695, -0.1765,  0.2361, -0.0543,  0.0771,  0.2328,  0.1437,  0.0289,\n",
      "          0.0836,  0.1229,  0.2050, -0.1231, -0.1486,  0.2418, -0.1702,  0.0644],\n",
      "        [-0.1972, -0.2393, -0.1072, -0.0610, -0.0949, -0.2070,  0.1950, -0.2175,\n",
      "         -0.2453, -0.0608,  0.1447, -0.1106,  0.0976,  0.0070,  0.1467,  0.2468],\n",
      "        [-0.2423, -0.1813, -0.1228, -0.0613, -0.0382, -0.1995,  0.1495, -0.1170,\n",
      "         -0.1918, -0.1813,  0.1138, -0.1162, -0.1512, -0.0801,  0.2345, -0.1161]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
