{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1452, -0.0541, -0.0288,  0.1386,  0.0652,  0.0067,  0.1749, -0.2419,\n",
      "         -0.1334,  0.1519,  0.1223, -0.0931, -0.0446,  0.0301,  0.1822, -0.0948],\n",
      "        [ 0.0662, -0.1325,  0.1769,  0.0744,  0.0389,  0.1381, -0.2016, -0.0752,\n",
      "         -0.1015,  0.1191,  0.0031, -0.2110, -0.0728, -0.1725,  0.1924, -0.1513],\n",
      "        [ 0.1350, -0.2261, -0.2043,  0.1860,  0.2388, -0.1962, -0.0749, -0.0336,\n",
      "         -0.2333,  0.0880,  0.0954,  0.0788, -0.0431,  0.0796, -0.1077,  0.0506],\n",
      "        [-0.0026, -0.1182,  0.2398,  0.0558,  0.1095, -0.0805,  0.2243,  0.1972,\n",
      "         -0.1097, -0.1086,  0.0303,  0.1558,  0.0597, -0.2079, -0.0612,  0.1764],\n",
      "        [ 0.0299, -0.0387,  0.1119,  0.1972, -0.1651, -0.0459,  0.1382,  0.1111,\n",
      "         -0.2060, -0.1861,  0.0973, -0.0466, -0.2340,  0.0902, -0.1532,  0.0789]],\n",
      "       requires_grad=True)\n",
      "OrderedDict([('weight',\n",
      "              tensor([[ 0.1452, -0.0541, -0.0288,  0.1386,  0.0652,  0.0067,  0.1749, -0.2419,\n",
      "         -0.1334,  0.1519,  0.1223, -0.0931, -0.0446,  0.0301,  0.1822, -0.0948],\n",
      "        [ 0.0662, -0.1325,  0.1769,  0.0744,  0.0389,  0.1381, -0.2016, -0.0752,\n",
      "         -0.1015,  0.1191,  0.0031, -0.2110, -0.0728, -0.1725,  0.1924, -0.1513],\n",
      "        [ 0.1350, -0.2261, -0.2043,  0.1860,  0.2388, -0.1962, -0.0749, -0.0336,\n",
      "         -0.2333,  0.0880,  0.0954,  0.0788, -0.0431,  0.0796, -0.1077,  0.0506],\n",
      "        [-0.0026, -0.1182,  0.2398,  0.0558,  0.1095, -0.0805,  0.2243,  0.1972,\n",
      "         -0.1097, -0.1086,  0.0303,  0.1558,  0.0597, -0.2079, -0.0612,  0.1764],\n",
      "        [ 0.0299, -0.0387,  0.1119,  0.1972, -0.1651, -0.0459,  0.1382,  0.1111,\n",
      "         -0.2060, -0.1861,  0.0973, -0.0466, -0.2340,  0.0902, -0.1532,  0.0789]])),\n",
      "             ('bias', tensor([ 0.1546,  0.2217, -0.0707,  0.0190, -0.0146]))])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        if node.op == \"call_module\":\n",
    "            #print(node.name)\n",
    "            #print(50*'-')\n",
    "            #print(node.target)\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())\n",
    "            #pprint(mg.mo)\n",
    "            \n",
    "#print(mg.modules)\n",
    "#print(type(mg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    "    activation_pruning_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = activation_pruning_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1452, -0.0541, -0.0288,  0.1386,  0.0652,  0.0067,  0.1749, -0.2419,\n",
      "         -0.1334,  0.1519,  0.1223, -0.0931, -0.0446,  0.0301,  0.1822, -0.0948],\n",
      "        [ 0.0662, -0.1325,  0.1769,  0.0744,  0.0389,  0.1381, -0.2016, -0.0752,\n",
      "         -0.1015,  0.1191,  0.0031, -0.2110, -0.0728, -0.1725,  0.1924, -0.1513],\n",
      "        [ 0.1350, -0.2261, -0.2043,  0.1860,  0.2388, -0.1962, -0.0749, -0.0336,\n",
      "         -0.2333,  0.0880,  0.0954,  0.0788, -0.0431,  0.0796, -0.1077,  0.0506],\n",
      "        [-0.0026, -0.1182,  0.2398,  0.0558,  0.1095, -0.0805,  0.2243,  0.1972,\n",
      "         -0.1097, -0.1086,  0.0303,  0.1558,  0.0597, -0.2079, -0.0612,  0.1764],\n",
      "        [ 0.0299, -0.0387,  0.1119,  0.1972, -0.1651, -0.0459,  0.1382,  0.1111,\n",
      "         -0.2060, -0.1861,  0.0973, -0.0466, -0.2340,  0.0902, -0.1532,  0.0789]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('weight',\n",
      "              tensor([[ 0.1452, -0.0541, -0.0288,  0.1386,  0.0652,  0.0067,  0.1749, -0.2419,\n",
      "         -0.1334,  0.1519,  0.1223, -0.0931, -0.0446,  0.0301,  0.1822, -0.0948],\n",
      "        [ 0.0662, -0.1325,  0.1769,  0.0744,  0.0389,  0.1381, -0.2016, -0.0752,\n",
      "         -0.1015,  0.1191,  0.0031, -0.2110, -0.0728, -0.1725,  0.1924, -0.1513],\n",
      "        [ 0.1350, -0.2261, -0.2043,  0.1860,  0.2388, -0.1962, -0.0749, -0.0336,\n",
      "         -0.2333,  0.0880,  0.0954,  0.0788, -0.0431,  0.0796, -0.1077,  0.0506],\n",
      "        [-0.0026, -0.1182,  0.2398,  0.0558,  0.1095, -0.0805,  0.2243,  0.1972,\n",
      "         -0.1097, -0.1086,  0.0303,  0.1558,  0.0597, -0.2079, -0.0612,  0.1764],\n",
      "        [ 0.0299, -0.0387,  0.1119,  0.1972, -0.1651, -0.0459,  0.1382,  0.1111,\n",
      "         -0.2060, -0.1861,  0.0973, -0.0466, -0.2340,  0.0902, -0.1532,  0.0789]])),\n",
      "             ('bias', tensor([ 0.1546,  0.2217, -0.0707,  0.0190, -0.0146]))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        if node.op == \"call_module\":\n",
    "            #print(node.name)\n",
    "            #print(50*'-')\n",
    "            #print(node.target)\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_items([(0, <function get_activation_hook.<locals>.sparsify_input at 0x7f9810134af0>)])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([(1, <function get_activation_hook.<locals>.sparsify_input at 0x7f9810134b80>)])\n",
      "odict_items([])\n",
      "odict_items([(2, <function get_activation_hook.<locals>.sparsify_input at 0x7f9810134c10>)])\n",
      "odict_items([])\n",
      "odict_items([(3, <function get_activation_hook.<locals>.sparsify_input at 0x7f9810134ca0>)])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([(4, <function get_activation_hook.<locals>.sparsify_input at 0x7f9810134d30>)])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'linear':\n",
    "    if node.op == \"call_module\":\n",
    "        #print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        #pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        pprint(mg.modules[node.target]._forward_pre_hooks.items())\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "       # print(mg.model.state_dict())\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        #print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # w = mg.modules[node.target].weight\n",
    "        # for s in w:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        # print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [10],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([ 0.1145,  0.0742,  0.1038, -0.0820,  0.0053,  0.0576,  0.0494,  0.0499,\n",
      "        -0.0856, -0.0203], requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 64],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[0.0163, 0.0360, 0.0481,  ..., 0.0202, 0.0000, 0.0566],\n",
      "        [0.0308, 0.0515, 0.0366,  ..., 0.0317, 0.0013, 0.0747],\n",
      "        [0.0456, 0.0404, 0.0565,  ..., 0.0366, 0.0002, 0.0623],\n",
      "        ...,\n",
      "        [0.0108, 0.0597, 0.0219,  ..., 0.0206, 0.0006, 0.0814],\n",
      "        [0.0336, 0.0452, 0.0330,  ..., 0.0347, 0.0012, 0.0821],\n",
      "        [0.0238, 0.0463, 0.0337,  ..., 0.0249, 0.0008, 0.0804]],\n",
      "       grad_fn=<ViewBackward0>)},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [10, 64],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([[ 0.1231,  0.1070,  0.0702, -0.0399, -0.0537,  0.0388,  0.0295, -0.0526,\n",
      "         -0.0089, -0.1205, -0.0649, -0.0419,  0.0919, -0.0557,  0.0272, -0.0472,\n",
      "         -0.0578, -0.0621, -0.0587,  0.0975,  0.0703,  0.0270, -0.0734,  0.0563,\n",
      "         -0.0547, -0.1000,  0.0131,  0.0098, -0.0884,  0.0028, -0.0037, -0.0332,\n",
      "          0.0846,  0.0170, -0.0016, -0.0207,  0.0802, -0.1033,  0.0559,  0.0725,\n",
      "         -0.0536, -0.0952, -0.0811,  0.0894,  0.0623, -0.0156,  0.0636, -0.0475,\n",
      "          0.0232,  0.0176, -0.0543, -0.0095,  0.0646, -0.0257,  0.1148, -0.1008,\n",
      "         -0.0753, -0.0745,  0.1248,  0.0132, -0.0006, -0.0839, -0.0127,  0.0429],\n",
      "        [ 0.1139,  0.1173, -0.0668,  0.0785,  0.0143,  0.1133, -0.0583, -0.0021,\n",
      "          0.0836, -0.0153,  0.0491,  0.0481, -0.0030, -0.0932, -0.0828, -0.0406,\n",
      "          0.1122,  0.1198,  0.0265, -0.1046, -0.0704, -0.0071, -0.0817, -0.0882,\n",
      "         -0.0713,  0.0616,  0.0718, -0.1036,  0.0839, -0.0144,  0.0540, -0.0446,\n",
      "         -0.0086, -0.0587, -0.0528,  0.0916, -0.0015,  0.0160,  0.0403,  0.0878,\n",
      "         -0.0036, -0.0460, -0.0857,  0.0860, -0.0586, -0.0883, -0.0176,  0.1125,\n",
      "          0.1061, -0.1154, -0.0501,  0.0284,  0.1029,  0.0280,  0.0096,  0.0899,\n",
      "          0.0387, -0.1225, -0.1155, -0.0554, -0.1032, -0.0108, -0.0460, -0.0963],\n",
      "        [-0.1221, -0.0440,  0.1052,  0.0727, -0.0385,  0.0084, -0.0680, -0.0643,\n",
      "          0.0789,  0.0439, -0.1163,  0.1159,  0.0563, -0.0416, -0.0062,  0.0390,\n",
      "          0.0913,  0.0735,  0.0418,  0.0787,  0.0441, -0.0193, -0.0719,  0.0198,\n",
      "          0.0849, -0.0750,  0.0623,  0.0737, -0.0823,  0.0008, -0.0992,  0.0791,\n",
      "          0.0543,  0.0678, -0.1157, -0.1185, -0.0754,  0.0629, -0.0797, -0.1191,\n",
      "         -0.1050,  0.1150,  0.0921,  0.1152, -0.0331, -0.1093,  0.0085,  0.0802,\n",
      "          0.1105, -0.0108, -0.0929, -0.1079,  0.0113,  0.0935,  0.1126, -0.0356,\n",
      "          0.0673, -0.0865, -0.0061, -0.0470,  0.0410, -0.0833,  0.0195, -0.0792],\n",
      "        [ 0.0607, -0.0353, -0.0634,  0.0618,  0.0797,  0.0874, -0.0061,  0.0094,\n",
      "          0.1010, -0.0929, -0.0200, -0.0787, -0.0299, -0.0031,  0.0409, -0.0902,\n",
      "          0.0550, -0.0433,  0.0910, -0.0159, -0.0857,  0.0645, -0.1165,  0.0119,\n",
      "          0.0148,  0.0387, -0.1080,  0.0133, -0.0910, -0.0312,  0.0187,  0.0214,\n",
      "          0.0101,  0.0289, -0.1051,  0.1085, -0.0300,  0.1085, -0.1223,  0.0269,\n",
      "         -0.0889, -0.0806,  0.1116,  0.0472,  0.0067, -0.0301,  0.0054,  0.0760,\n",
      "          0.0624, -0.0011,  0.0587, -0.0042, -0.1115,  0.0707, -0.0648, -0.0824,\n",
      "          0.0135, -0.0043,  0.0686, -0.0460,  0.0996,  0.0626, -0.0324,  0.1072],\n",
      "        [-0.0854,  0.0750,  0.0138, -0.0558,  0.0615,  0.0833,  0.0011, -0.0709,\n",
      "          0.0695, -0.0443, -0.0580, -0.0300,  0.0717,  0.1126,  0.0045,  0.0559,\n",
      "          0.0224, -0.1171, -0.0276,  0.0155,  0.0088,  0.0996,  0.1079, -0.0288,\n",
      "         -0.0037, -0.0705, -0.0837, -0.0402, -0.1079, -0.0596,  0.0557, -0.0794,\n",
      "          0.0155,  0.0487,  0.0652, -0.0576, -0.0523,  0.0643,  0.0916,  0.0543,\n",
      "         -0.0296, -0.1076,  0.1188,  0.0951,  0.0026, -0.0922, -0.0772, -0.1084,\n",
      "          0.0087, -0.0984,  0.0936,  0.1038, -0.0134,  0.0814, -0.0123, -0.0759,\n",
      "          0.1210,  0.0175,  0.0742,  0.1155, -0.0080, -0.0938, -0.0005, -0.0089],\n",
      "        [ 0.1207,  0.0218,  0.0128,  0.0019,  0.1173, -0.0409,  0.1133,  0.0980,\n",
      "         -0.0107,  0.0712,  0.1171, -0.1006, -0.0758, -0.0200, -0.1181,  0.0794,\n",
      "         -0.0522,  0.1071, -0.0319, -0.0109, -0.1212, -0.0397,  0.0822,  0.0679,\n",
      "         -0.0841, -0.0126,  0.0459,  0.0540, -0.0777, -0.0607, -0.0499,  0.0811,\n",
      "          0.1091, -0.1140, -0.0630, -0.0836, -0.1179, -0.0513,  0.0681, -0.0603,\n",
      "          0.0790,  0.1233,  0.0441,  0.0204,  0.0039,  0.0563, -0.0185, -0.0042,\n",
      "         -0.0649,  0.1123, -0.0516, -0.0839, -0.0494, -0.0193, -0.0688, -0.0653,\n",
      "         -0.0760, -0.1130, -0.0371,  0.0190,  0.1218, -0.1091, -0.0934,  0.1162],\n",
      "        [ 0.1107, -0.0342,  0.0255,  0.0535, -0.0221, -0.0299, -0.1129, -0.0712,\n",
      "          0.0350, -0.0857, -0.1232, -0.0641,  0.0994, -0.0575,  0.0213, -0.0269,\n",
      "          0.0637, -0.0998, -0.0749, -0.0949, -0.0200,  0.0587,  0.0025,  0.1074,\n",
      "          0.1011,  0.0013, -0.1083, -0.1201,  0.0585,  0.1074,  0.0784,  0.1160,\n",
      "         -0.0193,  0.0110,  0.0132,  0.0855,  0.1241, -0.0732, -0.0687, -0.0537,\n",
      "         -0.0764,  0.0341, -0.0408,  0.0166, -0.1065,  0.0667,  0.1092,  0.0806,\n",
      "         -0.0371, -0.0074, -0.0208, -0.0855, -0.0493, -0.0735, -0.0733, -0.0799,\n",
      "          0.0515, -0.0885,  0.0192, -0.0463,  0.0549, -0.1036,  0.1176,  0.0723],\n",
      "        [-0.0126, -0.0791, -0.0913,  0.0940, -0.1067, -0.0067,  0.1205, -0.0246,\n",
      "          0.0508, -0.0245,  0.1158, -0.0437,  0.0520, -0.1227,  0.1024,  0.0885,\n",
      "          0.0964,  0.1239, -0.0194,  0.0404, -0.0390,  0.0373, -0.1245, -0.1235,\n",
      "          0.0162,  0.0259,  0.0161,  0.0664, -0.1126, -0.0939,  0.0594,  0.0204,\n",
      "         -0.0179,  0.0412, -0.0644,  0.1004,  0.0243, -0.0913, -0.0645,  0.0474,\n",
      "          0.1233,  0.0539,  0.0927,  0.0657, -0.0419,  0.1059,  0.0671, -0.1235,\n",
      "         -0.0290, -0.0507,  0.0847, -0.0200,  0.0604, -0.0316, -0.0146, -0.0625,\n",
      "          0.0776, -0.0847, -0.0776, -0.1058, -0.0538, -0.0551,  0.0711, -0.0390],\n",
      "        [-0.1027,  0.0379, -0.0964, -0.0715,  0.0970, -0.0882, -0.0461, -0.0763,\n",
      "         -0.0384, -0.0887, -0.0832,  0.0368, -0.0474,  0.0683,  0.0079,  0.0484,\n",
      "          0.0047,  0.0508,  0.0372,  0.0857,  0.0281, -0.1192, -0.0831,  0.0776,\n",
      "         -0.1166,  0.0658,  0.1116,  0.0713, -0.0354,  0.1012,  0.0647,  0.1104,\n",
      "         -0.1126,  0.1144, -0.0628, -0.0373, -0.0273,  0.0575,  0.1030, -0.0574,\n",
      "         -0.0017, -0.0540, -0.0559, -0.0885, -0.0914, -0.0295, -0.0214,  0.1190,\n",
      "          0.0913,  0.0545,  0.0675,  0.0185, -0.1108, -0.0824,  0.0361, -0.0721,\n",
      "          0.0135, -0.0051, -0.1161, -0.0636, -0.0010, -0.0936,  0.0109, -0.0845],\n",
      "        [-0.0549,  0.0829,  0.0266,  0.1179,  0.0708,  0.0840, -0.0225, -0.1111,\n",
      "          0.1238, -0.0553, -0.0279, -0.1076,  0.0074, -0.0364,  0.0979,  0.0058,\n",
      "          0.0071,  0.0486, -0.0598, -0.0619,  0.1067, -0.0246,  0.0900,  0.0561,\n",
      "          0.0309, -0.0037,  0.0240,  0.0332,  0.0209, -0.1189,  0.1083, -0.0918,\n",
      "          0.0788, -0.1219, -0.0225, -0.0355, -0.1087, -0.0920,  0.1197, -0.1060,\n",
      "         -0.0178, -0.1115, -0.1186, -0.0258,  0.0551, -0.0368, -0.0778, -0.0508,\n",
      "          0.0501,  0.0660,  0.0142,  0.0161, -0.0554, -0.0949,  0.0532,  0.0002,\n",
      "         -0.0749, -0.0555, -0.0056, -0.1023, -0.1124,  0.0646,  0.0509,  0.0739]],\n",
      "       requires_grad=True)}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "        # for s in mask_2:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n",
    "#print(mg.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block_1.0.bias', tensor([-0.1754, -0.0768, -0.1785,  0.0166,  0.0276,  0.1453, -0.1076,  0.0642])), ('block_1.0.parametrizations.weight.original', tensor([[[[ 5.1704e-02,  1.2624e-01, -7.0364e-02],\n",
      "          [ 8.7340e-02, -2.5986e-02,  3.7529e-02],\n",
      "          [ 1.1660e-01,  2.4349e-02,  1.8000e-01]],\n",
      "\n",
      "         [[-1.0022e-02, -9.4345e-02, -6.9259e-02],\n",
      "          [ 1.5370e-01,  1.2753e-01,  3.1925e-02],\n",
      "          [-1.1334e-01,  1.6628e-01,  8.8755e-02]],\n",
      "\n",
      "         [[-8.4247e-02, -1.4654e-01, -1.2246e-01],\n",
      "          [ 9.5408e-02,  8.9733e-02,  3.2500e-02],\n",
      "          [ 3.8013e-02, -2.2334e-02,  1.1118e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5120e-02, -7.2599e-02,  1.7118e-01],\n",
      "          [ 1.0351e-01,  7.9553e-02, -7.9617e-02],\n",
      "          [-1.4024e-01,  2.5723e-02, -5.1885e-02]],\n",
      "\n",
      "         [[-1.7011e-01, -1.9724e-02,  1.7424e-01],\n",
      "          [-2.9218e-02,  1.9196e-01, -1.2844e-01],\n",
      "          [-3.1470e-02,  7.6522e-02,  5.6215e-03]],\n",
      "\n",
      "         [[ 5.6314e-02,  6.3420e-02,  1.8989e-01],\n",
      "          [ 1.5026e-01, -3.3128e-02, -4.1353e-02],\n",
      "          [ 1.1736e-01,  1.3027e-03, -4.2328e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0522e-02, -3.1300e-02, -1.6687e-01],\n",
      "          [ 1.4934e-01, -1.3308e-01, -2.9929e-02],\n",
      "          [ 6.3063e-02, -2.2150e-02, -1.7647e-01]],\n",
      "\n",
      "         [[-1.2311e-01,  1.2796e-01, -5.2410e-02],\n",
      "          [-8.4057e-02, -8.5129e-03, -1.5569e-01],\n",
      "          [ 1.8809e-01, -4.3816e-02,  8.8805e-02]],\n",
      "\n",
      "         [[-1.4293e-01, -1.1576e-01, -1.6168e-01],\n",
      "          [ 9.1641e-02,  3.6236e-02, -1.8535e-02],\n",
      "          [ 7.3741e-02,  8.7323e-02, -4.6959e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5238e-01,  3.8725e-02,  9.0705e-02],\n",
      "          [ 1.3388e-01,  9.2275e-02,  2.1228e-02],\n",
      "          [ 1.8487e-01, -1.5859e-01, -9.6275e-02]],\n",
      "\n",
      "         [[-1.8771e-01,  6.5528e-02, -1.8357e-01],\n",
      "          [-1.5845e-01, -1.3676e-02,  1.3393e-01],\n",
      "          [ 1.4438e-01, -5.6215e-02, -1.0195e-01]],\n",
      "\n",
      "         [[ 7.9669e-02,  2.4160e-02, -1.3619e-01],\n",
      "          [ 1.3609e-01,  1.6677e-02,  2.5590e-02],\n",
      "          [-1.8171e-01, -7.5986e-02,  4.1003e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0477e-02,  1.8071e-01, -1.0797e-01],\n",
      "          [-1.7619e-01,  6.6832e-02,  1.2278e-01],\n",
      "          [ 8.0127e-02,  1.6283e-01, -1.7860e-01]],\n",
      "\n",
      "         [[ 1.7336e-01, -1.0530e-01,  1.1999e-01],\n",
      "          [-5.2940e-03,  1.6183e-01, -1.6447e-01],\n",
      "          [-1.9748e-03,  1.1545e-01, -1.4533e-01]],\n",
      "\n",
      "         [[-4.7816e-02,  1.0988e-01,  1.8068e-01],\n",
      "          [-6.1194e-02,  1.0234e-04, -1.4489e-02],\n",
      "          [ 1.7936e-01, -1.6275e-01, -1.0647e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.1125e-02, -1.1378e-01, -1.8117e-02],\n",
      "          [-1.7262e-01, -2.6956e-02, -5.9510e-02],\n",
      "          [-1.8961e-01,  1.5506e-02,  1.7814e-01]],\n",
      "\n",
      "         [[ 1.3244e-01, -1.8273e-01,  1.6897e-01],\n",
      "          [-5.0649e-02,  6.0142e-03, -1.0693e-01],\n",
      "          [-1.4437e-01,  5.7867e-02,  5.9152e-02]],\n",
      "\n",
      "         [[-1.6283e-01,  8.4539e-02, -5.3863e-02],\n",
      "          [-2.2362e-02,  1.4602e-01, -1.3326e-01],\n",
      "          [-1.4660e-01, -3.5246e-02,  1.6367e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5900e-01, -9.2900e-02, -4.9845e-02],\n",
      "          [-1.6738e-01, -1.1778e-01, -1.7047e-01],\n",
      "          [-1.4208e-01, -9.4847e-02,  1.1766e-01]],\n",
      "\n",
      "         [[ 7.6310e-02,  1.7145e-01, -9.3629e-02],\n",
      "          [ 1.5037e-01,  7.4763e-02,  6.7978e-02],\n",
      "          [-1.2313e-01, -1.7256e-01, -3.0992e-02]],\n",
      "\n",
      "         [[ 1.8756e-01,  1.4744e-02,  6.4811e-02],\n",
      "          [-1.6612e-01, -6.1690e-02,  1.4028e-01],\n",
      "          [ 1.2523e-01,  9.0906e-02, -1.2269e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5990e-01, -1.5964e-01,  1.7345e-01],\n",
      "          [-1.0263e-01, -1.1241e-01, -6.9852e-02],\n",
      "          [-1.7700e-01, -4.5767e-02,  5.2140e-02]],\n",
      "\n",
      "         [[-1.0185e-01, -8.5317e-03,  1.1764e-01],\n",
      "          [ 1.3284e-01, -1.7913e-01, -1.5675e-01],\n",
      "          [-1.2446e-01, -7.8618e-02, -6.7420e-02]],\n",
      "\n",
      "         [[-1.3074e-01, -1.3845e-01, -1.4446e-01],\n",
      "          [-9.7685e-02, -1.4944e-01,  1.5959e-01],\n",
      "          [-1.4916e-01,  2.1493e-02,  6.5884e-02]]]])), ('block_1.0.parametrizations.weight.0.mask', tensor([[[[False,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False, False, False],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [ True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]]]])), ('block_2.0.bias', tensor([-0.0579, -0.0014, -0.0113, -0.0020, -0.0454, -0.0924,  0.1108,  0.0742,\n",
      "         0.0899, -0.0091, -0.0597, -0.0774, -0.0745, -0.0060,  0.0578, -0.0115])), ('block_2.0.parametrizations.weight.original', tensor([[[[ 3.4321e-02, -4.9850e-02,  2.9307e-02],\n",
      "          [ 2.5560e-02, -8.4711e-02,  1.7967e-02],\n",
      "          [-4.3849e-02,  2.8215e-02, -1.0321e-02]],\n",
      "\n",
      "         [[ 9.3043e-02,  9.5789e-02, -2.3457e-02],\n",
      "          [ 9.5743e-02, -2.8419e-02, -9.2512e-02],\n",
      "          [-9.0791e-03,  7.8199e-02,  2.4415e-02]],\n",
      "\n",
      "         [[-1.1611e-01, -1.1174e-01,  4.2443e-02],\n",
      "          [ 7.0311e-02, -8.6449e-02, -8.6879e-02],\n",
      "          [-1.2225e-02,  9.0938e-02,  5.4901e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8909e-02, -4.8778e-02, -1.1742e-03],\n",
      "          [-5.1027e-02, -1.0488e-01, -6.2889e-02],\n",
      "          [-1.1026e-02, -5.6141e-02,  8.5694e-02]],\n",
      "\n",
      "         [[ 9.2053e-02, -8.9485e-02,  8.8490e-02],\n",
      "          [-1.0706e-01, -9.6175e-02,  6.2511e-02],\n",
      "          [-3.8530e-02, -3.6260e-02, -2.6977e-02]],\n",
      "\n",
      "         [[-1.0523e-01, -5.3229e-02,  6.5811e-02],\n",
      "          [ 2.7730e-02, -9.3291e-02,  6.6582e-02],\n",
      "          [ 1.0126e-01,  1.0454e-01, -1.9337e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0386e-02, -4.3029e-02,  8.8698e-02],\n",
      "          [-7.3844e-03,  2.4893e-02, -4.1393e-02],\n",
      "          [-6.1318e-02,  1.1478e-01, -6.0276e-02]],\n",
      "\n",
      "         [[-8.2308e-02,  3.6465e-02,  1.0078e-01],\n",
      "          [-6.8828e-02,  5.9688e-02,  1.2829e-02],\n",
      "          [-2.4985e-02,  1.8574e-02,  5.5242e-02]],\n",
      "\n",
      "         [[ 6.1029e-02,  1.0907e-01, -1.1678e-01],\n",
      "          [-9.5131e-02,  7.4418e-02,  3.7318e-02],\n",
      "          [-2.5243e-03, -2.7965e-02, -1.9305e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0285e-01, -4.1361e-02,  7.9219e-02],\n",
      "          [-2.4342e-02,  1.9272e-02,  7.8148e-02],\n",
      "          [-3.9851e-02,  3.3437e-02,  1.3431e-03]],\n",
      "\n",
      "         [[ 1.2829e-02,  8.7143e-02, -5.8858e-02],\n",
      "          [ 9.7131e-03, -1.7133e-02, -7.0212e-02],\n",
      "          [-9.4219e-02,  3.5797e-02, -9.1581e-03]],\n",
      "\n",
      "         [[ 6.0417e-02,  8.4153e-02,  1.0460e-01],\n",
      "          [ 8.0772e-02,  5.3400e-02,  9.9163e-02],\n",
      "          [ 8.0512e-03, -6.3181e-02,  1.0740e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8020e-03,  2.0114e-03, -6.1956e-03],\n",
      "          [ 7.6301e-02,  9.0921e-02, -2.1973e-02],\n",
      "          [ 2.7793e-02,  9.5909e-02, -9.7892e-02]],\n",
      "\n",
      "         [[-1.4371e-02, -3.3803e-02, -8.5035e-04],\n",
      "          [-9.6610e-02,  2.8375e-02,  5.8946e-02],\n",
      "          [ 2.0310e-02, -8.1563e-02, -6.0019e-02]],\n",
      "\n",
      "         [[ 7.3400e-02,  7.9123e-02, -3.4140e-02],\n",
      "          [-1.1744e-01,  1.4977e-02, -1.9056e-02],\n",
      "          [-1.0310e-03,  9.8820e-02, -3.7014e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5992e-02, -7.3060e-02, -9.8696e-02],\n",
      "          [-9.1361e-02,  8.4061e-02,  1.1305e-01],\n",
      "          [-2.1191e-02,  6.5838e-03, -3.6708e-02]],\n",
      "\n",
      "         [[-1.0033e-01,  2.5174e-02,  1.5084e-02],\n",
      "          [ 6.1551e-02,  4.9753e-02, -1.0320e-01],\n",
      "          [ 6.8204e-02, -8.4432e-03,  1.0399e-01]],\n",
      "\n",
      "         [[-3.5598e-02, -1.0724e-01, -1.9777e-03],\n",
      "          [ 7.9074e-02,  5.6477e-02, -6.7962e-02],\n",
      "          [ 5.3793e-02,  6.2376e-02, -1.0139e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1918e-02,  3.5969e-03, -9.0362e-02],\n",
      "          [-1.0355e-01, -2.0965e-02, -1.0988e-01],\n",
      "          [ 3.5294e-02,  2.3280e-02, -7.7463e-02]],\n",
      "\n",
      "         [[-1.1847e-02,  7.2760e-05, -4.7375e-02],\n",
      "          [-1.0319e-01, -1.9802e-02, -1.1613e-01],\n",
      "          [-8.3724e-02, -1.8723e-02,  6.5509e-02]],\n",
      "\n",
      "         [[-5.8829e-02, -7.5160e-02,  5.0081e-02],\n",
      "          [ 8.4786e-02, -3.4419e-02, -1.1775e-01],\n",
      "          [ 5.8241e-02,  6.2422e-02, -9.7851e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6094e-02, -8.1790e-02, -2.7379e-02],\n",
      "          [ 1.3259e-02, -1.2868e-02,  2.9581e-02],\n",
      "          [ 2.6595e-02, -8.8599e-02,  9.0710e-02]],\n",
      "\n",
      "         [[ 5.6136e-02, -6.6920e-02, -6.5847e-02],\n",
      "          [ 4.3337e-02, -2.1878e-02,  9.5824e-03],\n",
      "          [ 8.7184e-02,  8.7198e-02,  7.3595e-02]],\n",
      "\n",
      "         [[-4.3243e-02, -5.2230e-02,  1.6344e-02],\n",
      "          [ 2.1657e-02, -7.9539e-03, -4.2570e-02],\n",
      "          [-4.3125e-04, -4.0415e-02,  3.3650e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4879e-02, -8.1556e-03,  9.8504e-02],\n",
      "          [-6.2002e-02,  7.9171e-02,  1.0844e-01],\n",
      "          [ 4.3844e-02,  3.1210e-02,  1.1316e-01]],\n",
      "\n",
      "         [[-1.1257e-01,  1.0720e-01,  3.4963e-02],\n",
      "          [ 1.6349e-02, -1.8074e-02,  1.3484e-02],\n",
      "          [ 6.6861e-02,  1.5014e-02,  1.4331e-02]],\n",
      "\n",
      "         [[ 5.1442e-02, -8.3921e-02,  9.1221e-02],\n",
      "          [ 4.8028e-02,  1.0760e-01, -8.5602e-02],\n",
      "          [-1.0724e-01, -9.9652e-02, -1.0456e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9724e-02,  4.7782e-02, -7.3244e-02],\n",
      "          [-5.5048e-02,  1.9284e-03,  1.0424e-01],\n",
      "          [ 1.0587e-01,  1.2675e-02, -6.6069e-02]],\n",
      "\n",
      "         [[ 9.0121e-02, -1.2886e-02,  7.9841e-02],\n",
      "          [-3.7366e-02,  8.7862e-02,  7.4537e-02],\n",
      "          [-1.2609e-03, -8.8299e-02,  5.8368e-02]],\n",
      "\n",
      "         [[ 8.1566e-02,  1.0130e-01,  7.4580e-02],\n",
      "          [-1.0346e-01, -1.1429e-02, -3.3229e-02],\n",
      "          [-7.7320e-02, -1.1157e-01,  1.0967e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3603e-02, -9.8970e-02, -4.4917e-02],\n",
      "          [-1.4035e-02, -1.0711e-01, -1.1245e-01],\n",
      "          [-1.3892e-02,  8.7547e-02, -8.1224e-02]],\n",
      "\n",
      "         [[-4.4316e-02, -7.8035e-02, -9.2933e-02],\n",
      "          [-8.9890e-02,  6.2053e-02, -7.5440e-02],\n",
      "          [-7.7220e-02,  1.7211e-02, -2.4072e-02]],\n",
      "\n",
      "         [[-7.4439e-02, -9.0372e-02, -3.0093e-02],\n",
      "          [-1.7002e-02,  1.0166e-01, -9.0273e-03],\n",
      "          [-5.5652e-02, -1.6259e-02,  4.6242e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3717e-02, -1.1424e-01, -3.4214e-02],\n",
      "          [ 3.1028e-02, -3.9923e-02, -7.0900e-02],\n",
      "          [-8.0319e-02, -3.2766e-02, -6.3780e-02]],\n",
      "\n",
      "         [[-8.5193e-02,  5.5011e-02, -6.8953e-02],\n",
      "          [ 3.3580e-02,  1.0460e-01, -5.4852e-02],\n",
      "          [ 1.8355e-02,  1.1222e-02, -5.2781e-02]],\n",
      "\n",
      "         [[ 5.1184e-02,  5.6302e-02, -5.1738e-02],\n",
      "          [ 3.5080e-02,  6.4245e-02,  1.1570e-01],\n",
      "          [ 4.3033e-02,  6.5007e-02, -1.1420e-01]]]])), ('block_2.0.parametrizations.weight.0.mask', tensor([[[[False, False, False],\n",
      "          [False,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [False, False, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False, False,  True],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [ True,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True, False, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False, False,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False,  True],\n",
      "          [False, False,  True]]]])), ('block_3.0.bias', tensor([-0.0784, -0.0823,  0.1050, -0.0046,  0.0173, -0.1200,  0.0377, -0.1103,\n",
      "        -0.1244, -0.0365,  0.1008, -0.1158,  0.0811,  0.1110, -0.0366, -0.0957,\n",
      "        -0.0809, -0.0415,  0.1245, -0.1105,  0.0680, -0.0942, -0.1394, -0.1249,\n",
      "        -0.0177, -0.0110, -0.1250, -0.0855,  0.1244,  0.1425,  0.0978, -0.0419])), ('block_3.0.parametrizations.weight.original', tensor([[[ 0.0942,  0.0771, -0.0921],\n",
      "         [-0.0340,  0.0404, -0.0543],\n",
      "         [-0.1249,  0.0302,  0.1132],\n",
      "         ...,\n",
      "         [-0.0298, -0.0024, -0.1340],\n",
      "         [-0.0616,  0.1423, -0.0293],\n",
      "         [ 0.1240, -0.1068,  0.0416]],\n",
      "\n",
      "        [[-0.0378,  0.0568, -0.1126],\n",
      "         [-0.1379,  0.1423,  0.0161],\n",
      "         [-0.0064,  0.1387, -0.0028],\n",
      "         ...,\n",
      "         [-0.0958,  0.0534, -0.1217],\n",
      "         [-0.0783, -0.1333, -0.1028],\n",
      "         [ 0.0250,  0.1196, -0.1393]],\n",
      "\n",
      "        [[ 0.1145,  0.1412, -0.0257],\n",
      "         [ 0.1049, -0.0771,  0.1345],\n",
      "         [ 0.1320,  0.1379, -0.0624],\n",
      "         ...,\n",
      "         [ 0.0517, -0.1160,  0.1212],\n",
      "         [-0.0876,  0.0013, -0.1411],\n",
      "         [-0.0088,  0.0595, -0.1414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1233,  0.1362,  0.0500],\n",
      "         [-0.1414,  0.1287, -0.0468],\n",
      "         [ 0.0052, -0.0635, -0.0418],\n",
      "         ...,\n",
      "         [ 0.1296, -0.0749, -0.0659],\n",
      "         [-0.0950, -0.1013, -0.0313],\n",
      "         [ 0.1027,  0.0946, -0.0229]],\n",
      "\n",
      "        [[ 0.0963, -0.1334,  0.1404],\n",
      "         [ 0.0128,  0.0478,  0.1285],\n",
      "         [ 0.0200,  0.1055,  0.0314],\n",
      "         ...,\n",
      "         [ 0.1434, -0.0911, -0.1200],\n",
      "         [ 0.0581,  0.1289, -0.1059],\n",
      "         [ 0.0134,  0.0272, -0.0063]],\n",
      "\n",
      "        [[-0.0932, -0.0892,  0.1430],\n",
      "         [ 0.0487,  0.0651, -0.0552],\n",
      "         [-0.1204,  0.0801,  0.0736],\n",
      "         ...,\n",
      "         [-0.0963, -0.1057, -0.0906],\n",
      "         [-0.0743,  0.0310, -0.0411],\n",
      "         [ 0.0651, -0.1359, -0.0436]]])), ('block_3.0.parametrizations.weight.0.mask', tensor([[[ True,  True,  True],\n",
      "         [False, False, False],\n",
      "         [ True, False,  True],\n",
      "         ...,\n",
      "         [False, False,  True],\n",
      "         [False,  True, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[False, False,  True],\n",
      "         [ True,  True, False],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        [[ True,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ True,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True,  True, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [False, False,  True],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [False, False, False],\n",
      "         [ True,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False],\n",
      "         [False,  True, False]]])), ('block_4.0.bias', tensor([-0.0171,  0.0328, -0.0253,  0.0287, -0.0194,  0.0007, -0.0336, -0.0985,\n",
      "        -0.0271,  0.0610,  0.0864, -0.0087,  0.0676,  0.0052, -0.0265, -0.0533,\n",
      "         0.0334,  0.0482, -0.0599,  0.0874, -0.0210, -0.0156, -0.0205,  0.0765,\n",
      "        -0.0795, -0.0606, -0.0897,  0.0431,  0.0543, -0.0960, -0.0505, -0.0803,\n",
      "        -0.0881,  0.0665,  0.0226,  0.0940, -0.0633,  0.0383, -0.0288,  0.0715,\n",
      "        -0.0804, -0.1002,  0.0893, -0.0253,  0.0462,  0.0440, -0.0138,  0.0021,\n",
      "         0.0310, -0.0675,  0.0485, -0.0273, -0.0074,  0.0588,  0.0653, -0.0915,\n",
      "         0.0470, -0.0995,  0.0742, -0.0374,  0.0537, -0.0247, -0.0184,  0.0191])), ('block_4.0.parametrizations.weight.original', tensor([[[-0.0871,  0.0270,  0.0818],\n",
      "         [-0.0270,  0.0673,  0.0456],\n",
      "         [-0.0528,  0.0475, -0.0385],\n",
      "         ...,\n",
      "         [-0.0313,  0.0451, -0.0036],\n",
      "         [-0.0873, -0.0556, -0.0913],\n",
      "         [ 0.1007,  0.0331,  0.1010]],\n",
      "\n",
      "        [[-0.0155,  0.0916, -0.0341],\n",
      "         [-0.0051, -0.0909, -0.0315],\n",
      "         [-0.0447,  0.0603,  0.0653],\n",
      "         ...,\n",
      "         [-0.0104, -0.0814,  0.0097],\n",
      "         [ 0.0017, -0.0677, -0.0316],\n",
      "         [-0.0032, -0.0041, -0.0328]],\n",
      "\n",
      "        [[ 0.0180, -0.0588,  0.0214],\n",
      "         [ 0.0353, -0.0795,  0.0676],\n",
      "         [-0.0087,  0.0813,  0.0909],\n",
      "         ...,\n",
      "         [ 0.0193,  0.0904,  0.0967],\n",
      "         [ 0.0688, -0.0831,  0.0122],\n",
      "         [-0.0289,  0.0965, -0.0990]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0510, -0.1000,  0.0584],\n",
      "         [-0.0318, -0.0078,  0.0929],\n",
      "         [-0.0445, -0.0814,  0.0450],\n",
      "         ...,\n",
      "         [-0.0947,  0.0798,  0.1019],\n",
      "         [-0.0447, -0.0113,  0.0974],\n",
      "         [ 0.0511, -0.0226, -0.0275]],\n",
      "\n",
      "        [[ 0.0723, -0.0909, -0.0881],\n",
      "         [-0.0709, -0.0440,  0.0858],\n",
      "         [ 0.0104, -0.0737, -0.0968],\n",
      "         ...,\n",
      "         [-0.0035, -0.0503, -0.0403],\n",
      "         [ 0.0247, -0.0087, -0.0401],\n",
      "         [ 0.0527, -0.0835,  0.0938]],\n",
      "\n",
      "        [[ 0.0798, -0.0488,  0.0334],\n",
      "         [-0.0327,  0.0808, -0.0488],\n",
      "         [-0.0655, -0.0700, -0.0797],\n",
      "         ...,\n",
      "         [ 0.0422,  0.0818,  0.0454],\n",
      "         [-0.0867,  0.0792, -0.0710],\n",
      "         [-0.0859, -0.0134,  0.0425]]])), ('block_4.0.parametrizations.weight.0.mask', tensor([[[ True, False,  True],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [ True, False,  True],\n",
      "         [ True, False,  True]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [False,  True, False],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [False,  True, False],\n",
      "         [False,  True, False],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[False, False, False],\n",
      "         [False,  True, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [ True,  True, False],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [False, False,  True],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False,  True, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [False,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False]]])), ('linear.bias', tensor([ 0.1145,  0.0742,  0.1038, -0.0820,  0.0053,  0.0576,  0.0494,  0.0499,\n",
      "        -0.0856, -0.0203])), ('linear.parametrizations.weight.original', tensor([[ 0.1231,  0.1070,  0.0702, -0.0399, -0.0537,  0.0388,  0.0295, -0.0526,\n",
      "         -0.0089, -0.1205, -0.0649, -0.0419,  0.0919, -0.0557,  0.0272, -0.0472,\n",
      "         -0.0578, -0.0621, -0.0587,  0.0975,  0.0703,  0.0270, -0.0734,  0.0563,\n",
      "         -0.0547, -0.1000,  0.0131,  0.0098, -0.0884,  0.0028, -0.0037, -0.0332,\n",
      "          0.0846,  0.0170, -0.0016, -0.0207,  0.0802, -0.1033,  0.0559,  0.0725,\n",
      "         -0.0536, -0.0952, -0.0811,  0.0894,  0.0623, -0.0156,  0.0636, -0.0475,\n",
      "          0.0232,  0.0176, -0.0543, -0.0095,  0.0646, -0.0257,  0.1148, -0.1008,\n",
      "         -0.0753, -0.0745,  0.1248,  0.0132, -0.0006, -0.0839, -0.0127,  0.0429],\n",
      "        [ 0.1139,  0.1173, -0.0668,  0.0785,  0.0143,  0.1133, -0.0583, -0.0021,\n",
      "          0.0836, -0.0153,  0.0491,  0.0481, -0.0030, -0.0932, -0.0828, -0.0406,\n",
      "          0.1122,  0.1198,  0.0265, -0.1046, -0.0704, -0.0071, -0.0817, -0.0882,\n",
      "         -0.0713,  0.0616,  0.0718, -0.1036,  0.0839, -0.0144,  0.0540, -0.0446,\n",
      "         -0.0086, -0.0587, -0.0528,  0.0916, -0.0015,  0.0160,  0.0403,  0.0878,\n",
      "         -0.0036, -0.0460, -0.0857,  0.0860, -0.0586, -0.0883, -0.0176,  0.1125,\n",
      "          0.1061, -0.1154, -0.0501,  0.0284,  0.1029,  0.0280,  0.0096,  0.0899,\n",
      "          0.0387, -0.1225, -0.1155, -0.0554, -0.1032, -0.0108, -0.0460, -0.0963],\n",
      "        [-0.1221, -0.0440,  0.1052,  0.0727, -0.0385,  0.0084, -0.0680, -0.0643,\n",
      "          0.0789,  0.0439, -0.1163,  0.1159,  0.0563, -0.0416, -0.0062,  0.0390,\n",
      "          0.0913,  0.0735,  0.0418,  0.0787,  0.0441, -0.0193, -0.0719,  0.0198,\n",
      "          0.0849, -0.0750,  0.0623,  0.0737, -0.0823,  0.0008, -0.0992,  0.0791,\n",
      "          0.0543,  0.0678, -0.1157, -0.1185, -0.0754,  0.0629, -0.0797, -0.1191,\n",
      "         -0.1050,  0.1150,  0.0921,  0.1152, -0.0331, -0.1093,  0.0085,  0.0802,\n",
      "          0.1105, -0.0108, -0.0929, -0.1079,  0.0113,  0.0935,  0.1126, -0.0356,\n",
      "          0.0673, -0.0865, -0.0061, -0.0470,  0.0410, -0.0833,  0.0195, -0.0792],\n",
      "        [ 0.0607, -0.0353, -0.0634,  0.0618,  0.0797,  0.0874, -0.0061,  0.0094,\n",
      "          0.1010, -0.0929, -0.0200, -0.0787, -0.0299, -0.0031,  0.0409, -0.0902,\n",
      "          0.0550, -0.0433,  0.0910, -0.0159, -0.0857,  0.0645, -0.1165,  0.0119,\n",
      "          0.0148,  0.0387, -0.1080,  0.0133, -0.0910, -0.0312,  0.0187,  0.0214,\n",
      "          0.0101,  0.0289, -0.1051,  0.1085, -0.0300,  0.1085, -0.1223,  0.0269,\n",
      "         -0.0889, -0.0806,  0.1116,  0.0472,  0.0067, -0.0301,  0.0054,  0.0760,\n",
      "          0.0624, -0.0011,  0.0587, -0.0042, -0.1115,  0.0707, -0.0648, -0.0824,\n",
      "          0.0135, -0.0043,  0.0686, -0.0460,  0.0996,  0.0626, -0.0324,  0.1072],\n",
      "        [-0.0854,  0.0750,  0.0138, -0.0558,  0.0615,  0.0833,  0.0011, -0.0709,\n",
      "          0.0695, -0.0443, -0.0580, -0.0300,  0.0717,  0.1126,  0.0045,  0.0559,\n",
      "          0.0224, -0.1171, -0.0276,  0.0155,  0.0088,  0.0996,  0.1079, -0.0288,\n",
      "         -0.0037, -0.0705, -0.0837, -0.0402, -0.1079, -0.0596,  0.0557, -0.0794,\n",
      "          0.0155,  0.0487,  0.0652, -0.0576, -0.0523,  0.0643,  0.0916,  0.0543,\n",
      "         -0.0296, -0.1076,  0.1188,  0.0951,  0.0026, -0.0922, -0.0772, -0.1084,\n",
      "          0.0087, -0.0984,  0.0936,  0.1038, -0.0134,  0.0814, -0.0123, -0.0759,\n",
      "          0.1210,  0.0175,  0.0742,  0.1155, -0.0080, -0.0938, -0.0005, -0.0089],\n",
      "        [ 0.1207,  0.0218,  0.0128,  0.0019,  0.1173, -0.0409,  0.1133,  0.0980,\n",
      "         -0.0107,  0.0712,  0.1171, -0.1006, -0.0758, -0.0200, -0.1181,  0.0794,\n",
      "         -0.0522,  0.1071, -0.0319, -0.0109, -0.1212, -0.0397,  0.0822,  0.0679,\n",
      "         -0.0841, -0.0126,  0.0459,  0.0540, -0.0777, -0.0607, -0.0499,  0.0811,\n",
      "          0.1091, -0.1140, -0.0630, -0.0836, -0.1179, -0.0513,  0.0681, -0.0603,\n",
      "          0.0790,  0.1233,  0.0441,  0.0204,  0.0039,  0.0563, -0.0185, -0.0042,\n",
      "         -0.0649,  0.1123, -0.0516, -0.0839, -0.0494, -0.0193, -0.0688, -0.0653,\n",
      "         -0.0760, -0.1130, -0.0371,  0.0190,  0.1218, -0.1091, -0.0934,  0.1162],\n",
      "        [ 0.1107, -0.0342,  0.0255,  0.0535, -0.0221, -0.0299, -0.1129, -0.0712,\n",
      "          0.0350, -0.0857, -0.1232, -0.0641,  0.0994, -0.0575,  0.0213, -0.0269,\n",
      "          0.0637, -0.0998, -0.0749, -0.0949, -0.0200,  0.0587,  0.0025,  0.1074,\n",
      "          0.1011,  0.0013, -0.1083, -0.1201,  0.0585,  0.1074,  0.0784,  0.1160,\n",
      "         -0.0193,  0.0110,  0.0132,  0.0855,  0.1241, -0.0732, -0.0687, -0.0537,\n",
      "         -0.0764,  0.0341, -0.0408,  0.0166, -0.1065,  0.0667,  0.1092,  0.0806,\n",
      "         -0.0371, -0.0074, -0.0208, -0.0855, -0.0493, -0.0735, -0.0733, -0.0799,\n",
      "          0.0515, -0.0885,  0.0192, -0.0463,  0.0549, -0.1036,  0.1176,  0.0723],\n",
      "        [-0.0126, -0.0791, -0.0913,  0.0940, -0.1067, -0.0067,  0.1205, -0.0246,\n",
      "          0.0508, -0.0245,  0.1158, -0.0437,  0.0520, -0.1227,  0.1024,  0.0885,\n",
      "          0.0964,  0.1239, -0.0194,  0.0404, -0.0390,  0.0373, -0.1245, -0.1235,\n",
      "          0.0162,  0.0259,  0.0161,  0.0664, -0.1126, -0.0939,  0.0594,  0.0204,\n",
      "         -0.0179,  0.0412, -0.0644,  0.1004,  0.0243, -0.0913, -0.0645,  0.0474,\n",
      "          0.1233,  0.0539,  0.0927,  0.0657, -0.0419,  0.1059,  0.0671, -0.1235,\n",
      "         -0.0290, -0.0507,  0.0847, -0.0200,  0.0604, -0.0316, -0.0146, -0.0625,\n",
      "          0.0776, -0.0847, -0.0776, -0.1058, -0.0538, -0.0551,  0.0711, -0.0390],\n",
      "        [-0.1027,  0.0379, -0.0964, -0.0715,  0.0970, -0.0882, -0.0461, -0.0763,\n",
      "         -0.0384, -0.0887, -0.0832,  0.0368, -0.0474,  0.0683,  0.0079,  0.0484,\n",
      "          0.0047,  0.0508,  0.0372,  0.0857,  0.0281, -0.1192, -0.0831,  0.0776,\n",
      "         -0.1166,  0.0658,  0.1116,  0.0713, -0.0354,  0.1012,  0.0647,  0.1104,\n",
      "         -0.1126,  0.1144, -0.0628, -0.0373, -0.0273,  0.0575,  0.1030, -0.0574,\n",
      "         -0.0017, -0.0540, -0.0559, -0.0885, -0.0914, -0.0295, -0.0214,  0.1190,\n",
      "          0.0913,  0.0545,  0.0675,  0.0185, -0.1108, -0.0824,  0.0361, -0.0721,\n",
      "          0.0135, -0.0051, -0.1161, -0.0636, -0.0010, -0.0936,  0.0109, -0.0845],\n",
      "        [-0.0549,  0.0829,  0.0266,  0.1179,  0.0708,  0.0840, -0.0225, -0.1111,\n",
      "          0.1238, -0.0553, -0.0279, -0.1076,  0.0074, -0.0364,  0.0979,  0.0058,\n",
      "          0.0071,  0.0486, -0.0598, -0.0619,  0.1067, -0.0246,  0.0900,  0.0561,\n",
      "          0.0309, -0.0037,  0.0240,  0.0332,  0.0209, -0.1189,  0.1083, -0.0918,\n",
      "          0.0788, -0.1219, -0.0225, -0.0355, -0.1087, -0.0920,  0.1197, -0.1060,\n",
      "         -0.0178, -0.1115, -0.1186, -0.0258,  0.0551, -0.0368, -0.0778, -0.0508,\n",
      "          0.0501,  0.0660,  0.0142,  0.0161, -0.0554, -0.0949,  0.0532,  0.0002,\n",
      "         -0.0749, -0.0555, -0.0056, -0.1023, -0.1124,  0.0646,  0.0509,  0.0739]])), ('linear.parametrizations.weight.0.mask', tensor([[ True,  True,  True, False, False, False, False, False, False,  True,\n",
      "         False, False,  True, False, False, False, False, False, False,  True,\n",
      "          True, False,  True, False, False,  True, False, False,  True, False,\n",
      "         False, False,  True, False, False, False,  True,  True, False,  True,\n",
      "         False,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True,  True, False,\n",
      "         False,  True, False, False],\n",
      "        [ True,  True, False,  True, False,  True, False, False,  True, False,\n",
      "         False, False, False,  True,  True, False,  True,  True, False,  True,\n",
      "          True, False,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         False, False, False, False, False,  True, False, False, False,  True,\n",
      "         False, False,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         False, False,  True, False, False,  True, False,  True,  True, False,\n",
      "          True, False, False,  True],\n",
      "        [ True, False,  True,  True, False, False,  True, False,  True, False,\n",
      "          True,  True, False, False, False, False,  True,  True, False,  True,\n",
      "         False, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "          True,  True, False,  True,  True,  True,  True, False,  True,  True,\n",
      "          True,  True,  True,  True, False,  True, False,  True,  True, False,\n",
      "          True,  True, False,  True,  True, False, False,  True, False, False,\n",
      "         False,  True, False,  True],\n",
      "        [False, False, False, False,  True,  True, False, False,  True,  True,\n",
      "         False,  True, False, False, False,  True, False, False,  True, False,\n",
      "          True, False,  True, False, False, False,  True, False,  True, False,\n",
      "         False, False, False, False,  True,  True, False,  True,  True, False,\n",
      "          True,  True,  True, False, False, False, False,  True, False, False,\n",
      "         False, False,  True,  True, False,  True, False, False,  True, False,\n",
      "          True, False, False,  True],\n",
      "        [ True,  True, False, False, False,  True, False,  True,  True, False,\n",
      "         False, False,  True,  True, False, False, False,  True, False, False,\n",
      "         False,  True,  True, False, False,  True,  True, False,  True, False,\n",
      "         False,  True, False, False, False, False, False, False,  True, False,\n",
      "         False,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "          True,  True, False,  True, False,  True,  True, False,  True,  True,\n",
      "         False,  True, False, False],\n",
      "        [ True, False, False, False,  True, False,  True,  True, False,  True,\n",
      "          True,  True,  True, False,  True,  True, False,  True, False, False,\n",
      "          True, False,  True,  True,  True, False, False, False,  True, False,\n",
      "         False,  True,  True,  True, False,  True,  True, False,  True, False,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "         False,  True, False, False,  True, False,  True,  True, False, False,\n",
      "          True,  True,  True,  True],\n",
      "        [ True, False, False, False, False, False,  True,  True, False,  True,\n",
      "          True, False,  True, False, False, False, False,  True,  True,  True,\n",
      "         False, False, False,  True,  True, False,  True,  True, False,  True,\n",
      "          True,  True, False, False, False,  True,  True,  True,  True, False,\n",
      "          True, False, False, False,  True, False,  True,  True, False, False,\n",
      "         False,  True, False,  True,  True,  True, False,  True, False, False,\n",
      "         False,  True,  True,  True],\n",
      "        [False,  True,  True,  True,  True, False,  True, False, False, False,\n",
      "          True, False, False,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False,  True,  True, False, False, False, False,  True,  True,\n",
      "         False, False, False, False, False,  True, False,  True, False, False,\n",
      "          True, False,  True, False, False,  True, False,  True, False, False,\n",
      "          True, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         False, False,  True, False],\n",
      "        [ True, False,  True,  True,  True,  True, False,  True, False,  True,\n",
      "          True, False, False,  True, False, False, False, False, False,  True,\n",
      "         False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
      "         False,  True,  True,  True, False, False, False, False,  True, False,\n",
      "         False, False, False,  True,  True, False, False,  True,  True, False,\n",
      "         False, False,  True,  True, False,  True, False, False,  True, False,\n",
      "         False,  True, False,  True],\n",
      "        [False,  True, False,  True,  True,  True, False,  True,  True, False,\n",
      "         False,  True, False, False,  True, False, False, False, False, False,\n",
      "          True, False,  True, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
      "         False,  True,  True, False, False, False,  True, False, False, False,\n",
      "         False, False, False,  True, False, False,  True, False, False,  True,\n",
      "          True, False, False,  True]]))])\n"
     ]
    }
   ],
   "source": [
    "print(mg.model.state_dict())\n",
    "#print(node.meta['mase'].parameters['common']['args']['weight']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[ 0.1231,  0.1070,  0.0702, -0.0399, -0.0537,  0.0388,  0.0295, -0.0526,\n",
      "         -0.0089, -0.1205, -0.0649, -0.0419,  0.0919, -0.0557,  0.0272, -0.0472,\n",
      "         -0.0578, -0.0621, -0.0587,  0.0975,  0.0703,  0.0270, -0.0734,  0.0563,\n",
      "         -0.0547, -0.1000,  0.0131,  0.0098, -0.0884,  0.0028, -0.0037, -0.0332,\n",
      "          0.0846,  0.0170, -0.0016, -0.0207,  0.0802, -0.1033,  0.0559,  0.0725,\n",
      "         -0.0536, -0.0952, -0.0811,  0.0894,  0.0623, -0.0156,  0.0636, -0.0475,\n",
      "          0.0232,  0.0176, -0.0543, -0.0095,  0.0646, -0.0257,  0.1148, -0.1008,\n",
      "         -0.0753, -0.0745,  0.1248,  0.0132, -0.0006, -0.0839, -0.0127,  0.0429],\n",
      "        [ 0.1139,  0.1173, -0.0668,  0.0785,  0.0143,  0.1133, -0.0583, -0.0021,\n",
      "          0.0836, -0.0153,  0.0491,  0.0481, -0.0030, -0.0932, -0.0828, -0.0406,\n",
      "          0.1122,  0.1198,  0.0265, -0.1046, -0.0704, -0.0071, -0.0817, -0.0882,\n",
      "         -0.0713,  0.0616,  0.0718, -0.1036,  0.0839, -0.0144,  0.0540, -0.0446,\n",
      "         -0.0086, -0.0587, -0.0528,  0.0916, -0.0015,  0.0160,  0.0403,  0.0878,\n",
      "         -0.0036, -0.0460, -0.0857,  0.0860, -0.0586, -0.0883, -0.0176,  0.1125,\n",
      "          0.1061, -0.1154, -0.0501,  0.0284,  0.1029,  0.0280,  0.0096,  0.0899,\n",
      "          0.0387, -0.1225, -0.1155, -0.0554, -0.1032, -0.0108, -0.0460, -0.0963],\n",
      "        [-0.1221, -0.0440,  0.1052,  0.0727, -0.0385,  0.0084, -0.0680, -0.0643,\n",
      "          0.0789,  0.0439, -0.1163,  0.1159,  0.0563, -0.0416, -0.0062,  0.0390,\n",
      "          0.0913,  0.0735,  0.0418,  0.0787,  0.0441, -0.0193, -0.0719,  0.0198,\n",
      "          0.0849, -0.0750,  0.0623,  0.0737, -0.0823,  0.0008, -0.0992,  0.0791,\n",
      "          0.0543,  0.0678, -0.1157, -0.1185, -0.0754,  0.0629, -0.0797, -0.1191,\n",
      "         -0.1050,  0.1150,  0.0921,  0.1152, -0.0331, -0.1093,  0.0085,  0.0802,\n",
      "          0.1105, -0.0108, -0.0929, -0.1079,  0.0113,  0.0935,  0.1126, -0.0356,\n",
      "          0.0673, -0.0865, -0.0061, -0.0470,  0.0410, -0.0833,  0.0195, -0.0792],\n",
      "        [ 0.0607, -0.0353, -0.0634,  0.0618,  0.0797,  0.0874, -0.0061,  0.0094,\n",
      "          0.1010, -0.0929, -0.0200, -0.0787, -0.0299, -0.0031,  0.0409, -0.0902,\n",
      "          0.0550, -0.0433,  0.0910, -0.0159, -0.0857,  0.0645, -0.1165,  0.0119,\n",
      "          0.0148,  0.0387, -0.1080,  0.0133, -0.0910, -0.0312,  0.0187,  0.0214,\n",
      "          0.0101,  0.0289, -0.1051,  0.1085, -0.0300,  0.1085, -0.1223,  0.0269,\n",
      "         -0.0889, -0.0806,  0.1116,  0.0472,  0.0067, -0.0301,  0.0054,  0.0760,\n",
      "          0.0624, -0.0011,  0.0587, -0.0042, -0.1115,  0.0707, -0.0648, -0.0824,\n",
      "          0.0135, -0.0043,  0.0686, -0.0460,  0.0996,  0.0626, -0.0324,  0.1072],\n",
      "        [-0.0854,  0.0750,  0.0138, -0.0558,  0.0615,  0.0833,  0.0011, -0.0709,\n",
      "          0.0695, -0.0443, -0.0580, -0.0300,  0.0717,  0.1126,  0.0045,  0.0559,\n",
      "          0.0224, -0.1171, -0.0276,  0.0155,  0.0088,  0.0996,  0.1079, -0.0288,\n",
      "         -0.0037, -0.0705, -0.0837, -0.0402, -0.1079, -0.0596,  0.0557, -0.0794,\n",
      "          0.0155,  0.0487,  0.0652, -0.0576, -0.0523,  0.0643,  0.0916,  0.0543,\n",
      "         -0.0296, -0.1076,  0.1188,  0.0951,  0.0026, -0.0922, -0.0772, -0.1084,\n",
      "          0.0087, -0.0984,  0.0936,  0.1038, -0.0134,  0.0814, -0.0123, -0.0759,\n",
      "          0.1210,  0.0175,  0.0742,  0.1155, -0.0080, -0.0938, -0.0005, -0.0089],\n",
      "        [ 0.1207,  0.0218,  0.0128,  0.0019,  0.1173, -0.0409,  0.1133,  0.0980,\n",
      "         -0.0107,  0.0712,  0.1171, -0.1006, -0.0758, -0.0200, -0.1181,  0.0794,\n",
      "         -0.0522,  0.1071, -0.0319, -0.0109, -0.1212, -0.0397,  0.0822,  0.0679,\n",
      "         -0.0841, -0.0126,  0.0459,  0.0540, -0.0777, -0.0607, -0.0499,  0.0811,\n",
      "          0.1091, -0.1140, -0.0630, -0.0836, -0.1179, -0.0513,  0.0681, -0.0603,\n",
      "          0.0790,  0.1233,  0.0441,  0.0204,  0.0039,  0.0563, -0.0185, -0.0042,\n",
      "         -0.0649,  0.1123, -0.0516, -0.0839, -0.0494, -0.0193, -0.0688, -0.0653,\n",
      "         -0.0760, -0.1130, -0.0371,  0.0190,  0.1218, -0.1091, -0.0934,  0.1162],\n",
      "        [ 0.1107, -0.0342,  0.0255,  0.0535, -0.0221, -0.0299, -0.1129, -0.0712,\n",
      "          0.0350, -0.0857, -0.1232, -0.0641,  0.0994, -0.0575,  0.0213, -0.0269,\n",
      "          0.0637, -0.0998, -0.0749, -0.0949, -0.0200,  0.0587,  0.0025,  0.1074,\n",
      "          0.1011,  0.0013, -0.1083, -0.1201,  0.0585,  0.1074,  0.0784,  0.1160,\n",
      "         -0.0193,  0.0110,  0.0132,  0.0855,  0.1241, -0.0732, -0.0687, -0.0537,\n",
      "         -0.0764,  0.0341, -0.0408,  0.0166, -0.1065,  0.0667,  0.1092,  0.0806,\n",
      "         -0.0371, -0.0074, -0.0208, -0.0855, -0.0493, -0.0735, -0.0733, -0.0799,\n",
      "          0.0515, -0.0885,  0.0192, -0.0463,  0.0549, -0.1036,  0.1176,  0.0723],\n",
      "        [-0.0126, -0.0791, -0.0913,  0.0940, -0.1067, -0.0067,  0.1205, -0.0246,\n",
      "          0.0508, -0.0245,  0.1158, -0.0437,  0.0520, -0.1227,  0.1024,  0.0885,\n",
      "          0.0964,  0.1239, -0.0194,  0.0404, -0.0390,  0.0373, -0.1245, -0.1235,\n",
      "          0.0162,  0.0259,  0.0161,  0.0664, -0.1126, -0.0939,  0.0594,  0.0204,\n",
      "         -0.0179,  0.0412, -0.0644,  0.1004,  0.0243, -0.0913, -0.0645,  0.0474,\n",
      "          0.1233,  0.0539,  0.0927,  0.0657, -0.0419,  0.1059,  0.0671, -0.1235,\n",
      "         -0.0290, -0.0507,  0.0847, -0.0200,  0.0604, -0.0316, -0.0146, -0.0625,\n",
      "          0.0776, -0.0847, -0.0776, -0.1058, -0.0538, -0.0551,  0.0711, -0.0390],\n",
      "        [-0.1027,  0.0379, -0.0964, -0.0715,  0.0970, -0.0882, -0.0461, -0.0763,\n",
      "         -0.0384, -0.0887, -0.0832,  0.0368, -0.0474,  0.0683,  0.0079,  0.0484,\n",
      "          0.0047,  0.0508,  0.0372,  0.0857,  0.0281, -0.1192, -0.0831,  0.0776,\n",
      "         -0.1166,  0.0658,  0.1116,  0.0713, -0.0354,  0.1012,  0.0647,  0.1104,\n",
      "         -0.1126,  0.1144, -0.0628, -0.0373, -0.0273,  0.0575,  0.1030, -0.0574,\n",
      "         -0.0017, -0.0540, -0.0559, -0.0885, -0.0914, -0.0295, -0.0214,  0.1190,\n",
      "          0.0913,  0.0545,  0.0675,  0.0185, -0.1108, -0.0824,  0.0361, -0.0721,\n",
      "          0.0135, -0.0051, -0.1161, -0.0636, -0.0010, -0.0936,  0.0109, -0.0845],\n",
      "        [-0.0549,  0.0829,  0.0266,  0.1179,  0.0708,  0.0840, -0.0225, -0.1111,\n",
      "          0.1238, -0.0553, -0.0279, -0.1076,  0.0074, -0.0364,  0.0979,  0.0058,\n",
      "          0.0071,  0.0486, -0.0598, -0.0619,  0.1067, -0.0246,  0.0900,  0.0561,\n",
      "          0.0309, -0.0037,  0.0240,  0.0332,  0.0209, -0.1189,  0.1083, -0.0918,\n",
      "          0.0788, -0.1219, -0.0225, -0.0355, -0.1087, -0.0920,  0.1197, -0.1060,\n",
      "         -0.0178, -0.1115, -0.1186, -0.0258,  0.0551, -0.0368, -0.0778, -0.0508,\n",
      "          0.0501,  0.0660,  0.0142,  0.0161, -0.0554, -0.0949,  0.0532,  0.0002,\n",
      "         -0.0749, -0.0555, -0.0056, -0.1023, -0.1124,  0.0646,  0.0509,  0.0739]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
