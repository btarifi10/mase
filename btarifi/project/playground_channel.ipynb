{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.actions import train\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0071, -0.1201, -0.2267, -0.0036,  0.0387,  0.2377, -0.0907,  0.1734,\n",
      "         -0.0068, -0.1752,  0.1893,  0.1971, -0.2455, -0.0030,  0.0605,  0.0689],\n",
      "        [ 0.0777, -0.0160, -0.1336,  0.1596, -0.1498,  0.0826, -0.0080, -0.1852,\n",
      "         -0.1340, -0.0444,  0.2480, -0.1136, -0.0744, -0.0110, -0.0194,  0.0241],\n",
      "        [-0.1639,  0.2252, -0.0322, -0.0671,  0.0073, -0.0872, -0.1262,  0.2293,\n",
      "         -0.2015, -0.1364,  0.1217, -0.1235,  0.0570,  0.0812,  0.2477,  0.1620],\n",
      "        [ 0.0175,  0.0241,  0.2209, -0.1608, -0.2049,  0.0016, -0.2360,  0.2398,\n",
      "          0.0985, -0.0579, -0.2063, -0.1056, -0.2181, -0.2238,  0.2105,  0.0833],\n",
      "        [-0.0650, -0.1742, -0.1779, -0.2297, -0.0787, -0.1829, -0.1394,  0.0014,\n",
      "         -0.0916,  0.1522, -0.1246, -0.0163,  0.2452,  0.0194, -0.0331, -0.2496]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('weight',\n",
      "              tensor([[-0.0071, -0.1201, -0.2267, -0.0036,  0.0387,  0.2377, -0.0907,  0.1734,\n",
      "         -0.0068, -0.1752,  0.1893,  0.1971, -0.2455, -0.0030,  0.0605,  0.0689],\n",
      "        [ 0.0777, -0.0160, -0.1336,  0.1596, -0.1498,  0.0826, -0.0080, -0.1852,\n",
      "         -0.1340, -0.0444,  0.2480, -0.1136, -0.0744, -0.0110, -0.0194,  0.0241],\n",
      "        [-0.1639,  0.2252, -0.0322, -0.0671,  0.0073, -0.0872, -0.1262,  0.2293,\n",
      "         -0.2015, -0.1364,  0.1217, -0.1235,  0.0570,  0.0812,  0.2477,  0.1620],\n",
      "        [ 0.0175,  0.0241,  0.2209, -0.1608, -0.2049,  0.0016, -0.2360,  0.2398,\n",
      "          0.0985, -0.0579, -0.2063, -0.1056, -0.2181, -0.2238,  0.2105,  0.0833],\n",
      "        [-0.0650, -0.1742, -0.1779, -0.2297, -0.0787, -0.1829, -0.1394,  0.0014,\n",
      "         -0.0916,  0.1522, -0.1246, -0.0163,  0.2452,  0.0194, -0.0331, -0.2496]])),\n",
      "             ('bias', tensor([ 0.0751, -0.0778,  0.0786, -0.0864, -0.1024]))])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        if node.op == \"call_module\":\n",
    "            #print(node.name)\n",
    "            #print(50*'-')\n",
    "            #print(node.target)\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())\n",
    "            \n",
    "            \n",
    "#print(mg.modules)\n",
    "#print(type(mg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    "    activation_pruning_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, -0.0000, -0.2267, -0.0000,  0.0000,  0.2377, -0.0000,  0.1734,\n",
      "         -0.0000, -0.1752,  0.1893,  0.1971, -0.2455, -0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000, -0.1336,  0.1596, -0.1498,  0.0000, -0.0000, -0.1852,\n",
      "         -0.1340, -0.0000,  0.2480, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "        [-0.1639,  0.2252, -0.0000, -0.0000,  0.0000, -0.0000, -0.1262,  0.2293,\n",
      "         -0.2015, -0.1364,  0.0000, -0.1235,  0.0000,  0.0000,  0.2477,  0.1620],\n",
      "        [ 0.0000,  0.0000,  0.2209, -0.1608, -0.2049,  0.0000, -0.2360,  0.2398,\n",
      "          0.0000, -0.0000, -0.2063, -0.0000, -0.2181, -0.2238,  0.2105,  0.0000],\n",
      "        [-0.0000, -0.1742, -0.1779, -0.2297, -0.0000, -0.1829, -0.1394,  0.0000,\n",
      "         -0.0000,  0.1522, -0.1246, -0.0000,  0.2452,  0.0000, -0.0000, -0.2496]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('bias', tensor([ 0.0751, -0.0778,  0.0786, -0.0864, -0.1024])),\n",
      "             ('parametrizations.weight.original',\n",
      "              tensor([[-0.0071, -0.1201, -0.2267, -0.0036,  0.0387,  0.2377, -0.0907,  0.1734,\n",
      "         -0.0068, -0.1752,  0.1893,  0.1971, -0.2455, -0.0030,  0.0605,  0.0689],\n",
      "        [ 0.0777, -0.0160, -0.1336,  0.1596, -0.1498,  0.0826, -0.0080, -0.1852,\n",
      "         -0.1340, -0.0444,  0.2480, -0.1136, -0.0744, -0.0110, -0.0194,  0.0241],\n",
      "        [-0.1639,  0.2252, -0.0322, -0.0671,  0.0073, -0.0872, -0.1262,  0.2293,\n",
      "         -0.2015, -0.1364,  0.1217, -0.1235,  0.0570,  0.0812,  0.2477,  0.1620],\n",
      "        [ 0.0175,  0.0241,  0.2209, -0.1608, -0.2049,  0.0016, -0.2360,  0.2398,\n",
      "          0.0985, -0.0579, -0.2063, -0.1056, -0.2181, -0.2238,  0.2105,  0.0833],\n",
      "        [-0.0650, -0.1742, -0.1779, -0.2297, -0.0787, -0.1829, -0.1394,  0.0014,\n",
      "         -0.0916,  0.1522, -0.1246, -0.0163,  0.2452,  0.0194, -0.0331, -0.2496]])),\n",
      "             ('parametrizations.weight.0.mask',\n",
      "              tensor([[False, False,  True, False, False,  True, False,  True, False,  True,\n",
      "          True,  True,  True, False, False, False],\n",
      "        [False, False,  True,  True,  True, False, False,  True,  True, False,\n",
      "          True, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False,  True,  True,  True,  True,\n",
      "         False,  True, False, False,  True,  True],\n",
      "        [False, False,  True,  True,  True, False,  True,  True, False, False,\n",
      "          True, False,  True,  True,  True, False],\n",
      "        [False,  True,  True,  True, False,  True,  True, False, False,  True,\n",
      "          True, False,  True, False, False,  True]]))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        if node.op == \"call_module\":\n",
    "            #print(node.name)\n",
    "            #print(50*'-')\n",
    "            #print(node.target)\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "            # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 117   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "117       Trainable params\n",
      "0         Non-trainable params\n",
      "117       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/agomotto3000/anaconda3/envs/mase/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1542/1542 [00:31<00:00, 49.04it/s, v_num=30, train_acc_step=0.445, val_acc_epoch=0.456, val_loss_epoch=1.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1542/1542 [00:31<00:00, 49.03it/s, v_num=30, train_acc_step=0.445, val_acc_epoch=0.456, val_loss_epoch=1.300]\n"
     ]
    }
   ],
   "source": [
    "model = mg.model\n",
    "model_info = get_model_info('jsc-tiny')\n",
    "dataset_info = get_dataset_info('jsc')\n",
    "task = \"cls\"\n",
    "\n",
    "train_params = {\n",
    "    \"model\": model,\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": task,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 1,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "train(**train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model_name = \"toy_convnet\"\n",
    "dataset_name = \"Cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 1.3748e-01,  2.1479e-02, -9.4732e-02],\n",
      "          [ 2.9365e-02,  1.4427e-01, -8.5327e-02],\n",
      "          [ 1.6447e-02,  8.1002e-02, -2.6879e-02]],\n",
      "\n",
      "         [[-1.3203e-01, -4.0379e-02,  1.2712e-01],\n",
      "          [-1.8229e-01, -1.4738e-02, -5.4161e-02],\n",
      "          [-2.4612e-02, -1.1651e-01, -3.0695e-02]],\n",
      "\n",
      "         [[ 1.2624e-01, -1.0735e-02,  1.4186e-01],\n",
      "          [ 9.0847e-02, -1.2447e-01,  1.7536e-01],\n",
      "          [ 1.0018e-01,  8.5701e-02,  1.7813e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9845e-02,  1.1027e-01,  1.1402e-01],\n",
      "          [-1.0543e-01,  1.2811e-01, -1.7400e-01],\n",
      "          [ 1.2780e-01,  1.2102e-01, -9.4646e-02]],\n",
      "\n",
      "         [[ 4.9147e-02,  1.9159e-01, -2.3558e-02],\n",
      "          [-1.8466e-01,  1.4989e-01, -1.3137e-01],\n",
      "          [-6.7507e-02,  8.6385e-02,  5.5279e-03]],\n",
      "\n",
      "         [[ 2.8780e-02, -1.3954e-01,  1.6852e-01],\n",
      "          [ 3.2005e-02, -1.9144e-01,  9.4916e-02],\n",
      "          [-2.4395e-03,  1.1808e-01, -1.2889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2024e-05, -2.7090e-03, -3.6521e-02],\n",
      "          [ 6.6903e-02, -5.0821e-02, -1.5914e-03],\n",
      "          [-3.3344e-04, -4.2687e-03, -1.1346e-01]],\n",
      "\n",
      "         [[ 1.0644e-01,  1.9707e-03, -1.4363e-01],\n",
      "          [-1.0466e-01,  6.3399e-02, -3.3935e-02],\n",
      "          [ 1.1182e-01, -1.6017e-02, -1.6411e-02]],\n",
      "\n",
      "         [[-6.1391e-02, -1.6581e-01, -2.3034e-02],\n",
      "          [ 1.2102e-01, -6.2285e-02,  8.4734e-02],\n",
      "          [-1.6145e-01, -1.0271e-01,  1.2427e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7800e-01, -1.5719e-01,  7.9682e-02],\n",
      "          [-9.1448e-02,  1.2018e-01, -4.3454e-02],\n",
      "          [-1.1007e-01,  3.6836e-03,  6.1442e-02]],\n",
      "\n",
      "         [[ 1.1316e-01, -1.1584e-01, -1.8120e-01],\n",
      "          [ 1.8850e-01, -2.6005e-02, -1.3770e-01],\n",
      "          [-9.1124e-02,  3.3013e-02, -8.7636e-02]],\n",
      "\n",
      "         [[-1.2117e-01, -1.1946e-02, -7.4002e-02],\n",
      "          [-1.0449e-01, -1.6674e-01, -1.7665e-01],\n",
      "          [-8.2055e-02,  4.5225e-02, -1.6924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7681e-02,  8.2558e-02,  1.7941e-02],\n",
      "          [ 5.6737e-02,  1.7552e-01, -2.9810e-02],\n",
      "          [ 9.5078e-02,  3.3256e-02,  8.8965e-02]],\n",
      "\n",
      "         [[ 1.8819e-01, -1.1427e-01,  9.0562e-03],\n",
      "          [ 1.0816e-01, -1.1161e-01, -1.8921e-01],\n",
      "          [ 4.7288e-02,  4.0721e-02, -1.0259e-01]],\n",
      "\n",
      "         [[ 1.8235e-02, -1.2289e-01,  6.1536e-03],\n",
      "          [-1.1327e-01,  7.9490e-02,  1.3292e-01],\n",
      "          [-9.4702e-02, -1.3729e-01, -8.6533e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2998e-01,  1.3294e-01,  7.8978e-02],\n",
      "          [-6.7378e-02, -1.2464e-01,  1.6839e-01],\n",
      "          [ 7.1478e-02, -3.8255e-03, -1.0208e-01]],\n",
      "\n",
      "         [[-8.8225e-02,  1.2188e-01,  1.9067e-01],\n",
      "          [-9.1131e-02,  6.5071e-02,  1.5968e-01],\n",
      "          [ 1.9058e-01, -1.6839e-01, -1.7416e-01]],\n",
      "\n",
      "         [[-1.1744e-02, -1.1639e-01,  1.6769e-01],\n",
      "          [ 1.7700e-01, -1.2135e-02,  9.5799e-02],\n",
      "          [-1.2063e-01,  1.9103e-02,  1.2298e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7454e-01,  1.3236e-02, -9.6806e-02],\n",
      "          [ 1.0493e-01, -1.7739e-01,  1.7731e-01],\n",
      "          [ 1.5874e-01,  7.1080e-02,  4.1057e-03]],\n",
      "\n",
      "         [[-8.6675e-02,  8.3419e-02,  4.6499e-03],\n",
      "          [ 1.4227e-01,  4.0836e-03, -8.9578e-02],\n",
      "          [-3.2970e-02, -3.2476e-02, -3.7406e-02]],\n",
      "\n",
      "         [[ 1.1284e-01, -8.1442e-02, -1.5794e-01],\n",
      "          [ 3.4568e-02,  5.3024e-02,  1.3732e-01],\n",
      "          [-1.3180e-01,  1.1319e-01,  3.5940e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5474e-01, -1.7806e-01,  3.1436e-02],\n",
      "          [-3.6155e-02,  2.6093e-02, -5.5522e-02],\n",
      "          [ 1.8125e-02, -1.7254e-01, -1.1417e-01]],\n",
      "\n",
      "         [[ 1.1152e-02, -1.7807e-01, -1.0281e-01],\n",
      "          [ 1.0673e-02, -9.2227e-02,  1.2225e-01],\n",
      "          [ 1.1569e-02,  1.9160e-01,  1.7921e-01]],\n",
      "\n",
      "         [[ 1.3393e-01, -1.1584e-01,  1.5162e-01],\n",
      "          [-8.5293e-02,  1.3082e-01, -1.2735e-01],\n",
      "          [ 2.7560e-02, -1.7687e-01, -1.7471e-01]]]], requires_grad=True)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[ 1.3748e-01,  2.1479e-02, -9.4732e-02],\n",
      "          [ 2.9365e-02,  1.4427e-01, -8.5327e-02],\n",
      "          [ 1.6447e-02,  8.1002e-02, -2.6879e-02]],\n",
      "\n",
      "         [[-1.3203e-01, -4.0379e-02,  1.2712e-01],\n",
      "          [-1.8229e-01, -1.4738e-02, -5.4161e-02],\n",
      "          [-2.4612e-02, -1.1651e-01, -3.0695e-02]],\n",
      "\n",
      "         [[ 1.2624e-01, -1.0735e-02,  1.4186e-01],\n",
      "          [ 9.0847e-02, -1.2447e-01,  1.7536e-01],\n",
      "          [ 1.0018e-01,  8.5701e-02,  1.7813e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9845e-02,  1.1027e-01,  1.1402e-01],\n",
      "          [-1.0543e-01,  1.2811e-01, -1.7400e-01],\n",
      "          [ 1.2780e-01,  1.2102e-01, -9.4646e-02]],\n",
      "\n",
      "         [[ 4.9147e-02,  1.9159e-01, -2.3558e-02],\n",
      "          [-1.8466e-01,  1.4989e-01, -1.3137e-01],\n",
      "          [-6.7507e-02,  8.6385e-02,  5.5279e-03]],\n",
      "\n",
      "         [[ 2.8780e-02, -1.3954e-01,  1.6852e-01],\n",
      "          [ 3.2005e-02, -1.9144e-01,  9.4916e-02],\n",
      "          [-2.4395e-03,  1.1808e-01, -1.2889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2024e-05, -2.7090e-03, -3.6521e-02],\n",
      "          [ 6.6903e-02, -5.0821e-02, -1.5914e-03],\n",
      "          [-3.3344e-04, -4.2687e-03, -1.1346e-01]],\n",
      "\n",
      "         [[ 1.0644e-01,  1.9707e-03, -1.4363e-01],\n",
      "          [-1.0466e-01,  6.3399e-02, -3.3935e-02],\n",
      "          [ 1.1182e-01, -1.6017e-02, -1.6411e-02]],\n",
      "\n",
      "         [[-6.1391e-02, -1.6581e-01, -2.3034e-02],\n",
      "          [ 1.2102e-01, -6.2285e-02,  8.4734e-02],\n",
      "          [-1.6145e-01, -1.0271e-01,  1.2427e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7800e-01, -1.5719e-01,  7.9682e-02],\n",
      "          [-9.1448e-02,  1.2018e-01, -4.3454e-02],\n",
      "          [-1.1007e-01,  3.6836e-03,  6.1442e-02]],\n",
      "\n",
      "         [[ 1.1316e-01, -1.1584e-01, -1.8120e-01],\n",
      "          [ 1.8850e-01, -2.6005e-02, -1.3770e-01],\n",
      "          [-9.1124e-02,  3.3013e-02, -8.7636e-02]],\n",
      "\n",
      "         [[-1.2117e-01, -1.1946e-02, -7.4002e-02],\n",
      "          [-1.0449e-01, -1.6674e-01, -1.7665e-01],\n",
      "          [-8.2055e-02,  4.5225e-02, -1.6924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7681e-02,  8.2558e-02,  1.7941e-02],\n",
      "          [ 5.6737e-02,  1.7552e-01, -2.9810e-02],\n",
      "          [ 9.5078e-02,  3.3256e-02,  8.8965e-02]],\n",
      "\n",
      "         [[ 1.8819e-01, -1.1427e-01,  9.0562e-03],\n",
      "          [ 1.0816e-01, -1.1161e-01, -1.8921e-01],\n",
      "          [ 4.7288e-02,  4.0721e-02, -1.0259e-01]],\n",
      "\n",
      "         [[ 1.8235e-02, -1.2289e-01,  6.1536e-03],\n",
      "          [-1.1327e-01,  7.9490e-02,  1.3292e-01],\n",
      "          [-9.4702e-02, -1.3729e-01, -8.6533e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2998e-01,  1.3294e-01,  7.8978e-02],\n",
      "          [-6.7378e-02, -1.2464e-01,  1.6839e-01],\n",
      "          [ 7.1478e-02, -3.8255e-03, -1.0208e-01]],\n",
      "\n",
      "         [[-8.8225e-02,  1.2188e-01,  1.9067e-01],\n",
      "          [-9.1131e-02,  6.5071e-02,  1.5968e-01],\n",
      "          [ 1.9058e-01, -1.6839e-01, -1.7416e-01]],\n",
      "\n",
      "         [[-1.1744e-02, -1.1639e-01,  1.6769e-01],\n",
      "          [ 1.7700e-01, -1.2135e-02,  9.5799e-02],\n",
      "          [-1.2063e-01,  1.9103e-02,  1.2298e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7454e-01,  1.3236e-02, -9.6806e-02],\n",
      "          [ 1.0493e-01, -1.7739e-01,  1.7731e-01],\n",
      "          [ 1.5874e-01,  7.1080e-02,  4.1057e-03]],\n",
      "\n",
      "         [[-8.6675e-02,  8.3419e-02,  4.6499e-03],\n",
      "          [ 1.4227e-01,  4.0836e-03, -8.9578e-02],\n",
      "          [-3.2970e-02, -3.2476e-02, -3.7406e-02]],\n",
      "\n",
      "         [[ 1.1284e-01, -8.1442e-02, -1.5794e-01],\n",
      "          [ 3.4568e-02,  5.3024e-02,  1.3732e-01],\n",
      "          [-1.3180e-01,  1.1319e-01,  3.5940e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5474e-01, -1.7806e-01,  3.1436e-02],\n",
      "          [-3.6155e-02,  2.6093e-02, -5.5522e-02],\n",
      "          [ 1.8125e-02, -1.7254e-01, -1.1417e-01]],\n",
      "\n",
      "         [[ 1.1152e-02, -1.7807e-01, -1.0281e-01],\n",
      "          [ 1.0673e-02, -9.2227e-02,  1.2225e-01],\n",
      "          [ 1.1569e-02,  1.9160e-01,  1.7921e-01]],\n",
      "\n",
      "         [[ 1.3393e-01, -1.1584e-01,  1.5162e-01],\n",
      "          [-8.5293e-02,  1.3082e-01, -1.2735e-01],\n",
      "          [ 2.7560e-02, -1.7687e-01, -1.7471e-01]]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.1693, -0.0775,  0.0651, -0.0930, -0.1775,  0.0550, -0.1746, -0.1815]))])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0264, -0.0990, -0.0090],\n",
      "          [-0.1100, -0.1175,  0.0886],\n",
      "          [ 0.0185,  0.0998,  0.0592]],\n",
      "\n",
      "         [[ 0.1152, -0.0820,  0.0208],\n",
      "          [-0.0883,  0.0623, -0.0870],\n",
      "          [ 0.0165,  0.0781,  0.0580]],\n",
      "\n",
      "         [[ 0.0829,  0.0471,  0.0944],\n",
      "          [-0.0724,  0.0281, -0.0726],\n",
      "          [ 0.0742,  0.0164, -0.0324]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682,  0.0340, -0.0899],\n",
      "          [ 0.0005, -0.0892, -0.0090],\n",
      "          [ 0.0094,  0.0177,  0.1055]],\n",
      "\n",
      "         [[-0.0556, -0.0140, -0.0835],\n",
      "          [ 0.0709, -0.0398,  0.0675],\n",
      "          [-0.0861, -0.0982,  0.0224]],\n",
      "\n",
      "         [[-0.0217, -0.0847,  0.0574],\n",
      "          [ 0.0776,  0.0987, -0.1070],\n",
      "          [-0.1032, -0.0984,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.0963,  0.0214],\n",
      "          [ 0.0178,  0.0100, -0.0062],\n",
      "          [ 0.0912,  0.0935,  0.0197]],\n",
      "\n",
      "         [[-0.0726, -0.0541, -0.0883],\n",
      "          [ 0.0822,  0.0130, -0.0563],\n",
      "          [-0.0285, -0.0023, -0.0545]],\n",
      "\n",
      "         [[ 0.0862,  0.0624,  0.0929],\n",
      "          [-0.0893,  0.0401, -0.0292],\n",
      "          [ 0.0553, -0.0797, -0.0291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0813,  0.0372,  0.0853],\n",
      "          [ 0.0482,  0.0736,  0.0347],\n",
      "          [-0.0558, -0.0624,  0.0190]],\n",
      "\n",
      "         [[ 0.0901, -0.0292, -0.0057],\n",
      "          [-0.0734,  0.0244,  0.1120],\n",
      "          [-0.0950, -0.1006,  0.1065]],\n",
      "\n",
      "         [[-0.0444,  0.0533,  0.0459],\n",
      "          [-0.0590, -0.0895, -0.1018],\n",
      "          [-0.0627,  0.0752, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[-0.0935,  0.0770, -0.0277],\n",
      "          [ 0.0582,  0.0652, -0.0918],\n",
      "          [-0.1164,  0.0865, -0.1015]],\n",
      "\n",
      "         [[ 0.0880, -0.0995,  0.1125],\n",
      "          [ 0.0430, -0.0124, -0.0604],\n",
      "          [ 0.0515, -0.1132,  0.0165]],\n",
      "\n",
      "         [[ 0.0826,  0.0565, -0.0261],\n",
      "          [-0.0670, -0.0915, -0.0630],\n",
      "          [ 0.0412,  0.0666,  0.1091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0980,  0.0889, -0.0025],\n",
      "          [-0.0024, -0.0668,  0.0565],\n",
      "          [ 0.0050,  0.0783, -0.0728]],\n",
      "\n",
      "         [[-0.0516, -0.0805, -0.0502],\n",
      "          [-0.0423,  0.1017,  0.0762],\n",
      "          [ 0.0564,  0.0306, -0.0064]],\n",
      "\n",
      "         [[-0.0082, -0.1171,  0.0080],\n",
      "          [ 0.0306,  0.1136,  0.0742],\n",
      "          [ 0.0702, -0.0610,  0.0773]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0678, -0.0860,  0.0712],\n",
      "          [-0.0385,  0.0325,  0.0677],\n",
      "          [ 0.0941,  0.0617, -0.1021]],\n",
      "\n",
      "         [[-0.0479, -0.0522, -0.0843],\n",
      "          [ 0.0876,  0.0224, -0.0209],\n",
      "          [-0.0134,  0.0392,  0.0182]],\n",
      "\n",
      "         [[-0.0864,  0.1121,  0.0078],\n",
      "          [-0.0344, -0.0595,  0.0431],\n",
      "          [-0.0775, -0.1130, -0.0875]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1006,  0.0279, -0.1116],\n",
      "          [-0.0274,  0.0472,  0.0561],\n",
      "          [-0.0932,  0.0299, -0.0501]],\n",
      "\n",
      "         [[ 0.0075,  0.0361, -0.0153],\n",
      "          [-0.0125,  0.0289,  0.0691],\n",
      "          [ 0.0070, -0.0497,  0.1040]],\n",
      "\n",
      "         [[-0.0698, -0.0718,  0.0983],\n",
      "          [ 0.0844,  0.0199, -0.0441],\n",
      "          [-0.0251,  0.0776, -0.0444]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0153,  0.0390,  0.0212],\n",
      "          [ 0.0908,  0.1161, -0.0959],\n",
      "          [-0.0182,  0.0581, -0.0498]],\n",
      "\n",
      "         [[-0.0750, -0.0898, -0.0044],\n",
      "          [ 0.0318,  0.0661, -0.0328],\n",
      "          [ 0.0646, -0.1121,  0.0534]],\n",
      "\n",
      "         [[-0.0917,  0.0869, -0.0858],\n",
      "          [ 0.0446, -0.0892,  0.0056],\n",
      "          [ 0.0295, -0.0899, -0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022, -0.1028, -0.0773],\n",
      "          [ 0.1139, -0.0884,  0.1080],\n",
      "          [-0.1028,  0.0832, -0.0256]],\n",
      "\n",
      "         [[ 0.0046,  0.0938,  0.0045],\n",
      "          [-0.0249,  0.0874, -0.0567],\n",
      "          [-0.0048,  0.0656,  0.0872]],\n",
      "\n",
      "         [[ 0.0667,  0.0404, -0.0214],\n",
      "          [-0.0236, -0.0360,  0.1005],\n",
      "          [ 0.0308,  0.0357, -0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0111,  0.0186,  0.0251],\n",
      "          [ 0.0609, -0.0373, -0.1067],\n",
      "          [-0.0667,  0.1012,  0.0346]],\n",
      "\n",
      "         [[-0.0595,  0.0940, -0.0642],\n",
      "          [-0.0243,  0.0586, -0.1053],\n",
      "          [-0.0098,  0.0503,  0.0019]],\n",
      "\n",
      "         [[-0.0916,  0.0103,  0.0763],\n",
      "          [ 0.0984,  0.1027,  0.0236],\n",
      "          [-0.0900,  0.0276,  0.0559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0867,  0.0393, -0.0238],\n",
      "          [ 0.0128,  0.0819,  0.0106],\n",
      "          [ 0.1084, -0.0259, -0.1101]],\n",
      "\n",
      "         [[ 0.0931,  0.0474, -0.0224],\n",
      "          [ 0.0580, -0.0052,  0.0148],\n",
      "          [ 0.0450,  0.0732, -0.0326]],\n",
      "\n",
      "         [[-0.0663,  0.1169, -0.0130],\n",
      "          [-0.0050, -0.0818,  0.0640],\n",
      "          [-0.0528, -0.0654,  0.0108]]]], requires_grad=True)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('weight',\n",
      "              tensor([[[[-0.0264, -0.0990, -0.0090],\n",
      "          [-0.1100, -0.1175,  0.0886],\n",
      "          [ 0.0185,  0.0998,  0.0592]],\n",
      "\n",
      "         [[ 0.1152, -0.0820,  0.0208],\n",
      "          [-0.0883,  0.0623, -0.0870],\n",
      "          [ 0.0165,  0.0781,  0.0580]],\n",
      "\n",
      "         [[ 0.0829,  0.0471,  0.0944],\n",
      "          [-0.0724,  0.0281, -0.0726],\n",
      "          [ 0.0742,  0.0164, -0.0324]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682,  0.0340, -0.0899],\n",
      "          [ 0.0005, -0.0892, -0.0090],\n",
      "          [ 0.0094,  0.0177,  0.1055]],\n",
      "\n",
      "         [[-0.0556, -0.0140, -0.0835],\n",
      "          [ 0.0709, -0.0398,  0.0675],\n",
      "          [-0.0861, -0.0982,  0.0224]],\n",
      "\n",
      "         [[-0.0217, -0.0847,  0.0574],\n",
      "          [ 0.0776,  0.0987, -0.1070],\n",
      "          [-0.1032, -0.0984,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.0963,  0.0214],\n",
      "          [ 0.0178,  0.0100, -0.0062],\n",
      "          [ 0.0912,  0.0935,  0.0197]],\n",
      "\n",
      "         [[-0.0726, -0.0541, -0.0883],\n",
      "          [ 0.0822,  0.0130, -0.0563],\n",
      "          [-0.0285, -0.0023, -0.0545]],\n",
      "\n",
      "         [[ 0.0862,  0.0624,  0.0929],\n",
      "          [-0.0893,  0.0401, -0.0292],\n",
      "          [ 0.0553, -0.0797, -0.0291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0813,  0.0372,  0.0853],\n",
      "          [ 0.0482,  0.0736,  0.0347],\n",
      "          [-0.0558, -0.0624,  0.0190]],\n",
      "\n",
      "         [[ 0.0901, -0.0292, -0.0057],\n",
      "          [-0.0734,  0.0244,  0.1120],\n",
      "          [-0.0950, -0.1006,  0.1065]],\n",
      "\n",
      "         [[-0.0444,  0.0533,  0.0459],\n",
      "          [-0.0590, -0.0895, -0.1018],\n",
      "          [-0.0627,  0.0752, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[-0.0935,  0.0770, -0.0277],\n",
      "          [ 0.0582,  0.0652, -0.0918],\n",
      "          [-0.1164,  0.0865, -0.1015]],\n",
      "\n",
      "         [[ 0.0880, -0.0995,  0.1125],\n",
      "          [ 0.0430, -0.0124, -0.0604],\n",
      "          [ 0.0515, -0.1132,  0.0165]],\n",
      "\n",
      "         [[ 0.0826,  0.0565, -0.0261],\n",
      "          [-0.0670, -0.0915, -0.0630],\n",
      "          [ 0.0412,  0.0666,  0.1091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0980,  0.0889, -0.0025],\n",
      "          [-0.0024, -0.0668,  0.0565],\n",
      "          [ 0.0050,  0.0783, -0.0728]],\n",
      "\n",
      "         [[-0.0516, -0.0805, -0.0502],\n",
      "          [-0.0423,  0.1017,  0.0762],\n",
      "          [ 0.0564,  0.0306, -0.0064]],\n",
      "\n",
      "         [[-0.0082, -0.1171,  0.0080],\n",
      "          [ 0.0306,  0.1136,  0.0742],\n",
      "          [ 0.0702, -0.0610,  0.0773]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0678, -0.0860,  0.0712],\n",
      "          [-0.0385,  0.0325,  0.0677],\n",
      "          [ 0.0941,  0.0617, -0.1021]],\n",
      "\n",
      "         [[-0.0479, -0.0522, -0.0843],\n",
      "          [ 0.0876,  0.0224, -0.0209],\n",
      "          [-0.0134,  0.0392,  0.0182]],\n",
      "\n",
      "         [[-0.0864,  0.1121,  0.0078],\n",
      "          [-0.0344, -0.0595,  0.0431],\n",
      "          [-0.0775, -0.1130, -0.0875]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1006,  0.0279, -0.1116],\n",
      "          [-0.0274,  0.0472,  0.0561],\n",
      "          [-0.0932,  0.0299, -0.0501]],\n",
      "\n",
      "         [[ 0.0075,  0.0361, -0.0153],\n",
      "          [-0.0125,  0.0289,  0.0691],\n",
      "          [ 0.0070, -0.0497,  0.1040]],\n",
      "\n",
      "         [[-0.0698, -0.0718,  0.0983],\n",
      "          [ 0.0844,  0.0199, -0.0441],\n",
      "          [-0.0251,  0.0776, -0.0444]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0153,  0.0390,  0.0212],\n",
      "          [ 0.0908,  0.1161, -0.0959],\n",
      "          [-0.0182,  0.0581, -0.0498]],\n",
      "\n",
      "         [[-0.0750, -0.0898, -0.0044],\n",
      "          [ 0.0318,  0.0661, -0.0328],\n",
      "          [ 0.0646, -0.1121,  0.0534]],\n",
      "\n",
      "         [[-0.0917,  0.0869, -0.0858],\n",
      "          [ 0.0446, -0.0892,  0.0056],\n",
      "          [ 0.0295, -0.0899, -0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022, -0.1028, -0.0773],\n",
      "          [ 0.1139, -0.0884,  0.1080],\n",
      "          [-0.1028,  0.0832, -0.0256]],\n",
      "\n",
      "         [[ 0.0046,  0.0938,  0.0045],\n",
      "          [-0.0249,  0.0874, -0.0567],\n",
      "          [-0.0048,  0.0656,  0.0872]],\n",
      "\n",
      "         [[ 0.0667,  0.0404, -0.0214],\n",
      "          [-0.0236, -0.0360,  0.1005],\n",
      "          [ 0.0308,  0.0357, -0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0111,  0.0186,  0.0251],\n",
      "          [ 0.0609, -0.0373, -0.1067],\n",
      "          [-0.0667,  0.1012,  0.0346]],\n",
      "\n",
      "         [[-0.0595,  0.0940, -0.0642],\n",
      "          [-0.0243,  0.0586, -0.1053],\n",
      "          [-0.0098,  0.0503,  0.0019]],\n",
      "\n",
      "         [[-0.0916,  0.0103,  0.0763],\n",
      "          [ 0.0984,  0.1027,  0.0236],\n",
      "          [-0.0900,  0.0276,  0.0559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0867,  0.0393, -0.0238],\n",
      "          [ 0.0128,  0.0819,  0.0106],\n",
      "          [ 0.1084, -0.0259, -0.1101]],\n",
      "\n",
      "         [[ 0.0931,  0.0474, -0.0224],\n",
      "          [ 0.0580, -0.0052,  0.0148],\n",
      "          [ 0.0450,  0.0732, -0.0326]],\n",
      "\n",
      "         [[-0.0663,  0.1169, -0.0130],\n",
      "          [-0.0050, -0.0818,  0.0640],\n",
      "          [-0.0528, -0.0654,  0.0108]]]])),\n",
      "             ('bias',\n",
      "              tensor([ 0.0327, -0.0662,  0.0240,  0.0063, -0.0862,  0.0806, -0.0006,  0.0446,\n",
      "         0.0734, -0.0719, -0.0531,  0.0851,  0.0861, -0.0850,  0.1083, -0.1116]))])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv2d':\n",
    "        if node.op == \"call_module\":\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"channel\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.8,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0698,  0.1103,  0.1140],\n",
      "          [-0.1054,  0.1281, -0.1740],\n",
      "          [ 0.1278,  0.1210, -0.0946]],\n",
      "\n",
      "         [[ 0.0491,  0.1916, -0.0236],\n",
      "          [-0.1847,  0.1499, -0.1314],\n",
      "          [-0.0675,  0.0864,  0.0055]],\n",
      "\n",
      "         [[ 0.0288, -0.1395,  0.1685],\n",
      "          [ 0.0320, -0.1914,  0.0949],\n",
      "          [-0.0024,  0.1181, -0.1289]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1300,  0.1329,  0.0790],\n",
      "          [-0.0674, -0.1246,  0.1684],\n",
      "          [ 0.0715, -0.0038, -0.1021]],\n",
      "\n",
      "         [[-0.0882,  0.1219,  0.1907],\n",
      "          [-0.0911,  0.0651,  0.1597],\n",
      "          [ 0.1906, -0.1684, -0.1742]],\n",
      "\n",
      "         [[-0.0117, -0.1164,  0.1677],\n",
      "          [ 0.1770, -0.0121,  0.0958],\n",
      "          [-0.1206,  0.0191,  0.1230]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]]], grad_fn=<MulBackward0>)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('bias',\n",
      "              tensor([ 0.1693, -0.0775,  0.0651, -0.0930, -0.1775,  0.0550, -0.1746, -0.1815])),\n",
      "             ('parametrizations.weight.original',\n",
      "              tensor([[[[ 1.3748e-01,  2.1479e-02, -9.4732e-02],\n",
      "          [ 2.9365e-02,  1.4427e-01, -8.5327e-02],\n",
      "          [ 1.6447e-02,  8.1002e-02, -2.6879e-02]],\n",
      "\n",
      "         [[-1.3203e-01, -4.0379e-02,  1.2712e-01],\n",
      "          [-1.8229e-01, -1.4738e-02, -5.4161e-02],\n",
      "          [-2.4612e-02, -1.1651e-01, -3.0695e-02]],\n",
      "\n",
      "         [[ 1.2624e-01, -1.0735e-02,  1.4186e-01],\n",
      "          [ 9.0847e-02, -1.2447e-01,  1.7536e-01],\n",
      "          [ 1.0018e-01,  8.5701e-02,  1.7813e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9845e-02,  1.1027e-01,  1.1402e-01],\n",
      "          [-1.0543e-01,  1.2811e-01, -1.7400e-01],\n",
      "          [ 1.2780e-01,  1.2102e-01, -9.4646e-02]],\n",
      "\n",
      "         [[ 4.9147e-02,  1.9159e-01, -2.3558e-02],\n",
      "          [-1.8466e-01,  1.4989e-01, -1.3137e-01],\n",
      "          [-6.7507e-02,  8.6385e-02,  5.5279e-03]],\n",
      "\n",
      "         [[ 2.8780e-02, -1.3954e-01,  1.6852e-01],\n",
      "          [ 3.2005e-02, -1.9144e-01,  9.4916e-02],\n",
      "          [-2.4395e-03,  1.1808e-01, -1.2889e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2024e-05, -2.7090e-03, -3.6521e-02],\n",
      "          [ 6.6903e-02, -5.0821e-02, -1.5914e-03],\n",
      "          [-3.3344e-04, -4.2687e-03, -1.1346e-01]],\n",
      "\n",
      "         [[ 1.0644e-01,  1.9707e-03, -1.4363e-01],\n",
      "          [-1.0466e-01,  6.3399e-02, -3.3935e-02],\n",
      "          [ 1.1182e-01, -1.6017e-02, -1.6411e-02]],\n",
      "\n",
      "         [[-6.1391e-02, -1.6581e-01, -2.3034e-02],\n",
      "          [ 1.2102e-01, -6.2285e-02,  8.4734e-02],\n",
      "          [-1.6145e-01, -1.0271e-01,  1.2427e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7800e-01, -1.5719e-01,  7.9682e-02],\n",
      "          [-9.1448e-02,  1.2018e-01, -4.3454e-02],\n",
      "          [-1.1007e-01,  3.6836e-03,  6.1442e-02]],\n",
      "\n",
      "         [[ 1.1316e-01, -1.1584e-01, -1.8120e-01],\n",
      "          [ 1.8850e-01, -2.6005e-02, -1.3770e-01],\n",
      "          [-9.1124e-02,  3.3013e-02, -8.7636e-02]],\n",
      "\n",
      "         [[-1.2117e-01, -1.1946e-02, -7.4002e-02],\n",
      "          [-1.0449e-01, -1.6674e-01, -1.7665e-01],\n",
      "          [-8.2055e-02,  4.5225e-02, -1.6924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7681e-02,  8.2558e-02,  1.7941e-02],\n",
      "          [ 5.6737e-02,  1.7552e-01, -2.9810e-02],\n",
      "          [ 9.5078e-02,  3.3256e-02,  8.8965e-02]],\n",
      "\n",
      "         [[ 1.8819e-01, -1.1427e-01,  9.0562e-03],\n",
      "          [ 1.0816e-01, -1.1161e-01, -1.8921e-01],\n",
      "          [ 4.7288e-02,  4.0721e-02, -1.0259e-01]],\n",
      "\n",
      "         [[ 1.8235e-02, -1.2289e-01,  6.1536e-03],\n",
      "          [-1.1327e-01,  7.9490e-02,  1.3292e-01],\n",
      "          [-9.4702e-02, -1.3729e-01, -8.6533e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2998e-01,  1.3294e-01,  7.8978e-02],\n",
      "          [-6.7378e-02, -1.2464e-01,  1.6839e-01],\n",
      "          [ 7.1478e-02, -3.8255e-03, -1.0208e-01]],\n",
      "\n",
      "         [[-8.8225e-02,  1.2188e-01,  1.9067e-01],\n",
      "          [-9.1131e-02,  6.5071e-02,  1.5968e-01],\n",
      "          [ 1.9058e-01, -1.6839e-01, -1.7416e-01]],\n",
      "\n",
      "         [[-1.1744e-02, -1.1639e-01,  1.6769e-01],\n",
      "          [ 1.7700e-01, -1.2135e-02,  9.5799e-02],\n",
      "          [-1.2063e-01,  1.9103e-02,  1.2298e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7454e-01,  1.3236e-02, -9.6806e-02],\n",
      "          [ 1.0493e-01, -1.7739e-01,  1.7731e-01],\n",
      "          [ 1.5874e-01,  7.1080e-02,  4.1057e-03]],\n",
      "\n",
      "         [[-8.6675e-02,  8.3419e-02,  4.6499e-03],\n",
      "          [ 1.4227e-01,  4.0836e-03, -8.9578e-02],\n",
      "          [-3.2970e-02, -3.2476e-02, -3.7406e-02]],\n",
      "\n",
      "         [[ 1.1284e-01, -8.1442e-02, -1.5794e-01],\n",
      "          [ 3.4568e-02,  5.3024e-02,  1.3732e-01],\n",
      "          [-1.3180e-01,  1.1319e-01,  3.5940e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5474e-01, -1.7806e-01,  3.1436e-02],\n",
      "          [-3.6155e-02,  2.6093e-02, -5.5522e-02],\n",
      "          [ 1.8125e-02, -1.7254e-01, -1.1417e-01]],\n",
      "\n",
      "         [[ 1.1152e-02, -1.7807e-01, -1.0281e-01],\n",
      "          [ 1.0673e-02, -9.2227e-02,  1.2225e-01],\n",
      "          [ 1.1569e-02,  1.9160e-01,  1.7921e-01]],\n",
      "\n",
      "         [[ 1.3393e-01, -1.1584e-01,  1.5162e-01],\n",
      "          [-8.5293e-02,  1.3082e-01, -1.2735e-01],\n",
      "          [ 2.7560e-02, -1.7687e-01, -1.7471e-01]]]])),\n",
      "             ('parametrizations.weight.0.mask',\n",
      "              tensor([[[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]]])),\n",
      "             ('parametrizations.weight.1.mask',\n",
      "              tensor([[[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]]]))])\n",
      "tensor([[[[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., 0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [-0., 0., -0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., -0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [-0., 0., -0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[0., -0., -0.],\n",
      "          [-0., 0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., 0., -0.]]],\n",
      "\n",
      "\n",
      "        [[[-0., 0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., -0., 0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., 0., 0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., -0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0., -0., 0.],\n",
      "          [-0., 0., 0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., 0., 0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., 0., 0.],\n",
      "          [0., -0., 0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., 0., -0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [0., -0., 0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., -0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [0., 0., -0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., 0.]]]], grad_fn=<MulBackward0>)\n",
      "--------------------------------------------------\n",
      "OrderedDict([('bias',\n",
      "              tensor([ 0.0327, -0.0662,  0.0240,  0.0063, -0.0862,  0.0806, -0.0006,  0.0446,\n",
      "         0.0734, -0.0719, -0.0531,  0.0851,  0.0861, -0.0850,  0.1083, -0.1116])),\n",
      "             ('parametrizations.weight.original',\n",
      "              tensor([[[[-0.0264, -0.0990, -0.0090],\n",
      "          [-0.1100, -0.1175,  0.0886],\n",
      "          [ 0.0185,  0.0998,  0.0592]],\n",
      "\n",
      "         [[ 0.1152, -0.0820,  0.0208],\n",
      "          [-0.0883,  0.0623, -0.0870],\n",
      "          [ 0.0165,  0.0781,  0.0580]],\n",
      "\n",
      "         [[ 0.0829,  0.0471,  0.0944],\n",
      "          [-0.0724,  0.0281, -0.0726],\n",
      "          [ 0.0742,  0.0164, -0.0324]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682,  0.0340, -0.0899],\n",
      "          [ 0.0005, -0.0892, -0.0090],\n",
      "          [ 0.0094,  0.0177,  0.1055]],\n",
      "\n",
      "         [[-0.0556, -0.0140, -0.0835],\n",
      "          [ 0.0709, -0.0398,  0.0675],\n",
      "          [-0.0861, -0.0982,  0.0224]],\n",
      "\n",
      "         [[-0.0217, -0.0847,  0.0574],\n",
      "          [ 0.0776,  0.0987, -0.1070],\n",
      "          [-0.1032, -0.0984,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.0963,  0.0214],\n",
      "          [ 0.0178,  0.0100, -0.0062],\n",
      "          [ 0.0912,  0.0935,  0.0197]],\n",
      "\n",
      "         [[-0.0726, -0.0541, -0.0883],\n",
      "          [ 0.0822,  0.0130, -0.0563],\n",
      "          [-0.0285, -0.0023, -0.0545]],\n",
      "\n",
      "         [[ 0.0862,  0.0624,  0.0929],\n",
      "          [-0.0893,  0.0401, -0.0292],\n",
      "          [ 0.0553, -0.0797, -0.0291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0813,  0.0372,  0.0853],\n",
      "          [ 0.0482,  0.0736,  0.0347],\n",
      "          [-0.0558, -0.0624,  0.0190]],\n",
      "\n",
      "         [[ 0.0901, -0.0292, -0.0057],\n",
      "          [-0.0734,  0.0244,  0.1120],\n",
      "          [-0.0950, -0.1006,  0.1065]],\n",
      "\n",
      "         [[-0.0444,  0.0533,  0.0459],\n",
      "          [-0.0590, -0.0895, -0.1018],\n",
      "          [-0.0627,  0.0752, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[-0.0935,  0.0770, -0.0277],\n",
      "          [ 0.0582,  0.0652, -0.0918],\n",
      "          [-0.1164,  0.0865, -0.1015]],\n",
      "\n",
      "         [[ 0.0880, -0.0995,  0.1125],\n",
      "          [ 0.0430, -0.0124, -0.0604],\n",
      "          [ 0.0515, -0.1132,  0.0165]],\n",
      "\n",
      "         [[ 0.0826,  0.0565, -0.0261],\n",
      "          [-0.0670, -0.0915, -0.0630],\n",
      "          [ 0.0412,  0.0666,  0.1091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0980,  0.0889, -0.0025],\n",
      "          [-0.0024, -0.0668,  0.0565],\n",
      "          [ 0.0050,  0.0783, -0.0728]],\n",
      "\n",
      "         [[-0.0516, -0.0805, -0.0502],\n",
      "          [-0.0423,  0.1017,  0.0762],\n",
      "          [ 0.0564,  0.0306, -0.0064]],\n",
      "\n",
      "         [[-0.0082, -0.1171,  0.0080],\n",
      "          [ 0.0306,  0.1136,  0.0742],\n",
      "          [ 0.0702, -0.0610,  0.0773]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0678, -0.0860,  0.0712],\n",
      "          [-0.0385,  0.0325,  0.0677],\n",
      "          [ 0.0941,  0.0617, -0.1021]],\n",
      "\n",
      "         [[-0.0479, -0.0522, -0.0843],\n",
      "          [ 0.0876,  0.0224, -0.0209],\n",
      "          [-0.0134,  0.0392,  0.0182]],\n",
      "\n",
      "         [[-0.0864,  0.1121,  0.0078],\n",
      "          [-0.0344, -0.0595,  0.0431],\n",
      "          [-0.0775, -0.1130, -0.0875]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1006,  0.0279, -0.1116],\n",
      "          [-0.0274,  0.0472,  0.0561],\n",
      "          [-0.0932,  0.0299, -0.0501]],\n",
      "\n",
      "         [[ 0.0075,  0.0361, -0.0153],\n",
      "          [-0.0125,  0.0289,  0.0691],\n",
      "          [ 0.0070, -0.0497,  0.1040]],\n",
      "\n",
      "         [[-0.0698, -0.0718,  0.0983],\n",
      "          [ 0.0844,  0.0199, -0.0441],\n",
      "          [-0.0251,  0.0776, -0.0444]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0153,  0.0390,  0.0212],\n",
      "          [ 0.0908,  0.1161, -0.0959],\n",
      "          [-0.0182,  0.0581, -0.0498]],\n",
      "\n",
      "         [[-0.0750, -0.0898, -0.0044],\n",
      "          [ 0.0318,  0.0661, -0.0328],\n",
      "          [ 0.0646, -0.1121,  0.0534]],\n",
      "\n",
      "         [[-0.0917,  0.0869, -0.0858],\n",
      "          [ 0.0446, -0.0892,  0.0056],\n",
      "          [ 0.0295, -0.0899, -0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022, -0.1028, -0.0773],\n",
      "          [ 0.1139, -0.0884,  0.1080],\n",
      "          [-0.1028,  0.0832, -0.0256]],\n",
      "\n",
      "         [[ 0.0046,  0.0938,  0.0045],\n",
      "          [-0.0249,  0.0874, -0.0567],\n",
      "          [-0.0048,  0.0656,  0.0872]],\n",
      "\n",
      "         [[ 0.0667,  0.0404, -0.0214],\n",
      "          [-0.0236, -0.0360,  0.1005],\n",
      "          [ 0.0308,  0.0357, -0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0111,  0.0186,  0.0251],\n",
      "          [ 0.0609, -0.0373, -0.1067],\n",
      "          [-0.0667,  0.1012,  0.0346]],\n",
      "\n",
      "         [[-0.0595,  0.0940, -0.0642],\n",
      "          [-0.0243,  0.0586, -0.1053],\n",
      "          [-0.0098,  0.0503,  0.0019]],\n",
      "\n",
      "         [[-0.0916,  0.0103,  0.0763],\n",
      "          [ 0.0984,  0.1027,  0.0236],\n",
      "          [-0.0900,  0.0276,  0.0559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0867,  0.0393, -0.0238],\n",
      "          [ 0.0128,  0.0819,  0.0106],\n",
      "          [ 0.1084, -0.0259, -0.1101]],\n",
      "\n",
      "         [[ 0.0931,  0.0474, -0.0224],\n",
      "          [ 0.0580, -0.0052,  0.0148],\n",
      "          [ 0.0450,  0.0732, -0.0326]],\n",
      "\n",
      "         [[-0.0663,  0.1169, -0.0130],\n",
      "          [-0.0050, -0.0818,  0.0640],\n",
      "          [-0.0528, -0.0654,  0.0108]]]])),\n",
      "             ('parametrizations.weight.0.mask',\n",
      "              tensor([[[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]]])),\n",
      "             ('parametrizations.weight.1.mask',\n",
      "              tensor([[[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [False, False, False]]]]))])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'conv2d':\n",
    "        if node.op == \"call_module\":\n",
    "            pprint(mg.modules[node.target].weight)\n",
    "            print(50*'-')\n",
    "            pprint(mg.modules[node.target].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n",
      "odict_items([])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    #if get_mase_op(node) == 'linear':\n",
    "    if node.op == \"call_module\":\n",
    "        #print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        #pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        pprint(mg.modules[node.target]._forward_pre_hooks.items())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear\n",
      "{'bias': {'from': None,\n",
      "          'precision': [32],\n",
      "          'shape': [10],\n",
      "          'type': 'float',\n",
      "          'value': Parameter containing:\n",
      "tensor([-0.0445,  0.0786,  0.1041, -0.0927,  0.0147,  0.0457,  0.1057, -0.0290,\n",
      "         0.0905,  0.0922], requires_grad=True)},\n",
      " 'data_in_0': {'precision': [32],\n",
      "               'shape': [512, 64],\n",
      "               'torch_dtype': torch.float32,\n",
      "               'type': 'float',\n",
      "               'value': tensor([[4.4416e-02, 0.0000e+00, 1.4396e-01,  ..., 4.4614e-04, 5.0736e-02,\n",
      "         0.0000e+00],\n",
      "        [3.8386e-02, 0.0000e+00, 1.9087e-01,  ..., 6.7570e-03, 4.6465e-02,\n",
      "         9.0773e-06],\n",
      "        [2.2434e-02, 0.0000e+00, 1.6967e-01,  ..., 6.1829e-04, 3.0395e-02,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.4487e-02, 0.0000e+00, 2.2211e-01,  ..., 8.9831e-05, 9.8996e-03,\n",
      "         0.0000e+00],\n",
      "        [4.6827e-02, 0.0000e+00, 1.6343e-01,  ..., 3.0457e-03, 5.0189e-02,\n",
      "         0.0000e+00],\n",
      "        [2.3559e-02, 0.0000e+00, 1.7879e-01,  ..., 2.5151e-03, 3.2171e-02,\n",
      "         1.4027e-05]], grad_fn=<ViewBackward0>)},\n",
      " 'weight': {'from': None,\n",
      "            'precision': [32],\n",
      "            'shape': [10, 64],\n",
      "            'type': 'float',\n",
      "            'value': Parameter containing:\n",
      "tensor([[ 0.0934,  0.1204,  0.0324, -0.0053, -0.0041,  0.0687,  0.0620, -0.0787,\n",
      "          0.1006, -0.0579,  0.0668,  0.1244, -0.0975,  0.0899, -0.0715,  0.0163,\n",
      "          0.0927,  0.0796, -0.1143,  0.0537,  0.0397,  0.0691, -0.0862,  0.1157,\n",
      "          0.0113, -0.1061,  0.0944,  0.0460, -0.0097, -0.0417,  0.0521,  0.0446,\n",
      "         -0.1070,  0.1065,  0.0362,  0.0056,  0.0176, -0.0080,  0.0745, -0.0038,\n",
      "         -0.0722,  0.1062, -0.1182, -0.0822,  0.0119,  0.0928, -0.0454, -0.0541,\n",
      "          0.0584,  0.0731, -0.0997,  0.0477, -0.0369,  0.0539,  0.0151,  0.0952,\n",
      "          0.0933, -0.0085,  0.0990,  0.0674,  0.0712,  0.0218, -0.1189,  0.0141],\n",
      "        [-0.1125,  0.1211, -0.1075, -0.0887, -0.1094,  0.0586,  0.1129, -0.0207,\n",
      "         -0.0451,  0.0991, -0.0577,  0.0336,  0.0432, -0.0425, -0.0087, -0.0105,\n",
      "         -0.0011, -0.0081,  0.0166, -0.0172, -0.0564, -0.0077,  0.0975,  0.0683,\n",
      "         -0.1064,  0.0903, -0.0721, -0.1117, -0.1050, -0.0152, -0.0124,  0.0629,\n",
      "         -0.1079,  0.0352,  0.0771, -0.0700, -0.0793,  0.0820, -0.0533, -0.0143,\n",
      "          0.0446, -0.1208,  0.1247, -0.1133, -0.1145, -0.0319,  0.0049, -0.0275,\n",
      "         -0.0500, -0.0081, -0.1049, -0.0759, -0.0482,  0.0390,  0.1246, -0.0344,\n",
      "          0.0186,  0.0864,  0.0229,  0.0529, -0.1225, -0.0339,  0.0730, -0.1045],\n",
      "        [ 0.1121, -0.0004,  0.0830,  0.0864, -0.1057, -0.0472, -0.0270,  0.0927,\n",
      "          0.1241,  0.1074,  0.0241,  0.0073, -0.0352,  0.0015,  0.0988, -0.0955,\n",
      "          0.0888, -0.0586,  0.0245, -0.0180, -0.0454, -0.0715, -0.0929, -0.0987,\n",
      "          0.0415,  0.1156,  0.0252, -0.0702,  0.0525,  0.0765,  0.0579,  0.0707,\n",
      "         -0.1076,  0.0682,  0.0986,  0.0353, -0.0004, -0.0714, -0.0408, -0.0916,\n",
      "          0.0863, -0.0789, -0.0199, -0.0050,  0.1068,  0.0432,  0.1018, -0.0925,\n",
      "         -0.0184, -0.0305, -0.0299,  0.0371, -0.0426,  0.1234, -0.1244,  0.0703,\n",
      "          0.0500,  0.0707,  0.0187, -0.0116, -0.0297,  0.0048, -0.0780,  0.0951],\n",
      "        [ 0.1102,  0.0719,  0.0183, -0.0159, -0.1122,  0.1220, -0.0639,  0.0720,\n",
      "          0.0473,  0.0434, -0.0959, -0.0923,  0.0023,  0.0117, -0.0367, -0.0268,\n",
      "          0.1132, -0.0051, -0.1162, -0.0308, -0.0359, -0.0346, -0.0052,  0.0734,\n",
      "          0.0261,  0.0033,  0.0227,  0.0949, -0.0903,  0.0983,  0.1103, -0.0249,\n",
      "         -0.1158, -0.0291,  0.1082, -0.0346, -0.0562,  0.0610, -0.0998,  0.0997,\n",
      "         -0.0177,  0.0828,  0.0870, -0.0635, -0.0490, -0.1106, -0.0850, -0.0448,\n",
      "          0.0566, -0.0470, -0.0640,  0.0180,  0.0677, -0.0913,  0.0731, -0.0616,\n",
      "         -0.1132, -0.1071, -0.0978, -0.0883,  0.0486,  0.0639, -0.0823, -0.0232],\n",
      "        [ 0.1218, -0.1129, -0.0982,  0.0277,  0.0020, -0.0596, -0.1060,  0.0611,\n",
      "         -0.0760,  0.0607,  0.0485, -0.0740, -0.0385, -0.0030, -0.0021, -0.0909,\n",
      "         -0.0903, -0.0655,  0.0622,  0.0250,  0.0259,  0.1157,  0.0091, -0.0546,\n",
      "         -0.0168, -0.0966,  0.1103,  0.0101, -0.0176,  0.0064, -0.1201, -0.1159,\n",
      "          0.0171, -0.0512,  0.0150, -0.0837, -0.0616,  0.0658,  0.0985,  0.0373,\n",
      "          0.0022,  0.0482,  0.0644, -0.0393,  0.0771, -0.0869,  0.0622,  0.0629,\n",
      "          0.0087,  0.0314,  0.0306, -0.1021,  0.0869,  0.0564, -0.0464, -0.0609,\n",
      "         -0.0135, -0.0606,  0.0077,  0.0901, -0.0116,  0.0377,  0.1152, -0.0202],\n",
      "        [ 0.0634, -0.0022, -0.0332, -0.1039, -0.1157, -0.1004,  0.0611,  0.0239,\n",
      "          0.0152, -0.0975,  0.0048,  0.0684, -0.1151, -0.0663,  0.0742,  0.0659,\n",
      "          0.1245, -0.0624, -0.1058,  0.0206, -0.0526,  0.0835,  0.0547,  0.0933,\n",
      "         -0.0465, -0.0840, -0.1140,  0.1025, -0.0225, -0.0618, -0.0925, -0.1023,\n",
      "          0.1204,  0.0688, -0.1209,  0.0963,  0.1172, -0.0828,  0.0901, -0.0115,\n",
      "         -0.0559,  0.1236, -0.0952, -0.0114,  0.0737, -0.0693,  0.0230,  0.1119,\n",
      "         -0.0735,  0.0075, -0.0542,  0.1169, -0.1085, -0.0863,  0.1147,  0.0177,\n",
      "         -0.0408, -0.0913, -0.0233, -0.1145,  0.0421, -0.0301,  0.0821,  0.0890],\n",
      "        [ 0.0050,  0.0113, -0.0020,  0.0174,  0.0530,  0.0242,  0.0183, -0.0645,\n",
      "         -0.0284,  0.1115,  0.1085, -0.0034,  0.0885, -0.0486, -0.0191, -0.0276,\n",
      "         -0.0122,  0.0121,  0.0962, -0.0518, -0.1108, -0.0883, -0.0238,  0.1126,\n",
      "         -0.1037,  0.0606,  0.0241, -0.1206,  0.0541, -0.0514,  0.0363, -0.0563,\n",
      "          0.0139,  0.1135, -0.1218, -0.1115,  0.0789, -0.1237,  0.0501, -0.1230,\n",
      "          0.0346, -0.0436, -0.1129,  0.0670,  0.0136,  0.0403,  0.0884, -0.0380,\n",
      "         -0.0789,  0.0961,  0.1236, -0.0335, -0.0871,  0.0943,  0.0588, -0.0330,\n",
      "          0.0438, -0.0416, -0.0487,  0.0178, -0.1069,  0.0684,  0.0713, -0.0653],\n",
      "        [-0.1044, -0.0123, -0.0148,  0.0567, -0.0391, -0.1178,  0.0622, -0.0173,\n",
      "         -0.0777,  0.0194, -0.0216,  0.0804,  0.0872,  0.1214,  0.0208,  0.0236,\n",
      "          0.0213, -0.1034,  0.0099,  0.1168, -0.1209, -0.0300, -0.0293, -0.0894,\n",
      "          0.1239,  0.0940,  0.0002, -0.1114,  0.0292,  0.1017, -0.1073,  0.0950,\n",
      "         -0.0945, -0.0649, -0.1090,  0.0581, -0.0614,  0.0280,  0.0026,  0.1213,\n",
      "          0.1078, -0.0858,  0.1212, -0.0939, -0.0368, -0.0464,  0.0794,  0.1169,\n",
      "          0.0288,  0.0945,  0.0084,  0.0891,  0.1126, -0.1226,  0.0603,  0.0249,\n",
      "          0.1182,  0.0320, -0.1182, -0.0945,  0.1005, -0.0490,  0.0984,  0.0864],\n",
      "        [ 0.0519,  0.0665, -0.0106, -0.0384,  0.0595, -0.0660,  0.1160, -0.0150,\n",
      "         -0.1107, -0.0137,  0.0889, -0.1170,  0.0561,  0.0096, -0.1237, -0.0786,\n",
      "          0.1133, -0.0469,  0.1028,  0.0295, -0.0710,  0.0500, -0.0459,  0.0906,\n",
      "          0.1134,  0.0833, -0.0719,  0.0733, -0.0604,  0.0091, -0.0622,  0.1239,\n",
      "         -0.0659,  0.1228, -0.0171,  0.0567,  0.0109, -0.0225, -0.0102, -0.0206,\n",
      "         -0.0009, -0.0812,  0.0742, -0.0743, -0.0960,  0.0018,  0.0330,  0.0674,\n",
      "          0.0363,  0.1110,  0.0361,  0.1218,  0.0372,  0.0353, -0.1103,  0.0461,\n",
      "         -0.0264, -0.0633, -0.0606,  0.1128, -0.0880, -0.0115,  0.0923,  0.0631],\n",
      "        [ 0.0915, -0.0665, -0.1117,  0.0730,  0.0970, -0.0589,  0.1008,  0.0029,\n",
      "          0.0783,  0.0818,  0.0333, -0.1249, -0.0743,  0.1214,  0.0522, -0.0211,\n",
      "         -0.1039, -0.0390, -0.0512, -0.1005, -0.0719,  0.0851, -0.0845,  0.0083,\n",
      "          0.0080, -0.0896,  0.0531, -0.0626,  0.0029,  0.0842, -0.0699, -0.0933,\n",
      "         -0.0533,  0.0259, -0.0645,  0.1170,  0.0709, -0.0568, -0.0918, -0.0033,\n",
      "          0.0882, -0.1095, -0.0651, -0.0091,  0.1053, -0.0927,  0.0409, -0.0658,\n",
      "         -0.0845, -0.0275,  0.0241, -0.0677,  0.0018,  0.0484,  0.0788,  0.1015,\n",
      "         -0.1218,  0.0687, -0.0323, -0.0264, -0.0320,  0.1104, -0.0463, -0.1029]],\n",
      "       requires_grad=True)}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        # total_w = 0\n",
    "        # pruned_w = 0\n",
    "        # mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "        # for s in mask_2:\n",
    "        #     total_w += s.numel()\n",
    "        #     pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        # pruned_percent = pruned_w / total_w\n",
    "        # print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n",
    "#print(mg.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.6,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block_1.0.bias', tensor([ 0.1008,  0.1006,  0.0213,  0.0648, -0.0629, -0.1817, -0.0902, -0.1284])), ('block_1.0.parametrizations.weight.original', tensor([[[[ 0.0944,  0.0471,  0.0161],\n",
      "          [-0.1590,  0.0563,  0.1508],\n",
      "          [ 0.1106,  0.1515, -0.0847]],\n",
      "\n",
      "         [[ 0.0242, -0.0580, -0.0695],\n",
      "          [-0.0390, -0.0946,  0.0599],\n",
      "          [ 0.0066,  0.1182,  0.0722]],\n",
      "\n",
      "         [[ 0.0477,  0.1016,  0.0493],\n",
      "          [ 0.0980, -0.0535, -0.0730],\n",
      "          [-0.0436, -0.0778,  0.1692]]],\n",
      "\n",
      "\n",
      "        [[[-0.0118,  0.0479, -0.1685],\n",
      "          [-0.1033,  0.1019,  0.1909],\n",
      "          [-0.0941, -0.1594,  0.0562]],\n",
      "\n",
      "         [[ 0.1403, -0.1430, -0.1551],\n",
      "          [ 0.1700, -0.1056, -0.0765],\n",
      "          [-0.1542, -0.1113, -0.1068]],\n",
      "\n",
      "         [[-0.0073, -0.0518, -0.0062],\n",
      "          [-0.1183, -0.0293,  0.0502],\n",
      "          [ 0.0126,  0.0405,  0.0821]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1837,  0.0905, -0.0382],\n",
      "          [ 0.1190, -0.1652, -0.0091],\n",
      "          [ 0.1463,  0.0432,  0.0725]],\n",
      "\n",
      "         [[ 0.0639,  0.0729, -0.0142],\n",
      "          [-0.0902,  0.1115, -0.0010],\n",
      "          [-0.1009, -0.0581, -0.0448]],\n",
      "\n",
      "         [[-0.1629,  0.1107,  0.0497],\n",
      "          [-0.0916,  0.0152,  0.1262],\n",
      "          [-0.0826,  0.0773, -0.0928]]],\n",
      "\n",
      "\n",
      "        [[[-0.0140,  0.0207, -0.1656],\n",
      "          [-0.1417, -0.0999,  0.1448],\n",
      "          [ 0.0654, -0.1589,  0.1834]],\n",
      "\n",
      "         [[-0.0897, -0.0438,  0.1724],\n",
      "          [ 0.1829, -0.1683, -0.1268],\n",
      "          [ 0.1802, -0.1291,  0.0818]],\n",
      "\n",
      "         [[-0.0812, -0.0415, -0.1910],\n",
      "          [ 0.1560, -0.0624,  0.0878],\n",
      "          [-0.1144,  0.0253,  0.0316]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1213,  0.1770, -0.1094],\n",
      "          [ 0.0071, -0.1116, -0.1496],\n",
      "          [-0.0540, -0.1532, -0.0039]],\n",
      "\n",
      "         [[-0.0259, -0.1286, -0.1637],\n",
      "          [ 0.0616,  0.1454, -0.1797],\n",
      "          [ 0.1419, -0.1648, -0.0068]],\n",
      "\n",
      "         [[ 0.1723, -0.1783, -0.0443],\n",
      "          [-0.0107, -0.0416, -0.1096],\n",
      "          [ 0.0993, -0.1047,  0.0558]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0984,  0.0244,  0.1119],\n",
      "          [-0.1702,  0.1853, -0.1489],\n",
      "          [-0.0803,  0.0396,  0.1630]],\n",
      "\n",
      "         [[ 0.1784,  0.0673, -0.0684],\n",
      "          [ 0.0868, -0.0143,  0.0665],\n",
      "          [ 0.1901, -0.0018,  0.1104]],\n",
      "\n",
      "         [[ 0.0723,  0.0169, -0.1588],\n",
      "          [ 0.1503, -0.1143, -0.0478],\n",
      "          [ 0.0807, -0.1497, -0.0384]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0473, -0.1136, -0.1408],\n",
      "          [-0.0861,  0.0125,  0.0565],\n",
      "          [ 0.1830, -0.0496, -0.1792]],\n",
      "\n",
      "         [[-0.0389,  0.0250, -0.1833],\n",
      "          [ 0.0237,  0.0960,  0.1379],\n",
      "          [-0.1691, -0.0667,  0.0951]],\n",
      "\n",
      "         [[-0.1454, -0.1396, -0.1051],\n",
      "          [ 0.1026,  0.1449, -0.1666],\n",
      "          [ 0.0424, -0.0716, -0.1429]]],\n",
      "\n",
      "\n",
      "        [[[-0.0987,  0.0022, -0.1591],\n",
      "          [-0.0025, -0.0221,  0.0029],\n",
      "          [ 0.1003,  0.0246,  0.0827]],\n",
      "\n",
      "         [[-0.1322,  0.0618, -0.0484],\n",
      "          [ 0.1542, -0.0995, -0.0266],\n",
      "          [ 0.1725, -0.1470, -0.0782]],\n",
      "\n",
      "         [[ 0.0618,  0.0330,  0.1690],\n",
      "          [-0.1409, -0.1194,  0.0563],\n",
      "          [ 0.1599,  0.0483, -0.0607]]]])), ('block_1.0.parametrizations.weight.0.mask', tensor([[[[ True, False, False],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True, False, False],\n",
      "          [False, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False, False,  True],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [False, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False, False]]]])), ('block_2.0.bias', tensor([-0.0246, -0.0785, -0.0512, -0.1090, -0.0769,  0.0033,  0.0221, -0.0812,\n",
      "        -0.1124, -0.0342, -0.0991,  0.0454, -0.1031,  0.0263,  0.1070, -0.0811])), ('block_2.0.parametrizations.weight.original', tensor([[[[ 0.0696, -0.0964, -0.0938],\n",
      "          [-0.0645,  0.0656, -0.0198],\n",
      "          [-0.0040,  0.0008,  0.0285]],\n",
      "\n",
      "         [[-0.0904, -0.0395,  0.0775],\n",
      "          [-0.0754, -0.0370,  0.0694],\n",
      "          [ 0.0863, -0.1120,  0.0614]],\n",
      "\n",
      "         [[ 0.0245, -0.0840, -0.0851],\n",
      "          [-0.0263,  0.1120,  0.0802],\n",
      "          [ 0.1125, -0.0971,  0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0886,  0.0623, -0.0825],\n",
      "          [ 0.0408, -0.1123,  0.0116],\n",
      "          [ 0.0194, -0.0466, -0.0701]],\n",
      "\n",
      "         [[ 0.1041, -0.1006, -0.0193],\n",
      "          [ 0.0920,  0.0159,  0.0381],\n",
      "          [ 0.1082, -0.0615,  0.0564]],\n",
      "\n",
      "         [[-0.0570, -0.1092,  0.0538],\n",
      "          [-0.0801,  0.0757, -0.0168],\n",
      "          [ 0.1057,  0.0841, -0.1101]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0729, -0.0010, -0.1044],\n",
      "          [ 0.0829,  0.0761, -0.0021],\n",
      "          [ 0.0209, -0.1154, -0.1153]],\n",
      "\n",
      "         [[ 0.1004, -0.0475, -0.0774],\n",
      "          [ 0.0246, -0.0858, -0.0797],\n",
      "          [-0.0891, -0.1000, -0.0471]],\n",
      "\n",
      "         [[ 0.0410, -0.0517,  0.0836],\n",
      "          [-0.0027,  0.0632,  0.0285],\n",
      "          [-0.0460, -0.0152, -0.0347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0800,  0.0339,  0.1128],\n",
      "          [ 0.0347, -0.0154,  0.0259],\n",
      "          [ 0.0360, -0.0563, -0.1083]],\n",
      "\n",
      "         [[ 0.0419,  0.0587, -0.1130],\n",
      "          [-0.0760, -0.0729, -0.0142],\n",
      "          [ 0.0287, -0.0527, -0.0708]],\n",
      "\n",
      "         [[ 0.0688, -0.0122,  0.0062],\n",
      "          [ 0.0389,  0.0325,  0.0126],\n",
      "          [ 0.0977, -0.0232, -0.0949]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0148, -0.0402,  0.0740],\n",
      "          [-0.0415,  0.0396, -0.0032],\n",
      "          [ 0.0495, -0.0174, -0.0311]],\n",
      "\n",
      "         [[ 0.0109, -0.0620, -0.0098],\n",
      "          [ 0.0453,  0.0354,  0.0257],\n",
      "          [-0.1086, -0.0690, -0.0434]],\n",
      "\n",
      "         [[ 0.0204, -0.0195, -0.1121],\n",
      "          [ 0.1018, -0.0533, -0.0956],\n",
      "          [ 0.0515, -0.0842,  0.0636]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1096,  0.1108, -0.0120],\n",
      "          [-0.0334,  0.0221,  0.0342],\n",
      "          [ 0.0794, -0.0490,  0.0537]],\n",
      "\n",
      "         [[-0.0998, -0.0271,  0.0220],\n",
      "          [ 0.0442,  0.0937, -0.0595],\n",
      "          [-0.1100,  0.0946,  0.1139]],\n",
      "\n",
      "         [[ 0.0994,  0.0404, -0.0038],\n",
      "          [-0.0782,  0.0927, -0.1176],\n",
      "          [ 0.0347,  0.0094, -0.0195]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0831, -0.0263, -0.0454],\n",
      "          [-0.0331, -0.0526, -0.0659],\n",
      "          [-0.0986,  0.0626, -0.0563]],\n",
      "\n",
      "         [[ 0.0031,  0.0467,  0.0015],\n",
      "          [-0.1138, -0.1079, -0.0533],\n",
      "          [ 0.1120,  0.0051, -0.0805]],\n",
      "\n",
      "         [[-0.1135, -0.0256, -0.0521],\n",
      "          [ 0.0907, -0.1002, -0.0078],\n",
      "          [-0.1140,  0.0187,  0.1107]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0848, -0.0256,  0.0797],\n",
      "          [ 0.0349, -0.0296,  0.0892],\n",
      "          [-0.0628,  0.0976,  0.0261]],\n",
      "\n",
      "         [[-0.0934, -0.0418,  0.0656],\n",
      "          [ 0.1168, -0.0169,  0.0436],\n",
      "          [-0.0406, -0.0524,  0.0552]],\n",
      "\n",
      "         [[-0.0497, -0.0057, -0.0781],\n",
      "          [-0.0670,  0.0636,  0.0039],\n",
      "          [-0.1149, -0.0239,  0.1108]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0604, -0.0937, -0.0872],\n",
      "          [-0.0839,  0.0488,  0.1008],\n",
      "          [-0.0883,  0.1142, -0.0079]],\n",
      "\n",
      "         [[-0.0516, -0.0554,  0.0113],\n",
      "          [-0.0473,  0.0986,  0.0126],\n",
      "          [-0.1175, -0.0366,  0.0314]],\n",
      "\n",
      "         [[-0.0659, -0.0372,  0.0800],\n",
      "          [-0.0622,  0.0749,  0.0678],\n",
      "          [ 0.0769, -0.0801,  0.1122]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0111,  0.0298,  0.1152],\n",
      "          [ 0.0642, -0.0379, -0.0622],\n",
      "          [ 0.0801, -0.0311,  0.1148]],\n",
      "\n",
      "         [[ 0.0358, -0.0668, -0.0669],\n",
      "          [ 0.0290, -0.0677,  0.0687],\n",
      "          [ 0.0656, -0.1028,  0.0399]],\n",
      "\n",
      "         [[ 0.0282,  0.1061,  0.0408],\n",
      "          [-0.0115,  0.0061,  0.0277],\n",
      "          [ 0.0501, -0.0737, -0.0649]]],\n",
      "\n",
      "\n",
      "        [[[-0.0404,  0.1099,  0.0231],\n",
      "          [-0.0090, -0.0683, -0.0610],\n",
      "          [-0.0768,  0.1123, -0.0680]],\n",
      "\n",
      "         [[ 0.0684, -0.0891,  0.0207],\n",
      "          [-0.0803,  0.0047,  0.0886],\n",
      "          [ 0.0546, -0.0954, -0.0960]],\n",
      "\n",
      "         [[-0.0132,  0.0169, -0.0210],\n",
      "          [-0.0797, -0.0790,  0.1074],\n",
      "          [ 0.0845, -0.0231,  0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0367,  0.0921, -0.0744],\n",
      "          [ 0.0561, -0.1077,  0.0049],\n",
      "          [-0.0546, -0.0975,  0.0231]],\n",
      "\n",
      "         [[ 0.0801, -0.0623,  0.1149],\n",
      "          [ 0.1007,  0.0493,  0.0470],\n",
      "          [-0.0638,  0.0428,  0.0803]],\n",
      "\n",
      "         [[-0.1115,  0.0301, -0.0382],\n",
      "          [-0.0099,  0.0321, -0.0608],\n",
      "          [ 0.1145, -0.0484,  0.0068]]]])), ('block_2.0.parametrizations.weight.0.mask', tensor([[[[ True,  True,  True],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False, False, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False, False, False],\n",
      "          [ True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [False, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False, False, False],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [False, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False, False]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ True, False, False],\n",
      "          [False, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True, False, False],\n",
      "          [False, False, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[False,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [ True,  True, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False,  True, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False,  True],\n",
      "          [False, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False,  True,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[False,  True, False],\n",
      "          [False, False, False],\n",
      "          [False,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[False,  True, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [False,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True, False, False],\n",
      "          [False, False,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [False, False, False],\n",
      "          [ True, False, False]]]])), ('block_3.0.bias', tensor([-0.1016, -0.0380, -0.1275, -0.1339,  0.0586, -0.1301,  0.0730, -0.1024,\n",
      "        -0.0986, -0.1241,  0.0172, -0.0062, -0.0186,  0.1399,  0.0899,  0.1365,\n",
      "         0.0360,  0.0025, -0.0385,  0.0661,  0.1062, -0.1035, -0.0413,  0.0329,\n",
      "         0.0179, -0.1251,  0.1312, -0.0194,  0.1401, -0.0465,  0.0529,  0.0660])), ('block_3.0.parametrizations.weight.original', tensor([[[ 0.0566,  0.0635,  0.0538],\n",
      "         [ 0.0212, -0.1118, -0.0844],\n",
      "         [ 0.0104,  0.1284,  0.0028],\n",
      "         ...,\n",
      "         [-0.0890,  0.1028, -0.0640],\n",
      "         [ 0.0743, -0.1347,  0.0798],\n",
      "         [ 0.0277, -0.1308,  0.1229]],\n",
      "\n",
      "        [[ 0.0695, -0.0558, -0.0840],\n",
      "         [-0.1386, -0.0235,  0.0969],\n",
      "         [-0.0218, -0.0594,  0.0583],\n",
      "         ...,\n",
      "         [-0.0641,  0.0558, -0.1270],\n",
      "         [-0.1020,  0.0291, -0.0829],\n",
      "         [ 0.0834, -0.0791,  0.1171]],\n",
      "\n",
      "        [[ 0.0464, -0.0335,  0.1011],\n",
      "         [-0.0040, -0.0459,  0.0077],\n",
      "         [ 0.1137, -0.0883, -0.1219],\n",
      "         ...,\n",
      "         [-0.0734, -0.0563,  0.1366],\n",
      "         [-0.0945, -0.0464,  0.0141],\n",
      "         [-0.0656,  0.1309, -0.1184]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0526,  0.0220,  0.0199],\n",
      "         [ 0.0966,  0.0388,  0.0102],\n",
      "         [ 0.0160, -0.0881, -0.1221],\n",
      "         ...,\n",
      "         [-0.1274,  0.0921,  0.0929],\n",
      "         [-0.0309, -0.1127, -0.0786],\n",
      "         [ 0.0696, -0.1322, -0.0722]],\n",
      "\n",
      "        [[-0.0525,  0.0742, -0.0093],\n",
      "         [-0.0991,  0.0309, -0.0994],\n",
      "         [ 0.1269, -0.1178,  0.0517],\n",
      "         ...,\n",
      "         [ 0.0258,  0.0324, -0.1431],\n",
      "         [ 0.1395, -0.1012, -0.1080],\n",
      "         [-0.0180,  0.0378, -0.0874]],\n",
      "\n",
      "        [[-0.0962, -0.1113, -0.1167],\n",
      "         [ 0.1066,  0.1335, -0.1037],\n",
      "         [-0.0229,  0.0322, -0.0955],\n",
      "         ...,\n",
      "         [-0.0027, -0.1287, -0.1109],\n",
      "         [-0.0703,  0.0141,  0.0059],\n",
      "         [-0.0717, -0.0771, -0.0235]]])), ('block_3.0.parametrizations.weight.0.mask', tensor([[[False, False, False],\n",
      "         [False,  True,  True],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        [[ True, False,  True],\n",
      "         [ True, False,  True],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [False, False,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False, False,  True],\n",
      "         [False, False, False],\n",
      "         [ True,  True,  True],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [ True, False, False],\n",
      "         [False,  True,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False, False, False],\n",
      "         [ True, False, False],\n",
      "         [False,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True],\n",
      "         [False,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True, False,  True],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [False, False,  True],\n",
      "         [ True,  True,  True],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [ True, False, False],\n",
      "         [ True,  True, False]]])), ('block_4.0.bias', tensor([ 0.0281, -0.0408,  0.0133,  0.0101,  0.0372, -0.0933, -0.0891,  0.0568,\n",
      "        -0.0457, -0.0438, -0.0489,  0.0955,  0.0522,  0.0998,  0.0682, -0.0019,\n",
      "         0.0621,  0.0605,  0.0941, -0.0651,  0.0997, -0.0286,  0.0252,  0.0668,\n",
      "         0.0037,  0.0840, -0.0293,  0.0908,  0.0696, -0.0504, -0.0964, -0.0926,\n",
      "         0.0650, -0.0395, -0.0350,  0.0399,  0.0283, -0.0067, -0.0093,  0.0618,\n",
      "         0.0475,  0.0705,  0.0613, -0.0427,  0.0502,  0.0710,  0.0378, -0.0726,\n",
      "        -0.0685,  0.0640, -0.0136,  0.0222,  0.0136, -0.0232, -0.0573,  0.0723,\n",
      "         0.0895, -0.0912,  0.0528,  0.0853,  0.0624, -0.0854,  0.0458, -0.0205])), ('block_4.0.parametrizations.weight.original', tensor([[[-0.0140, -0.0159,  0.0549],\n",
      "         [-0.0923, -0.0500,  0.0434],\n",
      "         [ 0.0547,  0.0178,  0.0500],\n",
      "         ...,\n",
      "         [-0.1003, -0.0885,  0.0375],\n",
      "         [-0.0071,  0.0037, -0.0565],\n",
      "         [-0.0660,  0.0482,  0.0731]],\n",
      "\n",
      "        [[-0.0921,  0.0155,  0.0006],\n",
      "         [-0.0248, -0.0522, -0.0991],\n",
      "         [ 0.0896, -0.0674,  0.0161],\n",
      "         ...,\n",
      "         [ 0.0573, -0.0900, -0.0962],\n",
      "         [-0.0192, -0.0348, -0.0434],\n",
      "         [-0.0604,  0.0365, -0.0194]],\n",
      "\n",
      "        [[ 0.0245,  0.0148,  0.0240],\n",
      "         [ 0.0800, -0.0262, -0.0296],\n",
      "         [-0.0601,  0.0455,  0.0325],\n",
      "         ...,\n",
      "         [-0.0853,  0.0334, -0.0769],\n",
      "         [ 0.0503,  0.0598,  0.1001],\n",
      "         [-0.0872,  0.0545, -0.0225]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0210, -0.0990, -0.0788],\n",
      "         [-0.0989,  0.0152,  0.0486],\n",
      "         [ 0.0662,  0.0390, -0.0789],\n",
      "         ...,\n",
      "         [-0.0191, -0.0240, -0.0639],\n",
      "         [ 0.0398,  0.0596,  0.0606],\n",
      "         [ 0.0772,  0.0991,  0.0895]],\n",
      "\n",
      "        [[-0.0024,  0.0022, -0.0872],\n",
      "         [-0.0215, -0.0712,  0.0017],\n",
      "         [ 0.0301,  0.0696, -0.0077],\n",
      "         ...,\n",
      "         [ 0.0824, -0.0350, -0.0865],\n",
      "         [ 0.0150, -0.0722, -0.0396],\n",
      "         [ 0.0693, -0.0693, -0.0097]],\n",
      "\n",
      "        [[ 0.0820, -0.0024, -0.0299],\n",
      "         [-0.0971, -0.0708,  0.0547],\n",
      "         [ 0.0487,  0.0842, -0.0089],\n",
      "         ...,\n",
      "         [ 0.0764, -0.0201, -0.0366],\n",
      "         [-0.0374, -0.0783, -0.0431],\n",
      "         [-0.0846, -0.0071,  0.0553]]])), ('block_4.0.parametrizations.weight.0.mask', tensor([[[False, False, False],\n",
      "         [ True, False, False],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [ True,  True, False],\n",
      "         [False, False, False],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False, False,  True],\n",
      "         [ True,  True, False],\n",
      "         ...,\n",
      "         [False,  True,  True],\n",
      "         [False, False, False],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[False, False, False],\n",
      "         [ True, False, False],\n",
      "         [False, False, False],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [False, False,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False, False],\n",
      "         [False, False,  True],\n",
      "         ...,\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False, False,  True],\n",
      "         [False,  True, False],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True, False,  True],\n",
      "         [False,  True, False],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [ True,  True, False],\n",
      "         [False,  True, False],\n",
      "         ...,\n",
      "         [ True, False, False],\n",
      "         [False,  True, False],\n",
      "         [ True, False, False]]])), ('linear.bias', tensor([-0.0445,  0.0786,  0.1041, -0.0927,  0.0147,  0.0457,  0.1057, -0.0290,\n",
      "         0.0905,  0.0922])), ('linear.parametrizations.weight.original', tensor([[ 0.0934,  0.1204,  0.0324, -0.0053, -0.0041,  0.0687,  0.0620, -0.0787,\n",
      "          0.1006, -0.0579,  0.0668,  0.1244, -0.0975,  0.0899, -0.0715,  0.0163,\n",
      "          0.0927,  0.0796, -0.1143,  0.0537,  0.0397,  0.0691, -0.0862,  0.1157,\n",
      "          0.0113, -0.1061,  0.0944,  0.0460, -0.0097, -0.0417,  0.0521,  0.0446,\n",
      "         -0.1070,  0.1065,  0.0362,  0.0056,  0.0176, -0.0080,  0.0745, -0.0038,\n",
      "         -0.0722,  0.1062, -0.1182, -0.0822,  0.0119,  0.0928, -0.0454, -0.0541,\n",
      "          0.0584,  0.0731, -0.0997,  0.0477, -0.0369,  0.0539,  0.0151,  0.0952,\n",
      "          0.0933, -0.0085,  0.0990,  0.0674,  0.0712,  0.0218, -0.1189,  0.0141],\n",
      "        [-0.1125,  0.1211, -0.1075, -0.0887, -0.1094,  0.0586,  0.1129, -0.0207,\n",
      "         -0.0451,  0.0991, -0.0577,  0.0336,  0.0432, -0.0425, -0.0087, -0.0105,\n",
      "         -0.0011, -0.0081,  0.0166, -0.0172, -0.0564, -0.0077,  0.0975,  0.0683,\n",
      "         -0.1064,  0.0903, -0.0721, -0.1117, -0.1050, -0.0152, -0.0124,  0.0629,\n",
      "         -0.1079,  0.0352,  0.0771, -0.0700, -0.0793,  0.0820, -0.0533, -0.0143,\n",
      "          0.0446, -0.1208,  0.1247, -0.1133, -0.1145, -0.0319,  0.0049, -0.0275,\n",
      "         -0.0500, -0.0081, -0.1049, -0.0759, -0.0482,  0.0390,  0.1246, -0.0344,\n",
      "          0.0186,  0.0864,  0.0229,  0.0529, -0.1225, -0.0339,  0.0730, -0.1045],\n",
      "        [ 0.1121, -0.0004,  0.0830,  0.0864, -0.1057, -0.0472, -0.0270,  0.0927,\n",
      "          0.1241,  0.1074,  0.0241,  0.0073, -0.0352,  0.0015,  0.0988, -0.0955,\n",
      "          0.0888, -0.0586,  0.0245, -0.0180, -0.0454, -0.0715, -0.0929, -0.0987,\n",
      "          0.0415,  0.1156,  0.0252, -0.0702,  0.0525,  0.0765,  0.0579,  0.0707,\n",
      "         -0.1076,  0.0682,  0.0986,  0.0353, -0.0004, -0.0714, -0.0408, -0.0916,\n",
      "          0.0863, -0.0789, -0.0199, -0.0050,  0.1068,  0.0432,  0.1018, -0.0925,\n",
      "         -0.0184, -0.0305, -0.0299,  0.0371, -0.0426,  0.1234, -0.1244,  0.0703,\n",
      "          0.0500,  0.0707,  0.0187, -0.0116, -0.0297,  0.0048, -0.0780,  0.0951],\n",
      "        [ 0.1102,  0.0719,  0.0183, -0.0159, -0.1122,  0.1220, -0.0639,  0.0720,\n",
      "          0.0473,  0.0434, -0.0959, -0.0923,  0.0023,  0.0117, -0.0367, -0.0268,\n",
      "          0.1132, -0.0051, -0.1162, -0.0308, -0.0359, -0.0346, -0.0052,  0.0734,\n",
      "          0.0261,  0.0033,  0.0227,  0.0949, -0.0903,  0.0983,  0.1103, -0.0249,\n",
      "         -0.1158, -0.0291,  0.1082, -0.0346, -0.0562,  0.0610, -0.0998,  0.0997,\n",
      "         -0.0177,  0.0828,  0.0870, -0.0635, -0.0490, -0.1106, -0.0850, -0.0448,\n",
      "          0.0566, -0.0470, -0.0640,  0.0180,  0.0677, -0.0913,  0.0731, -0.0616,\n",
      "         -0.1132, -0.1071, -0.0978, -0.0883,  0.0486,  0.0639, -0.0823, -0.0232],\n",
      "        [ 0.1218, -0.1129, -0.0982,  0.0277,  0.0020, -0.0596, -0.1060,  0.0611,\n",
      "         -0.0760,  0.0607,  0.0485, -0.0740, -0.0385, -0.0030, -0.0021, -0.0909,\n",
      "         -0.0903, -0.0655,  0.0622,  0.0250,  0.0259,  0.1157,  0.0091, -0.0546,\n",
      "         -0.0168, -0.0966,  0.1103,  0.0101, -0.0176,  0.0064, -0.1201, -0.1159,\n",
      "          0.0171, -0.0512,  0.0150, -0.0837, -0.0616,  0.0658,  0.0985,  0.0373,\n",
      "          0.0022,  0.0482,  0.0644, -0.0393,  0.0771, -0.0869,  0.0622,  0.0629,\n",
      "          0.0087,  0.0314,  0.0306, -0.1021,  0.0869,  0.0564, -0.0464, -0.0609,\n",
      "         -0.0135, -0.0606,  0.0077,  0.0901, -0.0116,  0.0377,  0.1152, -0.0202],\n",
      "        [ 0.0634, -0.0022, -0.0332, -0.1039, -0.1157, -0.1004,  0.0611,  0.0239,\n",
      "          0.0152, -0.0975,  0.0048,  0.0684, -0.1151, -0.0663,  0.0742,  0.0659,\n",
      "          0.1245, -0.0624, -0.1058,  0.0206, -0.0526,  0.0835,  0.0547,  0.0933,\n",
      "         -0.0465, -0.0840, -0.1140,  0.1025, -0.0225, -0.0618, -0.0925, -0.1023,\n",
      "          0.1204,  0.0688, -0.1209,  0.0963,  0.1172, -0.0828,  0.0901, -0.0115,\n",
      "         -0.0559,  0.1236, -0.0952, -0.0114,  0.0737, -0.0693,  0.0230,  0.1119,\n",
      "         -0.0735,  0.0075, -0.0542,  0.1169, -0.1085, -0.0863,  0.1147,  0.0177,\n",
      "         -0.0408, -0.0913, -0.0233, -0.1145,  0.0421, -0.0301,  0.0821,  0.0890],\n",
      "        [ 0.0050,  0.0113, -0.0020,  0.0174,  0.0530,  0.0242,  0.0183, -0.0645,\n",
      "         -0.0284,  0.1115,  0.1085, -0.0034,  0.0885, -0.0486, -0.0191, -0.0276,\n",
      "         -0.0122,  0.0121,  0.0962, -0.0518, -0.1108, -0.0883, -0.0238,  0.1126,\n",
      "         -0.1037,  0.0606,  0.0241, -0.1206,  0.0541, -0.0514,  0.0363, -0.0563,\n",
      "          0.0139,  0.1135, -0.1218, -0.1115,  0.0789, -0.1237,  0.0501, -0.1230,\n",
      "          0.0346, -0.0436, -0.1129,  0.0670,  0.0136,  0.0403,  0.0884, -0.0380,\n",
      "         -0.0789,  0.0961,  0.1236, -0.0335, -0.0871,  0.0943,  0.0588, -0.0330,\n",
      "          0.0438, -0.0416, -0.0487,  0.0178, -0.1069,  0.0684,  0.0713, -0.0653],\n",
      "        [-0.1044, -0.0123, -0.0148,  0.0567, -0.0391, -0.1178,  0.0622, -0.0173,\n",
      "         -0.0777,  0.0194, -0.0216,  0.0804,  0.0872,  0.1214,  0.0208,  0.0236,\n",
      "          0.0213, -0.1034,  0.0099,  0.1168, -0.1209, -0.0300, -0.0293, -0.0894,\n",
      "          0.1239,  0.0940,  0.0002, -0.1114,  0.0292,  0.1017, -0.1073,  0.0950,\n",
      "         -0.0945, -0.0649, -0.1090,  0.0581, -0.0614,  0.0280,  0.0026,  0.1213,\n",
      "          0.1078, -0.0858,  0.1212, -0.0939, -0.0368, -0.0464,  0.0794,  0.1169,\n",
      "          0.0288,  0.0945,  0.0084,  0.0891,  0.1126, -0.1226,  0.0603,  0.0249,\n",
      "          0.1182,  0.0320, -0.1182, -0.0945,  0.1005, -0.0490,  0.0984,  0.0864],\n",
      "        [ 0.0519,  0.0665, -0.0106, -0.0384,  0.0595, -0.0660,  0.1160, -0.0150,\n",
      "         -0.1107, -0.0137,  0.0889, -0.1170,  0.0561,  0.0096, -0.1237, -0.0786,\n",
      "          0.1133, -0.0469,  0.1028,  0.0295, -0.0710,  0.0500, -0.0459,  0.0906,\n",
      "          0.1134,  0.0833, -0.0719,  0.0733, -0.0604,  0.0091, -0.0622,  0.1239,\n",
      "         -0.0659,  0.1228, -0.0171,  0.0567,  0.0109, -0.0225, -0.0102, -0.0206,\n",
      "         -0.0009, -0.0812,  0.0742, -0.0743, -0.0960,  0.0018,  0.0330,  0.0674,\n",
      "          0.0363,  0.1110,  0.0361,  0.1218,  0.0372,  0.0353, -0.1103,  0.0461,\n",
      "         -0.0264, -0.0633, -0.0606,  0.1128, -0.0880, -0.0115,  0.0923,  0.0631],\n",
      "        [ 0.0915, -0.0665, -0.1117,  0.0730,  0.0970, -0.0589,  0.1008,  0.0029,\n",
      "          0.0783,  0.0818,  0.0333, -0.1249, -0.0743,  0.1214,  0.0522, -0.0211,\n",
      "         -0.1039, -0.0390, -0.0512, -0.1005, -0.0719,  0.0851, -0.0845,  0.0083,\n",
      "          0.0080, -0.0896,  0.0531, -0.0626,  0.0029,  0.0842, -0.0699, -0.0933,\n",
      "         -0.0533,  0.0259, -0.0645,  0.1170,  0.0709, -0.0568, -0.0918, -0.0033,\n",
      "          0.0882, -0.1095, -0.0651, -0.0091,  0.1053, -0.0927,  0.0409, -0.0658,\n",
      "         -0.0845, -0.0275,  0.0241, -0.0677,  0.0018,  0.0484,  0.0788,  0.1015,\n",
      "         -0.1218,  0.0687, -0.0323, -0.0264, -0.0320,  0.1104, -0.0463, -0.1029]])), ('linear.parametrizations.weight.0.mask', tensor([[ True,  True, False, False, False,  True, False,  True,  True, False,\n",
      "         False,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "         False, False,  True,  True, False, False, False, False,  True, False,\n",
      "          True,  True,  True,  True, False,  True, False, False, False,  True,\n",
      "          True, False, False, False, False,  True,  True, False,  True,  True,\n",
      "          True, False,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False,  True, False, False,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False,  True, False,  True,  True,  True,  True, False, False,\n",
      "         False,  True,  True,  True,  True, False, False, False, False, False,\n",
      "          True,  True, False, False,  True, False, False,  True, False, False,\n",
      "          True, False,  True,  True],\n",
      "        [ True, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         False, False, False, False,  True,  True,  True, False, False, False,\n",
      "         False,  True,  True,  True, False,  True, False,  True, False,  True,\n",
      "         False,  True,  True,  True,  True, False, False,  True, False,  True,\n",
      "          True,  True, False, False,  True, False,  True,  True, False, False,\n",
      "         False, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         False, False,  True,  True],\n",
      "        [ True,  True, False, False,  True,  True, False,  True, False, False,\n",
      "          True,  True, False, False, False, False,  True, False,  True, False,\n",
      "         False, False, False,  True, False, False, False,  True,  True,  True,\n",
      "          True, False,  True, False,  True, False, False, False,  True,  True,\n",
      "         False,  True,  True, False, False,  True,  True, False, False, False,\n",
      "         False, False,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         False, False,  True, False],\n",
      "        [ True,  True,  True, False, False, False,  True, False,  True, False,\n",
      "         False,  True, False, False, False,  True,  True, False, False, False,\n",
      "         False,  True, False, False, False,  True,  True, False, False, False,\n",
      "          True,  True, False, False, False,  True, False, False,  True, False,\n",
      "         False, False, False, False,  True,  True, False, False, False, False,\n",
      "         False,  True,  True, False, False, False, False, False, False,  True,\n",
      "         False, False,  True, False],\n",
      "        [False, False, False,  True,  True,  True, False, False, False,  True,\n",
      "         False,  True,  True, False,  True, False,  True, False,  True, False,\n",
      "         False,  True, False,  True, False,  True,  True,  True, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         False,  True,  True,  True,  True, False, False,  True, False,  True,\n",
      "         False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False,  True,\n",
      "          True, False,  True, False, False, False, False, False,  True, False,\n",
      "          True,  True, False,  True,  True, False, False,  True, False, False,\n",
      "         False, False, False,  True,  True,  True,  True,  True, False,  True,\n",
      "         False, False,  True,  True, False, False,  True, False,  True,  True,\n",
      "          True, False,  True,  True, False, False, False, False, False, False,\n",
      "          True,  True,  True, False],\n",
      "        [ True, False, False, False, False,  True, False, False,  True, False,\n",
      "         False,  True,  True,  True, False, False, False,  True, False,  True,\n",
      "          True, False, False,  True,  True,  True, False,  True, False,  True,\n",
      "          True,  True,  True, False,  True, False, False, False, False,  True,\n",
      "          True,  True,  True,  True, False, False,  True,  True, False,  True,\n",
      "         False,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "          True, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True, False,  True, False,\n",
      "          True,  True, False, False,  True,  True,  True, False,  True, False,\n",
      "          True, False, False,  True,  True,  True,  True,  True, False, False,\n",
      "         False,  True, False,  True, False, False, False, False, False, False,\n",
      "         False,  True,  True,  True,  True, False, False,  True, False,  True,\n",
      "         False,  True, False, False,  True, False, False, False, False,  True,\n",
      "          True, False,  True, False],\n",
      "        [ True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         False,  True,  True,  True, False, False,  True, False, False,  True,\n",
      "          True,  True,  True, False, False,  True, False, False, False,  True,\n",
      "          True,  True, False, False, False,  True,  True, False,  True, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True, False,\n",
      "         False,  True, False, False,  True,  True,  True,  True, False, False,\n",
      "         False,  True, False,  True]]))])\n"
     ]
    }
   ],
   "source": [
    "print(mg.model.state_dict())\n",
    "#print(node.meta['mase'].parameters['common']['args']['weight']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chop.actions import train\n",
    "# import torch\n",
    "\n",
    "# # print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "# model = mg.model\n",
    "# model_info = get_model_info('jsc-tiny')\n",
    "# dataset_info = get_dataset_info('jsc')\n",
    "# task = \"cls\"\n",
    "\n",
    "# train_params = {\n",
    "#     \"model\": model,\n",
    "#     \"model_info\": model_info,\n",
    "#     \"data_module\": data_module,\n",
    "#     \"dataset_info\": dataset_info,\n",
    "#     \"task\": task,\n",
    "#     \"optimizer\": \"adam\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"plt_trainer_args\": {\n",
    "#         \"max_epochs\": 1,\n",
    "#     }, \n",
    "#     \"auto_requeue\": False,\n",
    "#     \"save_path\": None,\n",
    "#     \"visualizer\": None,\n",
    "#     \"load_name\": None,\n",
    "#     \"load_type\": None\n",
    "# }\n",
    "\n",
    "# train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[ 0.0934,  0.1204,  0.0324, -0.0053, -0.0041,  0.0687,  0.0620, -0.0787,\n",
      "          0.1006, -0.0579,  0.0668,  0.1244, -0.0975,  0.0899, -0.0715,  0.0163,\n",
      "          0.0927,  0.0796, -0.1143,  0.0537,  0.0397,  0.0691, -0.0862,  0.1157,\n",
      "          0.0113, -0.1061,  0.0944,  0.0460, -0.0097, -0.0417,  0.0521,  0.0446,\n",
      "         -0.1070,  0.1065,  0.0362,  0.0056,  0.0176, -0.0080,  0.0745, -0.0038,\n",
      "         -0.0722,  0.1062, -0.1182, -0.0822,  0.0119,  0.0928, -0.0454, -0.0541,\n",
      "          0.0584,  0.0731, -0.0997,  0.0477, -0.0369,  0.0539,  0.0151,  0.0952,\n",
      "          0.0933, -0.0085,  0.0990,  0.0674,  0.0712,  0.0218, -0.1189,  0.0141],\n",
      "        [-0.1125,  0.1211, -0.1075, -0.0887, -0.1094,  0.0586,  0.1129, -0.0207,\n",
      "         -0.0451,  0.0991, -0.0577,  0.0336,  0.0432, -0.0425, -0.0087, -0.0105,\n",
      "         -0.0011, -0.0081,  0.0166, -0.0172, -0.0564, -0.0077,  0.0975,  0.0683,\n",
      "         -0.1064,  0.0903, -0.0721, -0.1117, -0.1050, -0.0152, -0.0124,  0.0629,\n",
      "         -0.1079,  0.0352,  0.0771, -0.0700, -0.0793,  0.0820, -0.0533, -0.0143,\n",
      "          0.0446, -0.1208,  0.1247, -0.1133, -0.1145, -0.0319,  0.0049, -0.0275,\n",
      "         -0.0500, -0.0081, -0.1049, -0.0759, -0.0482,  0.0390,  0.1246, -0.0344,\n",
      "          0.0186,  0.0864,  0.0229,  0.0529, -0.1225, -0.0339,  0.0730, -0.1045],\n",
      "        [ 0.1121, -0.0004,  0.0830,  0.0864, -0.1057, -0.0472, -0.0270,  0.0927,\n",
      "          0.1241,  0.1074,  0.0241,  0.0073, -0.0352,  0.0015,  0.0988, -0.0955,\n",
      "          0.0888, -0.0586,  0.0245, -0.0180, -0.0454, -0.0715, -0.0929, -0.0987,\n",
      "          0.0415,  0.1156,  0.0252, -0.0702,  0.0525,  0.0765,  0.0579,  0.0707,\n",
      "         -0.1076,  0.0682,  0.0986,  0.0353, -0.0004, -0.0714, -0.0408, -0.0916,\n",
      "          0.0863, -0.0789, -0.0199, -0.0050,  0.1068,  0.0432,  0.1018, -0.0925,\n",
      "         -0.0184, -0.0305, -0.0299,  0.0371, -0.0426,  0.1234, -0.1244,  0.0703,\n",
      "          0.0500,  0.0707,  0.0187, -0.0116, -0.0297,  0.0048, -0.0780,  0.0951],\n",
      "        [ 0.1102,  0.0719,  0.0183, -0.0159, -0.1122,  0.1220, -0.0639,  0.0720,\n",
      "          0.0473,  0.0434, -0.0959, -0.0923,  0.0023,  0.0117, -0.0367, -0.0268,\n",
      "          0.1132, -0.0051, -0.1162, -0.0308, -0.0359, -0.0346, -0.0052,  0.0734,\n",
      "          0.0261,  0.0033,  0.0227,  0.0949, -0.0903,  0.0983,  0.1103, -0.0249,\n",
      "         -0.1158, -0.0291,  0.1082, -0.0346, -0.0562,  0.0610, -0.0998,  0.0997,\n",
      "         -0.0177,  0.0828,  0.0870, -0.0635, -0.0490, -0.1106, -0.0850, -0.0448,\n",
      "          0.0566, -0.0470, -0.0640,  0.0180,  0.0677, -0.0913,  0.0731, -0.0616,\n",
      "         -0.1132, -0.1071, -0.0978, -0.0883,  0.0486,  0.0639, -0.0823, -0.0232],\n",
      "        [ 0.1218, -0.1129, -0.0982,  0.0277,  0.0020, -0.0596, -0.1060,  0.0611,\n",
      "         -0.0760,  0.0607,  0.0485, -0.0740, -0.0385, -0.0030, -0.0021, -0.0909,\n",
      "         -0.0903, -0.0655,  0.0622,  0.0250,  0.0259,  0.1157,  0.0091, -0.0546,\n",
      "         -0.0168, -0.0966,  0.1103,  0.0101, -0.0176,  0.0064, -0.1201, -0.1159,\n",
      "          0.0171, -0.0512,  0.0150, -0.0837, -0.0616,  0.0658,  0.0985,  0.0373,\n",
      "          0.0022,  0.0482,  0.0644, -0.0393,  0.0771, -0.0869,  0.0622,  0.0629,\n",
      "          0.0087,  0.0314,  0.0306, -0.1021,  0.0869,  0.0564, -0.0464, -0.0609,\n",
      "         -0.0135, -0.0606,  0.0077,  0.0901, -0.0116,  0.0377,  0.1152, -0.0202],\n",
      "        [ 0.0634, -0.0022, -0.0332, -0.1039, -0.1157, -0.1004,  0.0611,  0.0239,\n",
      "          0.0152, -0.0975,  0.0048,  0.0684, -0.1151, -0.0663,  0.0742,  0.0659,\n",
      "          0.1245, -0.0624, -0.1058,  0.0206, -0.0526,  0.0835,  0.0547,  0.0933,\n",
      "         -0.0465, -0.0840, -0.1140,  0.1025, -0.0225, -0.0618, -0.0925, -0.1023,\n",
      "          0.1204,  0.0688, -0.1209,  0.0963,  0.1172, -0.0828,  0.0901, -0.0115,\n",
      "         -0.0559,  0.1236, -0.0952, -0.0114,  0.0737, -0.0693,  0.0230,  0.1119,\n",
      "         -0.0735,  0.0075, -0.0542,  0.1169, -0.1085, -0.0863,  0.1147,  0.0177,\n",
      "         -0.0408, -0.0913, -0.0233, -0.1145,  0.0421, -0.0301,  0.0821,  0.0890],\n",
      "        [ 0.0050,  0.0113, -0.0020,  0.0174,  0.0530,  0.0242,  0.0183, -0.0645,\n",
      "         -0.0284,  0.1115,  0.1085, -0.0034,  0.0885, -0.0486, -0.0191, -0.0276,\n",
      "         -0.0122,  0.0121,  0.0962, -0.0518, -0.1108, -0.0883, -0.0238,  0.1126,\n",
      "         -0.1037,  0.0606,  0.0241, -0.1206,  0.0541, -0.0514,  0.0363, -0.0563,\n",
      "          0.0139,  0.1135, -0.1218, -0.1115,  0.0789, -0.1237,  0.0501, -0.1230,\n",
      "          0.0346, -0.0436, -0.1129,  0.0670,  0.0136,  0.0403,  0.0884, -0.0380,\n",
      "         -0.0789,  0.0961,  0.1236, -0.0335, -0.0871,  0.0943,  0.0588, -0.0330,\n",
      "          0.0438, -0.0416, -0.0487,  0.0178, -0.1069,  0.0684,  0.0713, -0.0653],\n",
      "        [-0.1044, -0.0123, -0.0148,  0.0567, -0.0391, -0.1178,  0.0622, -0.0173,\n",
      "         -0.0777,  0.0194, -0.0216,  0.0804,  0.0872,  0.1214,  0.0208,  0.0236,\n",
      "          0.0213, -0.1034,  0.0099,  0.1168, -0.1209, -0.0300, -0.0293, -0.0894,\n",
      "          0.1239,  0.0940,  0.0002, -0.1114,  0.0292,  0.1017, -0.1073,  0.0950,\n",
      "         -0.0945, -0.0649, -0.1090,  0.0581, -0.0614,  0.0280,  0.0026,  0.1213,\n",
      "          0.1078, -0.0858,  0.1212, -0.0939, -0.0368, -0.0464,  0.0794,  0.1169,\n",
      "          0.0288,  0.0945,  0.0084,  0.0891,  0.1126, -0.1226,  0.0603,  0.0249,\n",
      "          0.1182,  0.0320, -0.1182, -0.0945,  0.1005, -0.0490,  0.0984,  0.0864],\n",
      "        [ 0.0519,  0.0665, -0.0106, -0.0384,  0.0595, -0.0660,  0.1160, -0.0150,\n",
      "         -0.1107, -0.0137,  0.0889, -0.1170,  0.0561,  0.0096, -0.1237, -0.0786,\n",
      "          0.1133, -0.0469,  0.1028,  0.0295, -0.0710,  0.0500, -0.0459,  0.0906,\n",
      "          0.1134,  0.0833, -0.0719,  0.0733, -0.0604,  0.0091, -0.0622,  0.1239,\n",
      "         -0.0659,  0.1228, -0.0171,  0.0567,  0.0109, -0.0225, -0.0102, -0.0206,\n",
      "         -0.0009, -0.0812,  0.0742, -0.0743, -0.0960,  0.0018,  0.0330,  0.0674,\n",
      "          0.0363,  0.1110,  0.0361,  0.1218,  0.0372,  0.0353, -0.1103,  0.0461,\n",
      "         -0.0264, -0.0633, -0.0606,  0.1128, -0.0880, -0.0115,  0.0923,  0.0631],\n",
      "        [ 0.0915, -0.0665, -0.1117,  0.0730,  0.0970, -0.0589,  0.1008,  0.0029,\n",
      "          0.0783,  0.0818,  0.0333, -0.1249, -0.0743,  0.1214,  0.0522, -0.0211,\n",
      "         -0.1039, -0.0390, -0.0512, -0.1005, -0.0719,  0.0851, -0.0845,  0.0083,\n",
      "          0.0080, -0.0896,  0.0531, -0.0626,  0.0029,  0.0842, -0.0699, -0.0933,\n",
      "         -0.0533,  0.0259, -0.0645,  0.1170,  0.0709, -0.0568, -0.0918, -0.0033,\n",
      "          0.0882, -0.1095, -0.0651, -0.0091,  0.1053, -0.0927,  0.0409, -0.0658,\n",
      "         -0.0845, -0.0275,  0.0241, -0.0677,  0.0018,  0.0484,  0.0788,  0.1015,\n",
      "         -0.1218,  0.0687, -0.0323, -0.0264, -0.0320,  0.1104, -0.0463, -0.1029]],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# # pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        #pprint(mg.modules[node.target].weight)\n",
    "        #pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
