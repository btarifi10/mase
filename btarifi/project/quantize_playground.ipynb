{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | JSC_Tiny           | 127   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "127       Trainable params\n",
      "0         Non-trainable params\n",
      "127       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2108e2ea81df41ad9adf9c279f8696a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36bbe7e40624ba182a9b6904020664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9056867021a42c3825394bbaee70219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074f4a0c3e0e40c392007ac0d1a62cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afa5a069f3d444c9ca2bd3fbf314fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cfe55cffd34f3491caae5627d7f76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6abd780e81e44b28a550e959b447646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d257172789cc4672b39bb3268d15b568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.7024604678153992\n",
      "     test_loss_epoch        0.8855997920036316\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import test, train\n",
    "import torch\n",
    "\n",
    "# print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "task = \"cls\"\n",
    "\n",
    "train_params = {\n",
    "    \"model\": model,\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": task,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 5,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "train(**train_params)\n",
    "\n",
    "test(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_args = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 2,\n",
    "            \"data_in_frac_width\": 2,\n",
    "            # weight\n",
    "            \"weight_width\": 2,\n",
    "            \"weight_frac_width\": 2,\n",
    "            # bias\n",
    "            \"bias_width\": 2,\n",
    "            \"bias_frac_width\": 2,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "train_args = {\n",
    "    \"name\": \"accuracy\",\n",
    "    \"data_loader\": \"train_dataloader\",\n",
    "    \"num_samples\": 100000,\n",
    "    \"max_epochs\": 5,\n",
    "    \"lr_scheduler\": \"linear\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_warmup_steps\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8984857797622681, 'accuracy': 0.695439338684082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18a628037ae4eada5583c6df93f0ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.7018828392028809\n",
      "     test_loss_epoch        0.8859482407569885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import quantize_model\n",
    "\n",
    "config = {\n",
    "    \"quantization\": {\n",
    "        \"quantization_config\": quantize_args,\n",
    "        \"train\": train_args,\n",
    "    }\n",
    "}\n",
    "\n",
    "model, results = quantize_model(\n",
    "    model,\n",
    "    model_info,\n",
    "    \"cls\",\n",
    "    dataset_info,\n",
    "    data_module,\n",
    "    config,\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "train_params[\"model\"] = model\n",
    "\n",
    "test(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': x, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 16], 'torch_dtype': torch.float32, 'value': tensor([[-0.5212,  0.7433, -0.0861,  ..., -0.4481,  0.0681, -0.6988],\n",
      "        [-1.0589,  0.8081, -0.6282,  ...,  0.8267, -0.7490,  0.7000],\n",
      "        [ 1.6394, -0.6230, -1.1444,  ...,  0.4432, -1.2049, -1.4222],\n",
      "        ...,\n",
      "        [ 0.2202,  0.4173, -0.2213,  ..., -0.9140,  0.0816, -0.7952],\n",
      "        [-0.9233,  0.7204,  0.5704,  ...,  0.3653,  0.8774,  0.8447],\n",
      "        [-1.0569,  0.6942,  0.4043,  ...,  1.0141,  0.2708,  1.1340]])}}}, 'software': {'results': {'data_out_0': {'stat': {}}}}, 'hardware': {'is_implicit': True}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': seq_blocks_0, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [512, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[-0.5212,  0.7433, -0.0861,  ..., -0.4481,  0.0681, -0.6988],\n",
      "        [-1.0589,  0.8081, -0.6282,  ...,  0.8267, -0.7490,  0.7000],\n",
      "        [ 1.6394, -0.6230, -1.1444,  ...,  0.4432, -1.2049, -1.4222],\n",
      "        ...,\n",
      "        [ 0.2202,  0.4173, -0.2213,  ..., -0.9140,  0.0816, -0.7952],\n",
      "        [-0.9233,  0.7204,  0.5704,  ...,  0.3653,  0.8774,  0.8447],\n",
      "        [-1.0569,  0.6942,  0.4043,  ...,  1.0141,  0.2708,  1.1340]])}, 'weight': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n",
      "tensor([0.8151, 0.7648, 1.3135, 1.3453, 0.6770, 0.6982, 0.8447, 0.4978, 0.4875,\n",
      "        0.5787, 0.6871, 0.6534, 0.7248, 0.8477, 1.2732, 0.7970],\n",
      "       requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n",
      "tensor([ 0.5049,  0.5684,  0.0294, -0.0239,  0.8860, -0.6178, -0.0311,  0.6734,\n",
      "         0.7577,  1.0394, -0.1649, -0.1506, -0.0179,  0.2172, -0.0810,  0.9060],\n",
      "       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.0791, 1.1236, 0.0177,  ..., 0.0000, 0.1125, 0.3538],\n",
      "        [0.0000, 1.1685, 0.0000,  ..., 0.8301, 0.0000, 1.4501],\n",
      "        [1.7646, 0.1782, 0.0000,  ..., 0.5124, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6574, 0.8981, 0.0000,  ..., 0.0000, 0.1298, 0.2782],\n",
      "        [0.0000, 1.1078, 0.8781,  ..., 0.4479, 1.1437, 1.5635],\n",
      "        [0.0000, 1.0896, 0.6604,  ..., 0.9853, 0.3708, 1.7903]],\n",
      "       grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}, 'weight': {'stat': {}}, 'bias': {'stat': {}}, 'running_mean': {'stat': {}}, 'running_var': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': seq_blocks_1, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [512, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0791, 1.1236, 0.0177,  ..., 0.0000, 0.1125, 0.3538],\n",
      "        [0.0000, 1.1685, 0.0000,  ..., 0.8301, 0.0000, 1.4501],\n",
      "        [1.7646, 0.1782, 0.0000,  ..., 0.5124, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6574, 0.8981, 0.0000,  ..., 0.0000, 0.1298, 0.2782],\n",
      "        [0.0000, 1.1078, 0.8781,  ..., 0.4479, 1.1437, 1.5635],\n",
      "        [0.0000, 1.0896, 0.6604,  ..., 0.9853, 0.3708, 1.7903]],\n",
      "       grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.0791, 1.1236, 0.0177,  ..., 0.0000, 0.1125, 0.3538],\n",
      "        [0.0000, 1.1685, 0.0000,  ..., 0.8301, 0.0000, 1.4501],\n",
      "        [1.7646, 0.1782, 0.0000,  ..., 0.5124, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6574, 0.8981, 0.0000,  ..., 0.0000, 0.1298, 0.2782],\n",
      "        [0.0000, 1.1078, 0.8781,  ..., 0.4479, 1.1437, 1.5635],\n",
      "        [0.0000, 1.0896, 0.6604,  ..., 0.9853, 0.3708, 1.7903]],\n",
      "       grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': seq_blocks_2, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': {'data_in_0': {'shape': [512, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0791, 1.1236, 0.0177,  ..., 0.0000, 0.1125, 0.3538],\n",
      "        [0.0000, 1.1685, 0.0000,  ..., 0.8301, 0.0000, 1.4501],\n",
      "        [1.7646, 0.1782, 0.0000,  ..., 0.5124, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6574, 0.8981, 0.0000,  ..., 0.0000, 0.1298, 0.2782],\n",
      "        [0.0000, 1.1078, 0.8781,  ..., 0.4479, 1.1437, 1.5635],\n",
      "        [0.0000, 1.0896, 0.6604,  ..., 0.9853, 0.3708, 1.7903]],\n",
      "       grad_fn=<ReluBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [5, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[ 0.0829,  0.1509, -0.2380,  0.0673, -0.2939,  0.0683,  0.0586, -0.0245,\n",
      "         -0.0167,  0.1401, -0.0761,  0.0796,  0.0603, -0.0731,  0.3072,  0.1545],\n",
      "        [ 0.1668,  0.1587, -0.2411,  0.3641, -0.1361, -0.1130,  0.0558, -0.1061,\n",
      "         -0.0147,  0.2215, -0.0951,  0.0275,  0.0612, -0.0682, -0.1065, -0.0513],\n",
      "        [-0.0161,  0.0423, -0.1503,  0.2443,  0.2151,  0.0151,  0.0615, -0.1499,\n",
      "         -0.1429,  0.0594, -0.0060, -0.0306, -0.0233,  0.0678, -0.4285, -0.2221],\n",
      "        [-0.0341, -0.0056,  0.2740, -0.5499, -0.0401,  0.1539, -0.0400, -0.0583,\n",
      "          0.1088, -0.0397, -0.0177,  0.0126,  0.0581,  0.0063,  0.2324, -0.1571],\n",
      "        [-0.1369, -0.0669,  0.4017, -0.1437,  0.0970,  0.0752, -0.1080,  0.2031,\n",
      "         -0.0098, -0.3225, -0.0134,  0.1232, -0.2251,  0.0833, -0.0542, -0.0496]],\n",
      "       requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n",
      "tensor([0.1863, 0.0879, 0.2261, 0.0058, 0.0257], requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 5], 'torch_dtype': torch.float32, 'value': tensor([[ 0.2085,  0.1988,  0.2104, -0.0449, -0.1581],\n",
      "        [ 0.5825,  0.3143, -0.0609, -0.2551, -0.4723],\n",
      "        [ 0.4533,  0.5697,  0.1153, -0.0571, -0.5289],\n",
      "        ...,\n",
      "        [ 0.2171,  0.1902,  0.1528, -0.0221, -0.0627],\n",
      "        [ 0.4142,  0.0147, -0.3228, -0.1663, -0.0602],\n",
      "        [ 0.3353, -0.0121, -0.2010, -0.0867, -0.1324]],\n",
      "       grad_fn=<AddmmBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}, 'weight': {'stat': {}}, 'bias': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': seq_blocks_3, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [512, 5], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[ 0.2085,  0.1988,  0.2104, -0.0449, -0.1581],\n",
      "        [ 0.5825,  0.3143, -0.0609, -0.2551, -0.4723],\n",
      "        [ 0.4533,  0.5697,  0.1153, -0.0571, -0.5289],\n",
      "        ...,\n",
      "        [ 0.2171,  0.1902,  0.1528, -0.0221, -0.0627],\n",
      "        [ 0.4142,  0.0147, -0.3228, -0.1663, -0.0602],\n",
      "        [ 0.3353, -0.0121, -0.2010, -0.0867, -0.1324]],\n",
      "       grad_fn=<AddmmBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n",
      "tensor([1.7877, 2.0819, 2.8395, 3.3916, 2.2451], requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n",
      "tensor([1.0811, 0.7700, 0.5951, 0.4068, 0.7096], requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 5], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 0.0975, 3.5874, 2.1867, 0.8914],\n",
      "        [3.1547, 1.6037, 0.3817, 0.0000, 0.0000],\n",
      "        [1.6529, 4.9346, 2.4639, 2.0160, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 2.9075, 2.5067, 1.6288],\n",
      "        [1.1975, 0.0000, 0.0000, 0.4879, 1.6481],\n",
      "        [0.2803, 0.0000, 0.0000, 1.6016, 1.0901]], grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}, 'weight': {'stat': {}}, 'bias': {'stat': {}}, 'running_mean': {'stat': {}}, 'running_var': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': seq_blocks_4, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [512, 5], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0000, 0.0975, 3.5874, 2.1867, 0.8914],\n",
      "        [3.1547, 1.6037, 0.3817, 0.0000, 0.0000],\n",
      "        [1.6529, 4.9346, 2.4639, 2.0160, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 2.9075, 2.5067, 1.6288],\n",
      "        [1.1975, 0.0000, 0.0000, 0.4879, 1.6481],\n",
      "        [0.2803, 0.0000, 0.0000, 1.6016, 1.0901]], grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 5], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 0.0975, 3.5874, 2.1867, 0.8914],\n",
      "        [3.1547, 1.6037, 0.3817, 0.0000, 0.0000],\n",
      "        [1.6529, 4.9346, 2.4639, 2.0160, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 2.9075, 2.5067, 1.6288],\n",
      "        [1.1975, 0.0000, 0.0000, 0.4879, 1.6481],\n",
      "        [0.2803, 0.0000, 0.0000, 1.6016, 1.0901]], grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n",
      "{'model': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "), 'node': output, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [512, 5], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 0.0975, 3.5874, 2.1867, 0.8914],\n",
      "        [3.1547, 1.6037, 0.3817, 0.0000, 0.0000],\n",
      "        [1.6529, 4.9346, 2.4639, 2.0160, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 2.9075, 2.5067, 1.6288],\n",
      "        [1.1975, 0.0000, 0.0000, 0.4879, 1.6481],\n",
      "        [0.2803, 0.0000, 0.0000, 1.6016, 1.0901]], grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}}}, 'hardware': {'is_implicit': True}}}\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "dummy_in = next(iter(input_generator))\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == \"linear\":\n",
    "        print(node.meta['mase'].parameters['common']['args']['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in mg.model.modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        print(module.weight)\n",
    "        print(module.w_quantizer(module.weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
