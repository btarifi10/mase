{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "model_name = \"jsc-custom\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "model_oneshot = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg_base = MaseGraph(model=model_base)\n",
    "mg_oneshot = MaseGraph(model=model_oneshot)\n",
    "\n",
    "mg_base, _ = init_metadata_analysis_pass(mg_base, None)\n",
    "mg_base, _ = add_common_metadata_analysis_pass(mg_base, {\"dummy_in\": dummy_in})\n",
    "mg_base, _ = add_software_metadata_analysis_pass(mg_base, None)\n",
    "\n",
    "mg_oneshot, _ = init_metadata_analysis_pass(mg_oneshot, None)\n",
    "mg_oneshot, _ = add_common_metadata_analysis_pass(mg_oneshot, {\"dummy_in\": dummy_in})\n",
    "mg_oneshot, _ = add_software_metadata_analysis_pass(mg_oneshot, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the JSC network and then pruning it to see final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "\n",
    "default_train_params = {\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": \"cls\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 10,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "base_train_params = copy.deepcopy(default_train_params)\n",
    "base_train_params[\"model\"] = mg_base.model\n",
    "base_train_params[\"plt_trainer_args\"][\"max_epochs\"] = 5\n",
    "\n",
    "visualizer = TensorBoardLogger(\n",
    "    save_dir=\"./project/vgg-cifar/tensorboard\"\n",
    ")\n",
    "base_train_params[\"visualizer\"] = visualizer\n",
    "\n",
    "oneshot_train_params_1 = copy.deepcopy(default_train_params)\n",
    "oneshot_train_params_1[\"model\"] = mg_oneshot.model\n",
    "oneshot_train_params_1[\"plt_trainer_args\"][\"max_epochs\"] = 3\n",
    "\n",
    "oneshot_train_params_2 = copy.deepcopy(default_train_params)\n",
    "oneshot_train_params_2[\"model\"] = mg_oneshot.model\n",
    "oneshot_train_params_2[\"plt_trainer_args\"][\"max_epochs\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 1.3 K \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df673b0b7764500879cb210792a7f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef3ad0b401642c6a69487f164b9f040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d386e74b94466b8a18edbc6e88d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4514b7b0898f4b7e9d610fa03ff87fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7962f3abe34f688fd7bc845fb6b6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b39b251b844774b64e21a56d098922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320aedfe5f8e4d1596e93b683242d8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b1e0ec1d2949a78b3bd129911944d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.7335353493690491\n",
      "     test_loss_epoch        0.7563168406486511\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import test, train\n",
    "\n",
    "train(**base_train_params)\n",
    "test(**base_train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model after pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd96a5c79ab41a0ab60f03116e46760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.32749971747398376\n",
      "     test_loss_epoch         1.498740792274475\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,},\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg_base, _ = prune_transform_pass(mg_base, pass_args)\n",
    "\n",
    "base_train_params[\"model\"] = mg_base.model\n",
    "test(**base_train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One shot pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 1.3 K \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6ddff9af1540d4b7864be53a4cd69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09fb0e65146464db1e787f0c371da90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc351542707461ab9f084e6357d84a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d6d1cc6c784124b615a09aa487be9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc75c70fce604d0584f7c35017ca62d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import test, train\n",
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "\n",
    "train(**oneshot_train_params_1)\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,},\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 1.3 K \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76ac4af93e4b21b100bb71b6a743d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc07e9d507e49188bb67dbe119bc537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfc18d556034a8abe9a9cb04f54430e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a12c4c4b7a419ab794d778c176b68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aa7e9fb1e543dc873863e2855fd2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.5370740294456482\n",
      "     test_loss_epoch         1.142966389656067\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "mg_oneshot.model = oneshot_train_params_1[\"model\"]\n",
    "mg_oneshot, _ = prune_transform_pass(mg_oneshot, pass_args)\n",
    "\n",
    "oneshot_train_params_2[\"model\"] = mg_oneshot.model\n",
    "train(**oneshot_train_params_2)\n",
    "test(**oneshot_train_params_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "model_lt = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15627.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "  0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from chop.actions.optimize.prune import prune_iterative\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./project/vgg-cifar/tensorboard')\n",
    "\n",
    "pass_args = {\n",
    "    \"iterative_prune\": {\n",
    "        \"num_iterations\": 1,\n",
    "        \"scope\": \"global\",\n",
    "        \"granularity\": \"elementwise\",\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"sparsity\": 0.7\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"name\": \"accuracy\",\n",
    "        \"data_loader\": \"train_dataloader\",\n",
    "        \"num_samples\": 10000,\n",
    "        \"max_epochs\": 10,\n",
    "        \"lr_scheduler\": \"linear\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"num_warmup_steps\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model, mg, results = prune_iterative(\n",
    "    model_lt,\n",
    "    model_info,\n",
    "    \"cls\",\n",
    "    dataset_info,\n",
    "    data_module,\n",
    "    {\"prune\": pass_args},\n",
    "    visualizer=writer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46906c930b2343eda6174f7c4aa9e039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.26980000734329224\n",
      "     test_loss_epoch        1.9204679727554321\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from chop.actions import test, train\n",
    "\n",
    "lt_train_params = copy.deepcopy(default_train_params)\n",
    "lt_train_params[\"model\"] = model\n",
    "\n",
    "test(**lt_train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_1_0\n",
      "216\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.39814814814814814\n",
      "---------------------------------------------------------------------------\n",
      "block_2_0\n",
      "1152\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.6675347222222222\n",
      "---------------------------------------------------------------------------\n",
      "block_3_0\n",
      "1536\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.5696614583333334\n",
      "---------------------------------------------------------------------------\n",
      "block_4_0\n",
      "6144\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.7576497395833334\n",
      "---------------------------------------------------------------------------\n",
      "linear\n",
      "640\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.61875\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "last = []\n",
    "\n",
    "mg_lt = MaseGraph(model=model)\n",
    "mg_lt, _ = init_metadata_analysis_pass(mg_lt, None)\n",
    "mg_lt, _ = add_common_metadata_analysis_pass(mg_lt, {\"dummy_in\": dummy_in})\n",
    "mg_lt, _ = add_software_metadata_analysis_pass(mg_lt, None)\n",
    "\n",
    "for node in mg_lt.fx_graph.nodes:\n",
    "    if get_mase_op(node) in ['linear', \"conv2d\", \"conv1d\"]:\n",
    "        print(node.name)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        module = mg_lt.modules[node.target]\n",
    "        # print(module.weight.numel())\n",
    "        w = module.weight\n",
    "        # print(w.shape)\n",
    "        # print(\"Num of masks: \", len(mg_lt.modules[node.target].parametrizations['weight']))\n",
    "        # if node.name == \"block_1_0\":\n",
    "        #     for mask in mg_lt.modules[node.target].parametrizations['weight']:\n",
    "        #         last.append(mask._buffers['mask'].detach().numpy())\n",
    "        #         print(mask._buffers['mask'].detach().numpy())\n",
    "\n",
    "        flat_w = w.flatten()\n",
    "        total_w += flat_w.numel()\n",
    "        pruned_w += flat_w.numel() - flat_w[flat_w != 0].numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "        print(75*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Pruning more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "model_lt = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.actions.optimize.prune import prune_iterative\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./project/vgg-cifar/tensorboard')\n",
    "\n",
    "pass_args = {\n",
    "    \"iterative_prune\": {\n",
    "        \"num_iterations\": 5,\n",
    "        \"scope\": \"global\",\n",
    "        \"granularity\": \"elementwise\",\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"sparsity\": 0.7\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"name\": \"accuracy\",\n",
    "        \"data_loader\": \"train_dataloader\",\n",
    "        \"num_samples\": 10000,\n",
    "        \"max_epochs\": 10,\n",
    "        \"lr_scheduler\": \"linear\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"num_warmup_steps\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model, results = prune_iterative(\n",
    "    model_lt,\n",
    "    model_info,\n",
    "    \"cls\",\n",
    "    dataset_info,\n",
    "    data_module,\n",
    "    {\"prune\": pass_args},\n",
    "    visualizer=writer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_train_params = copy.deepcopy(default_train_params)\n",
    "lt_train_params[\"model\"] = model\n",
    "\n",
    "test(**lt_train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "last = []\n",
    "\n",
    "mg_lt = MaseGraph(model=model)\n",
    "mg_lt, _ = init_metadata_analysis_pass(mg_lt, None)\n",
    "mg_lt, _ = add_common_metadata_analysis_pass(mg_lt, {\"dummy_in\": dummy_in})\n",
    "mg_lt, _ = add_software_metadata_analysis_pass(mg_lt, None)\n",
    "\n",
    "for node in mg_lt.fx_graph.nodes:\n",
    "    if get_mase_op(node) in ['linear', \"conv2d\", \"conv1d\"]:\n",
    "        print(node.name)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        module = mg_lt.modules[node.target]\n",
    "        # print(module.weight.numel())\n",
    "        w = module.weight\n",
    "        # print(w.shape)\n",
    "        # print(\"Num of masks: \", len(mg_lt.modules[node.target].parametrizations['weight']))\n",
    "        # if node.name == \"block_1_0\":\n",
    "        #     for mask in mg_lt.modules[node.target].parametrizations['weight']:\n",
    "        #         last.append(mask._buffers['mask'].detach().numpy())\n",
    "        #         print(mask._buffers['mask'].detach().numpy())\n",
    "\n",
    "        flat_w = w.flatten()\n",
    "        total_w += flat_w.numel()\n",
    "        pruned_w += flat_w.numel() - flat_w[flat_w != 0].numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "        print(75*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
