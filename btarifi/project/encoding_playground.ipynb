{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model_name = \"vgg7\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.actions import test, train\n",
    "import torch\n",
    "\n",
    "# print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "task = \"cls\"\n",
    "\n",
    "save_path = \"./vgg-uncompressed/\"\n",
    "\n",
    "train_params = {\n",
    "    \"model\": model,\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": task,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 3e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 1,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_params[\"save_path\"] = save_path\n",
    "\n",
    "train(**train_params)\n",
    "\n",
    "test(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.interface.save_and_load import save_mase_graph_interface_pass\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "dummy_in = next(iter(input_generator))\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "torch.save(mg.model.state_dict(), f'{save_path}/model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 1932.83it/s]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.35s/it]\n",
      "  0%|          | 0/9 [01:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from chop.actions.optimize.prune import prune_iterative\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./project/vgg-cifar/tensorboard')\n",
    "\n",
    "pass_args = {\n",
    "    \"iterative_prune\": {\n",
    "        \"num_iterations\": 1,\n",
    "        \"scope\": \"global\",\n",
    "        \"granularity\": \"elementwise\",\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"sparsity\": 0.5\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"name\": \"accuracy\",\n",
    "        \"data_loader\": \"train_dataloader\",\n",
    "        \"num_samples\": 1000,\n",
    "        \"max_epochs\": 1,\n",
    "        \"lr_scheduler\": \"linear\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"num_warmup_steps\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None\n",
    ")\n",
    "\n",
    "\n",
    "model, mg, results = prune_iterative(\n",
    "    model,\n",
    "    model_info,\n",
    "    \"cls\",\n",
    "    dataset_info,\n",
    "    data_module,\n",
    "    {\"prune\": pass_args},\n",
    "    visualizer=writer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_args = {\n",
    "    \"by\": \"name\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 5,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 5,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 5,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "train_args = {\n",
    "    \"name\": \"accuracy\",\n",
    "    \"data_loader\": \"train_dataloader\",\n",
    "    \"num_samples\": 1000,\n",
    "    \"max_epochs\": 1,\n",
    "    \"lr_scheduler\": \"linear\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 3e-3,\n",
    "    \"num_warmup_steps\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3024988174438477, 'accuracy': 0.10000000149011612}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a65cc90d0842ceb4923bbc3f45f312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.10000000149011612\n",
      "     test_loss_epoch        2.4431118965148926\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import quantize_model\n",
    "\n",
    "config = {\n",
    "    \"quantization\": {\n",
    "        \"quantization_config\": quantize_args,\n",
    "        \"train\": train_args,\n",
    "    }\n",
    "}\n",
    "\n",
    "model, mg, results = quantize_model(\n",
    "    model,\n",
    "    model_info,\n",
    "    \"cls\",\n",
    "    dataset_info,\n",
    "    data_module,\n",
    "    config,\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "train_params[\"model\"] = model\n",
    "\n",
    "test(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import heapq\n",
    "import json\n",
    "import bitarray, os\n",
    "\n",
    "from chop.passes.graph.utils import get_node_actual_target\n",
    "\n",
    "def huffman_encode(freqs):\n",
    "    heap = [[weight, [symbol, \"\"]] for symbol, weight in freqs.items()]\n",
    "    heapq.heapify(heap)\n",
    "    while len(heap) > 1:\n",
    "        lo = heapq.heappop(heap)\n",
    "        hi = heapq.heappop(heap)\n",
    "        for pair in lo[1:]:\n",
    "            pair[1] = '0' + pair[1]\n",
    "        for pair in hi[1:]:\n",
    "            pair[1] = '1' + pair[1]\n",
    "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "    return dict(sorted(heapq.heappop(heap)[1:], key=lambda p: (len(p[-1]), p)))\n",
    "\n",
    "def find_module_of_parameter(model, full_param_name):\n",
    "    \"\"\"\n",
    "    Find the module that contains the specified parameter.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The PyTorch model to search within.\n",
    "    - full_param_name: The full name of the parameter (including module path).\n",
    "    \n",
    "    Returns:\n",
    "    - The module containing the parameter, or None if not found.\n",
    "    \"\"\"\n",
    "    # Split the full parameter name into parts\n",
    "    parts = full_param_name.split('.')\n",
    "    submodule_path = parts[:-1]  # Everything except the last part, which is the parameter name\n",
    "    \n",
    "    # Start with the base model\n",
    "    current_module = model\n",
    "    \n",
    "    # Traverse the modules according to the path\n",
    "    for submodule_name in submodule_path:\n",
    "        # Update the current_module to go deeper\n",
    "        if hasattr(current_module, submodule_name):\n",
    "            current_module = getattr(current_module, submodule_name)\n",
    "        else:\n",
    "            # Return None if any part of the path doesn't exist\n",
    "            return None\n",
    "    \n",
    "    return current_module\n",
    "\n",
    "def flatten_parameters(model, mg):\n",
    "    \"\"\"Flatten and concatenate all model parameters into a list.\"\"\"\n",
    "    named_params = list(model.named_parameters())\n",
    "\n",
    "    get_named_params = lambda name, params: [param for param in params if name in param[0]]\n",
    "\n",
    "    param_list = []\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        module = get_node_actual_target(node)\n",
    "        if node.target in mg.modules:\n",
    "            named_params_node = get_named_params(f\"{node.target}.\", named_params)      \n",
    "            for name, param in module.named_parameters():\n",
    "                actual_name, actual_param = get_named_params(name, named_params_node)[0]\n",
    "                actual_module = find_module_of_parameter(model, actual_name)\n",
    "                if isinstance(actual_module, torch.nn.utils.parametrize.ParametrizationList) and \"weight\" in actual_name:\n",
    "                    actual_param = actual_param * actual_module[0].mask.to(actual_param.dtype)\n",
    "                if hasattr(module, \"w_quantizer\"):\n",
    "                    actual_param = module.w_quantizer(actual_param)\n",
    "                if hasattr(module, \"b_quantizer\"):\n",
    "                    actual_param = module.b_quantizer(actual_param)\n",
    "                param_list.extend(actual_param.flatten().tolist())\n",
    "\n",
    "\n",
    "    \n",
    "    return param_list\n",
    "\n",
    "\n",
    "def huffman_encode_pass(mg, pass_args):\n",
    "    model = pass_args['model']\n",
    "\n",
    "    save_dir = pass_args['save_dir']\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        os.makedirs(os.path.join(save_dir, \"parameters\"))\n",
    "        os.makedirs(os.path.join(save_dir, \"masks\"))\n",
    "\n",
    "    params = flatten_parameters(model, mg)\n",
    "    freqs = Counter(params)\n",
    "\n",
    "    global_huffman_codes = huffman_encode(freqs)\n",
    "\n",
    "    huffman_codes_path = os.path.join(save_dir, \"global_huffman_codes.json\")\n",
    "    with open(huffman_codes_path, 'w') as file:\n",
    "        json.dump(global_huffman_codes, file)\n",
    "    \n",
    "    named_params = list(model.named_parameters())\n",
    "\n",
    "    get_named_params = lambda name, params: [param for param in params if name in param[0]]\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        module = get_node_actual_target(node)\n",
    "        if node.target in mg.modules:\n",
    "            named_params_node = get_named_params(f\"{node.target}.\", named_params)      \n",
    "            for name, param in module.named_parameters():\n",
    "                actual_name, actual_param = get_named_params(name, named_params_node)[0]\n",
    "                actual_module = find_module_of_parameter(model, actual_name)\n",
    "                if isinstance(actual_module, torch.nn.utils.parametrize.ParametrizationList) and \"weight\" in actual_name:\n",
    "                    actual_param = actual_param * actual_module[0].mask.to(actual_param.dtype)\n",
    "                if hasattr(module, \"w_quantizer\"):\n",
    "                    actual_param = module.w_quantizer(actual_param)\n",
    "                if hasattr(module, \"b_quantizer\"):\n",
    "                    actual_param = module.b_quantizer(actual_param)\n",
    "                \n",
    "                actual_param_values = actual_param.flatten().tolist()\n",
    "                # Encode using global Huffman codes\n",
    "                encoded_values = ''.join([global_huffman_codes[val] for val in actual_param_values])\n",
    "                ba = bitarray.bitarray(encoded_values)\n",
    "                \n",
    "                # Save encoded parameters\n",
    "                # encoded_file_path = os.path.join(save_dir, \"parameters\", f\"{actual_name}.bin\")\n",
    "                encoded_file_path = os.path.join(save_dir, \"parameters\", f\"{node.target}.{name}.{len(ba)}.bin\")\n",
    "\n",
    "                with open(encoded_file_path, 'wb') as encoded_file:\n",
    "                    ba.tofile(encoded_file)\n",
    "\n",
    "\n",
    "    # for name, buffer in model.named_buffers():\n",
    "    #     # Assuming buffer is already quantized\n",
    "    #     if not \"mask\" in name:\n",
    "    #         continue\n",
    "\n",
    "    #     mask = buffer.flatten().tolist()\n",
    "\n",
    "    #     binary_code = {True: '1', False: '0'}\n",
    "        \n",
    "    #     # Encode using global Huffman codes\n",
    "    #     encoded_values = ''.join([binary_code[val] for val in mask])\n",
    "    #     ba = bitarray.bitarray(encoded_values)\n",
    "        \n",
    "    #     # Save encoded parameters\n",
    "    #     encoded_file_path = os.path.join(save_dir, \"masks\", f\"{name}.bin\")\n",
    "    #     with open(encoded_file_path, 'wb') as encoded_file:\n",
    "    #         ba.tofile(encoded_file)\n",
    "\n",
    "    return mg, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, _ = huffman_encode_pass(mg, {\"save_dir\": \"./vgg-compressed\", \"model\": model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_huffman(encoded_data, huffman_codes):\n",
    "    reverse_huffman_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    decoded_data = []\n",
    "    code = \"\"\n",
    "    for bit in encoded_data:\n",
    "        code += str(bit)\n",
    "        if code in reverse_huffman_codes:\n",
    "            decoded_data.append(float(reverse_huffman_codes[code]))\n",
    "            code = \"\"\n",
    "    return decoded_data\n",
    "\n",
    "def load_huffman_encoded_model(mg, pass_args):\n",
    "    load_dir = pass_args['load_dir']\n",
    "    dummy_in = pass_args['dummy_in']\n",
    "\n",
    "    model = mg.model\n",
    "\n",
    "    with open(f\"{load_dir}/global_huffman_codes.json\", 'r') as file:\n",
    "        huffman_codes = json.load(file)\n",
    "\n",
    "    encoded_parameter_files = os.listdir(os.path.join(load_dir, \"parameters\"))\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        file_name = None\n",
    "        for file in encoded_parameter_files:\n",
    "            if file.startswith(name):\n",
    "                file_name = file\n",
    "                break\n",
    "        \n",
    "        if file_name is None:\n",
    "            continue\n",
    "\n",
    "        encoded_file_path = os.path.join(load_dir, \"parameters\", file_name)\n",
    "        num_bits = int(file_name.split('.')[-2])\n",
    "\n",
    "        with open(encoded_file_path, 'rb') as encoded_file:\n",
    "            encoded_data = bitarray.bitarray()\n",
    "            encoded_data.fromfile(encoded_file)\n",
    "            encoded_data = encoded_data[:num_bits]\n",
    "            decoded_data = decode_huffman(encoded_data, huffman_codes)\n",
    "            decoded_data = torch.tensor(decoded_data)\n",
    "            decoded_data = decoded_data.view(param.shape)\n",
    "            param.data = decoded_data\n",
    "\n",
    "    mg = MaseGraph(model)\n",
    "\n",
    "    mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "    mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "    mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "    return mg, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('feature_layers.0.weight', tensor([[[[ 0.0312,  0.1562,  0.0625],\n",
      "          [-0.0312, -0.1250, -0.0312],\n",
      "          [-0.0312,  0.1250, -0.0938]],\n",
      "\n",
      "         [[ 0.1875,  0.0938, -0.0938],\n",
      "          [-0.0938, -0.1875,  0.0312],\n",
      "          [ 0.1562,  0.0938, -0.1562]],\n",
      "\n",
      "         [[-0.0938, -0.0312,  0.1562],\n",
      "          [ 0.0312, -0.0625, -0.0625],\n",
      "          [-0.0312,  0.1875,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0938,  0.1250,  0.0938],\n",
      "          [ 0.1562, -0.0312, -0.1562],\n",
      "          [ 0.1875, -0.1250,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.1250,  0.0312],\n",
      "          [-0.0938, -0.0625, -0.0938],\n",
      "          [ 0.1250, -0.0312,  0.0312]],\n",
      "\n",
      "         [[ 0.0625, -0.1250, -0.1562],\n",
      "          [-0.0625,  0.0312,  0.1250],\n",
      "          [-0.0625, -0.1875,  0.1562]]],\n",
      "\n",
      "\n",
      "        [[[-0.0312,  0.0000,  0.1250],\n",
      "          [ 0.0938,  0.1250, -0.0312],\n",
      "          [ 0.1250,  0.0312, -0.1250]],\n",
      "\n",
      "         [[-0.1562,  0.0625,  0.0625],\n",
      "          [ 0.0000,  0.1562,  0.1562],\n",
      "          [-0.0938, -0.1562, -0.0938]],\n",
      "\n",
      "         [[ 0.1562,  0.0625,  0.1250],\n",
      "          [-0.0312,  0.0938, -0.0938],\n",
      "          [-0.0312,  0.0312, -0.1875]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1562, -0.1562,  0.0625],\n",
      "          [ 0.1562, -0.0312, -0.0938],\n",
      "          [ 0.0312, -0.1875,  0.0938]],\n",
      "\n",
      "         [[-0.0938, -0.0625, -0.0312],\n",
      "          [ 0.1875,  0.1875,  0.0625],\n",
      "          [-0.1250, -0.1250,  0.0312]],\n",
      "\n",
      "         [[-0.0625,  0.1250,  0.1250],\n",
      "          [ 0.0312,  0.0312, -0.0625],\n",
      "          [-0.0625, -0.0938, -0.1875]]],\n",
      "\n",
      "\n",
      "        [[[-0.1250, -0.1875,  0.0625],\n",
      "          [-0.1562, -0.0938,  0.0000],\n",
      "          [ 0.0938,  0.1250, -0.1562]],\n",
      "\n",
      "         [[-0.1562,  0.1250,  0.1562],\n",
      "          [ 0.1875, -0.1875, -0.0938],\n",
      "          [ 0.1562, -0.0938, -0.0938]],\n",
      "\n",
      "         [[ 0.0625, -0.0312,  0.0938],\n",
      "          [ 0.0938,  0.1562, -0.0625],\n",
      "          [ 0.0312,  0.1562, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1562,  0.0938,  0.1250],\n",
      "          [ 0.0625, -0.0625, -0.1250],\n",
      "          [ 0.1562, -0.0312,  0.0000]],\n",
      "\n",
      "         [[-0.1562,  0.0000,  0.0625],\n",
      "          [ 0.1250, -0.1875,  0.1875],\n",
      "          [-0.0938,  0.1562,  0.0625]],\n",
      "\n",
      "         [[ 0.1562, -0.0625, -0.0312],\n",
      "          [-0.0625,  0.0625,  0.1250],\n",
      "          [ 0.0000, -0.1562,  0.0625]]]])), ('feature_layers.0.bias', tensor([ 0.0938, -0.1562,  0.0312,  0.0625,  0.0000,  0.0000,  0.1250, -0.0312,\n",
      "         0.1250,  0.0000, -0.1875, -0.1875,  0.0938, -0.1875, -0.1250,  0.0312,\n",
      "         0.1562, -0.1562,  0.1562,  0.0625, -0.1250, -0.1875, -0.0625,  0.0938,\n",
      "         0.1875, -0.0625,  0.0000, -0.1250, -0.1562,  0.0938,  0.0312,  0.0938,\n",
      "        -0.1562, -0.1562, -0.1562, -0.0625,  0.0938, -0.0938,  0.1250,  0.0625,\n",
      "        -0.1250, -0.0938,  0.0000, -0.1875, -0.1875,  0.1562, -0.0938, -0.1562,\n",
      "        -0.0312, -0.1250,  0.1250,  0.1250, -0.1875,  0.1562, -0.0625, -0.0625,\n",
      "        -0.0938,  0.0000, -0.1562, -0.0625,  0.0312,  0.1250,  0.0000,  0.1562,\n",
      "         0.1250,  0.0938,  0.0625, -0.0938,  0.0312, -0.1250,  0.0625,  0.1875,\n",
      "         0.1562,  0.1562, -0.0625,  0.0625, -0.0938,  0.0312, -0.1562,  0.1250,\n",
      "         0.0000,  0.1250, -0.1562, -0.1250,  0.1875, -0.1250,  0.0000, -0.0938,\n",
      "         0.0000, -0.0938,  0.0938, -0.1875,  0.0938,  0.0625, -0.1875, -0.0625,\n",
      "         0.0000, -0.0938, -0.0312,  0.1562,  0.1875, -0.1875,  0.0625, -0.0625,\n",
      "         0.1875,  0.0625,  0.0938,  0.0938, -0.0938,  0.0938,  0.1875,  0.1562,\n",
      "         0.0000, -0.1250,  0.0312, -0.1562,  0.0938, -0.0938, -0.0312, -0.0625,\n",
      "         0.0000,  0.0000, -0.1250,  0.0625, -0.0625, -0.1875, -0.0938,  0.0625])), ('feature_layers.1.weight', tensor([0.9964, 1.0035, 0.9962, 1.0011, 0.9991, 0.9998, 1.0000, 1.0039, 0.9966,\n",
      "        1.0003, 1.0011, 0.9987, 0.9987, 1.0004, 0.9979, 1.0017, 1.0007, 0.9966,\n",
      "        0.9986, 1.0003, 0.9985, 1.0037, 0.9991, 1.0017, 1.0037, 1.0002, 1.0014,\n",
      "        0.9975, 0.9993, 0.9978, 0.9985, 0.9983, 0.9963, 0.9981, 0.9990, 0.9964,\n",
      "        1.0037, 0.9990, 1.0015, 0.9961, 0.9983, 0.9993, 0.9964, 0.9985, 0.9980,\n",
      "        0.9985, 0.9964, 0.9970, 0.9964, 1.0020, 1.0017, 1.0000, 1.0014, 0.9999,\n",
      "        1.0036, 0.9965, 0.9985, 0.9962, 0.9979, 0.9977, 0.9967, 0.9962, 0.9983,\n",
      "        0.9977, 0.9983, 0.9979, 1.0008, 1.0015, 0.9998, 0.9992, 0.9983, 1.0012,\n",
      "        1.0037, 0.9985, 0.9990, 0.9978, 1.0038, 0.9963, 0.9999, 0.9967, 1.0021,\n",
      "        1.0011, 0.9985, 0.9999, 1.0019, 1.0017, 0.9971, 0.9986, 0.9986, 1.0014,\n",
      "        1.0015, 1.0037, 0.9999, 0.9984, 0.9985, 0.9963, 0.9980, 0.9999, 0.9986,\n",
      "        0.9977, 0.9977, 0.9998, 0.9986, 0.9967, 0.9979, 0.9987, 1.0010, 0.9963,\n",
      "        1.0035, 0.9983, 1.0000, 0.9988, 0.9985, 1.0000, 0.9985, 1.0015, 0.9969,\n",
      "        0.9990, 0.9988, 1.0036, 0.9985, 0.9998, 1.0018, 0.9997, 1.0015, 0.9988,\n",
      "        0.9963, 1.0002])), ('feature_layers.1.bias', tensor([-3.6757e-03, -1.2893e-03, -3.9249e-03,  8.2203e-04, -1.3776e-03,\n",
      "         2.5516e-05, -8.3544e-04, -1.5939e-03, -3.4054e-03,  4.9799e-04,\n",
      "        -3.7590e-03,  7.6140e-04, -3.4089e-03, -3.5016e-03, -3.5423e-03,\n",
      "         1.4364e-03,  3.1478e-03, -1.4054e-03, -1.6827e-03, -1.2685e-03,\n",
      "        -3.7382e-03, -1.2221e-03, -1.5532e-03, -3.1521e-03, -3.9047e-03,\n",
      "         3.0297e-03, -2.1807e-03, -2.4811e-03, -3.3706e-03, -3.6438e-03,\n",
      "         7.4820e-04, -1.6898e-03, -1.3705e-03, -3.4788e-03, -1.5742e-03,\n",
      "        -3.4496e-03, -3.0426e-03, -1.0831e-03, -8.8924e-04, -3.2770e-03,\n",
      "        -1.2994e-03,  6.7725e-04, -3.8331e-03, -1.4938e-03, -3.5634e-03,\n",
      "        -1.5610e-03, -3.7001e-03, -3.7292e-03, -3.7784e-03, -1.5981e-03,\n",
      "         1.4781e-03, -3.3597e-03, -3.7711e-03, -3.3835e-03, -4.2285e-04,\n",
      "        -3.4820e-03, -3.5709e-03, -1.6644e-03,  5.6293e-05, -2.3992e-03,\n",
      "        -3.3288e-03, -1.5263e-03, -1.7025e-03, -3.8398e-03, -1.6465e-03,\n",
      "        -3.5352e-03,  9.9263e-04, -1.5397e-03, -1.6294e-03, -2.0238e-03,\n",
      "        -1.6096e-03,  3.4807e-04, -1.8281e-03, -3.4511e-03, -1.6304e-03,\n",
      "         2.3387e-04, -1.4456e-03, -3.7740e-03, -1.5813e-03, -9.9917e-04,\n",
      "        -1.6956e-03,  2.9794e-03,  1.1821e-03,  7.9599e-04, -1.2352e-03,\n",
      "         1.4779e-03,  3.7294e-04, -1.5414e-03, -3.0898e-03,  1.2530e-03,\n",
      "        -3.6676e-03, -1.7067e-04, -2.1587e-05, -3.5461e-03, -1.5806e-03,\n",
      "        -3.9219e-03, -1.1708e-03, -1.4104e-03, -1.3148e-03, -1.7083e-04,\n",
      "        -1.5264e-03, -1.6491e-04, -1.5654e-03, -3.3052e-03, -2.3869e-03,\n",
      "        -3.7310e-03, -3.6892e-03, -3.6065e-03,  1.1332e-03, -3.7303e-03,\n",
      "         7.3259e-04, -3.8897e-03, -3.8496e-03,  8.4841e-04, -1.3527e-03,\n",
      "        -3.5885e-03, -1.7399e-03, -1.1802e-03, -1.6193e-03,  1.5749e-03,\n",
      "        -3.6740e-03,  7.8202e-04,  1.9709e-03, -3.7164e-03, -1.6527e-03,\n",
      "        -3.7828e-03, -1.6800e-03, -4.8761e-04])), ('feature_layers.1.running_mean', tensor([ 0.0795, -0.1499, -0.0185,  0.0482,  0.0477,  0.0314,  0.1531, -0.0123,\n",
      "         0.0510, -0.1101, -0.1793, -0.2510,  0.0386, -0.2286, -0.1372,  0.0681,\n",
      "         0.1209, -0.1803,  0.1344,  0.1307, -0.1021, -0.2100, -0.0619,  0.0116,\n",
      "         0.1442, -0.0029, -0.0056, -0.1245, -0.2058,  0.1333, -0.0071,  0.1461,\n",
      "        -0.1325, -0.1781, -0.1073,  0.0021,  0.0425, -0.0581, -0.0113,  0.0266,\n",
      "        -0.1185, -0.2044,  0.1111, -0.1844, -0.1983,  0.2661,  0.0342, -0.1503,\n",
      "        -0.0750, -0.1519,  0.2456,  0.0565, -0.1888,  0.1383, -0.1895, -0.0716,\n",
      "        -0.0957,  0.0136, -0.1229, -0.0142,  0.1094,  0.1372, -0.0066,  0.1650,\n",
      "         0.1894,  0.0832,  0.1137, -0.0671,  0.1240, -0.1669,  0.0645,  0.1408,\n",
      "         0.0463,  0.1210,  0.0022,  0.0235, -0.1192,  0.0295, -0.1022,  0.1853,\n",
      "         0.0344,  0.1412, -0.0879, -0.1690,  0.2221, -0.0610, -0.0764, -0.1211,\n",
      "        -0.0573, -0.0487,  0.0630, -0.2056,  0.0538,  0.1000, -0.1567,  0.0175,\n",
      "        -0.0145, -0.0634, -0.0780,  0.1771,  0.1653, -0.2013,  0.0596, -0.1344,\n",
      "         0.0810,  0.0626,  0.0982,  0.1128, -0.0874,  0.0220,  0.2456,  0.2121,\n",
      "         0.0594, -0.1002,  0.0198, -0.0964,  0.1168,  0.0040, -0.0046, -0.0898,\n",
      "         0.0346,  0.0254, -0.1352,  0.0963, -0.0997, -0.1875, -0.0202,  0.0212])), ('feature_layers.1.running_var', tensor([0.1615, 0.0851, 0.4161, 0.5235, 0.6909, 0.2466, 1.1230, 0.2678, 1.3627,\n",
      "        2.1222, 0.3520, 0.9977, 1.1942, 0.9158, 0.2312, 0.7601, 0.6220, 0.2033,\n",
      "        0.1836, 0.4376, 0.3653, 0.1796, 0.3526, 0.1805, 0.1981, 0.3502, 0.4696,\n",
      "        0.5563, 0.2322, 0.1245, 1.1654, 0.3130, 0.1942, 0.5981, 0.4691, 0.3591,\n",
      "        0.2865, 0.5273, 0.5552, 0.3572, 1.2641, 0.4449, 0.7942, 0.4153, 1.7862,\n",
      "        0.9548, 2.1835, 0.2976, 0.4363, 0.4189, 2.5716, 0.4685, 0.1144, 0.2838,\n",
      "        0.6041, 0.6491, 0.4122, 0.1918, 0.2496, 0.3043, 3.0261, 0.2823, 0.2505,\n",
      "        0.4703, 1.2346, 0.3308, 0.2763, 0.4880, 0.4894, 0.2902, 1.0315, 0.2360,\n",
      "        0.2610, 0.1719, 0.5585, 0.2072, 0.1776, 0.6394, 0.2291, 0.8231, 0.1259,\n",
      "        0.4028, 0.4848, 1.4189, 0.7259, 0.5811, 0.4762, 0.9682, 0.2698, 0.8870,\n",
      "        0.9314, 0.1313, 0.7137, 0.1694, 0.3816, 0.4633, 0.2216, 0.9854, 0.7694,\n",
      "        0.5782, 0.1573, 0.1713, 0.4864, 0.9990, 0.8293, 0.4234, 0.6714, 0.2760,\n",
      "        1.2335, 1.1201, 0.2537, 0.4392, 0.5110, 0.8760, 0.1478, 0.7227, 0.1746,\n",
      "        0.3225, 0.1111, 0.2158, 0.3987, 0.2048, 1.9531, 0.7599, 0.2816, 0.1772,\n",
      "        0.1870, 0.4352])), ('feature_layers.1.num_batches_tracked', tensor(2)), ('feature_layers.3.weight', tensor([[[[ 0.0000, -0.0312, -0.0312],\n",
      "          [ 0.0000, -0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[-0.0312, -0.0312, -0.0312],\n",
      "          [ 0.0312, -0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0312],\n",
      "          [-0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0312,  0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0312, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0312,  0.0000],\n",
      "          [-0.0312, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[-0.0312, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0312,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312, -0.0312],\n",
      "          [-0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0312]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312, -0.0312],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0312,  0.0312,  0.0312],\n",
      "          [-0.0312, -0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312, -0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312, -0.0312, -0.0312],\n",
      "          [-0.0312,  0.0000,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000, -0.0312, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [-0.0312,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0312, -0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312, -0.0312,  0.0000]]]])), ('feature_layers.3.bias', tensor([-0.0312,  0.0000,  0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0312,  0.0000, -0.0312,  0.0312, -0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312, -0.0312, -0.0312,  0.0312,  0.0000,  0.0312,  0.0312,\n",
      "        -0.0312,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "        -0.0312, -0.0312, -0.0312, -0.0312, -0.0312,  0.0312, -0.0312,  0.0000,\n",
      "        -0.0312,  0.0312,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0312,  0.0000, -0.0312,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "        -0.0312, -0.0312, -0.0312,  0.0312,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0312,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312, -0.0312, -0.0312, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,\n",
      "         0.0000, -0.0312,  0.0312, -0.0312,  0.0000,  0.0000, -0.0312, -0.0312,\n",
      "         0.0312,  0.0312, -0.0312,  0.0000, -0.0312,  0.0000, -0.0312,  0.0312])), ('feature_layers.4.weight', tensor([0.9982, 1.0012, 1.0001, 0.9986, 1.0015, 1.0037, 0.9988, 0.9962, 1.0037,\n",
      "        0.9965, 1.0036, 0.9986, 1.0024, 0.9983, 0.9976, 0.9963, 0.9984, 1.0030,\n",
      "        1.0037, 0.9967, 0.9963, 1.0037, 0.9990, 0.9963, 0.9982, 0.9983, 1.0008,\n",
      "        0.9981, 1.0003, 1.0014, 0.9977, 1.0001, 1.0021, 0.9983, 0.9961, 0.9990,\n",
      "        0.9997, 0.9962, 0.9998, 0.9979, 1.0037, 0.9996, 0.9964, 0.9977, 0.9998,\n",
      "        0.9965, 0.9979, 0.9990, 0.9965, 0.9988, 1.0036, 0.9964, 1.0001, 0.9961,\n",
      "        1.0005, 0.9983, 1.0002, 1.0015, 0.9983, 1.0012, 1.0035, 1.0034, 0.9993,\n",
      "        0.9999, 0.9984, 1.0011, 0.9985, 1.0000, 0.9984, 1.0037, 0.9965, 0.9996,\n",
      "        0.9998, 0.9986, 0.9988, 1.0015, 0.9964, 0.9985, 0.9982, 0.9978, 0.9981,\n",
      "        0.9962, 0.9975, 0.9998, 0.9985, 0.9963, 0.9978, 1.0037, 1.0004, 1.0015,\n",
      "        0.9992, 0.9985, 0.9963, 0.9986, 0.9984, 0.9985, 0.9969, 1.0000, 0.9984,\n",
      "        1.0018, 1.0036, 0.9969, 0.9985, 1.0016, 1.0016, 1.0012, 1.0002, 0.9962,\n",
      "        1.0015, 0.9977, 1.0003, 1.0034, 1.0013, 0.9962, 0.9964, 0.9987, 0.9985,\n",
      "        0.9967, 1.0026, 0.9965, 0.9990, 0.9990, 1.0010, 0.9984, 0.9980, 1.0023,\n",
      "        0.9968, 0.9993])), ('feature_layers.4.bias', tensor([-1.4375e-03, -1.2711e-03,  7.3308e-04, -1.5226e-03,  1.7668e-03,\n",
      "        -3.6055e-03, -3.6958e-03,  8.4116e-04, -1.4907e-05, -1.4082e-03,\n",
      "        -1.6243e-03, -1.4250e-03, -1.9064e-04,  2.4511e-03, -2.2306e-03,\n",
      "        -3.7666e-03, -3.5205e-03, -1.6917e-03, -1.6610e-03, -9.5668e-04,\n",
      "        -1.7068e-03, -2.2222e-03, -4.3270e-04, -3.7338e-03,  2.3563e-05,\n",
      "        -1.6649e-03,  8.4667e-04, -3.3918e-03, -1.3917e-03, -2.4691e-03,\n",
      "        -3.7090e-03,  1.3414e-04, -3.7681e-03, -3.7359e-03, -1.6708e-03,\n",
      "        -1.6167e-03, -1.5647e-03, -3.7531e-03, -1.5741e-03, -1.4919e-03,\n",
      "         1.6321e-04,  1.5719e-03, -3.8133e-03, -3.7053e-03, -6.4727e-05,\n",
      "        -3.6819e-03,  5.5110e-05, -3.7842e-03, -3.6234e-03, -1.3921e-03,\n",
      "        -1.5452e-03, -3.7116e-03, -1.1486e-03, -3.8645e-03, -3.7955e-03,\n",
      "        -3.7529e-03, -1.6123e-03, -1.3328e-03, -3.7298e-03, -3.9432e-03,\n",
      "        -1.6053e-03, -4.2171e-04, -8.9271e-04, -3.7370e-03, -1.4994e-03,\n",
      "        -1.6794e-03, -1.4338e-03, -4.1079e-04, -3.7159e-03, -1.1152e-04,\n",
      "        -3.5634e-03, -1.1427e-03, -3.6606e-03, -1.3479e-03, -1.5108e-03,\n",
      "        -3.6913e-03, -3.5675e-03, -1.4128e-03, -3.5238e-03, -3.9779e-03,\n",
      "        -3.4023e-03, -1.5645e-03, -3.3709e-03, -3.8037e-03,  3.6543e-03,\n",
      "        -1.2095e-03, -3.8686e-03, -3.6727e-03, -3.9549e-03, -3.8503e-03,\n",
      "        -1.5844e-03, -1.5352e-03, -3.5813e-03, -3.3180e-03, -1.5716e-03,\n",
      "        -1.6495e-03, -1.4317e-03,  1.4682e-04, -6.0907e-04, -3.7263e-03,\n",
      "        -1.0662e-04, -2.5979e-03, -1.7096e-03,  2.1237e-03, -3.2183e-03,\n",
      "        -3.7211e-03, -1.3170e-03, -1.6105e-03, -3.7131e-03, -1.5640e-03,\n",
      "        -1.5409e-03,  1.4137e-03, -3.7418e-03, -1.6688e-03, -3.6360e-03,\n",
      "        -1.5890e-03, -3.7418e-03, -3.1448e-03, -1.7039e-03, -7.4337e-04,\n",
      "        -3.7714e-03,  3.9102e-05, -3.8594e-03, -1.6117e-03, -9.6652e-04,\n",
      "        -3.6607e-03, -3.3233e-03, -3.1052e-03])), ('feature_layers.4.running_mean', tensor([ 0.2333,  0.0561, -0.1976, -0.3857,  0.1748,  0.5929,  0.3186, -0.6382,\n",
      "         0.7297,  0.3789,  0.4030, -0.2589,  0.7746, -0.8361, -0.3256, -0.1132,\n",
      "        -0.1069,  0.9965,  0.3946, -0.3496, -0.5175,  0.1995,  0.0300,  0.2193,\n",
      "         0.5207,  0.1489, -0.0304,  0.6584,  0.2258, -0.0915, -0.0262, -1.0252,\n",
      "         0.6715,  0.1678, -0.0916, -0.0873,  0.0758,  0.3618,  0.1602,  0.2085,\n",
      "         0.5607,  0.0423, -0.8700,  0.3742,  0.1903, -0.3498, -0.4341,  0.2229,\n",
      "        -0.6408,  0.4760,  0.3630, -0.7737,  0.1872, -0.4545,  0.3631, -0.3614,\n",
      "         0.5211,  0.0967, -0.0463,  0.6848,  0.3943,  0.4721,  0.1767, -0.0999,\n",
      "        -0.8728,  0.1992,  0.2135,  0.0893,  0.3753,  0.5198, -0.2146,  0.2829,\n",
      "         0.2826, -0.1652,  0.4805,  0.4399,  0.1050, -0.5068,  0.3207,  0.2452,\n",
      "         0.7386, -0.3157,  0.5039,  0.9532, -0.4451, -0.2480,  0.7735,  0.4900,\n",
      "         0.4929,  0.2528,  0.5169,  0.0826,  0.1078, -0.6483, -0.6087, -0.9279,\n",
      "         0.9086,  0.5551, -0.0925,  0.7294,  0.2047,  0.0885, -0.3774, -0.2893,\n",
      "         0.2055,  0.4046,  0.6770, -0.3385,  0.6782,  0.3048,  0.4404,  0.0739,\n",
      "         0.3225, -0.4322,  0.5793, -0.1534,  0.5103, -0.6557,  0.3037, -0.3082,\n",
      "         0.2691,  0.3626,  0.4863, -0.4126,  0.4148,  0.6462, -0.6081,  0.1604])), ('feature_layers.4.running_var', tensor([0.2854, 0.2055, 0.1519, 0.2313, 0.1483, 0.2193, 0.2851, 0.9541, 0.3727,\n",
      "        0.2406, 0.3253, 0.2152, 0.3305, 0.4573, 1.0893, 0.8167, 0.7789, 0.4251,\n",
      "        0.2196, 0.7113, 0.4293, 0.2620, 0.7382, 0.9575, 0.1676, 0.8102, 0.7857,\n",
      "        0.2420, 0.6307, 0.2223, 0.7989, 0.3961, 0.2630, 0.3948, 0.2579, 0.2233,\n",
      "        0.3881, 0.4115, 0.5922, 0.3805, 0.3244, 0.2423, 0.6096, 0.5772, 0.2148,\n",
      "        1.0563, 0.3010, 0.1723, 0.2439, 0.2449, 0.3798, 0.6236, 0.0959, 1.0946,\n",
      "        0.3784, 1.0419, 0.2344, 0.2794, 0.6935, 0.3287, 0.2615, 0.5880, 0.2456,\n",
      "        0.3467, 0.4700, 0.4233, 0.2644, 0.4609, 0.4743, 0.3863, 0.1886, 0.2199,\n",
      "        0.6366, 0.3838, 0.4017, 0.3388, 0.1159, 0.9178, 0.1525, 0.4396, 0.2752,\n",
      "        0.5439, 0.3385, 0.3278, 0.2020, 1.1875, 0.2845, 0.3687, 0.4492, 0.2302,\n",
      "        0.3698, 0.4111, 0.8626, 0.3568, 1.0483, 0.3527, 0.3749, 0.1689, 0.6705,\n",
      "        0.3911, 0.3547, 0.3703, 0.5953, 0.6368, 0.2035, 0.4672, 0.2276, 0.5281,\n",
      "        0.2330, 0.1807, 0.1582, 0.1340, 0.2779, 0.3557, 0.2054, 0.2667, 0.4604,\n",
      "        0.2730, 0.1899, 0.5965, 0.5010, 0.4563, 0.2927, 0.8120, 0.2657, 0.2934,\n",
      "        0.2942, 0.1249])), ('feature_layers.4.num_batches_tracked', tensor(2)), ('feature_layers.7.weight', tensor([[[[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0312],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [-0.0312, -0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0312, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0312,  0.0312],\n",
      "          [-0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0312, -0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0312,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312, -0.0312],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312, -0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0312],\n",
      "          [ 0.0000, -0.0312, -0.0312],\n",
      "          [-0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312, -0.0312],\n",
      "          [ 0.0312, -0.0312, -0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0312],\n",
      "          [-0.0312,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0312, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]]]])), ('feature_layers.7.bias', tensor([ 0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0312,  0.0000,  0.0312,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,\n",
      "         0.0000, -0.0312,  0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0312, -0.0312,  0.0312,\n",
      "        -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000, -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0312, -0.0312,  0.0000,  0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0312,  0.0312, -0.0312,  0.0312,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312, -0.0312,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000, -0.0312,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312, -0.0312,  0.0312,  0.0000,  0.0000,  0.0312,\n",
      "         0.0000,  0.0312,  0.0312,  0.0312,  0.0000, -0.0312,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0312,  0.0312, -0.0312,  0.0312,  0.0000,\n",
      "         0.0312, -0.0312,  0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,  0.0000,  0.0312,\n",
      "         0.0312,  0.0312,  0.0000,  0.0312,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0312,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0312, -0.0312,  0.0312,  0.0000,\n",
      "         0.0000, -0.0312,  0.0312,  0.0312,  0.0000,  0.0312,  0.0312,  0.0000,\n",
      "         0.0312,  0.0000, -0.0312,  0.0000,  0.0312, -0.0312,  0.0312,  0.0000,\n",
      "        -0.0312, -0.0312, -0.0312,  0.0312,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0312,  0.0312, -0.0312,  0.0312,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000])), ('feature_layers.8.weight', tensor([0.9965, 0.9983, 1.0001, 0.9985, 1.0032, 0.9962, 0.9966, 0.9978, 0.9966,\n",
      "        0.9979, 1.0012, 0.9963, 0.9964, 1.0001, 0.9984, 0.9963, 0.9978, 0.9985,\n",
      "        1.0014, 1.0015, 1.0014, 0.9981, 1.0037, 0.9963, 0.9966, 1.0009, 1.0021,\n",
      "        0.9982, 1.0014, 1.0021, 1.0015, 0.9965, 0.9985, 0.9961, 1.0030, 1.0002,\n",
      "        1.0035, 1.0034, 0.9962, 0.9988, 0.9985, 0.9999, 0.9963, 0.9989, 0.9986,\n",
      "        1.0020, 1.0009, 0.9986, 0.9965, 0.9989, 1.0013, 1.0034, 1.0037, 1.0019,\n",
      "        1.0014, 1.0014, 1.0003, 0.9999, 0.9977, 0.9968, 0.9964, 1.0021, 0.9986,\n",
      "        1.0035, 0.9976, 0.9980, 0.9988, 0.9985, 0.9979, 0.9988, 0.9999, 1.0000,\n",
      "        0.9989, 0.9971, 1.0013, 1.0037, 1.0002, 0.9966, 0.9966, 1.0036, 1.0036,\n",
      "        1.0007, 1.0008, 0.9985, 1.0002, 0.9962, 0.9987, 0.9963, 0.9964, 0.9980,\n",
      "        0.9997, 0.9984, 0.9998, 0.9977, 0.9967, 1.0013, 0.9999, 1.0013, 0.9965,\n",
      "        1.0011, 1.0013, 1.0022, 0.9978, 0.9965, 0.9986, 1.0001, 0.9994, 0.9976,\n",
      "        0.9964, 1.0019, 1.0013, 1.0002, 1.0002, 0.9962, 0.9974, 0.9988, 0.9963,\n",
      "        1.0035, 1.0010, 0.9979, 0.9984, 1.0037, 0.9974, 0.9963, 0.9987, 0.9966,\n",
      "        0.9988, 1.0036, 0.9965, 0.9983, 0.9986, 0.9983, 0.9982, 0.9998, 0.9962,\n",
      "        0.9991, 1.0022, 1.0007, 0.9965, 0.9967, 0.9964, 0.9985, 0.9974, 0.9990,\n",
      "        0.9981, 0.9964, 0.9999, 0.9965, 1.0016, 0.9995, 1.0012, 1.0014, 0.9968,\n",
      "        1.0008, 0.9965, 0.9991, 1.0022, 0.9964, 0.9965, 0.9977, 1.0001, 1.0034,\n",
      "        1.0014, 1.0035, 0.9998, 1.0022, 0.9965, 0.9995, 0.9985, 1.0012, 0.9965,\n",
      "        0.9990, 1.0034, 0.9984, 0.9967, 0.9965, 1.0014, 0.9990, 1.0039, 1.0020,\n",
      "        0.9965, 1.0015, 0.9984, 1.0000, 0.9963, 1.0017, 1.0014, 1.0002, 0.9987,\n",
      "        0.9963, 0.9987, 1.0015, 0.9964, 1.0002, 1.0016, 0.9984, 0.9997, 0.9964,\n",
      "        0.9965, 0.9968, 0.9965, 0.9986, 0.9987, 1.0001, 1.0031, 1.0016, 0.9970,\n",
      "        1.0005, 0.9973, 0.9966, 1.0037, 1.0034, 0.9969, 0.9965, 1.0034, 0.9964,\n",
      "        1.0037, 1.0001, 1.0037, 1.0035, 0.9981, 0.9966, 1.0035, 1.0001, 1.0012,\n",
      "        1.0036, 0.9997, 1.0033, 0.9986, 0.9985, 0.9981, 0.9990, 0.9985, 0.9985,\n",
      "        1.0033, 0.9969, 0.9979, 1.0014, 0.9985, 0.9985, 1.0037, 0.9985, 0.9984,\n",
      "        0.9966, 1.0001, 0.9986, 0.9986, 1.0035, 0.9966, 1.0012, 0.9971, 0.9977,\n",
      "        0.9963, 0.9998, 0.9965, 1.0036])), ('feature_layers.8.bias', tensor([-3.4616e-03, -1.6284e-03, -3.4214e-03, -5.4567e-04, -1.1133e-03,\n",
      "        -3.9632e-03, -1.9438e-03, -2.3070e-03, -1.4486e-03, -2.1544e-03,\n",
      "        -1.6108e-03, -1.4062e-03, -3.7245e-03, -1.4674e-03, -1.6714e-03,\n",
      "         7.6482e-04, -3.8785e-03, -1.2964e-03, -3.7181e-03, -2.0825e-04,\n",
      "        -2.5706e-03, -1.9194e-03, -2.2590e-03, -2.5155e-03, -3.4548e-03,\n",
      "        -1.6842e-03, -1.2329e-03, -2.7373e-03, -2.3077e-03, -1.5736e-03,\n",
      "        -1.4935e-03, -3.6921e-03, -1.4076e-03, -3.8476e-03, -1.7070e-03,\n",
      "        -1.1888e-03, -2.4943e-03, -1.7220e-04, -3.8173e-03, -3.7366e-03,\n",
      "        -1.4053e-03, -3.7486e-03, -3.6439e-03, -3.6712e-03, -1.4743e-03,\n",
      "        -1.6331e-03,  1.4273e-04, -1.3853e-03, -3.7167e-03,  2.4403e-04,\n",
      "        -3.7560e-03,  4.2392e-05, -1.6190e-03, -1.6648e-03, -2.2867e-03,\n",
      "        -2.1815e-03, -1.4376e-03, -1.5242e-03, -1.9162e-04, -3.1386e-03,\n",
      "        -1.6420e-03, -3.7449e-03, -1.4983e-03, -1.6793e-03, -3.7266e-03,\n",
      "        -2.3770e-03, -1.0199e-03, -3.4477e-03, -1.6778e-03, -1.1647e-03,\n",
      "         3.7659e-05,  1.5578e-04, -9.4113e-04, -2.9400e-03, -1.5114e-03,\n",
      "        -1.4889e-04, -3.6943e-03, -3.3541e-03, -1.2886e-03, -3.6901e-03,\n",
      "         1.3039e-04, -1.1871e-04, -1.5934e-03, -1.4621e-03, -3.7534e-03,\n",
      "        -1.6178e-03, -1.3556e-03, -1.6138e-03, -3.6920e-03, -3.8142e-03,\n",
      "        -1.6910e-03,  7.7852e-04, -2.1157e-03, -1.7080e-03, -4.9004e-04,\n",
      "        -3.7505e-03, -1.3037e-03, -3.8905e-03, -3.6624e-03, -1.3342e-03,\n",
      "        -2.2505e-03, -1.5851e-03, -2.4898e-04,  8.4611e-05, -1.5154e-03,\n",
      "        -7.3606e-05, -3.7532e-03,  6.5741e-05, -1.4460e-03, -1.6653e-03,\n",
      "        -2.2023e-03, -3.5126e-03, -1.4102e-03, -3.9236e-03, -5.7549e-04,\n",
      "        -1.4397e-03, -3.6907e-03, -3.7413e-05, -1.6067e-03, -2.0988e-03,\n",
      "        -3.7691e-03, -1.2669e-03, -5.1761e-04, -3.5671e-03,  2.0906e-04,\n",
      "        -3.5780e-03,  1.9751e-04, -1.7027e-03, -3.6046e-03, -3.7182e-03,\n",
      "        -1.3517e-03, -1.6588e-03, -2.0246e-03,  1.9424e-05, -3.8462e-03,\n",
      "        -7.0655e-04, -1.0732e-03, -1.6291e-03, -1.4272e-03, -1.5008e-03,\n",
      "        -3.5457e-03, -1.4282e-03, -3.6290e-03, -3.6860e-03, -1.3746e-03,\n",
      "        -2.0984e-03, -1.1379e-06, -3.6362e-03, -4.3875e-04, -3.7684e-03,\n",
      "        -2.2334e-03, -2.6001e-03, -3.6282e-03,  8.2611e-04, -3.4826e-03,\n",
      "        -7.9038e-04, -3.7039e-03, -3.4671e-03, -3.4303e-03, -2.2339e-03,\n",
      "         1.4300e-03, -1.4022e-03, -2.2789e-03, -1.2419e-04, -3.7665e-03,\n",
      "        -1.6499e-03, -2.0761e-03, -7.5463e-04, -7.6341e-05, -1.6808e-03,\n",
      "        -1.6089e-03, -8.8706e-04, -1.5973e-03, -1.6287e-03, -3.1334e-03,\n",
      "        -2.3552e-03, -2.3470e-03, -3.6270e-04, -1.6369e-03, -1.2242e-04,\n",
      "        -2.0478e-03, -5.0170e-04, -2.7967e-03, -1.6649e-03, -3.5217e-03,\n",
      "        -1.0121e-04, -3.9347e-03, -3.3577e-03, -1.3515e-03, -3.5508e-03,\n",
      "        -3.3838e-03, -3.7803e-03, -3.5847e-03, -1.2374e-03, -3.7404e-03,\n",
      "        -1.6383e-03, -3.7848e-03, -3.7685e-03, -3.4900e-03, -3.6632e-03,\n",
      "        -1.3430e-03, -3.4217e-03, -4.2205e-04, -1.5126e-03, -1.5987e-03,\n",
      "        -2.2441e-03, -2.4746e-03, -1.3353e-03, -1.9683e-03, -3.3884e-03,\n",
      "        -7.7914e-05, -3.7568e-03, -3.2531e-03, -3.4760e-03, -1.5597e-03,\n",
      "        -3.6976e-03, -1.5990e-03, -3.8124e-03,  7.8519e-05, -1.5427e-03,\n",
      "        -1.1340e-03, -3.4286e-03, -1.6234e-03, -7.9634e-04, -1.6464e-03,\n",
      "        -3.7478e-03,  6.1936e-04, -3.7379e-03, -1.3795e-03, -1.5406e-03,\n",
      "        -1.4902e-03, -1.2850e-03, -1.5126e-03, -1.4381e-03, -1.3472e-04,\n",
      "        -9.6490e-04, -1.3397e-03,  1.1914e-04, -1.5589e-03, -3.6475e-03,\n",
      "        -1.5780e-03, -1.4811e-03, -1.4772e-03, -3.6091e-03, -1.2079e-03,\n",
      "        -1.4101e-03, -3.6689e-03, -3.8106e-03, -2.0784e-03, -3.6829e-03,\n",
      "        -3.7390e-03, -3.8088e-03, -3.5008e-03, -3.0083e-03, -3.4894e-03,\n",
      "        -1.4479e-03])), ('feature_layers.8.running_mean', tensor([ 1.1058e-03,  5.0869e-01,  6.5765e-01,  1.3538e+00,  9.3527e-01,\n",
      "         8.2248e-02, -4.0077e-01,  3.8253e-01,  6.2859e-01,  5.6350e-01,\n",
      "         2.4527e-01,  4.5930e-01, -1.7874e-01,  5.5142e-01, -3.9219e-01,\n",
      "        -2.6532e-01,  4.7271e-01, -4.6016e-01,  4.0986e-01,  6.7374e-01,\n",
      "         4.6111e-01,  1.0855e+00,  3.8719e-01, -1.2508e-01, -4.1245e-01,\n",
      "         8.1304e-01,  1.7294e-01, -2.7420e-01,  8.0018e-01,  7.9683e-01,\n",
      "         6.6868e-01,  3.2729e-01,  9.1105e-03,  1.0579e+00,  4.8893e-01,\n",
      "         1.2962e+00,  6.7271e-01,  7.0589e-01,  1.7965e-01, -7.4150e-01,\n",
      "         1.9614e-01,  5.1475e-01,  3.2424e-01,  7.4102e-01, -2.6743e-01,\n",
      "         5.4557e-01,  1.0204e+00, -2.6882e-01,  9.4561e-01, -3.7191e-01,\n",
      "         1.7924e-01,  6.1133e-01,  5.7590e-01,  2.4788e-01,  1.0113e+00,\n",
      "        -5.1200e-03,  6.1041e-01,  9.3327e-01, -2.0473e-01,  7.2261e-01,\n",
      "        -1.5144e-01,  2.2395e-01, -3.3297e-01,  3.9575e-01,  6.1972e-02,\n",
      "         1.1145e+00, -1.0260e+00,  3.2108e-01,  7.1215e-02, -6.1404e-01,\n",
      "         4.7243e-01,  5.9296e-01,  4.5623e-01,  7.5858e-01,  1.7186e-01,\n",
      "         5.4044e-01,  3.1284e-01,  1.1232e+00,  4.7834e-01,  5.2804e-01,\n",
      "         7.8507e-01,  1.1584e+00,  3.3816e-01,  6.0099e-01,  6.6252e-01,\n",
      "        -3.9699e-02, -2.1409e-01, -3.0372e-01, -1.7899e-01,  8.4083e-01,\n",
      "         4.8272e-01, -2.0826e-01, -2.0087e-02,  2.4822e-01,  4.8765e-01,\n",
      "         6.1733e-01,  1.0898e+00,  6.1319e-01, -4.7174e-01,  9.3821e-01,\n",
      "         3.1105e-01,  1.9951e-01,  3.2205e-01, -5.0647e-01,  1.0763e+00,\n",
      "         5.9323e-01,  5.3556e-01,  3.1097e-01,  3.0384e-01,  6.3745e-01,\n",
      "         7.7396e-01,  6.6500e-01,  6.3814e-01,  2.9688e-01, -4.0109e-01,\n",
      "         2.9718e-01,  1.9448e-01,  9.6857e-01,  6.3829e-01,  3.5456e-01,\n",
      "        -7.9354e-01,  8.1497e-01,  5.4991e-01,  1.4810e-01,  4.8984e-01,\n",
      "         8.4147e-01, -6.6006e-01,  5.1755e-01, -3.9778e-01, -5.3317e-01,\n",
      "         5.7289e-01,  3.9359e-01,  6.5813e-01,  6.4385e-01,  6.1201e-01,\n",
      "        -5.5704e-01,  3.0339e-01,  5.0439e-01, -2.9122e-01, -4.1436e-01,\n",
      "         3.5680e-01,  3.2967e-01,  6.6436e-01,  1.7877e-02,  1.2048e+00,\n",
      "        -1.4321e-01,  3.2078e-01,  1.2617e-01,  3.6143e-01,  6.7903e-01,\n",
      "         8.1058e-01,  7.3553e-01,  3.1694e-01, -1.3467e-01, -1.0236e+00,\n",
      "        -2.2958e-01,  6.4081e-02, -6.9488e-01,  1.7471e-01, -1.1497e-01,\n",
      "         9.2345e-01,  7.9838e-01,  1.0006e+00,  4.3322e-01,  8.9278e-01,\n",
      "         2.1597e-01, -1.0544e-01,  7.4303e-01,  4.3811e-01,  4.8228e-01,\n",
      "         1.3024e-01,  9.9039e-01,  6.0534e-01,  5.4132e-02, -9.6085e-01,\n",
      "        -3.4553e-01,  3.0195e-01,  5.9216e-01,  7.6248e-01,  1.4303e+00,\n",
      "        -1.7014e-01,  5.5150e-01,  3.3488e-01,  2.7080e-01,  2.2553e-01,\n",
      "         1.5377e-01,  7.9857e-01,  1.0921e+00, -1.0430e-01,  4.8108e-01,\n",
      "        -4.3659e-03,  5.6800e-01, -2.2007e-01,  4.3970e-01,  4.8253e-01,\n",
      "         6.5411e-01,  7.6132e-01,  6.1168e-01, -3.9769e-01,  4.1752e-01,\n",
      "         4.3517e-01, -4.5264e-01,  7.0156e-01,  1.1540e+00,  8.4715e-01,\n",
      "         8.4374e-01,  5.7675e-01,  6.2313e-01, -3.4460e-01,  2.1627e-01,\n",
      "         1.2481e+00,  1.0290e+00, -7.6649e-01, -4.7776e-01,  7.3241e-01,\n",
      "        -7.6134e-01,  2.6266e-01,  4.1429e-01,  1.0919e+00,  9.8139e-01,\n",
      "         6.8684e-01, -4.2432e-01,  5.1589e-01,  6.2025e-01,  1.0093e+00,\n",
      "         8.7770e-01,  7.5945e-01,  6.1271e-01, -4.2792e-02, -2.1927e-01,\n",
      "         8.2455e-01,  2.3182e-01, -2.8331e-01,  1.2394e-01,  1.1091e+00,\n",
      "        -9.1718e-01,  2.9942e-01,  3.7137e-01,  1.2827e-01, -9.9457e-01,\n",
      "         7.6578e-01, -2.3407e-01, -7.5080e-01,  4.0901e-01,  1.2419e+00,\n",
      "        -9.4122e-01,  6.4566e-01,  9.1220e-01, -1.1131e+00,  7.7719e-01,\n",
      "         5.9069e-01,  2.1638e-01,  4.1322e-01,  1.1365e+00, -3.0249e-01,\n",
      "         6.8413e-01])), ('feature_layers.8.running_var', tensor([0.1972, 0.6560, 0.6482, 0.3971, 1.2686, 0.2000, 0.4683, 0.4691, 0.4429,\n",
      "        0.7935, 0.4950, 1.2099, 0.4796, 0.2287, 0.3912, 0.4271, 0.4812, 0.6011,\n",
      "        0.6595, 0.9066, 0.6134, 0.8906, 0.6065, 0.3272, 0.3602, 1.0753, 0.7875,\n",
      "        0.5346, 1.0170, 1.1116, 0.3979, 0.5335, 0.2109, 0.9551, 0.5854, 1.6456,\n",
      "        1.1408, 0.9359, 0.4063, 0.3974, 0.3701, 0.5671, 0.3321, 0.7807, 0.5228,\n",
      "        0.8306, 1.3028, 0.1906, 0.8245, 0.2481, 0.7917, 0.9633, 0.7034, 0.4542,\n",
      "        0.8934, 0.7348, 0.3219, 0.6358, 0.3133, 0.7243, 0.3657, 0.3871, 0.4336,\n",
      "        0.8858, 0.5715, 0.6820, 0.5505, 0.3743, 0.5961, 0.7225, 0.3529, 0.4364,\n",
      "        0.3600, 0.3410, 0.5062, 0.8479, 0.9774, 0.6605, 0.1923, 0.8332, 0.5862,\n",
      "        1.1273, 0.6050, 0.3059, 0.4861, 0.5895, 0.2201, 0.3510, 0.2061, 0.8338,\n",
      "        1.1678, 0.6864, 0.3511, 0.4188, 0.4591, 0.9763, 0.7715, 0.6569, 0.4934,\n",
      "        0.9387, 0.8892, 0.7947, 0.4043, 0.3465, 0.9867, 0.5167, 1.1175, 0.2838,\n",
      "        0.3104, 0.9865, 0.8270, 0.6551, 0.7674, 0.3187, 0.5927, 0.4365, 0.1979,\n",
      "        1.4303, 0.7477, 0.6025, 0.3795, 0.8074, 0.3893, 0.2760, 0.7876, 0.8126,\n",
      "        0.4569, 0.9809, 0.2031, 0.3020, 0.2845, 0.4760, 0.5255, 1.0730, 0.4196,\n",
      "        0.4608, 0.3162, 0.4511, 0.2168, 0.3306, 0.7286, 0.5927, 0.7067, 1.0068,\n",
      "        0.7998, 0.4270, 0.4219, 0.1493, 0.1752, 0.8550, 1.0910, 1.1772, 0.4376,\n",
      "        0.1186, 0.4264, 0.4853, 0.6731, 0.2850, 0.3760, 0.3349, 0.6446, 0.6413,\n",
      "        1.1918, 0.9914, 0.8267, 0.6181, 0.2476, 0.9112, 0.2411, 0.9244, 0.4760,\n",
      "        1.0111, 0.9064, 0.3733, 0.4054, 0.2317, 1.0214, 0.3734, 0.6441, 1.3194,\n",
      "        0.3126, 0.8199, 0.5905, 0.8140, 0.2762, 0.3600, 0.8541, 0.6456, 0.3758,\n",
      "        0.2843, 0.6173, 0.8254, 0.2839, 0.7317, 0.7116, 0.5529, 0.7154, 0.9639,\n",
      "        0.1820, 0.8290, 0.2574, 0.9156, 0.3999, 0.8207, 1.5028, 1.0780, 0.4357,\n",
      "        0.9100, 0.5776, 0.3398, 1.3789, 1.2600, 0.4667, 0.2201, 1.1062, 0.9138,\n",
      "        0.6923, 0.7896, 1.2784, 1.2752, 0.4931, 0.2728, 1.0259, 0.3496, 1.5651,\n",
      "        0.6855, 1.2379, 0.8710, 0.2597, 0.2870, 0.5415, 0.5873, 0.2418, 0.3206,\n",
      "        1.2043, 0.3083, 0.2332, 0.5875, 0.4706, 0.4580, 0.7033, 0.5498, 0.2719,\n",
      "        0.6502, 1.3511, 0.9439, 0.5200, 1.3955, 1.4382, 1.1582, 0.7971, 0.6217,\n",
      "        0.4814, 1.3014, 0.3319, 0.6314])), ('feature_layers.8.num_batches_tracked', tensor(2)), ('feature_layers.10.weight', tensor([[[[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0312,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0312],\n",
      "          [-0.0312, -0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0312, -0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]]]])), ('feature_layers.10.bias', tensor([ 0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0312,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0312,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,\n",
      "        -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0312,  0.0000, -0.0312, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0312, -0.0312,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0312,  0.0000,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0312, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000])), ('feature_layers.11.weight', tensor([0.9964, 0.9998, 1.0033, 1.0018, 0.9978, 1.0015, 0.9986, 1.0014, 0.9964,\n",
      "        0.9983, 0.9966, 1.0012, 1.0018, 1.0016, 0.9980, 1.0021, 1.0002, 1.0034,\n",
      "        1.0015, 1.0014, 1.0018, 0.9985, 0.9986, 1.0003, 0.9999, 1.0023, 0.9962,\n",
      "        0.9993, 1.0002, 1.0034, 0.9978, 1.0036, 1.0021, 0.9968, 0.9986, 1.0000,\n",
      "        1.0000, 1.0037, 0.9996, 0.9967, 0.9965, 1.0010, 0.9967, 1.0036, 0.9987,\n",
      "        1.0022, 0.9996, 1.0035, 1.0003, 1.0015, 0.9965, 1.0013, 0.9998, 1.0030,\n",
      "        0.9986, 0.9962, 0.9965, 1.0004, 0.9999, 0.9966, 1.0015, 1.0001, 0.9984,\n",
      "        1.0000, 1.0020, 0.9963, 0.9988, 0.9985, 1.0012, 1.0002, 1.0015, 0.9983,\n",
      "        0.9985, 1.0003, 1.0004, 0.9988, 1.0001, 1.0010, 0.9976, 1.0022, 0.9966,\n",
      "        1.0013, 1.0002, 0.9988, 0.9992, 1.0002, 0.9998, 1.0002, 1.0012, 0.9985,\n",
      "        0.9962, 0.9999, 1.0029, 0.9968, 0.9988, 1.0033, 0.9988, 0.9996, 0.9966,\n",
      "        0.9984, 1.0016, 0.9965, 1.0022, 1.0003, 0.9965, 0.9982, 1.0005, 0.9964,\n",
      "        1.0016, 0.9965, 0.9965, 1.0003, 1.0032, 0.9983, 0.9985, 1.0035, 0.9964,\n",
      "        0.9965, 1.0036, 0.9964, 0.9994, 0.9965, 0.9983, 0.9977, 0.9983, 1.0034,\n",
      "        0.9988, 1.0015, 0.9999, 1.0018, 0.9981, 0.9980, 0.9998, 1.0016, 1.0003,\n",
      "        0.9978, 0.9964, 0.9966, 0.9992, 1.0030, 1.0020, 1.0000, 0.9966, 1.0000,\n",
      "        1.0011, 0.9992, 0.9998, 0.9964, 0.9963, 1.0009, 0.9978, 1.0035, 0.9965,\n",
      "        0.9999, 1.0039, 0.9983, 1.0017, 1.0037, 0.9968, 1.0001, 1.0035, 0.9965,\n",
      "        0.9987, 1.0016, 0.9966, 1.0001, 0.9983, 1.0035, 1.0013, 0.9998, 0.9969,\n",
      "        0.9999, 0.9983, 1.0027, 1.0035, 0.9984, 0.9984, 0.9984, 0.9985, 0.9993,\n",
      "        1.0011, 0.9967, 0.9983, 1.0016, 1.0025, 1.0014, 0.9966, 0.9980, 1.0001,\n",
      "        0.9964, 0.9986, 0.9965, 0.9965, 0.9999, 1.0016, 0.9979, 0.9964, 1.0025,\n",
      "        0.9986, 0.9965, 1.0016, 1.0036, 1.0011, 1.0014, 1.0031, 1.0036, 1.0018,\n",
      "        1.0038, 0.9990, 0.9983, 0.9999, 0.9964, 1.0019, 1.0036, 0.9965, 0.9964,\n",
      "        0.9981, 0.9965, 0.9966, 1.0015, 1.0025, 0.9987, 0.9964, 0.9998, 1.0036,\n",
      "        0.9996, 0.9993, 0.9985, 0.9981, 0.9996, 1.0034, 0.9995, 1.0017, 0.9962,\n",
      "        0.9964, 0.9998, 0.9965, 1.0036, 0.9984, 1.0035, 0.9985, 0.9963, 0.9964,\n",
      "        0.9989, 0.9964, 1.0013, 0.9963, 0.9981, 0.9985, 0.9986, 1.0036, 1.0010,\n",
      "        1.0019, 1.0015, 0.9986, 1.0000])), ('feature_layers.11.bias', tensor([-1.5633e-03, -3.6228e-03, -8.3759e-04, -1.6124e-03, -2.4046e-03,\n",
      "        -2.4023e-03, -1.3771e-03, -3.7955e-03, -3.7415e-03, -3.5384e-03,\n",
      "        -3.4456e-03, -2.3214e-03, -3.6984e-03, -1.4596e-04, -2.3371e-03,\n",
      "         2.0366e-03,  7.2872e-04, -8.8527e-05, -2.1686e-03, -3.7657e-03,\n",
      "        -3.7142e-03, -3.5728e-03, -1.3998e-03, -1.5418e-03, -3.6334e-03,\n",
      "        -1.5295e-03, -1.6612e-03, -2.9012e-04, -3.7630e-03, -3.7812e-03,\n",
      "        -4.4640e-05, -3.7245e-03, -3.7828e-03, -4.3058e-04, -1.2877e-03,\n",
      "        -5.0557e-06, -2.1689e-03, -1.0782e-04, -3.8113e-03, -1.0379e-03,\n",
      "        -1.4648e-03, -3.7068e-03, -1.3732e-03, -1.6411e-03, -1.3969e-03,\n",
      "        -1.6329e-03, -1.3366e-03, -1.5691e-05,  5.2205e-05, -3.7140e-03,\n",
      "        -3.5951e-03, -1.7025e-03, -2.1288e-03, -1.1703e-03, -1.7039e-03,\n",
      "        -3.4541e-03, -1.4251e-03,  1.4497e-04, -8.1130e-05, -1.4740e-03,\n",
      "        -3.6513e-03, -2.0948e-03, -3.6090e-03,  1.7902e-04, -8.3334e-04,\n",
      "        -3.5890e-03, -1.6874e-03, -1.6255e-03, -2.2998e-03, -1.5900e-03,\n",
      "        -3.8604e-03, -3.7146e-03, -1.5871e-03, -3.2634e-03, -3.7301e-03,\n",
      "         1.3578e-04, -3.7087e-03, -1.2055e-04, -1.4101e-03, -1.6280e-03,\n",
      "        -1.9428e-03, -3.7124e-03, -1.5115e-03, -1.2424e-03, -1.3095e-03,\n",
      "         1.9252e-04, -3.7697e-03, -2.2251e-03, -2.2752e-03, -1.4633e-03,\n",
      "        -3.7926e-03, -3.6387e-03, -1.6893e-03, -3.3939e-03, -1.4417e-03,\n",
      "        -1.5745e-03, -3.4908e-03, -1.7051e-03, -1.4016e-03, -1.6476e-03,\n",
      "        -3.8194e-03, -3.5128e-03, -1.6035e-03, -2.0286e-03, -3.6062e-03,\n",
      "        -3.7780e-03, -2.5356e-03, -1.6735e-03, -2.4154e-03, -3.5641e-03,\n",
      "        -3.3754e-03, -2.1425e-03, -3.6835e-03,  8.6434e-05,  9.1389e-05,\n",
      "        -2.2525e-03, -3.6894e-03, -3.7198e-03, -1.6468e-03, -3.7769e-03,\n",
      "        -3.8021e-03, -3.6396e-03, -1.6905e-03, -2.1550e-03, -1.5557e-03,\n",
      "        -3.5787e-05, -1.0709e-05, -2.2937e-03, -1.4514e-03, -1.6324e-03,\n",
      "        -7.4419e-04, -3.0864e-03, -1.6733e-03, -1.1950e-04, -6.6656e-05,\n",
      "        -3.5948e-03, -3.5558e-03, -3.3854e-03, -1.9296e-03, -3.7117e-03,\n",
      "        -8.4237e-05, -3.6841e-03, -3.6311e-03, -1.6167e-03, -1.1726e-03,\n",
      "        -3.6711e-03, -3.5979e-03, -1.5610e-03, -1.6340e-03,  2.7869e-04,\n",
      "        -1.6213e-03, -2.2180e-03, -3.5398e-03, -3.4332e-03, -3.7604e-03,\n",
      "        -1.6299e-03, -1.6983e-03, -8.6217e-05, -1.3610e-03, -1.7290e-03,\n",
      "        -1.5153e-03, -2.7874e-03, -3.5389e-03, -2.1748e-03, -3.4044e-03,\n",
      "        -1.6533e-03, -1.0023e-07, -1.6953e-03, -3.7127e-03, -1.5986e-03,\n",
      "        -3.5335e-03, -3.6977e-03, -3.7903e-03, -8.9831e-05, -1.4622e-04,\n",
      "        -1.6613e-03, -1.4712e-03, -3.6987e-03, -3.6048e-03, -9.3891e-04,\n",
      "        -1.7285e-03, -3.5561e-03, -2.1636e-03, -1.7372e-04, -3.6767e-03,\n",
      "        -3.9394e-03, -3.6799e-03, -3.6788e-03, -1.4412e-03, -1.4552e-03,\n",
      "        -1.4995e-03, -3.6237e-03, -3.5660e-03, -3.8528e-03, -3.7311e-03,\n",
      "        -2.1881e-04, -1.6021e-03, -1.6512e-03, -1.2965e-03, -3.4826e-03,\n",
      "        -1.8097e-03, -1.5445e-03, -2.3840e-03, -3.7041e-03, -1.5854e-03,\n",
      "         5.5452e-05, -1.6826e-03, -1.6527e-03, -3.7054e-03, -3.7058e-03,\n",
      "        -3.7315e-03, -3.6425e-03, -1.3346e-03, -1.6324e-03, -3.5634e-03,\n",
      "        -3.4036e-03, -2.2943e-03, -1.3872e-03, -1.2631e-03, -3.8360e-03,\n",
      "        -1.6591e-03, -1.6299e-03, -3.7959e-03, -1.7664e-04, -1.6680e-03,\n",
      "        -3.6894e-03, -2.7596e-03, -1.5856e-03, -2.0797e-03, -1.6480e-03,\n",
      "        -3.6810e-03, -1.6757e-03, -3.8310e-03, -1.6348e-03, -3.6534e-03,\n",
      "        -3.7553e-03, -1.4846e-03, -2.2408e-03, -1.7016e-03, -1.0719e-03,\n",
      "        -5.1238e-05, -3.7643e-03, -1.9863e-03, -3.7673e-03, -3.5818e-03,\n",
      "        -3.8832e-03, -3.7081e-03, -2.1011e-03, -1.2738e-03, -3.5804e-03,\n",
      "        -1.6653e-03, -1.6026e-03, -1.6964e-03, -2.2767e-03, -1.2815e-03,\n",
      "        -3.6572e-03])), ('feature_layers.11.running_mean', tensor([-0.1625,  1.3107,  0.9473,  1.2906,  0.8759,  1.0840, -0.0344,  1.5772,\n",
      "         1.0505,  0.5385, -0.5196,  1.0594,  1.7082,  0.7479,  1.6490,  0.7090,\n",
      "         1.3066,  0.8422,  1.3096,  1.7640,  0.6206, -0.0895,  0.1684,  1.4908,\n",
      "         1.1753,  1.1849,  0.3011, -0.9284,  1.5186,  1.0022,  0.3603,  0.8705,\n",
      "         1.0001,  0.6899,  1.0587, -1.4934,  1.4319,  1.4432,  1.6797, -0.8143,\n",
      "        -0.8565,  1.1592,  1.2372,  0.6685,  1.4222,  1.4165,  1.2631,  1.0852,\n",
      "         1.6096,  0.9390, -0.9352,  1.3817,  1.6263,  1.3540,  0.6386,  1.0079,\n",
      "         0.0693,  1.3193,  1.1341,  1.0213,  1.1313,  1.3554, -1.1166,  1.0749,\n",
      "         1.2212,  0.3092,  0.4484,  1.0010,  1.2216,  1.6959,  0.8423,  1.1921,\n",
      "         0.0349,  1.3117,  1.3001,  0.8157,  1.1441,  0.9218,  1.8337,  0.7890,\n",
      "        -0.2448,  1.1986,  1.3571, -0.8920,  1.7733, -0.6974,  1.5957,  1.4347,\n",
      "         1.7261,  1.3421,  0.5457,  1.2297,  1.3403,  0.8753,  0.7011,  1.0890,\n",
      "         0.5667,  1.2507, -0.7446,  1.5285,  1.4671,  0.5624,  1.2450,  1.2078,\n",
      "         1.2138,  0.8698,  1.1853,  1.0436,  0.8257,  1.3115,  0.3404,  1.2446,\n",
      "         0.8684,  0.4244,  1.4094,  0.9451,  0.4592, -0.1467,  0.7292,  0.6783,\n",
      "         1.3543,  1.3644,  1.0344,  1.3793, -0.0688,  1.5094,  0.3044,  1.0439,\n",
      "         1.3422,  1.1228,  1.6271,  0.8062,  1.0034,  1.3664,  1.8053, -0.2148,\n",
      "         0.2957, -0.0679,  0.7466,  1.0390,  1.2733,  0.9737,  1.0005,  1.7811,\n",
      "         1.6542,  1.2038,  0.9213,  0.9270, -0.3019,  1.7905,  1.2982,  1.0806,\n",
      "         0.5144,  1.6182,  1.3849,  0.7664,  1.2444,  0.9541, -0.1212,  1.9335,\n",
      "         0.5581, -0.7515,  1.4662,  0.8567, -1.2266,  0.9831,  0.4607,  1.7708,\n",
      "         0.9016,  1.2035,  0.5075,  1.1392,  1.9459,  0.9514,  1.0723,  1.5738,\n",
      "         0.7917,  0.9634,  0.9654,  0.8392,  1.4169,  0.5029,  1.5677,  0.6547,\n",
      "         0.7928,  0.8398,  1.2331,  1.2815,  1.1194,  0.7573,  1.4046, -0.8467,\n",
      "         1.4026,  0.8373,  1.7718,  1.4232,  0.5076,  1.0855,  1.1868,  0.0376,\n",
      "         1.0226,  0.5754,  0.9573,  0.8454,  1.1031,  0.9768,  1.2595,  0.8510,\n",
      "         0.6360, -0.5816,  0.8079, -0.8078,  1.0768,  1.3124, -0.4380, -0.0507,\n",
      "         1.2080, -0.3367, -1.0844,  0.9996,  1.5381,  0.5697,  0.9851,  1.4207,\n",
      "         1.8667,  1.1181, -1.5543,  0.9828,  0.8110,  0.8402,  0.9632,  1.1268,\n",
      "         0.8480,  0.0233,  1.5679,  1.4040, -0.7870,  1.3140,  1.2477,  1.1351,\n",
      "         0.3626,  0.9261, -0.8085,  1.3463,  0.4651,  0.8583, -0.6762,  1.5688,\n",
      "        -0.2729,  1.6728,  0.7235,  0.9302,  1.3146,  1.5982, -1.3085,  1.1881])), ('feature_layers.11.running_var', tensor([0.9555, 1.8396, 3.2328, 4.6773, 3.0872, 3.4280, 0.9519, 2.8640, 3.9343,\n",
      "        0.8982, 1.7172, 3.6960, 6.8693, 2.7875, 4.4345, 1.6960, 3.2936, 2.9504,\n",
      "        2.8907, 4.4655, 1.7060, 0.6127, 1.3931, 4.8904, 1.7105, 3.6454, 0.2343,\n",
      "        3.1721, 3.6934, 3.7964, 0.4344, 2.2769, 4.1473, 0.9306, 1.1431, 6.0296,\n",
      "        4.9105, 3.3898, 5.1160, 1.7887, 0.6318, 5.7567, 2.2312, 2.2789, 4.4838,\n",
      "        4.6759, 2.3561, 2.2181, 5.2363, 2.7199, 1.1206, 4.2696, 5.5743, 3.8345,\n",
      "        1.4813, 1.8604, 0.6352, 3.4985, 3.1106, 2.1853, 2.7655, 3.6237, 2.2611,\n",
      "        1.7328, 3.8667, 1.0437, 1.2364, 2.8492, 3.2104, 3.9435, 3.0050, 3.3134,\n",
      "        0.7812, 4.2360, 3.8472, 1.6718, 2.9479, 3.1114, 3.7615, 2.6721, 0.8396,\n",
      "        3.5357, 4.9094, 3.6268, 5.1810, 2.9488, 3.6470, 4.6285, 5.0522, 3.4496,\n",
      "        1.4838, 3.3252, 3.7898, 3.4330, 2.2421, 3.7626, 1.5626, 2.8494, 1.1172,\n",
      "        3.8932, 4.0128, 1.2898, 2.5962, 2.7879, 2.1472, 2.7759, 4.1397, 2.9103,\n",
      "        1.9496, 3.8749, 1.9283, 2.9692, 2.6129, 0.6367, 3.4007, 2.3853, 2.2486,\n",
      "        0.3111, 3.1385, 3.0543, 4.3306, 2.9297, 2.3421, 1.4271, 0.4469, 4.7234,\n",
      "        0.4641, 3.4906, 4.1129, 4.1382, 3.8576, 0.7731, 2.5568, 2.3056, 6.0571,\n",
      "        1.8361, 0.5393, 0.6392, 3.8185, 1.7409, 2.8682, 3.0597, 3.4905, 5.2865,\n",
      "        4.4508, 3.6892, 4.2254, 2.7955, 1.7212, 5.1898, 3.6892, 2.1645, 2.6629,\n",
      "        5.4929, 4.6082, 1.2126, 3.4061, 2.8699, 0.7381, 5.1853, 2.3001, 1.1997,\n",
      "        5.0017, 2.0729, 2.9023, 2.8227, 1.4932, 6.0042, 4.1967, 3.6610, 0.8635,\n",
      "        4.3391, 6.5729, 2.9514, 3.2507, 4.0332, 0.7669, 2.8036, 3.7465, 1.0392,\n",
      "        3.9350, 2.0599, 3.2015, 2.0214, 2.2333, 2.1548, 4.0147, 5.2795, 3.1289,\n",
      "        1.4728, 3.1012, 0.8714, 3.6214, 2.1355, 4.9082, 3.2581, 3.0756, 3.2290,\n",
      "        2.5978, 0.4408, 2.3558, 1.6400, 3.3341, 3.0038, 4.8000, 3.2776, 4.3646,\n",
      "        2.7391, 0.6947, 0.7009, 2.3835, 1.5208, 2.7344, 3.5648, 1.6288, 0.6564,\n",
      "        2.7109, 1.5853, 3.8092, 3.1221, 4.6801, 1.7674, 3.7073, 5.5971, 6.3689,\n",
      "        2.3000, 6.3298, 3.9084, 2.1990, 2.9968, 3.3400, 3.2458, 2.6384, 0.5439,\n",
      "        4.1139, 4.2129, 2.3010, 3.7680, 4.0018, 2.5108, 0.5240, 2.4489, 0.8378,\n",
      "        5.0841, 1.6064, 2.4866, 1.8854, 4.2362, 1.6609, 4.8373, 1.7877, 2.6000,\n",
      "        3.1330, 5.6728, 4.4202, 3.9126])), ('feature_layers.11.num_batches_tracked', tensor(2)), ('feature_layers.14.weight', tensor([[[[ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0312, -0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0312,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0312,  0.0312],\n",
      "          [ 0.0000, -0.0312, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0312,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0312,  0.0000],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312, -0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0312, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0312,  0.0000, -0.0312],\n",
      "          [-0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312, -0.0312,  0.0000]]]])), ('feature_layers.14.bias', tensor([ 0.0000,  0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0312, -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0312, -0.0312,\n",
      "         0.0000, -0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0312, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0312,  0.0000, -0.0312,  0.0000, -0.0312, -0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0312,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "        -0.0312, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312, -0.0312,\n",
      "         0.0000,  0.0312,  0.0312,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0312,  0.0000,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0000,  0.0312, -0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0312, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0312, -0.0312, -0.0312,  0.0000, -0.0312,\n",
      "         0.0000,  0.0312,  0.0000,  0.0000, -0.0312, -0.0312,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000, -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "        -0.0312,  0.0000,  0.0000, -0.0312,  0.0312,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0312,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0312,  0.0312,  0.0312,  0.0000,  0.0312, -0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0312, -0.0312,  0.0000,  0.0000,\n",
      "         0.0000, -0.0312,  0.0000,  0.0312,  0.0000,  0.0000, -0.0312,  0.0312,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0312,  0.0000,  0.0000, -0.0312,\n",
      "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312, -0.0312,\n",
      "         0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0312,\n",
      "         0.0000,  0.0312,  0.0000, -0.0312,  0.0000,  0.0000,  0.0312,  0.0000])), ('feature_layers.15.weight', tensor([0.9963, 1.0035, 1.0015, 1.0034, 0.9998, 0.9984, 0.9998, 1.0000, 1.0014,\n",
      "        1.0036, 0.9968, 1.0016, 1.0005, 1.0023, 0.9989, 0.9979, 1.0034, 1.0033,\n",
      "        0.9984, 0.9980, 0.9976, 1.0000, 1.0013, 0.9993, 1.0023, 0.9985, 1.0003,\n",
      "        1.0000, 0.9962, 0.9962, 0.9963, 0.9989, 0.9983, 0.9985, 1.0005, 0.9983,\n",
      "        0.9968, 1.0000, 0.9984, 0.9984, 0.9984, 0.9998, 0.9999, 0.9980, 0.9981,\n",
      "        1.0003, 1.0035, 1.0000, 0.9984, 1.0014, 1.0000, 1.0015, 1.0034, 0.9963,\n",
      "        0.9968, 0.9979, 1.0000, 0.9980, 0.9963, 0.9989, 0.9983, 0.9988, 0.9984,\n",
      "        0.9999, 1.0021, 0.9965, 1.0002, 1.0023, 0.9963, 0.9985, 1.0009, 1.0011,\n",
      "        1.0023, 0.9981, 1.0014, 1.0034, 0.9963, 0.9977, 0.9965, 1.0015, 1.0002,\n",
      "        0.9984, 1.0034, 0.9992, 1.0001, 0.9984, 1.0001, 0.9985, 1.0020, 0.9983,\n",
      "        1.0038, 1.0000, 1.0034, 0.9964, 1.0034, 0.9967, 0.9976, 1.0013, 1.0014,\n",
      "        0.9985, 1.0014, 1.0016, 0.9978, 1.0035, 0.9964, 0.9982, 1.0002, 0.9998,\n",
      "        0.9994, 1.0033, 1.0011, 0.9999, 0.9965, 0.9999, 1.0022, 0.9979, 1.0023,\n",
      "        0.9965, 1.0001, 0.9984, 0.9964, 1.0039, 0.9964, 1.0019, 1.0015, 1.0004,\n",
      "        0.9987, 0.9986, 1.0021, 1.0024, 0.9963, 0.9965, 1.0023, 0.9988, 0.9990,\n",
      "        0.9962, 0.9987, 1.0015, 0.9977, 0.9988, 0.9986, 0.9992, 1.0008, 0.9989,\n",
      "        1.0013, 1.0002, 0.9986, 0.9963, 0.9999, 0.9998, 0.9992, 0.9985, 0.9965,\n",
      "        0.9967, 0.9965, 0.9967, 1.0037, 0.9998, 0.9990, 1.0035, 0.9965, 1.0006,\n",
      "        0.9996, 1.0022, 1.0039, 1.0020, 0.9984, 0.9963, 0.9990, 0.9987, 1.0001,\n",
      "        1.0003, 1.0022, 1.0000, 0.9965, 0.9964, 0.9964, 1.0012, 1.0035, 1.0017,\n",
      "        0.9963, 1.0033, 0.9999, 0.9993, 1.0014, 1.0036, 1.0002, 0.9976, 0.9985,\n",
      "        0.9978, 0.9963, 0.9983, 0.9978, 0.9989, 0.9985, 0.9963, 0.9984, 1.0021,\n",
      "        1.0035, 0.9978, 0.9963, 1.0002, 0.9984, 0.9965, 1.0000, 0.9981, 1.0034,\n",
      "        0.9964, 0.9963, 0.9961, 1.0007, 1.0037, 1.0035, 1.0021, 1.0022, 1.0034,\n",
      "        0.9973, 1.0014, 0.9985, 0.9977, 0.9964, 1.0014, 1.0038, 1.0037, 1.0001,\n",
      "        0.9963, 0.9983, 1.0014, 0.9964, 0.9964, 0.9964, 0.9985, 1.0000, 1.0035,\n",
      "        0.9999, 0.9985, 1.0001, 1.0035, 1.0035, 1.0001, 1.0035, 1.0033, 1.0014,\n",
      "        1.0034, 0.9966, 0.9992, 1.0036, 0.9980, 0.9983, 0.9963, 0.9984, 0.9965,\n",
      "        1.0013, 0.9984, 0.9999, 0.9965, 1.0016, 1.0001, 1.0035, 0.9997, 0.9964,\n",
      "        0.9980, 0.9963, 1.0015, 1.0021, 0.9964, 0.9964, 0.9986, 0.9964, 0.9965,\n",
      "        1.0001, 0.9986, 1.0035, 0.9962, 1.0002, 1.0009, 1.0036, 1.0016, 0.9983,\n",
      "        0.9985, 0.9980, 0.9965, 1.0011, 1.0038, 0.9963, 1.0013, 0.9979, 1.0015,\n",
      "        1.0020, 1.0036, 1.0036, 1.0000, 1.0022, 0.9965, 1.0014, 1.0034, 0.9999,\n",
      "        0.9984, 0.9985, 0.9986, 0.9988, 0.9964, 1.0021, 1.0021, 1.0002, 1.0034,\n",
      "        0.9983, 0.9963, 0.9985, 1.0014, 1.0002, 1.0016, 1.0022, 0.9967, 1.0000,\n",
      "        0.9984, 1.0034, 1.0002, 1.0000, 0.9963, 0.9965, 1.0013, 1.0020, 1.0033,\n",
      "        0.9965, 1.0000, 1.0035, 1.0000, 1.0015, 0.9964, 0.9964, 1.0036, 1.0005,\n",
      "        1.0015, 0.9974, 1.0034, 0.9966, 1.0001, 1.0035, 1.0032, 0.9996, 1.0024,\n",
      "        0.9967, 1.0022, 0.9963, 1.0035, 0.9977, 0.9985, 1.0000, 1.0020, 0.9984,\n",
      "        0.9983, 1.0002, 0.9964, 1.0020, 0.9983, 1.0000, 1.0013, 1.0036, 0.9987,\n",
      "        0.9963, 0.9983, 1.0021, 0.9965, 0.9980, 0.9965, 1.0024, 1.0002, 1.0006,\n",
      "        0.9999, 1.0023, 0.9963, 0.9970, 1.0034, 1.0022, 0.9983, 0.9978, 0.9983,\n",
      "        0.9985, 0.9998, 0.9984, 0.9985, 1.0003, 0.9962, 1.0035, 0.9963, 1.0037,\n",
      "        0.9986, 0.9980, 0.9986, 0.9986, 1.0035, 1.0015, 0.9967, 0.9985, 0.9984,\n",
      "        0.9980, 0.9965, 0.9985, 1.0023, 1.0038, 0.9965, 1.0036, 0.9983, 1.0014,\n",
      "        0.9985, 1.0035, 0.9966, 1.0001, 0.9998, 1.0015, 1.0001, 1.0003, 0.9970,\n",
      "        1.0035, 1.0030, 0.9981, 0.9965, 0.9972, 0.9964, 1.0023, 0.9993, 1.0001,\n",
      "        1.0022, 1.0001, 0.9965, 1.0014, 1.0016, 0.9979, 0.9965, 0.9985, 0.9964,\n",
      "        0.9979, 0.9998, 1.0016, 0.9999, 0.9985, 1.0037, 0.9979, 1.0001, 1.0012,\n",
      "        0.9985, 0.9985, 1.0035, 1.0001, 0.9978, 0.9977, 1.0034, 0.9975, 1.0006,\n",
      "        0.9969, 1.0021, 1.0022, 1.0003, 1.0016, 1.0016, 0.9985, 0.9984, 0.9985,\n",
      "        0.9986, 0.9998, 1.0022, 0.9963, 1.0036, 1.0022, 1.0000, 0.9996, 0.9964,\n",
      "        1.0021, 0.9966, 0.9984, 0.9965, 0.9963, 1.0000, 0.9999, 0.9984, 0.9977,\n",
      "        0.9996, 0.9964, 1.0012, 0.9980, 0.9984, 0.9998, 0.9966, 1.0000, 1.0033,\n",
      "        1.0034, 0.9979, 0.9963, 0.9983, 0.9967, 1.0037, 1.0035, 0.9964, 0.9962,\n",
      "        0.9964, 0.9964, 1.0021, 1.0036, 1.0022, 0.9970, 1.0027, 1.0034, 0.9984,\n",
      "        1.0015, 0.9969, 0.9964, 0.9963, 1.0016, 0.9965, 0.9992, 0.9967])), ('feature_layers.15.bias', tensor([-3.7038e-03, -1.6203e-03, -2.0519e-03, -1.8308e-04, -8.8068e-05,\n",
      "        -2.1430e-03, -2.1465e-03,  2.6807e-04, -1.4623e-03, -1.5700e-03,\n",
      "        -3.4463e-03, -3.7738e-03, -2.4242e-03, -1.6921e-03, -1.6832e-03,\n",
      "        -2.1712e-03, -1.6087e-04, -2.2349e-04, -1.5847e-03, -1.9183e-03,\n",
      "        -2.4368e-03, -1.5635e-03, -2.2366e-03, -9.1490e-04, -1.5625e-03,\n",
      "        -2.2698e-03, -9.2600e-06, -1.6798e-03, -3.8963e-03, -2.8313e-03,\n",
      "        -3.7019e-03, -2.1819e-03, -1.2838e-04, -2.3271e-03, -1.4005e-03,\n",
      "        -3.6370e-03, -3.7271e-03, -5.5690e-06, -1.6163e-03, -1.7071e-03,\n",
      "        -1.6004e-03, -1.6008e-03, -3.2440e-03, -2.1822e-03, -2.2245e-03,\n",
      "        -4.5418e-05, -1.4904e-04, -3.7788e-03, -2.0153e-03, -2.1753e-03,\n",
      "         2.0804e-04, -2.3395e-03, -1.1012e-03, -1.7300e-03, -1.4404e-03,\n",
      "        -2.0636e-03, -1.6871e-03, -1.2029e-04, -1.7047e-03, -1.4645e-03,\n",
      "        -1.6039e-03, -1.5191e-03, -3.7083e-03, -2.1050e-04, -1.6385e-03,\n",
      "        -3.7930e-03, -1.3681e-03, -3.6734e-03, -1.4907e-03, -3.5135e-03,\n",
      "        -1.3143e-03, -3.7461e-03, -1.5338e-03, -1.2114e-04, -2.2737e-03,\n",
      "         7.2808e-05, -1.6351e-03, -3.7378e-03, -3.5610e-03, -2.2145e-03,\n",
      "        -2.1329e-03, -2.6536e-05, -2.1074e-04, -3.7070e-03, -8.0281e-05,\n",
      "        -1.4943e-03, -3.7738e-03, -4.8919e-05, -1.6892e-03, -1.4920e-03,\n",
      "        -3.6675e-03,  1.5559e-06, -5.6255e-05, -3.6825e-03, -3.2597e-05,\n",
      "        -3.4290e-03, -2.2349e-03, -2.0387e-04, -2.2820e-03, -1.5078e-03,\n",
      "        -2.3399e-03, -2.4352e-03, -2.3188e-03, -1.4759e-03, -3.1531e-03,\n",
      "        -1.5741e-03, -3.7312e-03, -1.2249e-04, -6.5727e-04, -1.6466e-04,\n",
      "        -1.7887e-04, -9.4428e-05, -3.5472e-03, -8.1074e-05, -7.6927e-04,\n",
      "        -1.9525e-03, -1.5616e-03, -3.5374e-03, -3.7159e-03, -1.5543e-03,\n",
      "        -1.6040e-03,  7.0480e-04, -3.6507e-03, -1.6315e-03, -1.5734e-04,\n",
      "        -1.3958e-03, -2.2051e-03, -2.1136e-03, -1.6632e-03,  1.6204e-03,\n",
      "        -3.6680e-03, -1.6522e-03, -3.7236e-03, -3.3558e-03, -3.3970e-03,\n",
      "        -3.7593e-03, -1.5159e-03, -2.2474e-03, -2.2926e-03, -1.2139e-03,\n",
      "        -1.6460e-03, -2.3312e-03, -3.8231e-03, -3.4282e-03, -2.2613e-03,\n",
      "        -3.3470e-03, -3.7094e-03, -3.6739e-03, -1.3705e-04, -1.2289e-04,\n",
      "        -1.2676e-03, -1.4834e-03, -3.6080e-03, -3.5308e-03, -3.4954e-03,\n",
      "        -1.4918e-03, -2.6428e-05, -3.8013e-03, -1.5464e-03, -1.6898e-04,\n",
      "        -1.4683e-03, -9.5362e-05, -5.1137e-04, -1.6462e-03, -3.6810e-03,\n",
      "        -3.7542e-03, -1.5810e-03, -2.6853e-03, -1.4729e-03, -1.4212e-03,\n",
      "        -9.0027e-05, -6.5949e-05, -1.6755e-03,  7.4458e-05, -1.3315e-03,\n",
      "        -3.7358e-03, -1.4906e-03, -1.3703e-05, -2.6191e-03, -2.9042e-03,\n",
      "        -1.4854e-03, -2.1252e-04, -5.7323e-05, -3.4384e-03, -2.8700e-03,\n",
      "        -1.5380e-03, -1.5503e-03, -3.4917e-03, -1.5283e-03, -2.0929e-03,\n",
      "        -3.6893e-03, -1.6070e-03, -2.3474e-03, -2.2437e-03, -3.5604e-03,\n",
      "        -3.7193e-03, -9.2474e-04, -1.6797e-03, -7.6850e-04, -3.8839e-05,\n",
      "        -3.6510e-03, -3.7527e-03, -1.6533e-03, -1.4938e-03, -3.7443e-03,\n",
      "        -2.0742e-03, -2.2915e-03, -3.6806e-03, -3.7217e-03, -3.9351e-03,\n",
      "        -3.7607e-03, -1.2642e-04, -3.6918e-03, -1.7229e-03, -1.6855e-03,\n",
      "        -2.0016e-04, -3.0839e-03,  3.2284e-03,  1.8068e-05, -3.6154e-03,\n",
      "        -3.7133e-03, -2.2552e-03, -1.1679e-04, -1.3257e-04, -1.5517e-03,\n",
      "        -3.6388e-03, -1.5553e-03, -2.2645e-03, -3.7044e-03, -1.5762e-03,\n",
      "        -1.5129e-03, -2.2350e-03, -3.7257e-03, -1.7159e-04, -6.2582e-04,\n",
      "        -1.4130e-03, -3.6460e-03, -2.4690e-04, -8.0072e-05,  8.2665e-05,\n",
      "        -2.4555e-03, -2.1947e-03, -2.3176e-03, -1.5825e-04, -3.4989e-03,\n",
      "        -2.8866e-03, -2.1511e-03, -2.2833e-03, -2.3566e-03, -3.7871e-03,\n",
      "        -1.5905e-03, -3.5017e-03, -3.3006e-03, -1.4930e-03,  4.9629e-05,\n",
      "        -3.4844e-03, -2.3195e-04, -1.0332e-04, -1.6245e-04, -1.5452e-03,\n",
      "        -3.8570e-03, -2.0701e-03, -3.6164e-03, -1.5311e-04, -1.6352e-03,\n",
      "        -1.6069e-03, -3.6337e-03, -1.4953e-03, -3.7834e-03, -1.6109e-03,\n",
      "         3.6897e-06, -1.5072e-03,  2.3573e-03, -2.3208e-03, -1.5891e-03,\n",
      "         1.1227e-03, -1.3997e-04, -2.1906e-03, -1.7068e-03, -1.5951e-03,\n",
      "        -2.1666e-03, -3.4716e-03, -1.5889e-03, -2.8723e-04, -3.6918e-03,\n",
      "        -1.6483e-03, -3.7739e-03, -2.2689e-03, -3.8025e-03, -1.4042e-04,\n",
      "        -1.4971e-03, -3.7212e-03, -8.8763e-04, -3.5937e-03, -2.3470e-03,\n",
      "        -2.2485e-04, -1.4660e-03, -1.5934e-03, -1.6517e-03, -1.5194e-03,\n",
      "        -1.4708e-03, -3.6909e-03,  1.7480e-03, -3.7459e-03, -1.7210e-03,\n",
      "        -6.9145e-05, -1.4925e-03, -3.6193e-03,  5.1978e-06, -2.5439e-03,\n",
      "        -3.6401e-03, -1.0659e-03, -3.6474e-03, -3.5764e-03, -3.7076e-03,\n",
      "        -1.5427e-03, -2.2014e-04,  9.8484e-04, -3.6588e-03, -3.7322e-03,\n",
      "        -1.6337e-03, -2.2931e-03, -1.5722e-03, -2.2278e-03, -1.4324e-03,\n",
      "        -2.0516e-03, -6.3879e-05, -8.4225e-05,  8.4346e-04, -3.6704e-03,\n",
      "        -3.6501e-03, -1.3028e-04,  1.1767e-04, -2.2565e-03, -2.2829e-04,\n",
      "        -3.7385e-03, -1.4660e-03, -3.7200e-03, -2.5342e-03, -2.4480e-04,\n",
      "        -5.9339e-04, -1.5406e-03, -3.6761e-03, -1.6950e-03, -3.7234e-03,\n",
      "        -2.2511e-03, -2.0812e-03, -3.5432e-03, -3.7595e-03, -3.6610e-03,\n",
      "        -2.3396e-03, -1.6797e-03, -1.6771e-03, -1.5413e-03, -1.6718e-03,\n",
      "        -1.5804e-03, -3.6921e-03, -2.7656e-03, -1.3263e-04, -1.4965e-03,\n",
      "        -3.8861e-03, -3.8305e-03, -1.6340e-03, -1.4434e-03, -1.0014e-04,\n",
      "        -3.5231e-03, -1.5613e-03, -2.0141e-03, -2.8322e-03, -9.4251e-05,\n",
      "        -1.5247e-03, -3.7364e-03, -3.6104e-03, -2.1894e-03, -2.6515e-04,\n",
      "        -1.6644e-03, -3.7367e-03, -1.8702e-03, -1.2294e-03, -1.2732e-04,\n",
      "         1.5759e-03, -1.3438e-03, -1.1279e-04, -3.7627e-03, -2.2824e-03,\n",
      "        -3.7606e-03, -5.9897e-05, -1.5216e-03, -1.0355e-04, -1.4426e-03,\n",
      "        -1.3968e-03, -1.6621e-04, -1.6916e-04, -1.4612e-03, -3.5679e-03,\n",
      "        -1.5633e-03, -3.4677e-03, -3.5825e-03, -1.5288e-03,  2.1424e-03,\n",
      "        -3.6884e-03, -1.4965e-03, -1.7329e-04, -3.7309e-03, -2.3037e-03,\n",
      "        -1.6247e-03, -1.2061e-04, -3.5789e-03, -3.6751e-03, -2.1494e-04,\n",
      "        -2.2512e-03, -1.3942e-04,  5.7202e-04, -3.6555e-03, -3.7268e-03,\n",
      "        -1.4629e-04, -2.1360e-03, -3.0561e-03, -3.3259e-03, -3.6743e-03,\n",
      "        -1.5447e-03, -1.0974e-03, -1.0298e-04, -1.6643e-03, -5.7689e-04,\n",
      "        -3.5470e-03, -1.6900e-04, -1.1765e-03, -7.8959e-05, -3.5589e-03,\n",
      "        -2.2741e-03, -3.7057e-03, -2.4098e-03, -1.1402e-03, -2.3589e-03,\n",
      "        -1.6437e-03, -1.5190e-03, -1.6253e-03, -1.2530e-04, -1.6311e-03,\n",
      "        -2.5853e-03, -3.5612e-03, -2.8824e-05, -2.1304e-04,  1.6726e-04,\n",
      "        -2.2942e-03, -4.3263e-05, -2.2772e-04, -1.3535e-03, -1.2915e-03,\n",
      "        -1.3729e-03, -1.5589e-03, -1.6345e-03, -2.0054e-03, -1.5623e-03,\n",
      "        -3.3229e-03, -1.5182e-03, -1.5344e-03, -3.5819e-03, -1.4734e-03,\n",
      "        -1.6618e-03, -1.6569e-03, -1.6721e-03, -1.2280e-04, -1.5839e-03,\n",
      "        -3.6750e-03, -3.6936e-03, -3.5709e-03, -1.6683e-03, -1.3929e-03,\n",
      "        -3.6809e-03, -1.5537e-03, -3.7470e-03, -6.3512e-05,  1.9518e-04,\n",
      "        -1.5096e-03, -2.6303e-03,  7.3766e-04, -3.4924e-03, -3.9570e-03,\n",
      "        -2.1576e-03, -2.1283e-03, -2.2405e-03, -3.4706e-03, -3.8142e-03,\n",
      "        -1.6789e-03,  2.0806e-03, -2.7590e-03, -1.6776e-03, -1.6381e-03,\n",
      "        -3.3996e-03, -3.7444e-03, -2.3995e-04, -3.6642e-03, -3.8472e-03,\n",
      "        -1.5719e-03, -3.5708e-03, -1.7107e-03, -2.3198e-03,  1.1978e-04,\n",
      "        -3.6757e-03, -1.5844e-03, -1.6981e-04, -1.4115e-03, -2.1840e-03,\n",
      "        -3.6281e-03, -3.5469e-03, -1.6188e-03,  4.8847e-05, -3.4935e-03,\n",
      "        -7.9288e-05, -3.5597e-03])), ('feature_layers.15.running_mean', tensor([-1.6184,  0.8886,  1.3422,  1.4102,  1.8119,  0.9176,  1.6526,  0.6499,\n",
      "         0.9464,  1.8832,  0.6987,  1.9138,  1.3648,  1.8885,  1.4936,  1.6215,\n",
      "         1.5427,  1.3453, -1.2270,  0.6600, -0.0273,  1.9033,  1.1013,  1.4383,\n",
      "         1.1222,  1.3773,  0.9605,  1.8293, -0.8460, -0.7323, -0.7555,  1.7246,\n",
      "         0.2671, -1.1941,  2.0052, -0.9051,  0.8166, -0.7677,  1.1195, -0.3193,\n",
      "         0.1955,  1.6828, -1.4737,  1.1411,  2.0739,  1.2228,  1.1650,  1.8457,\n",
      "         1.7309,  0.8951,  1.3373,  0.1101,  1.8303, -0.2102,  0.6842,  0.6799,\n",
      "         0.9258,  1.6643,  0.3239,  1.0518,  0.1040,  1.1836,  0.7594, -0.5522,\n",
      "         1.1639,  0.1882,  0.9426,  1.2879, -0.2851, -0.3563,  0.9879,  1.5986,\n",
      "         1.0551,  1.6532,  0.9017,  1.0535, -0.2960,  1.5805, -0.6846,  1.4632,\n",
      "         1.4432, -0.4513,  0.8597,  1.4642,  1.4499,  0.2163,  0.7479, -0.6631,\n",
      "         1.4724, -0.3145,  1.1732,  2.2038,  1.0927, -0.9001,  1.3946,  1.1371,\n",
      "         0.3339,  0.9136,  1.3662, -1.3098,  1.0436,  1.2435,  1.3675,  1.1453,\n",
      "         1.7685,  0.0684,  1.8060,  2.4073, -0.8517,  0.8735,  1.4582,  0.1069,\n",
      "        -0.6186,  0.6127,  0.9888,  0.1209,  1.2275, -1.3177,  0.9766, -0.4821,\n",
      "        -0.4818,  1.6775,  0.0470,  1.5342,  1.5884,  0.6958,  1.4944,  1.2129,\n",
      "         1.1632,  0.8516, -1.2813, -0.5121,  2.1158,  1.3612,  1.7268, -0.8748,\n",
      "         1.5121,  1.8526, -1.3065,  0.2925,  0.2279,  1.7425,  1.0552,  1.2316,\n",
      "         1.8688,  1.2341,  1.1496,  1.6131, -0.9885,  2.2294,  2.0254,  1.7596,\n",
      "         1.3922,  1.2049,  0.1364,  0.4794,  1.0065,  1.6850,  1.0383,  0.9479,\n",
      "         1.0953,  1.3102,  0.0086,  0.7247,  1.4655,  0.9213, -0.5866, -0.2043,\n",
      "         2.0885,  0.5495,  1.5300,  1.3564,  1.6472,  0.1442,  0.4377,  0.3039,\n",
      "        -0.0277,  1.4611,  1.5224,  1.0782, -0.7981,  1.3006,  1.3671,  1.2522,\n",
      "         1.0495,  1.3620,  1.4841,  0.1421,  1.7722, -0.4948, -0.9478, -0.3249,\n",
      "        -0.3820,  1.0890,  0.8004,  0.2744,  0.2099,  1.7550,  1.1509,  0.4539,\n",
      "        -1.1887,  1.1597, -0.5505,  0.9801,  1.2131,  1.7558,  0.7671, -1.2506,\n",
      "        -1.0315, -1.4935,  0.8966,  1.3406,  1.7880,  1.5315,  1.2401,  1.3569,\n",
      "         0.8463,  0.9323, -0.5363, -0.0746, -0.9994,  1.0435,  1.1774,  1.7107,\n",
      "         2.0146,  0.0678, -0.0078,  1.2904, -0.2273, -0.6814, -1.5766,  0.4407,\n",
      "         1.7983,  1.3373,  1.3657,  0.8957,  0.8803,  1.8719,  1.4026,  0.9808,\n",
      "         1.1394,  0.8148,  1.2576,  1.2887, -0.7538,  0.5491,  1.7373,  1.5227,\n",
      "        -1.8442, -0.4087, -0.3211, -0.2319,  1.4181, -1.0183,  1.0836, -1.5090,\n",
      "         1.2871,  1.0588,  1.1899,  1.8556,  0.5274,  2.0188,  1.1229,  0.8943,\n",
      "         0.5663,  0.0191, -1.1864,  1.2092, -1.1422,  1.1987,  1.3166, -0.7820,\n",
      "         2.3174,  0.0939,  1.9252, -0.0489,  1.3728,  0.8508, -0.1129,  0.5460,\n",
      "         1.8899, -0.7654,  0.7794,  1.5463,  0.5358,  0.8798,  1.2202,  0.9001,\n",
      "         0.9190,  1.3962,  1.3139,  1.3650,  1.9988,  0.9598,  0.7258,  0.7722,\n",
      "         1.0225, -0.7301,  1.3287,  0.8225,  1.6664, -0.3887,  0.9740,  1.1250,\n",
      "         2.0299,  1.4707,  0.6014, -0.0142,  0.4792,  1.1057,  1.2344,  0.7547,\n",
      "         0.7744,  0.7697,  1.4468, -0.2228,  1.4152,  1.2565,  1.1541,  0.0625,\n",
      "        -1.3929,  2.0959,  1.5194,  1.6581, -0.0671,  0.7023,  1.1389,  1.8059,\n",
      "         1.4319, -1.7825, -1.3685,  1.8005,  1.5736,  0.7973, -1.3934,  0.9606,\n",
      "         1.3272,  1.6362,  0.8507,  1.7646,  0.8074,  0.3865,  0.3748,  1.0996,\n",
      "        -1.8493,  0.8035, -0.8314,  0.3325,  1.7421,  1.7395, -0.5427, -1.0708,\n",
      "         1.9469,  0.7532,  1.3355, -0.6181,  1.5588,  1.3428,  1.2988,  1.4381,\n",
      "         0.1832,  0.5991,  1.8932,  0.9366,  1.5992,  0.9662,  1.5450,  0.6007,\n",
      "         1.4329, -0.5982,  1.4551, -0.3800,  1.0197,  1.4154,  1.7800,  0.0302,\n",
      "         1.4799,  1.1835,  0.6771,  1.0010, -0.6972, -1.7980,  1.5533, -0.0132,\n",
      "         1.2766, -1.5262,  1.5041,  0.5814,  1.5996,  0.7534,  1.1837,  1.5912,\n",
      "         0.5120,  1.4575, -1.2903, -0.8307,  1.2910, -0.9404, -0.6093,  1.8394,\n",
      "         1.1957, -1.6033,  1.3764,  0.9119,  1.3491,  0.0134,  1.5524,  0.4683,\n",
      "         1.2516, -0.9744,  1.3334,  1.9374, -0.7627,  1.5442,  1.6046,  2.3981,\n",
      "         1.1538,  0.4752,  1.4856, -0.2225,  1.2510,  1.5420,  1.7138,  1.2458,\n",
      "         2.1003,  0.6081,  1.3145,  1.8564,  0.9357,  0.0342, -1.0743,  0.6514,\n",
      "         0.1691,  1.2476,  2.1187,  0.8509, -0.6633,  1.7360,  1.4634,  1.9193,\n",
      "         0.7874, -0.4740, -0.1040,  1.5178,  0.6057,  1.4018,  0.6981,  1.5138,\n",
      "         0.9664,  1.8715,  1.4275,  1.8047,  1.8753,  1.0429,  0.9933,  1.3478,\n",
      "        -0.2461, -0.0134,  1.4925,  1.2183,  0.4539,  1.2954, -0.7704,  1.3001,\n",
      "         1.0637,  1.7749,  1.4701,  0.5680,  1.6315,  1.2556, -0.6407, -0.5499,\n",
      "         0.2473,  1.5418,  1.5170,  0.4740,  1.7563,  1.7187, -0.2666,  1.7855,\n",
      "         1.4092,  1.6076, -0.6643,  0.6012,  1.1239,  0.7912,  2.2893,  1.0422,\n",
      "        -0.4869, -0.8269,  0.7674,  1.9156,  0.8802, -2.3272, -0.5495, -0.6149,\n",
      "         0.6594,  0.8918,  1.3361,  1.7309,  1.4214,  1.2946,  1.0117,  1.2095,\n",
      "         1.2956,  0.6790,  1.3376,  0.9572,  1.2569,  0.4605,  1.2162,  0.8137])), ('feature_layers.15.running_var', tensor([11.2794,  4.3967,  8.5281,  8.2766, 13.1720,  6.3375,  7.3777,  1.5462,\n",
      "         4.8513, 15.4053,  2.7351, 10.3242, 11.7007, 14.3308, 10.1613,  9.6996,\n",
      "        10.3243,  9.1299,  5.6442,  0.8333,  1.0795, 14.4277,  5.2319,  8.9740,\n",
      "         7.7575,  7.2998,  3.5910, 10.5402,  2.6070,  2.1065,  3.5174, 10.0601,\n",
      "         0.8366,  8.3750, 13.1684,  3.5807,  4.0698,  4.0930,  4.9136,  1.3834,\n",
      "         1.4562, 11.7206,  8.4303,  5.4819, 15.0322,  6.9217,  5.9016, 13.5013,\n",
      "         9.6371,  4.9254,  5.7097,  0.2190, 11.0964,  2.4305,  5.8805,  1.0090,\n",
      "         5.9333, 11.2343,  2.3343,  6.7008,  2.2483,  4.5519,  2.4708,  2.0625,\n",
      "         6.0836,  0.6404,  3.1846,  7.3389,  2.6292,  3.0297,  4.3819, 10.3724,\n",
      "         4.3887,  9.8089,  3.7929,  4.4746,  2.1395, 12.6699,  4.3541, 11.0998,\n",
      "         8.1563,  1.6101,  5.5006,  6.4796,  7.6561,  1.3458,  2.4505,  2.1502,\n",
      "         9.8074,  2.8171,  5.2461, 19.4309,  6.3590,  3.6410,  7.0865,  5.3810,\n",
      "         0.6319,  4.8137,  8.3407, 10.4899,  6.1881,  6.8307,  7.2982,  6.1421,\n",
      "        15.8558,  0.5308, 13.5756, 19.2939,  2.4158,  6.1506,  7.5763,  1.1741,\n",
      "         1.4925,  2.2082,  9.9259,  0.7728,  4.7163,  7.5677,  4.7632,  1.8395,\n",
      "         4.4250, 11.1070,  1.0919,  7.9082, 10.1089,  2.2458,  9.9465,  6.2652,\n",
      "         4.6540,  4.2139,  8.6243,  1.8328, 13.5230,  9.5074, 11.5104,  3.7012,\n",
      "         9.9925, 11.0996,  9.2645,  2.9133,  1.4755, 14.9670,  5.8657,  7.0842,\n",
      "        11.2845, 11.1575,  6.4202, 10.8984,  5.0512, 16.2028, 10.5644, 12.1360,\n",
      "        10.3178,  4.3653,  0.5701,  2.7004,  5.6809, 11.0424,  4.4382,  4.5695,\n",
      "         5.4488,  7.3479,  1.7736,  3.3276,  9.8049,  5.6200,  2.2039,  1.0324,\n",
      "        13.6746,  1.6749,  9.8076,  7.9559, 12.3133,  1.1551,  0.8941,  1.1489,\n",
      "         1.0066, 10.1053,  8.6935,  5.6150,  4.8745,  7.4152,  5.1876,  6.1715,\n",
      "         4.6458,  7.3201,  8.5697,  1.0440, 11.1818,  2.2399,  3.5642,  2.4150,\n",
      "         2.5953,  3.4539,  4.8531,  0.9273,  0.4215, 13.5232,  6.9636,  0.7916,\n",
      "         9.0296,  7.1174,  2.8965,  6.8826,  7.3285, 11.3262,  4.2229,  6.6739,\n",
      "         4.8587, 10.8348,  4.6519,  6.8482, 13.0819,  8.6636,  7.9565,  7.4652,\n",
      "         4.4009,  4.0316,  2.8827,  0.4079,  5.0534,  5.9993,  8.5390, 11.1037,\n",
      "        15.5296,  1.4781,  0.7759,  7.2899,  0.9292,  2.7090,  7.1478,  0.5761,\n",
      "        11.3407,  5.0865,  9.7030,  2.2634,  5.7741, 10.5552,  9.2361,  4.1054,\n",
      "         7.3226,  4.7303,  9.1221,  7.7246,  4.0497,  2.8497, 11.3312,  9.7997,\n",
      "        15.0137,  2.1873,  1.2601,  1.0464,  8.9902,  5.0990,  4.3152, 10.9963,\n",
      "         7.2004,  4.9125,  7.9973,  9.9736,  3.1680,  9.4764,  7.4871,  4.0739,\n",
      "         2.5869,  0.3162,  8.2665,  7.3092,  3.8200,  3.5959,  4.6689,  2.5905,\n",
      "        18.4320,  0.8691, 14.9531,  1.2638,  7.3019,  3.9880,  1.4861,  5.2593,\n",
      "        14.1845,  3.4211,  2.2061,  7.1723,  1.0506,  3.4797,  5.3989,  4.2424,\n",
      "         4.8108,  6.2974,  8.9564,  8.7511, 14.3416,  5.8861,  5.2701,  2.3017,\n",
      "         2.2361,  3.4646,  8.4848,  4.9323,  9.6279,  2.0157,  6.3841,  6.8565,\n",
      "        16.3585,  8.1838,  1.5980,  2.3066,  1.5971,  8.3440,  4.3383,  3.1818,\n",
      "         4.5526,  8.0289,  8.6948,  1.3297,  6.2350,  8.9764,  5.4684,  0.8141,\n",
      "        10.9056, 14.6968, 12.2889, 10.8789,  0.2124,  1.5705,  5.2447,  8.5525,\n",
      "         5.8963, 15.6372,  9.3935, 13.2320,  7.8229,  3.8899,  7.4787,  6.5030,\n",
      "         5.6271, 11.2226,  3.7688, 13.8092,  3.1457,  1.6548,  2.2065,  8.1159,\n",
      "        12.2359,  2.4266,  6.5408,  0.5646, 11.9317, 14.0274,  3.6213,  7.4778,\n",
      "        10.4788,  5.8556,  8.5680,  1.6665,  9.2388,  7.8019,  6.6233, 10.0414,\n",
      "         1.3486,  1.7208, 13.1645,  3.7928, 10.9097,  4.2657,  9.9662,  4.0869,\n",
      "        10.4264,  3.5601,  9.2760,  1.0477,  3.4649,  6.3646, 12.6532,  0.4673,\n",
      "        10.4168,  6.8088,  2.6359,  4.1824,  5.7481, 12.9865,  8.4579,  0.2797,\n",
      "         7.4516,  8.0575,  7.2067,  3.6367, 10.6686,  4.6217,  5.5105, 11.8705,\n",
      "         1.9511,  7.6367,  9.3802,  4.2396,  8.5083,  6.1135,  2.2403, 16.7034,\n",
      "         8.0638,  9.0447,  8.7462,  5.5558,  6.9117,  0.7017, 11.3935,  1.0302,\n",
      "         8.7255,  5.5325,  9.4536, 14.0840,  3.1285, 10.2115, 11.3764, 19.2389,\n",
      "         5.2965,  3.2973,  9.0149,  1.5164,  8.0019,  7.4818, 12.5724,  8.0290,\n",
      "        19.5352,  1.5755, 10.5565, 11.3071,  2.9824,  0.8388,  5.9643,  1.7578,\n",
      "         0.8344,  9.5429, 16.6729,  2.5087,  3.9003, 11.0989,  9.5403, 12.0235,\n",
      "         3.1430,  2.6118,  1.2597, 12.5272,  2.9696,  9.4466,  2.2302,  8.4649,\n",
      "         3.8046, 13.5016, 11.0772, 10.9766, 11.2366,  7.7725,  4.6297, 11.4491,\n",
      "         1.6096,  1.6181,  8.1129,  6.4848,  1.6348,  4.1599,  4.5645,  7.0418,\n",
      "         5.5011, 13.1916,  9.9763,  2.6177,  9.5815,  7.3393,  3.6387,  2.9365,\n",
      "         0.8851,  8.5043, 11.7112,  1.6468, 11.6814, 12.6565,  2.3381, 12.3113,\n",
      "         5.3875, 13.4465,  1.6601,  4.4386,  6.2569,  5.7962, 17.9840,  5.6275,\n",
      "         0.7227,  4.9537,  4.7991, 14.9571,  4.3439, 20.9571,  3.8237,  3.0473,\n",
      "         2.1253,  4.2273,  8.4752, 16.5759,  8.4111,  7.6876,  4.3508,  5.3598,\n",
      "         6.2306,  1.8779,  6.5354,  3.2197,  7.6160,  1.2797,  7.3972,  2.0019])), ('feature_layers.15.num_batches_tracked', tensor(2)), ('feature_layers.17.weight', tensor([[[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0312,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0312,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0312],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0312, -0.0312,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]]])), ('feature_layers.17.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('feature_layers.18.weight', tensor([0.9984, 0.9985, 0.9965, 0.9964, 0.9965, 0.9965, 0.9985, 0.9965, 0.9965,\n",
      "        0.9965, 0.9985, 0.9983, 0.9984, 0.9985, 0.9965, 0.9985, 0.9964, 0.9984,\n",
      "        0.9985, 0.9964, 0.9965, 0.9983, 0.9965, 0.9965, 0.9965, 0.9965, 0.9985,\n",
      "        0.9964, 0.9985, 0.9984, 0.9965, 0.9965, 0.9984, 0.9985, 0.9984, 0.9985,\n",
      "        0.9985, 0.9964, 0.9965, 0.9964, 0.9984, 0.9964, 0.9964, 0.9965, 0.9984,\n",
      "        0.9985, 0.9964, 0.9985, 0.9986, 0.9965, 0.9984, 0.9984, 0.9984, 0.9985,\n",
      "        0.9985, 0.9985, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9965, 0.9985,\n",
      "        0.9985, 0.9964, 0.9965, 0.9964, 0.9985, 0.9964, 0.9984, 0.9985, 0.9965,\n",
      "        0.9965, 0.9965, 0.9983, 0.9964, 0.9964, 0.9985, 0.9984, 0.9965, 0.9983,\n",
      "        0.9964, 0.9965, 0.9985, 0.9964, 0.9964, 0.9985, 0.9985, 0.9964, 0.9965,\n",
      "        0.9985, 0.9964, 0.9964, 0.9984, 0.9965, 0.9985, 0.9985, 0.9964, 0.9964,\n",
      "        0.9965, 0.9985, 0.9964, 0.9985, 0.9984, 0.9965, 0.9984, 0.9985, 0.9964,\n",
      "        0.9985, 0.9964, 0.9985, 0.9984, 0.9985, 0.9964, 0.9984, 0.9964, 0.9964,\n",
      "        0.9964, 0.9964, 0.9985, 0.9963, 0.9984, 0.9964, 0.9985, 0.9984, 0.9985,\n",
      "        0.9985, 0.9965, 0.9985, 0.9963, 0.9965, 0.9984, 0.9985, 0.9965, 0.9965,\n",
      "        0.9985, 0.9984, 0.9984, 0.9985, 0.9964, 0.9963, 0.9964, 0.9985, 0.9964,\n",
      "        0.9964, 0.9965, 0.9985, 0.9965, 0.9984, 0.9964, 0.9985, 0.9984, 0.9984,\n",
      "        0.9964, 0.9984, 0.9985, 0.9965, 0.9984, 0.9984, 0.9964, 0.9963, 0.9985,\n",
      "        0.9965, 0.9985, 0.9964, 0.9964, 0.9984, 0.9964, 0.9964, 0.9965, 0.9965,\n",
      "        0.9964, 0.9964, 0.9965, 0.9964, 0.9984, 0.9965, 0.9983, 0.9984, 0.9965,\n",
      "        0.9985, 0.9985, 0.9985, 0.9985, 0.9964, 0.9964, 0.9985, 0.9964, 0.9964,\n",
      "        0.9984, 0.9965, 0.9984, 0.9966, 0.9964, 0.9984, 0.9985, 0.9963, 0.9984,\n",
      "        0.9965, 0.9985, 0.9965, 0.9964, 0.9984, 0.9964, 0.9985, 0.9964, 0.9965,\n",
      "        0.9984, 0.9984, 0.9985, 0.9984, 0.9985, 0.9964, 0.9985, 0.9965, 0.9984,\n",
      "        0.9964, 0.9985, 0.9985, 0.9965, 0.9964, 0.9985, 0.9984, 0.9965, 0.9985,\n",
      "        0.9985, 0.9964, 0.9964, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9965,\n",
      "        0.9985, 0.9965, 0.9984, 0.9985, 0.9964, 0.9965, 0.9964, 0.9966, 0.9985,\n",
      "        0.9964, 0.9985, 0.9964, 0.9984, 0.9964, 0.9985, 0.9964, 0.9985, 0.9964,\n",
      "        0.9984, 0.9964, 0.9985, 0.9985, 0.9984, 0.9985, 0.9984, 0.9984, 0.9965,\n",
      "        0.9963, 0.9965, 0.9965, 0.9984, 0.9985, 0.9963, 0.9985, 0.9964, 0.9965,\n",
      "        0.9984, 0.9984, 0.9964, 0.9985, 0.9963, 0.9964, 0.9964, 0.9964, 0.9984,\n",
      "        0.9965, 0.9984, 0.9985, 0.9965, 0.9985, 0.9985, 0.9965, 0.9984, 0.9965,\n",
      "        0.9964, 0.9984, 0.9985, 0.9965, 0.9985, 0.9986, 0.9964, 0.9985, 0.9985,\n",
      "        0.9964, 0.9985, 0.9984, 0.9964, 0.9965, 0.9984, 0.9984, 0.9984, 0.9964,\n",
      "        0.9965, 0.9963, 0.9963, 0.9984, 0.9964, 0.9984, 0.9984, 0.9985, 0.9965,\n",
      "        0.9965, 0.9985, 0.9985, 0.9965, 0.9964, 0.9964, 0.9984, 0.9965, 0.9964,\n",
      "        0.9964, 0.9965, 0.9963, 0.9984, 0.9984, 0.9985, 0.9965, 0.9964, 0.9964,\n",
      "        0.9984, 0.9964, 0.9984, 0.9964, 0.9965, 0.9964, 0.9965, 0.9964, 0.9985,\n",
      "        0.9964, 0.9984, 0.9984, 0.9965, 0.9985, 0.9964, 0.9965, 0.9964, 0.9964,\n",
      "        0.9984, 0.9985, 0.9963, 0.9965, 0.9964, 0.9984, 0.9986, 0.9986, 0.9985,\n",
      "        0.9964, 0.9964, 0.9984, 0.9964, 0.9964, 0.9964, 0.9984, 0.9964, 0.9985,\n",
      "        0.9964, 0.9965, 0.9964, 0.9985, 0.9965, 0.9964, 0.9964, 0.9965, 0.9985,\n",
      "        0.9985, 0.9964, 0.9984, 0.9965, 0.9985, 0.9985, 0.9964, 0.9984, 0.9964,\n",
      "        0.9963, 0.9985, 0.9964, 0.9965, 0.9964, 0.9984, 0.9984, 0.9985, 0.9985,\n",
      "        0.9985, 0.9965, 0.9964, 0.9964, 0.9983, 0.9985, 0.9984, 0.9964, 0.9985,\n",
      "        0.9985, 0.9985, 0.9964, 0.9984, 0.9965, 0.9964, 0.9964, 0.9964, 0.9965,\n",
      "        0.9964, 0.9985, 0.9984, 0.9965, 0.9964, 0.9965, 0.9985, 0.9985, 0.9965,\n",
      "        0.9965, 0.9984, 0.9984, 0.9985, 0.9985, 0.9984, 0.9965, 0.9985, 0.9984,\n",
      "        0.9985, 0.9985, 0.9965, 0.9983, 0.9964, 0.9965, 0.9983, 0.9964, 0.9965,\n",
      "        0.9964, 0.9985, 0.9985, 0.9965, 0.9985, 0.9964, 0.9985, 0.9965, 0.9985,\n",
      "        0.9985, 0.9985, 0.9965, 0.9984, 0.9963, 0.9984, 0.9964, 0.9965, 0.9964,\n",
      "        0.9985, 0.9984, 0.9965, 0.9984, 0.9964, 0.9984, 0.9965, 0.9965, 0.9963,\n",
      "        0.9985, 0.9964, 0.9964, 0.9985, 0.9985, 0.9984, 0.9964, 0.9965, 0.9963,\n",
      "        0.9984, 0.9985, 0.9984, 0.9985, 0.9984, 0.9985, 0.9983, 0.9964, 0.9964,\n",
      "        0.9964, 0.9984, 0.9984, 0.9965, 0.9964, 0.9963, 0.9964, 0.9964, 0.9965,\n",
      "        0.9965, 0.9964, 0.9965, 0.9985, 0.9965, 0.9985, 0.9964, 0.9984, 0.9964,\n",
      "        0.9985, 0.9964, 0.9964, 0.9984, 0.9964, 0.9964, 0.9985, 0.9963])), ('feature_layers.18.bias', tensor([-0.0016, -0.0015, -0.0037, -0.0036, -0.0035, -0.0035, -0.0016, -0.0035,\n",
      "        -0.0035, -0.0015, -0.0016, -0.0017, -0.0017, -0.0035, -0.0016, -0.0017,\n",
      "        -0.0016, -0.0016, -0.0015, -0.0036, -0.0036, -0.0017, -0.0035, -0.0036,\n",
      "        -0.0035, -0.0016, -0.0036, -0.0036, -0.0015, -0.0016, -0.0037, -0.0015,\n",
      "        -0.0016, -0.0015, -0.0017, -0.0016, -0.0016, -0.0016, -0.0035, -0.0037,\n",
      "        -0.0017, -0.0036, -0.0036, -0.0015, -0.0037, -0.0016, -0.0036, -0.0015,\n",
      "        -0.0035, -0.0016, -0.0016, -0.0017, -0.0037, -0.0015, -0.0015, -0.0036,\n",
      "        -0.0036, -0.0016, -0.0036, -0.0036, -0.0036, -0.0035, -0.0036, -0.0036,\n",
      "        -0.0036, -0.0035, -0.0036, -0.0016, -0.0036, -0.0017, -0.0036, -0.0036,\n",
      "        -0.0016, -0.0036, -0.0016, -0.0036, -0.0037, -0.0015, -0.0016, -0.0035,\n",
      "        -0.0017, -0.0036, -0.0035, -0.0016, -0.0037, -0.0016, -0.0015, -0.0016,\n",
      "        -0.0037, -0.0035, -0.0016, -0.0036, -0.0036, -0.0016, -0.0037, -0.0035,\n",
      "        -0.0015, -0.0036, -0.0036, -0.0036, -0.0015, -0.0036, -0.0015, -0.0016,\n",
      "        -0.0036, -0.0016, -0.0015, -0.0036, -0.0015, -0.0036, -0.0016, -0.0017,\n",
      "        -0.0016, -0.0016, -0.0016, -0.0036, -0.0036, -0.0036, -0.0035, -0.0035,\n",
      "        -0.0037, -0.0016, -0.0016, -0.0015, -0.0016, -0.0015, -0.0036, -0.0036,\n",
      "        -0.0016, -0.0037, -0.0035, -0.0015, -0.0036, -0.0036, -0.0036, -0.0016,\n",
      "        -0.0016, -0.0036, -0.0016, -0.0036, -0.0036, -0.0037, -0.0016, -0.0036,\n",
      "        -0.0036, -0.0036, -0.0015, -0.0035, -0.0016, -0.0016, -0.0015, -0.0035,\n",
      "        -0.0017, -0.0036, -0.0016, -0.0015, -0.0035, -0.0016, -0.0036, -0.0037,\n",
      "        -0.0037, -0.0016, -0.0035, -0.0016, -0.0016, -0.0036, -0.0016, -0.0036,\n",
      "        -0.0036, -0.0035, -0.0035, -0.0036, -0.0036, -0.0015, -0.0037, -0.0016,\n",
      "        -0.0036, -0.0037, -0.0016, -0.0036, -0.0016, -0.0015, -0.0036, -0.0015,\n",
      "        -0.0036, -0.0036, -0.0016, -0.0036, -0.0016, -0.0016, -0.0016, -0.0017,\n",
      "        -0.0035, -0.0017, -0.0017, -0.0016, -0.0037, -0.0017, -0.0036, -0.0015,\n",
      "        -0.0036, -0.0036, -0.0016, -0.0036, -0.0015, -0.0016, -0.0035, -0.0016,\n",
      "        -0.0016, -0.0015, -0.0016, -0.0015, -0.0016, -0.0015, -0.0035, -0.0036,\n",
      "        -0.0037, -0.0015, -0.0016, -0.0016, -0.0037, -0.0015, -0.0016, -0.0035,\n",
      "        -0.0035, -0.0036, -0.0036, -0.0036, -0.0016, -0.0016, -0.0035, -0.0035,\n",
      "        -0.0036, -0.0035, -0.0016, -0.0016, -0.0016, -0.0016, -0.0036, -0.0036,\n",
      "        -0.0037, -0.0035, -0.0015, -0.0036, -0.0015, -0.0016, -0.0015, -0.0036,\n",
      "        -0.0015, -0.0036, -0.0015, -0.0016, -0.0036, -0.0016, -0.0015, -0.0016,\n",
      "        -0.0036, -0.0015, -0.0016, -0.0016, -0.0035, -0.0037, -0.0016, -0.0036,\n",
      "        -0.0016, -0.0017, -0.0037, -0.0016, -0.0016, -0.0035, -0.0036, -0.0016,\n",
      "        -0.0036, -0.0035, -0.0037, -0.0036, -0.0036, -0.0036, -0.0017, -0.0036,\n",
      "        -0.0016, -0.0015, -0.0036, -0.0036, -0.0015, -0.0035, -0.0016, -0.0016,\n",
      "        -0.0016, -0.0016, -0.0016, -0.0015, -0.0016, -0.0015, -0.0037, -0.0035,\n",
      "        -0.0015, -0.0036, -0.0016, -0.0016, -0.0036, -0.0036, -0.0016, -0.0016,\n",
      "        -0.0036, -0.0016, -0.0036, -0.0037, -0.0037, -0.0036, -0.0036, -0.0036,\n",
      "        -0.0016, -0.0015, -0.0016, -0.0035, -0.0015, -0.0015, -0.0036, -0.0036,\n",
      "        -0.0036, -0.0016, -0.0036, -0.0035, -0.0036, -0.0035, -0.0037, -0.0016,\n",
      "        -0.0016, -0.0015, -0.0016, -0.0037, -0.0036, -0.0016, -0.0036, -0.0016,\n",
      "        -0.0016, -0.0035, -0.0036, -0.0036, -0.0036, -0.0015, -0.0036, -0.0016,\n",
      "        -0.0017, -0.0015, -0.0016, -0.0017, -0.0035, -0.0036, -0.0036, -0.0017,\n",
      "        -0.0016, -0.0037, -0.0015, -0.0036, -0.0016, -0.0015, -0.0015, -0.0016,\n",
      "        -0.0016, -0.0036, -0.0016, -0.0036, -0.0036, -0.0037, -0.0036, -0.0037,\n",
      "        -0.0015, -0.0037, -0.0035, -0.0036, -0.0016, -0.0036, -0.0037, -0.0015,\n",
      "        -0.0036, -0.0016, -0.0036, -0.0036, -0.0036, -0.0035, -0.0015, -0.0016,\n",
      "        -0.0036, -0.0037, -0.0036, -0.0037, -0.0016, -0.0036, -0.0016, -0.0036,\n",
      "        -0.0016, -0.0016, -0.0016, -0.0015, -0.0016, -0.0016, -0.0036, -0.0037,\n",
      "        -0.0017, -0.0015, -0.0017, -0.0016, -0.0016, -0.0016, -0.0015, -0.0036,\n",
      "        -0.0016, -0.0035, -0.0037, -0.0036, -0.0036, -0.0036, -0.0036, -0.0015,\n",
      "        -0.0017, -0.0036, -0.0036, -0.0017, -0.0035, -0.0015, -0.0016, -0.0036,\n",
      "        -0.0016, -0.0017, -0.0035, -0.0015, -0.0016, -0.0035, -0.0016, -0.0036,\n",
      "        -0.0015, -0.0015, -0.0015, -0.0037, -0.0036, -0.0035, -0.0017, -0.0016,\n",
      "        -0.0035, -0.0036, -0.0016, -0.0015, -0.0035, -0.0015, -0.0037, -0.0015,\n",
      "        -0.0035, -0.0035, -0.0035, -0.0017, -0.0015, -0.0016, -0.0037, -0.0016,\n",
      "        -0.0036, -0.0035, -0.0036, -0.0036, -0.0016, -0.0016, -0.0016, -0.0036,\n",
      "        -0.0037, -0.0035, -0.0036, -0.0037, -0.0016, -0.0037, -0.0036, -0.0015,\n",
      "        -0.0015, -0.0016, -0.0036, -0.0036, -0.0037, -0.0016, -0.0017, -0.0016,\n",
      "        -0.0035, -0.0015, -0.0015, -0.0017, -0.0036, -0.0037, -0.0036, -0.0016,\n",
      "        -0.0036, -0.0015, -0.0036, -0.0037, -0.0016, -0.0036, -0.0016, -0.0035,\n",
      "        -0.0036, -0.0036, -0.0017, -0.0036, -0.0016, -0.0036, -0.0016, -0.0036,\n",
      "        -0.0015, -0.0036, -0.0036, -0.0017, -0.0036, -0.0036, -0.0016, -0.0037])), ('feature_layers.18.running_mean', tensor([ 5.1610e-01,  9.8857e-02, -2.5298e-01, -1.3807e+00,  4.5015e-02,\n",
      "        -1.3889e-01, -7.9600e-01, -8.6982e-01, -9.1191e-01, -3.9990e-01,\n",
      "        -8.8110e-01, -1.3817e+00, -6.0013e-01, -9.4420e-04, -9.8808e-01,\n",
      "        -7.0050e-01, -4.4739e-02, -1.0226e+00,  1.5430e-01, -2.3974e-01,\n",
      "        -5.5107e-01, -4.3967e-02, -5.2895e-02, -6.6241e-01, -3.3031e-01,\n",
      "        -6.5336e-01, -9.2134e-01, -1.4062e-01, -6.7627e-02,  1.6018e-01,\n",
      "        -4.6379e-01,  6.5503e-02, -7.3573e-01, -7.4002e-02, -5.6060e-01,\n",
      "        -1.1641e+00, -5.5868e-01, -1.1931e+00, -1.1581e+00, -1.1181e+00,\n",
      "        -1.0076e+00, -9.4362e-01, -1.0120e+00, -5.8178e-01, -1.0955e+00,\n",
      "        -4.1051e-01, -8.2982e-01,  7.2241e-02, -6.8321e-01, -8.1924e-01,\n",
      "        -9.0806e-01, -8.2352e-01, -4.2854e-01,  1.3953e-01, -4.4898e-01,\n",
      "        -4.6957e-01, -1.4539e-02, -3.2017e-01,  3.4845e-01, -6.4698e-01,\n",
      "         2.3838e-01, -1.2694e+00, -6.1331e-01, -7.8511e-01, -7.6841e-01,\n",
      "        -8.1890e-01, -1.1233e+00, -1.1654e+00, -9.8216e-01, -6.7303e-01,\n",
      "        -4.4917e-01, -1.0820e+00,  5.5891e-02, -3.9250e-02,  3.8662e-01,\n",
      "        -1.1507e+00, -5.5264e-01, -2.3001e-01, -1.2908e+00, -2.5476e-02,\n",
      "        -1.0050e+00,  8.8475e-02,  4.3975e-01, -8.1590e-01, -1.0549e+00,\n",
      "        -1.1670e+00,  3.9713e-01, -8.1172e-01, -1.2196e+00,  1.1781e-01,\n",
      "        -6.4362e-01, -1.2938e-02, -5.9707e-01,  4.9152e-01, -6.0786e-01,\n",
      "        -1.3230e-01, -1.3376e-02, -1.1941e+00, -1.1019e+00, -5.8585e-01,\n",
      "        -1.9422e-01, -1.0573e+00,  1.8840e-01, -2.1225e-01, -1.1373e+00,\n",
      "        -1.3076e+00,  1.3128e-01, -6.0292e-01,  1.2097e-01, -1.5967e-01,\n",
      "        -6.7636e-01, -2.6794e-01, -6.4826e-01, -8.1928e-01, -1.5240e-01,\n",
      "         5.6566e-01, -1.1566e+00, -7.1135e-01, -9.5685e-01, -7.7134e-01,\n",
      "        -1.2915e+00, -8.0531e-01, -1.1466e+00,  2.8151e-02, -9.6211e-01,\n",
      "        -6.9503e-01, -6.0184e-01, -7.4658e-01, -6.1880e-01, -1.0321e+00,\n",
      "         7.3374e-02,  4.9179e-01, -4.3992e-01, -1.1057e+00, -1.9724e-01,\n",
      "        -1.1766e+00,  2.4372e-01, -7.4843e-02, -1.0747e+00, -8.3830e-01,\n",
      "         3.8333e-01, -5.6608e-01, -7.1316e-01, -2.5332e-01, -1.1601e+00,\n",
      "         3.4847e-01, -8.1166e-01, -2.2338e-02, -3.8901e-03, -1.4114e+00,\n",
      "        -6.2227e-01, -3.2109e-01, -4.1529e-01, -9.6024e-01, -1.1741e+00,\n",
      "        -5.4905e-02,  2.4773e-01,  2.4261e-01, -9.3532e-01, -6.8520e-01,\n",
      "        -9.6700e-01,  2.8961e-01,  1.7592e-01,  3.2372e-01, -1.1173e+00,\n",
      "        -1.2666e-01,  5.0497e-01, -6.3545e-01,  9.7932e-02, -1.0504e+00,\n",
      "        -8.9224e-02, -1.8893e-01, -8.4369e-01, -2.5305e-01, -8.1016e-01,\n",
      "        -8.3368e-01, -8.8540e-01, -5.9295e-01,  4.0846e-01, -5.2427e-01,\n",
      "        -4.6125e-01, -1.6396e-01, -8.2111e-01,  3.5872e-01, -7.9953e-01,\n",
      "        -1.6139e-01, -6.6873e-01, -1.0022e+00, -6.9297e-01, -1.2741e-01,\n",
      "        -8.9949e-01, -5.9200e-01, -4.1406e-01, -7.5602e-01, -1.0238e+00,\n",
      "        -8.2166e-01, -1.2428e+00, -2.1563e-01, -1.1619e+00, -7.9166e-02,\n",
      "        -7.8414e-01, -1.1794e+00,  1.3404e-01,  1.6443e-01, -2.4886e-01,\n",
      "        -6.6257e-01, -2.8409e-01, -4.0482e-01, -1.2846e+00,  3.0288e-02,\n",
      "         5.3172e-01, -5.9874e-02, -1.2645e+00, -6.6158e-01, -7.9843e-01,\n",
      "        -1.1481e+00, -8.2626e-02, -1.1109e+00,  1.2553e-02, -1.1086e+00,\n",
      "        -1.1231e+00, -5.9082e-01, -9.4561e-01,  3.9278e-02, -1.3813e-02,\n",
      "        -1.1207e+00, -9.9645e-01, -1.1357e+00, -6.3045e-01, -5.1934e-01,\n",
      "        -1.5241e-01, -9.7346e-01, -1.0283e+00,  2.3319e-01, -1.1895e+00,\n",
      "        -9.1844e-01, -1.2305e+00, -8.3971e-01, -1.0217e+00, -1.6117e-01,\n",
      "        -3.5508e-01, -6.7863e-01, -6.7313e-02,  1.4573e-01, -5.3728e-01,\n",
      "        -9.4484e-01,  8.2419e-01, -6.5360e-02, -1.0252e-02, -1.3867e+00,\n",
      "         1.1387e-01, -5.4899e-01, -7.8612e-01, -1.1716e+00, -2.6755e-01,\n",
      "         2.8103e-01, -3.8178e-01, -1.3858e-02,  1.2757e-01, -1.1795e+00,\n",
      "        -9.0288e-01, -1.2561e+00, -1.3609e+00, -4.6264e-01, -8.9237e-01,\n",
      "        -6.9588e-01, -1.3216e+00, -9.1686e-01, -1.1204e+00, -1.0613e-01,\n",
      "        -1.2913e+00,  3.9072e-01, -1.2979e+00, -3.0336e-01, -4.4724e-01,\n",
      "        -1.0340e+00,  5.4093e-02, -2.3267e-01, -1.2434e+00, -7.3899e-01,\n",
      "         4.1983e-01,  1.7353e-01, -5.6209e-01, -7.2374e-01, -5.8364e-02,\n",
      "        -1.5386e-01,  4.0689e-01, -4.2240e-01,  3.7799e-01, -9.1650e-01,\n",
      "        -7.1220e-01, -3.1734e-01, -4.9591e-01,  8.2153e-02, -4.2233e-01,\n",
      "         1.1946e-01, -1.8450e-01, -1.0276e+00, -5.4795e-01, -7.9743e-01,\n",
      "        -7.7993e-01, -8.5830e-01, -1.0566e+00, -1.1221e-01, -1.1478e+00,\n",
      "        -4.2122e-01, -6.9220e-01,  3.7127e-01, -8.2924e-01, -9.6994e-01,\n",
      "        -8.7417e-01, -7.5818e-01, -6.8871e-01, -7.8495e-01, -5.2397e-01,\n",
      "        -3.3449e-01, -3.1645e-01, -2.2770e-01, -1.0887e+00, -2.6487e-01,\n",
      "         6.2191e-01, -3.6623e-02,  3.5206e-02,  1.5165e-01, -4.8547e-01,\n",
      "        -7.8807e-01, -1.0331e+00, -9.2270e-01, -8.3571e-02, -2.7187e-01,\n",
      "        -1.1528e+00, -1.3000e+00, -1.0804e+00, -1.0261e+00, -8.1879e-01,\n",
      "        -7.0519e-01, -9.7972e-01,  7.4226e-03, -8.5633e-01, -1.1049e+00,\n",
      "        -7.4744e-01, -1.3023e-01, -1.0473e+00,  2.6192e-01,  3.6961e-01,\n",
      "        -6.8327e-01, -8.0824e-01, -2.1522e-01, -9.7145e-01, -3.6112e-01,\n",
      "        -2.8500e-01, -7.3454e-01, -8.6835e-01, -2.9663e-01,  4.9546e-02,\n",
      "        -1.1468e+00, -1.8154e-01,  1.4623e-01, -3.1871e-01, -5.1874e-01,\n",
      "        -1.1006e+00, -1.0125e+00, -1.2121e+00, -1.0404e+00, -9.2243e-01,\n",
      "        -1.2335e+00, -1.0739e+00, -1.0505e+00,  1.8202e-01, -1.0095e+00,\n",
      "        -1.2738e-02, -1.2609e+00, -9.8543e-01, -6.5189e-01, -9.1871e-01,\n",
      "         2.8585e-01, -7.9690e-01, -7.9598e-01,  2.4543e-01, -1.4477e+00,\n",
      "        -3.5936e-01,  1.9414e-01,  4.2683e-01, -5.0124e-01,  6.2115e-01,\n",
      "        -7.5992e-01, -8.1071e-01, -5.7816e-01, -4.5381e-01, -1.3477e+00,\n",
      "        -9.8745e-01, -5.6122e-02, -7.0056e-01, -1.2071e+00, -9.2717e-01,\n",
      "        -7.9858e-01, -6.7157e-01, -6.0685e-01, -8.8881e-01, -9.0077e-01,\n",
      "        -1.0515e+00,  2.0350e-01, -1.1056e+00,  1.5764e-01, -6.9886e-01,\n",
      "        -4.1080e-01, -1.4113e-01,  3.1517e-02, -1.0013e+00, -1.2223e-01,\n",
      "        -6.9698e-01, -1.1043e+00, -1.4597e-01, -1.1613e+00, -7.4395e-02,\n",
      "         1.4196e-01, -7.7546e-01, -8.2702e-01, -7.1764e-01, -7.1726e-01,\n",
      "        -1.9319e-01, -1.0945e+00, -8.8921e-01,  7.7097e-02, -1.2892e+00,\n",
      "        -6.7296e-01,  2.2763e-01, -2.9171e-01, -9.0627e-01, -1.1274e+00,\n",
      "        -1.1545e+00,  1.5362e-01,  1.7626e-01,  2.4008e-02, -9.4381e-01,\n",
      "        -1.0135e+00,  3.0708e-01, -8.3373e-01, -9.9834e-01, -9.6148e-01,\n",
      "        -1.3904e-01, -1.1106e+00, -5.0175e-01, -4.6820e-01,  3.2523e-01,\n",
      "        -2.2927e-01, -1.2674e+00,  5.4842e-01, -5.8123e-01, -8.4308e-01,\n",
      "        -1.5461e-02, -6.9388e-01, -4.3731e-01, -4.0638e-01, -6.5302e-01,\n",
      "        -1.5742e+00, -1.1255e-01, -7.4861e-01, -9.1329e-01,  2.4621e-01,\n",
      "        -5.5898e-02, -6.7111e-01, -9.1305e-01, -9.6740e-01,  9.6474e-02,\n",
      "        -1.0573e+00, -1.4010e+00, -8.2316e-01, -5.7643e-01, -6.5896e-01,\n",
      "         2.8118e-01,  1.1096e-01,  1.5248e-01, -3.7013e-01,  2.3665e-01,\n",
      "        -1.0157e+00, -1.1898e+00, -2.0769e-01, -4.1940e-01,  1.2790e-01,\n",
      "        -1.1136e-01,  1.2999e-01, -3.2025e-01, -1.2177e+00, -1.0710e+00,\n",
      "        -8.2742e-01, -2.4835e-01,  5.6631e-01,  8.8492e-03, -8.7599e-01,\n",
      "        -8.7413e-01, -5.2426e-01, -1.1672e+00, -1.0066e+00, -6.1496e-01,\n",
      "        -2.6274e-01, -1.1134e+00, -9.9142e-01, -6.5966e-01, -1.1192e+00,\n",
      "        -2.3735e-01,  9.4729e-02,  6.7799e-01, -1.1260e+00,  1.2497e-01,\n",
      "        -1.1518e+00,  3.6504e-03, -5.9034e-01, -1.0765e+00, -3.7213e-01,\n",
      "         1.7336e-01, -1.0235e+00])), ('feature_layers.18.running_var', tensor([ 4.1841,  0.2400,  0.6976, 14.3982,  0.2551,  0.3852,  5.3683,  7.7749,\n",
      "         7.3839,  1.5953,  7.8117, 12.4642,  4.5389,  0.6393,  7.0741,  5.4881,\n",
      "         0.3920,  8.6528,  0.8434,  0.6637,  2.8952,  0.2039,  0.3087,  5.9687,\n",
      "         0.9708,  6.4148,  8.8250,  0.4133,  0.2573,  0.6548,  3.5533,  1.0306,\n",
      "         5.1966,  0.4341,  2.9382,  9.5067,  2.3667, 10.9720, 10.2874,  9.0026,\n",
      "         7.7824,  7.7688,  8.6626,  4.3223,  8.8664,  2.4416,  6.7041,  0.8990,\n",
      "         4.5038,  5.7657,  8.0068,  7.2662,  2.0724,  1.1057,  3.8751,  2.9386,\n",
      "         0.2104,  1.1881,  1.3584,  5.5424,  0.5878, 11.7206,  5.0261,  6.4992,\n",
      "         7.3176,  7.7181,  9.9999, 11.9491,  9.9961,  4.9439,  0.8739,  8.6025,\n",
      "         0.2789,  0.1534,  1.2299, 12.3415,  3.8039,  0.5066, 13.6623,  0.4474,\n",
      "         8.5663,  0.3317,  1.6397,  6.0141, 10.5085,  8.5949,  1.5802,  6.6623,\n",
      "        11.6874,  0.3382,  3.6080,  0.2122,  4.9898,  2.3025,  5.6091,  0.2861,\n",
      "         0.6339,  9.7404, 10.1599,  5.2325,  0.4339, 10.5098,  0.6772,  1.4353,\n",
      "         8.7721, 11.9014,  0.6597,  5.3168,  0.4995,  1.3806,  5.3652,  1.3702,\n",
      "         6.0229,  6.2055,  0.5270,  1.9799, 10.5336,  4.9416,  8.5846,  5.6625,\n",
      "        11.5272,  5.1408,  9.3645,  0.3525,  9.6192,  4.7845,  5.2320,  6.9397,\n",
      "         2.4394,  7.2051,  0.7800,  2.3999,  0.7115, 10.2201,  0.6181, 11.3635,\n",
      "         1.2547,  0.4300,  9.2824,  8.7704,  1.5517,  2.8053,  5.3294,  0.6775,\n",
      "        10.1801,  0.9656,  8.7914,  0.2469,  0.4587, 14.4631,  5.4323,  0.6973,\n",
      "         2.1067,  8.4524, 12.0201,  0.3801,  1.1103,  1.1528,  7.5517,  4.6933,\n",
      "         8.2988,  0.7308,  0.3999,  1.4617,  9.1169,  0.3603,  2.4042,  5.7451,\n",
      "         0.4002,  8.5034,  0.4734,  0.3722,  6.1981,  0.4029,  4.6110,  7.8242,\n",
      "         9.0768,  3.8818,  1.4775,  6.1855,  2.3935,  0.4005,  7.0323,  1.0525,\n",
      "         6.0007,  0.8825,  6.9561,  9.3562,  5.3624,  0.4382,  6.0658,  3.1321,\n",
      "         0.5486,  5.6523,  8.9112,  7.3044,  9.9781,  0.1563,  9.4813,  0.9374,\n",
      "         5.9038, 10.9802,  0.4974,  0.5090,  0.3547,  6.5233,  0.5109,  2.9480,\n",
      "        13.0541,  0.4915,  3.4666,  0.3559, 12.7640,  4.8389,  5.5818, 10.3298,\n",
      "         0.4226, 10.8721,  0.4196,  9.4345,  9.7956,  3.3533,  6.5797,  0.5265,\n",
      "         1.1378,  9.9462,  7.9682,  8.6798,  4.2584,  3.9087,  0.2755,  7.4571,\n",
      "         6.7217,  1.0081, 11.4207,  6.6626,  9.8002,  5.7812,  9.1051,  0.5783,\n",
      "         2.0579,  5.5656,  0.3226,  0.1531,  3.3347, 10.8636,  3.6854,  0.7031,\n",
      "         0.5374, 13.4653,  0.5808,  4.0387,  6.1457, 10.0627,  0.9850,  1.0089,\n",
      "         2.9504,  0.5729,  0.3850, 10.5205,  8.1109, 11.9669, 11.9399,  3.3841,\n",
      "         8.6269,  5.8425, 12.0496,  6.9298, 11.8932,  0.1924, 14.3386,  1.1423,\n",
      "        10.8165,  0.4227,  2.2978,  7.1717,  0.4043,  0.3281, 13.1176,  5.1219,\n",
      "         0.9846,  0.1825,  2.5581,  4.9095,  0.1883,  0.0888,  2.8661,  2.3938,\n",
      "         1.1142,  7.8060,  7.1397,  0.5818,  2.9604,  0.4564,  2.1690,  0.7989,\n",
      "         0.4041,  8.6858,  3.8709,  5.8656,  6.3995,  6.1084,  9.3065,  0.3286,\n",
      "         8.5887,  3.7748,  4.6360,  1.2355,  4.8912,  8.7325,  8.8674,  5.9245,\n",
      "         6.2310,  6.7192,  3.6219,  0.4436,  0.8915,  2.1854,  9.4646,  0.8503,\n",
      "         4.0211,  0.3744,  0.6267,  0.3790,  0.6471,  4.9967,  7.2658,  7.4323,\n",
      "         0.4082,  0.7291, 10.2705, 11.2356,  9.5616,  6.7937,  5.7423,  4.6163,\n",
      "         7.8425,  0.1649,  7.4976,  7.8072,  6.8343,  0.6157,  7.6458,  0.5154,\n",
      "         1.2025,  5.6692,  7.0531,  0.5203,  7.8331,  1.1831,  1.0672,  7.6710,\n",
      "         7.5015,  1.3855,  0.6668,  9.5539,  0.3681,  0.4319,  0.8622,  3.2959,\n",
      "         9.1030,  9.7005, 10.9022,  7.5643,  7.2251, 10.3801,  7.9553,  8.1510,\n",
      "         1.5656,  7.8763,  0.4158, 11.4294,  7.0476,  7.0480,  7.8167,  0.6218,\n",
      "         6.7541,  3.6607,  0.5331, 14.5574,  1.4955,  0.3045,  1.5456,  1.5621,\n",
      "         3.3038,  6.3448,  7.1832,  2.9149,  3.2516, 11.6363,  7.1760,  0.3315,\n",
      "         5.5025, 10.2869,  5.9006,  5.9143,  6.1495,  5.5257,  4.8442,  7.1451,\n",
      "         8.7314,  0.4636,  8.6978,  0.1988,  6.7553,  1.8762,  0.2295,  0.3136,\n",
      "         7.3616,  0.4224,  4.3102,  8.3120,  0.2660,  8.8468,  0.3930,  0.7916,\n",
      "         4.9504,  7.7070,  5.1224,  5.9581,  0.3185,  9.4325,  5.6978,  0.3291,\n",
      "        10.7118,  5.9374,  0.4770,  0.0933,  7.9946,  8.9419, 10.1060,  0.3232,\n",
      "         0.7072,  0.5523,  7.6046,  9.0529,  0.6690,  7.2260,  8.8802,  9.0905,\n",
      "         0.4229,  9.7875,  3.6262,  1.0427,  1.0719,  0.4679, 10.4544,  1.8163,\n",
      "         0.6713,  7.7301,  0.3702,  6.1717,  0.2362,  1.9708,  3.2419, 17.1501,\n",
      "         0.2833,  4.5313,  8.5739,  0.3302,  0.4890,  4.7895,  5.4186,  7.4922,\n",
      "         0.6025, 10.9488, 14.6476,  5.8933,  2.6207,  4.2362,  0.5448,  0.5362,\n",
      "         0.1925,  1.8894,  1.0562, 10.3640, 11.2569,  1.5357,  2.8329,  0.3896,\n",
      "         0.2759,  0.3978,  0.7249,  8.5583, 10.4416,  6.2893,  1.2397,  1.3399,\n",
      "         0.2218,  7.5363,  7.5528,  1.6596, 10.6419,  9.2288,  4.1695,  1.2991,\n",
      "         9.1861,  9.1005,  3.9918, 11.0241,  0.2424,  0.1222,  3.6207,  8.5245,\n",
      "         1.7533,  9.1013,  0.3626,  4.3314, 11.7307,  2.0092,  0.8214,  7.0803])), ('feature_layers.18.num_batches_tracked', tensor(2)), ('classifier.0.weight', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])), ('classifier.0.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('classifier.2.weight', tensor([[ 0.0312, -0.0312,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0312,  0.0000,  ...,  0.0000,  0.0312, -0.0312],\n",
      "        [-0.0312, -0.0312,  0.0000,  ..., -0.0312,  0.0000, -0.0312],\n",
      "        ...,\n",
      "        [ 0.0312,  0.0312, -0.0312,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0312,  0.0000, -0.0312,  ...,  0.0312,  0.0000,  0.0000],\n",
      "        [ 0.0312,  0.0312,  0.0312,  ..., -0.0312,  0.0000,  0.0000]])), ('classifier.2.bias', tensor([ 0.0312,  0.0000,  0.0000,  ..., -0.0312,  0.0312,  0.0000])), ('last_layer.weight', tensor([[-0.0312,  0.0000, -0.0312,  ...,  0.0000, -0.0312,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0312,  ...,  0.0312,  0.0312,  0.0000],\n",
      "        [ 0.0000, -0.0312, -0.0312,  ...,  0.0000,  0.0000,  0.0312],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0312,  0.0000,  ..., -0.0312, -0.0312,  0.0312],\n",
      "        [ 0.0000,  0.0000,  0.0312,  ..., -0.0312,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0312,  0.0000,  ...,  0.0312,  0.0000,  0.0000]])), ('last_layer.bias', tensor([ 0.0312,  0.0000, -0.0312,  0.0000, -0.0312,  0.0312,  0.0000,  0.0000,\n",
      "        -0.0312,  0.0312]))])\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fbb8ed733641718b54a2c0db641ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.10000000149011612\n",
      "     test_loss_epoch         2.302914619445801\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "model_rebuilt = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None\n",
    ")\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "dummy_in = next(iter(input_generator))\n",
    "\n",
    "mg_r = MaseGraph(model_rebuilt)\n",
    "\n",
    "mg_r, _ = init_metadata_analysis_pass(mg_r, None)\n",
    "mg_r, _ = add_common_metadata_analysis_pass(mg_r, {\"dummy_in\": dummy_in})\n",
    "mg_r, _ = add_software_metadata_analysis_pass(mg_r, None)\n",
    "\n",
    "mg_r, _ = load_huffman_encoded_model(mg_r, {\"load_dir\": \"./vgg-compressed\", \"dummy_in\": dummy_in})\n",
    "\n",
    "model_rebuilt = mg_r.model\n",
    "\n",
    "print(model_rebuilt.state_dict())\n",
    "\n",
    "train_params[\"model\"] = model_rebuilt\n",
    "\n",
    "test(**train_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
