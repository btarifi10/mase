{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "# LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    "    max_batches=1\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 127   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "127       Trainable params\n",
      "0         Non-trainable params\n",
      "127       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d345a4f758349659bc05db5a8313d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cd7b2e89ee4f728575e28afc8d8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8631e74f55ea4acc8c1bd7cfadfe7da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import train\n",
    "import torch\n",
    "\n",
    "# print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "model = mg.model\n",
    "model_info = get_model_info('jsc-tiny')\n",
    "dataset_info = get_dataset_info('jsc')\n",
    "task = \"cls\"\n",
    "\n",
    "train_params = {\n",
    "    \"model\": model,\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": task,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 1,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_2\n",
      "--------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([[ 2.1387e-03,  7.5056e-02, -2.8624e-01,  1.7213e-02, -1.9997e-01,\n",
      "          1.7816e-03, -4.2284e-03,  5.1670e-02, -2.9266e-02,  1.1370e-02,\n",
      "         -3.6431e-02,  3.0126e-02,  1.4913e-01, -8.9499e-02,  3.1914e-01,\n",
      "          1.9919e-01],\n",
      "        [ 1.2857e-01,  1.0549e-01, -4.1898e-01,  4.0291e-01, -5.2149e-02,\n",
      "         -7.8776e-02, -7.8595e-02, -2.7975e-02,  8.6640e-02, -1.2171e-01,\n",
      "          2.0111e-01, -9.9952e-02,  1.1763e-01,  3.0851e-02,  2.6543e-02,\n",
      "         -1.3726e-01],\n",
      "        [-1.2600e-02,  1.4879e-02,  4.6097e-03,  1.7954e-01,  2.7007e-01,\n",
      "         -5.1302e-02,  1.7064e-01, -1.4796e-01, -1.7629e-01,  9.6660e-02,\n",
      "          1.0504e-02, -8.1087e-02, -6.5705e-02,  1.2889e-01, -4.7654e-01,\n",
      "         -2.1522e-01],\n",
      "        [ 5.4981e-05, -2.4064e-02,  2.3299e-01, -4.7142e-01,  7.0458e-02,\n",
      "         -8.1796e-03,  8.9741e-03, -7.6902e-02,  3.6819e-02,  3.9025e-02,\n",
      "          3.2290e-02, -3.0554e-02, -8.3023e-02,  8.7781e-02,  2.3660e-01,\n",
      "         -1.8829e-01],\n",
      "        [-6.8088e-02, -4.7156e-02,  3.6779e-01, -7.1508e-02,  7.7875e-02,\n",
      "         -2.8539e-02, -1.2477e-01,  1.4475e-01,  2.7701e-02,  2.3106e-02,\n",
      "         -2.0584e-01,  8.7227e-02, -8.3684e-02,  3.9336e-02, -7.5276e-02,\n",
      "         -7.6887e-03]], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # print(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"global\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.5,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg, _ = prune_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_blocks_2\n",
      "tensor([[False, False,  True, False,  True, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
      "          True,  True,  True, False, False,  True],\n",
      "        [False, False, False,  True,  True, False,  True,  True,  True,  True,\n",
      "         False,  True, False,  True,  True,  True],\n",
      "        [False, False,  True,  True, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True],\n",
      "        [False, False,  True, False, False, False,  True,  True, False, False,\n",
      "          True,  True,  True, False, False, False]])\n",
      "tensor([[False, False,  True, False,  True, False, False, False, False, False,\n",
      "         False, False,  True, False,  True,  True],\n",
      "        [False, False,  True,  True, False, False, False, False, False, False,\n",
      "          True, False, False, False, False, False],\n",
      "        [False, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         False, False, False, False,  True,  True],\n",
      "        [False, False,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True],\n",
      "        [False, False,  True, False, False, False, False, False, False, False,\n",
      "          True, False, False, False, False, False]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True],\n",
      "        [False, False,  True,  True,  True, False, False,  True, False, False,\n",
      "          True, False, False,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "          True, False,  True, False,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
      "          True, False, False,  True,  True,  True]])\n",
      "Pruned percent: 0.75\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        # pprint(mg.modules[node.target].weight)\n",
    "        pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        pprint(mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "        print(mg.modules[node.target].parametrizations['weight'][0].mask == mg.modules[node.target].parametrizations['weight'][1].mask)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        w = mg.modules[node.target].weight\n",
    "        for s in w:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: seq_blocks_2\n",
      "tensor([[-0.0000,  0.1373, -0.4103,  0.1213, -0.0665, -0.0000,  0.0000,  0.0000,\n",
      "         -0.0698,  0.0000, -0.0000,  0.0000,  0.1044, -0.0617,  0.3110,  0.2112],\n",
      "        [ 0.0896,  0.1528, -0.3329,  0.3900,  0.0669, -0.2552,  0.0713, -0.0000,\n",
      "         -0.0000,  0.1347,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.1270],\n",
      "        [-0.0000,  0.0927,  0.1679,  0.1217, -0.0000,  0.0858,  0.0000, -0.0716,\n",
      "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0687, -0.4497, -0.2138],\n",
      "        [-0.0000,  0.0000,  0.1436, -0.4103, -0.0000,  0.0689, -0.0000, -0.0000,\n",
      "          0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.2211, -0.1743],\n",
      "        [-0.0000, -0.0000,  0.3617,  0.0000,  0.0000, -0.0000, -0.2324,  0.1435,\n",
      "          0.0803, -0.1727, -0.1531,  0.1713, -0.1773,  0.0000, -0.0675,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Pruned percent: 0.5\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(f\"Layer: {node.name}\")\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        # pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        mask_2= mg.modules[node.target].parametrizations['weight'][0].mask\n",
    "        for s in mask_2:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s.nonzero().numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "\n",
    "        print(50*'-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 127   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | acc_val   | MulticlassAccuracy | 0     \n",
      "4 | acc_test  | MulticlassAccuracy | 0     \n",
      "5 | loss_val  | MeanMetric         | 0     \n",
      "6 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "127       Trainable params\n",
      "0         Non-trainable params\n",
      "127       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e0cb332ed145afbcc2018e77b620cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a803a36beb45e99970fc6085eed0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkt123/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import train\n",
    "import torch\n",
    "\n",
    "# print(isinstance(mg.model, torch.nn.Module))\n",
    "\n",
    "model = mg.model\n",
    "model_info = get_model_info('jsc-tiny')\n",
    "dataset_info = get_dataset_info('jsc')\n",
    "task = \"cls\"\n",
    "\n",
    "train_params = {\n",
    "    \"model\": model,\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": task,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 1,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_0\n",
      "--------------------------------------------------\n",
      "tensor([[-0.0000, -0.0000, -1.6369,  0.5552, -0.7419, -0.0000,  0.0000,  0.0000,\n",
      "         -0.0000,  0.0000,  0.7397, -0.0000,  0.0000,  0.0000,  0.7932,  1.3671],\n",
      "        [ 0.8332,  0.0000, -0.4090, -1.0126, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "          0.0000,  0.0000,  0.6031, -0.1658,  0.4106, -0.2976, -0.7187, -1.2277],\n",
      "        [ 0.0000,  0.0189,  0.0000, -0.1738,  0.2096, -1.7474, -0.0000, -0.3942,\n",
      "          0.0000, -0.0000,  0.0000, -0.0905,  0.3919, -0.0000,  0.0000, -1.5387],\n",
      "        [-0.0000, -0.0000,  0.2736, -0.5186,  0.0000, -1.3009, -0.0000, -0.0000,\n",
      "          0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.2842, -1.3053],\n",
      "        [-0.0000,  0.1588,  1.3117, -0.0839,  0.2535,  0.0833, -0.0000,  0.2678,\n",
      "         -0.4250, -0.1340, -0.2888,  0.2900, -0.3746,  0.2911, -0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[False, False,  True,  True,  True, False, False, False, False, False,\n",
      "          True, False, False, False,  True,  True],\n",
      "        [ True, False,  True,  True, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True],\n",
      "        [False,  True, False,  True,  True,  True, False,  True, False, False,\n",
      "         False,  True,  True, False, False,  True],\n",
      "        [False, False,  True,  True, False,  True, False, False, False, False,\n",
      "         False, False, False, False,  True,  True],\n",
      "        [False,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False]])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "# pprint(mg.meta['mase'].__dict__)\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "    if get_mase_op(node) == 'linear':\n",
    "        print(node.name)\n",
    "        print(50*'-')\n",
    "        # pprint(node.meta['mase'].parameters['common'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['data_in_0']['value'])\n",
    "        # pprint(node.meta['mase'].parameters['common']['args']['weight']['value'])\n",
    "        pprint(mg.modules[node.target].weight)\n",
    "        pprint(mg.modules[node.target].parametrizations['weight'][0].mask)\n",
    "        # pprint(node.meta['mase'].parameters['common']['results']['data_out_0']['value'])\n",
    "\n",
    "        print(50*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
