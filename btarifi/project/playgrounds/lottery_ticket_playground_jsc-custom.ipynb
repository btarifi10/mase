{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:18:08.639842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 14:18:09.819788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "model_name = \"jsc-custom\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "model_oneshot = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "model_lt = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "dummy_in = {\"x\": next(iter(data_module.train_dataloader()))[0]}\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg_base = MaseGraph(model=model_base)\n",
    "mg_oneshot = MaseGraph(model=model_oneshot)\n",
    "mg_lt = MaseGraph(model=model_lt)\n",
    "\n",
    "mg_base, _ = init_metadata_analysis_pass(mg_base, None)\n",
    "mg_base, _ = add_common_metadata_analysis_pass(mg_base, {\"dummy_in\": dummy_in})\n",
    "mg_base, _ = add_software_metadata_analysis_pass(mg_base, None)\n",
    "\n",
    "mg_oneshot, _ = init_metadata_analysis_pass(mg_oneshot, None)\n",
    "mg_oneshot, _ = add_common_metadata_analysis_pass(mg_oneshot, {\"dummy_in\": dummy_in})\n",
    "mg_oneshot, _ = add_software_metadata_analysis_pass(mg_oneshot, None)\n",
    "\n",
    "mg_lt, _ = init_metadata_analysis_pass(mg_lt, None)\n",
    "mg_lt, _ = add_common_metadata_analysis_pass(mg_lt, {\"dummy_in\": dummy_in})\n",
    "mg_lt, _ = add_software_metadata_analysis_pass(mg_lt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the VGG network and then pruning it to see final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "default_train_params = {\n",
    "    \"model_info\": model_info,\n",
    "    \"data_module\": data_module,\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"task\": \"cls\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0,\n",
    "    \"plt_trainer_args\": {\n",
    "        \"max_epochs\": 5,\n",
    "    }, \n",
    "    \"auto_requeue\": False,\n",
    "    \"save_path\": None,\n",
    "    \"visualizer\": None,\n",
    "    \"load_name\": None,\n",
    "    \"load_type\": None\n",
    "}\n",
    "\n",
    "base_train_params = copy.deepcopy(default_train_params)\n",
    "base_train_params[\"model\"] = mg_base.model\n",
    "base_train_params[\"plt_trainer_args\"][\"max_epochs\"] = 5\n",
    "\n",
    "oneshot_train_params_1 = copy.deepcopy(default_train_params)\n",
    "oneshot_train_params_1[\"model\"] = mg_oneshot.model\n",
    "oneshot_train_params_1[\"plt_trainer_args\"][\"max_epochs\"] = 1\n",
    "\n",
    "oneshot_train_params_2 = copy.deepcopy(default_train_params)\n",
    "oneshot_train_params_2[\"model\"] = mg_oneshot.model\n",
    "oneshot_train_params_2[\"plt_trainer_args\"][\"max_epochs\"] = 1\n",
    "\n",
    "lt_train_params = copy.deepcopy(default_train_params)\n",
    "lt_train_params[\"model\"] = mg_lt.model\n",
    "lt_train_params[\"plt_trainer_args\"][\"max_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.actions import test, train\n",
    "\n",
    "train(**base_train_params)\n",
    "test(**base_train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model after pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,},\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,\n",
    "    },\n",
    "}\n",
    " \n",
    "mg_base, _ = prune_transform_pass(mg_base, pass_args)\n",
    "\n",
    "base_train_params[\"model\"] = mg_base.model\n",
    "test(**base_train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One shot pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.actions import test, train\n",
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "\n",
    "# train(**oneshot_train_params_1)\n",
    "pass_args = {\n",
    "    \"weight\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" :  \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,},\n",
    "    \"activation\":{\n",
    "        \"scope\" : \"local\",\n",
    "        \"granularity\" : \"elementwise\",\n",
    "        \"method\" : \"l1-norm\",\n",
    "        \"sparsity\" : 0.7,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_oneshot.model = oneshot_train_params_1[\"model\"]\n",
    "mg_oneshot, _ = prune_transform_pass(mg_oneshot, pass_args)\n",
    "\n",
    "# oneshot_train_params_2[\"model\"] = mg_oneshot.model\n",
    "# train(**oneshot_train_params_2)\n",
    "# test(**oneshot_train_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.analysis.pruning.calculate_sparsity import add_pruning_metadata_analysis_pass\n",
    "\n",
    "\n",
    "mg_oneshot, _ = add_pruning_metadata_analysis_pass(mg_oneshot, {\"dummy_in\": dummy_in, \"add_value\": True})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_10\n",
      "{'args': {'bias': {'from': None,\n",
      "                   'precision': [32],\n",
      "                   'shape': [5],\n",
      "                   'type': 'float',\n",
      "                   'value': Parameter containing:\n",
      "tensor([-0.1997,  0.1969,  0.0932, -0.1758, -0.1422], requires_grad=True)},\n",
      "          'data_in_0': {'precision': [32],\n",
      "                        'shape': [256, 16],\n",
      "                        'torch_dtype': torch.float32,\n",
      "                        'type': 'float',\n",
      "                        'value': tensor([[0.0000, 0.0000, 0.0000,  ..., 1.3371, 3.6396, 0.0000],\n",
      "        [0.6497, 0.0000, 0.5663,  ..., 0.0400, 0.0000, 0.0000],\n",
      "        [0.5050, 0.1814, 0.0000,  ..., 0.5731, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6828, 0.4171, 0.1024,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.8731, 0.0000],\n",
      "        [0.1452, 0.0000, 0.0000,  ..., 1.9893, 2.3441, 2.0208]],\n",
      "       grad_fn=<MulBackward0>)},\n",
      "          'weight': {'from': None,\n",
      "                     'precision': [32],\n",
      "                     'shape': [5, 16],\n",
      "                     'type': 'float',\n",
      "                     'value': Parameter containing:\n",
      "tensor([[ 0.1550, -0.2203,  0.2042,  0.2348,  0.1352,  0.1455,  0.0142,  0.1096,\n",
      "         -0.1485,  0.1367, -0.1045, -0.0066,  0.0202, -0.0591,  0.1373,  0.2149],\n",
      "        [ 0.0911, -0.1152, -0.0565,  0.0923, -0.1683, -0.1278, -0.1859, -0.1583,\n",
      "         -0.1640, -0.0654,  0.1732,  0.0321, -0.1737, -0.0136,  0.1383, -0.1592],\n",
      "        [ 0.0464,  0.1197,  0.0307,  0.1941, -0.0746,  0.0352,  0.0251,  0.2353,\n",
      "          0.0118,  0.0910,  0.2122,  0.0128,  0.0131,  0.0388, -0.2062, -0.0807],\n",
      "        [ 0.1232,  0.0747, -0.1190,  0.0981,  0.1768, -0.0500,  0.1326, -0.2318,\n",
      "         -0.0140, -0.0775,  0.0084, -0.0591, -0.0511,  0.0271, -0.0695, -0.0331],\n",
      "        [ 0.1464,  0.1588, -0.1321, -0.2079, -0.2184, -0.2177,  0.1012, -0.2425,\n",
      "          0.0045,  0.2149,  0.1776, -0.1207, -0.0738,  0.1509,  0.0576,  0.1124]],\n",
      "       requires_grad=True)}},\n",
      " 'mase_op': 'linear',\n",
      " 'mase_type': 'module_related_func',\n",
      " 'results': {'data_out_0': {'precision': [32],\n",
      "                            'shape': [256, 5],\n",
      "                            'torch_dtype': torch.float32,\n",
      "                            'type': 'float',\n",
      "                            'value': tensor([[ 0.4253,  0.8908, -0.0120, -0.5702, -0.4540],\n",
      "        [ 0.1267, -0.0391,  0.2326, -0.1776, -0.2750],\n",
      "        [-0.1051,  0.0842,  0.2793, -0.1917,  0.1948],\n",
      "        ...,\n",
      "        [-0.1509,  0.1986,  0.1872, -0.0806,  0.0323],\n",
      "        [ 0.3307,  0.1352, -0.0942, -0.4634, -0.7902],\n",
      "        [ 0.3157, -0.1936, -0.4100, -0.5349,  0.2150]],\n",
      "       grad_fn=<AddmmBackward0>)}}}\n",
      "{'args': {'bias': {'stat': {}},\n",
      "          'data_in_0': {'sparsity': 0.699951171875, 'stat': {}},\n",
      "          'weight': {'mask_value': tensor([[False,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True],\n",
      "        [False, False, False, False,  True, False,  True,  True,  True, False,\n",
      "          True, False,  True, False, False,  True],\n",
      "        [False, False, False,  True, False, False, False,  True, False, False,\n",
      "          True, False, False, False,  True, False],\n",
      "        [False, False, False, False,  True, False, False,  True, False, False,\n",
      "         False, False, False, False, False, False],\n",
      "        [False,  True, False,  True,  True,  True, False,  True, False,  True,\n",
      "          True, False, False, False, False, False]]),\n",
      "                     'sparsity': 0.699999988079071,\n",
      "                     'stat': {}},\n",
      "          'weight_mask': {'value': tensor([[False, False, False,  ..., False,  True, False],\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [False,  True, False,  ..., False,  True, False],\n",
      "        ...,\n",
      "        [ True,  True, False,  ..., False, False, False],\n",
      "        [False,  True, False,  ..., False, False, False],\n",
      "        [False,  True,  True,  ..., False,  True, False]])}},\n",
      " 'results': {'data_out_0': {'stat': {}}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "for node in mg_oneshot.fx_graph.nodes:\n",
    "    if node.name == \"seq_blocks_10\" and get_mase_op(node) in ['linear', 'conv2d']:\n",
    "        print(node.name)\n",
    "        pprint(node.meta['mase'].parameters['common'])\n",
    "        pprint(node.meta['mase'].parameters['software'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.utils import get_mase_op\n",
    "\n",
    "\n",
    "for node in mg_oneshot.fx_graph.nodes:\n",
    "    if get_mase_op(node) in ['linear', \"conv2d\", \"conv1d\"]:\n",
    "        print(node.name)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        module = mg_oneshot.modules[node.target]\n",
    "        print(module.weight.numel())\n",
    "        w = module.weight\n",
    "        print(\"Num of masks: \", len(mg_oneshot.modules[node.target].parametrizations['weight']))\n",
    "\n",
    "        for s in w:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s[s.nonzero()].numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "        print(75*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lottery Ticket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.utils import get_mase_op\n",
    "import copy, torch\n",
    "from chop.actions import test, train\n",
    "from chop.passes.graph.transforms import (\n",
    "    prune_transform_pass,\n",
    ")\n",
    "\n",
    "\n",
    "def prune_lottery_ticket(mg, pass_args):\n",
    "    overall_sparsity = pass_args[\"lottery_ticket\"][\"sparsity\"]\n",
    "    num_iterations = pass_args[\"lottery_ticket\"][\"num_iterations\"]\n",
    "\n",
    "    iteration_sparsity = 1 - ((1 - overall_sparsity)**(1 / num_iterations))\n",
    "\n",
    "    data_module = MaseDataModule(\n",
    "        name=pass_args[\"config\"][\"dataset\"],\n",
    "        batch_size=pass_args[\"config\"][\"batch_size\"],\n",
    "        model_name=pass_args[\"config\"][\"model\"],\n",
    "        num_workers=0,\n",
    "    )\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup()\n",
    "\n",
    "    train_test_args = {\n",
    "        \"model\": mg.model,\n",
    "        \"model_info\": get_model_info(pass_args[\"config\"][\"model\"]),\n",
    "        \"data_module\": data_module,\n",
    "        \"dataset_info\": get_dataset_info(pass_args[\"config\"][\"dataset\"]),\n",
    "        \"task\": pass_args[\"config\"][\"task\"],\n",
    "        \"optimizer\": pass_args[\"config\"][\"optimizer\"],\n",
    "        \"learning_rate\": pass_args[\"config\"][\"learning_rate\"],\n",
    "        \"weight_decay\": pass_args[\"config\"][\"weight_decay\"],\n",
    "        \"plt_trainer_args\": {\n",
    "            \"max_epochs\": pass_args[\"config\"][\"max_epochs\"],\n",
    "        },\n",
    "        \"auto_requeue\": False,\n",
    "        \"save_path\": None,\n",
    "        \"visualizer\": None,\n",
    "        \"load_name\": None,\n",
    "        \"load_type\": None,\n",
    "    }\n",
    "\n",
    "    prune_args = {\n",
    "        \"weight\": {\n",
    "            \"scope\": pass_args[\"lottery_ticket\"][\"scope\"],\n",
    "            \"granularity\": pass_args[\"lottery_ticket\"][\"granularity\"],\n",
    "            \"method\": pass_args[\"lottery_ticket\"][\"method\"],\n",
    "            \"sparsity\": iteration_sparsity,\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"scope\": pass_args[\"lottery_ticket\"][\"scope\"],\n",
    "            \"granularity\": pass_args[\"lottery_ticket\"][\"granularity\"],\n",
    "            \"method\": pass_args[\"lottery_ticket\"][\"method\"],\n",
    "            \"sparsity\": iteration_sparsity,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "    original_w_b = {}\n",
    "\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        if get_mase_op(node) in [\"linear\", \"conv2d\", \"conv1d\"]:\n",
    "            original_w_b[node.name] = {\n",
    "                \"weight\": mg.modules[node.target].weight,\n",
    "                \"bias\": mg.modules[node.target].bias,\n",
    "                \"meta_weight\": node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"][\"value\"],\n",
    "                \"meta_bias\": node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"bias\"][\"value\"],\n",
    "            }\n",
    "            \n",
    "    for i in range(num_iterations):\n",
    "        mg, _ = prune_transform_pass(mg, prune_args)\n",
    "\n",
    "        train(**train_test_args)\n",
    "\n",
    "        # copy the weights from the original model to the pruned model\n",
    "        for node in mg.fx_graph.nodes:\n",
    "            if get_mase_op(node) in [\"linear\", \"conv2d\", \"conv1d\"]:\n",
    "                with torch.no_grad():\n",
    "                    mg.modules[node.target].weight.copy_(original_w_b[node.name]['weight'])\n",
    "                    # mg.modules[node.target].weight.copy_(original_w_b[node.name]['weight'])\n",
    "\n",
    "                    mg.modules[node.target].bias.copy_(original_w_b[node.name]['bias'])\n",
    "\n",
    "                    # update the mase metadata weights\n",
    "                    node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight\"][\"value\"] = original_w_b[node.name]['meta_weight']\n",
    "                    \n",
    "                    node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"bias\"][\"value\"] = original_w_b[node.name]['meta_bias']\n",
    "\n",
    "    train(**train_test_args)\n",
    "\n",
    "    test(**train_test_args)\n",
    "\n",
    "    return mg, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "model_lt = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "dummy_in = {\"x\": next(iter(data_module.train_dataloader()))[0]}\n",
    "\n",
    "mg_lt = MaseGraph(model=model_lt)\n",
    "\n",
    "mg_lt, _ = init_metadata_analysis_pass(mg_lt, None)\n",
    "mg_lt, _ = add_common_metadata_analysis_pass(mg_lt, {\"dummy_in\": dummy_in})\n",
    "mg_lt, _ = add_software_metadata_analysis_pass(mg_lt, None)\n",
    "\n",
    "lt_train_params['data_module'] = data_module\n",
    "lt_train_params['model'] = mg_lt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prune_lottery_ticket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m pass_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlottery_ticket\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     19\u001b[0m }\n\u001b[0;32m---> 21\u001b[0m mg_lt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprune_lottery_ticket\u001b[49m(mg_lt, pass_args)\n\u001b[1;32m     23\u001b[0m lt_train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mg_lt\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     24\u001b[0m test(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlt_train_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prune_lottery_ticket' is not defined"
     ]
    }
   ],
   "source": [
    "pass_args = {\n",
    "    \"lottery_ticket\": {\n",
    "        \"num_iterations\": 5,\n",
    "        \"scope\": \"global\",\n",
    "        \"granularity\": \"elementwise\",\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"sparsity\": 0.7\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"dataset\": \"jsc\",\n",
    "        \"model\": \"jsc-custom\",\n",
    "        \"task\": \"cls\",\n",
    "        \"batch_size\": 256,\n",
    "        \"max_epochs\": 1,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "mg_lt, _ = prune(mg_lt, pass_args)\n",
    "\n",
    "lt_train_params[\"model\"] = mg_lt.model\n",
    "test(**lt_train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_blocks_2\n",
      "512\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.6875\n",
      "---------------------------------------------------------------------------\n",
      "seq_blocks_6\n",
      "512\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.73046875\n",
      "---------------------------------------------------------------------------\n",
      "seq_blocks_10\n",
      "80\n",
      "Num of masks:  5\n",
      "Pruned percent: 0.6\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "last = []\n",
    "for node in mg_lt.fx_graph.nodes:\n",
    "    if get_mase_op(node) in ['linear', \"conv2d\", \"conv1d\"]:\n",
    "        print(node.name)\n",
    "        total_w = 0\n",
    "        pruned_w = 0\n",
    "        module = mg_lt.modules[node.target]\n",
    "        print(module.weight.numel())\n",
    "        w = module.weight\n",
    "        print(\"Num of masks: \", len(mg_lt.modules[node.target].parametrizations['weight']))\n",
    "        if node.name == \"seq_blocks_10\":\n",
    "            for mask in mg_lt.modules[node.target].parametrizations['weight']:\n",
    "                last.append(mask._buffers['mask'].detach().numpy())\n",
    "\n",
    "        for s in w:\n",
    "            total_w += s.numel()\n",
    "            pruned_w += s.numel() - s[s.nonzero()].numel()\n",
    "\n",
    "        pruned_percent = pruned_w / total_w\n",
    "        print(f\"Pruned percent: {pruned_percent}\")\n",
    "        print(75*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "---------------------------------------------------------------------------\n",
      "0.3\n",
      "---------------------------------------------------------------------------\n",
      "0.3875\n",
      "---------------------------------------------------------------------------\n",
      "0.4875\n",
      "---------------------------------------------------------------------------\n",
      "0.6\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for m in last:\n",
    "    m = m.flatten()\n",
    "    print(len(m[m==False]) / len(m))\n",
    "    print(75*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
