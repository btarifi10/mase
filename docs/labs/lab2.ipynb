{"cells":[{"cell_type":"markdown","metadata":{"id":"Oa09Had3Ldfq"},"source":["# Installing MASE (again)\n","\n","Run the block below to install MASE in the current Colab runtime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ClqAsevLdJx"},"outputs":[],"source":["git_token = \"YOUR_GIT_TOKEN\"\n","short_code = \"YOUR_SHORT_CODE\"\n","\n","# Check the current python version (It should be using Python 3.10) and update pip to the latest version.\n","!python --version\n","!python -m pip install --user --upgrade pip\n","\n","# Clone MASE from your branch (the branch must already exist)\n","!git clone -b lab1_{short_code} https://{git_token}@github.com/DeepWok/mase.git\n","\n","# Install requirements\n","!python -m pip install -r ./mase/machop/requirements.txt\n","\n","# Change working directory to machop\n","%cd ./mase/machop/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gg2xBbRmYZ1g"},"outputs":[],"source":["!./ch --help"]},{"cell_type":"markdown","metadata":{"id":"VF0krky2N4dr"},"source":["# General introduction\n","\n","In this lab, you will learn how to use the software stack of MASE. There are in total 7 tasks you would need to finish, and 1 optional task."]},{"cell_type":"markdown","metadata":{"id":"DIOZ48aaMqhV"},"source":["# Turning you network to a graph\n","\n","One specific feature of MASE is its capability to transform DL models to a computation graph using the [torch.fx](<https://pytorch.org/docs/stable/fx.html>) framework.\n"]},{"cell_type":"markdown","metadata":{"id":"cjBbOikbLJdN"},"source":["## Use the Transform functionality without CLI\n","\n","This tutorial describes how to use the MASE transform functionality for a pre-trained model."]},{"cell_type":"markdown","metadata":{"id":"j5sg0OpYLJdO"},"source":["## Import related packages and machop"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4KO86-UYLJdP"},"outputs":[],"source":["import sys\n","import logging\n","import os\n","from pathlib import Path\n","from pprint import pprint as pp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd ~/dev/advanced-deep-learning-systems/mase/machop\n","!pwd\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# figure out the correct path\n","machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n","assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n","sys.path.append(str(machop_path))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"l7BE0UToLJdQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"]}],"source":["from chop.dataset import MaseDataModule, get_dataset_info\n","from chop.tools.logger import set_logging_verbosity\n","\n","from chop.passes.graph import (\n","    save_node_meta_param_interface_pass,\n","    report_node_meta_param_analysis_pass,\n","    profile_statistics_analysis_pass,\n","    add_common_metadata_analysis_pass,\n","    init_metadata_analysis_pass,\n","    add_software_metadata_analysis_pass,\n",")\n","from chop.tools.get_input import InputGenerator\n","from chop.tools.checkpoint_load import load_model\n","from chop.ir import MaseGraph\n","\n","from chop.models import get_model_info, get_model\n","\n","set_logging_verbosity(\"info\")"]},{"cell_type":"markdown","metadata":{"id":"q35_tV4QLJdQ"},"source":["## Set up the dataset\n","\n","Here we create a `MaseDataModule` using the `jsc` dataset from lab1. Note the `MaseDataModule` also requires the name of the model you plan to use data module with. In this case it is `jsc-tiny`."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ztEzclWrLJdR"},"outputs":[],"source":["batch_size = 8\n","model_name = \"jsc-tiny\"\n","dataset_name = \"jsc\"\n","\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n",")\n","data_module.prepare_data()\n","data_module.setup()\n"]},{"cell_type":"markdown","metadata":{"id":"08-4XdNYLJdR"},"source":["## Set up the model \n","\n","Here we use the previously trained `jsc-tiny` model in lab 1 as an example."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # If you stored your model checkpoint on Google Drive, remember to mount the drive to the current runtime in order to access it\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gIU4s9CiLJdR"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-tiny_varying-epoch/software/training_ckpts/best-v5.ckpt\u001b[0m\n"]}],"source":["# üìùÔ∏è change this CHECKPOINT_PATH to the one you trained in Lab1\n","CHECKPOINT_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-tiny_varying-epoch/software/training_ckpts/best-v5.ckpt\"\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False)\n","\n","model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"]},{"cell_type":"markdown","metadata":{"id":"lrIWs8XvLJdR"},"source":["# Get a dummy data in\n","With the dataset module and model information, we can grab an input generator."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ygyzBWJyLJdR"},"outputs":[],"source":["# get the input generator\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","# a demonstration of how to feed an input value to the model\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n"]},{"cell_type":"markdown","metadata":{"id":"-sucUgAVLJdS"},"source":["## Generate a MaseGraph\n","We have two forms of passes: transform passes and analysis passes, both of them would require the model to be transferred into a MaseGraph to allow manipulation."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wSmp6oaGLJdS"},"outputs":[],"source":["# generate the mase graph and initialize node metadata\n","mg = MaseGraph(model=model)"]},{"cell_type":"markdown","metadata":{"id":"SiEehxhNLJdS"},"source":["## Running an Analysis pass\n","Analysis pass DOES NOT change the graph\n","\n","The following analysis passes are essential to prepare the graph for other passes"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"UuXo32cJLJdS"},"outputs":[],"source":["mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","mg, _ = add_software_metadata_analysis_pass(mg, None)"]},{"cell_type":"markdown","metadata":{"id":"bAE-LFypLJdS"},"source":["We will first run a simple graph analysis to understand the structure of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4c2sgqdLJdS"},"outputs":[],"source":["# report graph is an analysis pass that shows you the detailed information in the graph\n","from chop.passes.graph import report_graph_analysis_pass\n","_ = report_graph_analysis_pass(mg)"]},{"cell_type":"markdown","metadata":{"id":"GjIq-hnWLJdS"},"source":["## Running another Analysis pass: Profile statistics\n","\n","The pass `profile_statistics_analysis_pass` collects statistics of parameters and activations, and save them to node's metadata.\n","\n","Here is a list of all the supported statistics. Refer to the `__init__` of statistic classes in `chop.passes.analysis.statistical_profiler.stat` to check the args each stat class takes.\n","\n","This is a more complex analysis than the previous pass, and thus it would require you to pass in additional arguments for this pass.\n","\n","### Example: the range of weights & input activations of nodes\n","\n","Say we want to collect the tensor-wise min-max range of the 1st `torch.nn.Linear` nodes' weights & bias, and the channel-wise 97% quantile min-max of the 1st `torch.nn.Linear` nodes' input activations. We can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTcTTDV8LJdS"},"outputs":[],"source":["\n","pass_args = {\n","    \"by\": \"type\",                                                            # collect statistics by node name\n","    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n","    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n","    \"weight_statistics\": {\n","        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n","    },\n","    \"activation_statistics\": {\n","        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n","    },\n","    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n","    \"num_samples\": 32,                                                       # feed 32 samples to the model\n","}"]},{"cell_type":"markdown","metadata":{"id":"NhxtJNCVLJdT"},"source":["We can use the `report_node_meta_param_analysis_pass` to inspect the collected statistics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGAXEK29LJdT"},"outputs":[],"source":["mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n","mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"]},{"cell_type":"markdown","metadata":{"id":"6330lcJfLJdT"},"source":["## Running a Transform pass: Quantisation\n","\n","As its name suggests, the transform pass would modify the `MaseGraph`.\n","Similar to the previous analysis pass example, we would need to first declare the configuration for the pass."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"t3MO3JYQLJdT"},"outputs":[],"source":["pass_args = {\n","    \"by\": \"type\",\n","    \"default\": {\"config\": {\"name\": None}},\n","    \"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 2,\n","            \"data_in_frac_width\": 2,\n","            # weight\n","            \"weight_width\": 2,\n","            \"weight_frac_width\": 2,\n","            # bias\n","            \"bias_width\": 2,\n","            \"bias_frac_width\": 2,\n","        }\n","    },\n","}"]},{"cell_type":"markdown","metadata":{"id":"OLuqdnuLLJdT"},"source":["We can then proceed to apply the transformation, in this case, we kept the original graph on purpose, so that we can print a `diff`."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"zPiJQvs4LJdT"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2, 2]\n","[2, 2]\n","[2, 2]\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34m\n","| Original type   | OP           |   Total |   Changed |   Unchanged |\n","|-----------------+--------------+---------+-----------+-------------|\n","| BatchNorm1d     | batch_norm1d |       1 |         0 |           1 |\n","| Linear          | linear       |       1 |         1 |           0 |\n","| ReLU            | relu         |       2 |         0 |           2 |\n","| output          | output       |       1 |         0 |           1 |\n","| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"]}],"source":["from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","\n","ori_mg = MaseGraph(model=model)\n","ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n","ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n","\n","mg, _ = quantize_transform_pass(mg, pass_args)\n","summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'model': GraphModule(\n","  (seq_blocks): Module(\n","    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (1): ReLU(inplace=True)\n","    (2): LinearInteger(in_features=16, out_features=5, bias=True)\n","    (3): ReLU(inplace=True)\n","  )\n","), 'node': seq_blocks_2, 'internal_layers': {<class 'torch.nn.modules.linear.Linear'>: 'linear', <class 'torch.nn.modules.activation.ReLU'>: 'relu'}, 'parameters': {'common': {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'integer', 'precision': [2, 2], 'value': tensor([[ 0.0000,  2.4579,  3.8632,  4.5264,  2.9850,  2.3667,  0.0000,  0.4154,\n","          0.2906,  1.1159,  2.6019,  1.3734,  0.0738,  0.7653,  3.6468,  3.7762],\n","        [ 1.1938,  1.6222,  0.7995,  0.0000,  1.8328,  0.5130,  2.3464,  0.5518,\n","          2.0110,  0.0000,  0.7045,  0.0000,  0.0000,  0.0000,  0.8410,  0.4322],\n","        [ 4.7299,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5658,\n","          0.0933,  0.0000,  0.0000,  0.0000,  0.0000,  0.8393,  0.0000,  0.0000],\n","        [ 1.6247,  1.5325,  0.4292,  0.0000,  1.1767,  0.2515,  1.7802,  0.5995,\n","          1.6486,  0.0000,  0.2767,  0.0000,  0.0000,  0.0000,  0.6735,  0.2141],\n","        [ 0.0000,  2.3461,  5.2728, 10.0267,  2.9555,  2.8422,  0.0000,  0.0000,\n","          0.0000,  0.0000,  0.8517,  0.0000,  0.0000,  0.0000,  5.7901,  4.1397],\n","        [ 0.0613,  1.9712,  0.9927,  0.0000,  1.3317,  0.3719,  0.7771,  0.8854,\n","          1.0067,  1.8169,  2.5503,  0.8644,  0.8406,  1.9400,  0.2304,  0.8684],\n","        [ 0.0000,  2.0933,  0.7147,  0.0000,  0.9174,  0.3460,  0.4155,  1.2465,\n","          0.7753,  1.5041,  2.2094,  0.6328,  0.4406,  1.8818,  0.0814,  1.3773],\n","        [ 1.7284,  1.3315,  0.5270,  0.0000,  0.7428,  0.0000,  0.3925,  0.4534,\n","          0.7606,  0.7806,  1.8202,  0.0000,  0.0398,  0.2138,  0.6075,  0.0687]],\n","       grad_fn=<ReluBackward0>)}, 'weight': {'type': 'integer', 'precision': [2, 2], 'shape': [5, 16], 'from': None, 'value': Parameter containing:\n","tensor([[ 0.2331,  0.3884, -1.0914,  0.3969, -0.8659, -0.0328,  0.0839,  0.2979,\n","          0.0936,  0.2755,  0.2650,  0.1353,  0.1019, -0.2631,  0.5150,  0.7165],\n","        [ 0.7992,  0.6747, -0.5891, -0.6662,  0.4610,  0.5258, -0.0229,  0.0552,\n","         -0.0106,  0.0981,  0.5996, -0.1758, -0.1675, -0.0182, -1.3771, -0.7674],\n","        [ 0.3838,  0.6537,  0.5972, -4.0353,  0.4353, -0.1253,  0.0438, -0.2171,\n","         -0.0809, -0.0214,  0.1954, -0.0559, -0.0239,  0.1670,  0.7255, -1.3367],\n","        [ 0.3738,  0.4229,  0.6606, -1.0253,  0.2204, -0.8483,  0.0708, -0.0104,\n","          0.0429,  0.0050,  0.2494, -0.0741, -0.1032,  0.2761,  0.8217, -0.9791],\n","        [ 0.0187,  0.2125,  0.6670,  0.0766,  0.2760,  0.3236, -0.5192,  0.3155,\n","         -0.2197, -0.0141, -0.4678,  0.5206, -0.5413,  0.1130, -0.3857, -0.0663]],\n","       requires_grad=True)}, 'bias': {'type': 'integer', 'precision': [2, 2], 'shape': [5], 'from': None, 'value': Parameter containing:\n","tensor([0.0546, 0.3673, 1.1420, 0.4331, 0.3801], requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 5], 'torch_dtype': torch.float32, 'value': tensor([[1.6510, 0.0000, 0.0000, 0.0000, 3.3546],\n","        [0.0000, 1.9474, 3.8621, 2.7527, 0.0000],\n","        [1.7093, 4.2730, 2.5328, 2.4103, 1.3526],\n","        [0.5888, 2.1704, 3.5754, 2.6215, 0.0000],\n","        [2.7123, 0.0000, 0.0000, 0.0000, 3.9928],\n","        [0.6183, 2.3869, 3.0619, 2.3817, 0.4541],\n","        [1.4247, 2.0986, 1.8640, 1.4531, 0.8002],\n","        [1.0028, 2.9550, 3.8937, 3.1547, 0.0000]], grad_fn=<ReluBackward0>)}}}, 'software': {'args': {'data_in_0': {'stat': {}}, 'weight': {'stat': {}}, 'bias': {'stat': {}}}, 'results': {'data_out_0': {'stat': {}}}}, 'hardware': {}}}\n"]}],"source":["from chop.passes.graph.utils import get_mase_op\n","\n","for node in mg.nodes:\n","    if get_mase_op(node) == \"linear\":\n","        print(node.meta[\"mase\"].__dict__)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear(in_features=16, out_features=5, bias=True)\n","tensor([0.0546, 0.3673, 1.1420, 0.4331, 0.3801])\n","tensor([[ 0.2331,  0.3884, -1.0914,  0.3969, -0.8659, -0.0328,  0.0839,  0.2979,\n","          0.0936,  0.2755,  0.2650,  0.1353,  0.1019, -0.2631,  0.5150,  0.7165],\n","        [ 0.7992,  0.6747, -0.5891, -0.6662,  0.4610,  0.5258, -0.0229,  0.0552,\n","         -0.0106,  0.0981,  0.5996, -0.1758, -0.1675, -0.0182, -1.3771, -0.7674],\n","        [ 0.3838,  0.6537,  0.5972, -4.0353,  0.4353, -0.1253,  0.0438, -0.2171,\n","         -0.0809, -0.0214,  0.1954, -0.0559, -0.0239,  0.1670,  0.7255, -1.3367],\n","        [ 0.3738,  0.4229,  0.6606, -1.0253,  0.2204, -0.8483,  0.0708, -0.0104,\n","          0.0429,  0.0050,  0.2494, -0.0741, -0.1032,  0.2761,  0.8217, -0.9791],\n","        [ 0.0187,  0.2125,  0.6670,  0.0766,  0.2760,  0.3236, -0.5192,  0.3155,\n","         -0.2197, -0.0141, -0.4678,  0.5206, -0.5413,  0.1130, -0.3857, -0.0663]])\n","LinearInteger(in_features=16, out_features=5, bias=True)\n","tensor([0.0546, 0.3673, 1.1420, 0.4331, 0.3801])\n","tensor([[ 0.2331,  0.3884, -1.0914,  0.3969, -0.8659, -0.0328,  0.0839,  0.2979,\n","          0.0936,  0.2755,  0.2650,  0.1353,  0.1019, -0.2631,  0.5150,  0.7165],\n","        [ 0.7992,  0.6747, -0.5891, -0.6662,  0.4610,  0.5258, -0.0229,  0.0552,\n","         -0.0106,  0.0981,  0.5996, -0.1758, -0.1675, -0.0182, -1.3771, -0.7674],\n","        [ 0.3838,  0.6537,  0.5972, -4.0353,  0.4353, -0.1253,  0.0438, -0.2171,\n","         -0.0809, -0.0214,  0.1954, -0.0559, -0.0239,  0.1670,  0.7255, -1.3367],\n","        [ 0.3738,  0.4229,  0.6606, -1.0253,  0.2204, -0.8483,  0.0708, -0.0104,\n","          0.0429,  0.0050,  0.2494, -0.0741, -0.1032,  0.2761,  0.8217, -0.9791],\n","        [ 0.0187,  0.2125,  0.6670,  0.0766,  0.2760,  0.3236, -0.5192,  0.3155,\n","         -0.2197, -0.0141, -0.4678,  0.5206, -0.5413,  0.1130, -0.3857, -0.0663]])\n"]}],"source":["from pprint import pprint\n","\n","pprint(ori_mg.modules['seq_blocks.2'])\n","pprint(ori_mg.modules['seq_blocks.2'].bias.data)\n","pprint(ori_mg.modules['seq_blocks.2'].weight.data)\n","\n","pprint(mg.modules['seq_blocks.2'])\n","pprint(mg.modules['seq_blocks.2'].bias.data)\n","pprint(mg.modules['seq_blocks.2'].weight.data)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLU(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: ReLU(inplace=True)\n","transformed seq_blocks_3: ReLU(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n"]}],"source":["from chop.passes.graph.utils import get_node_actual_target\n","\n","for og_node, node in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34m\n","| Original type   | OP           |   Total |   Changed |   Unchanged |\n","|-----------------+--------------+---------+-----------+-------------|\n","| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n","| Dropout         | dropout      |       2 |         0 |           2 |\n","| Linear          | linear       |       3 |         3 |           0 |\n","| ReLU            | relu         |       4 |         4 |           0 |\n","| output          | output       |       1 |         0 |           1 |\n","| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=32, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=32, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_3: BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_4: ReLU(inplace=True)\n","transformed seq_blocks_4: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_5: Dropout(p=0.2, inplace=False)\n","transformed seq_blocks_5: Dropout(p=0.2, inplace=False)\n","----------------------------------------------\n","original seq_blocks_6: Linear(in_features=32, out_features=16, bias=True)\n","transformed seq_blocks_6: LinearInteger(in_features=32, out_features=16, bias=True)\n","----------------------------------------------\n","original seq_blocks_7: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_7: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_8: ReLU(inplace=True)\n","transformed seq_blocks_8: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_9: Dropout(p=0.2, inplace=False)\n","transformed seq_blocks_9: Dropout(p=0.2, inplace=False)\n","----------------------------------------------\n","original seq_blocks_10: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_10: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_11: BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_11: BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_12: ReLU(inplace=True)\n","transformed seq_blocks_12: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n"]}],"source":["from chop.passes.graph.utils import get_node_actual_target\n","from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","batch_size = 8\n","model_name = \"jsc-custom\"\n","dataset_name = \"jsc\"\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n",")\n","data_module.prepare_data()\n","data_module.setup()\n","\n","LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/lab-1_jsc-custom/software/training_ckpts/best.ckpt\"\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False)\n","\n","model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n","\n","# get the input generator\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","# a demonstration of how to feed an input value to the model\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n","\n","pass_args = {\n","    \"by\": \"type\",\n","    \"default\": {\"config\": {\"name\": None}},\n","    \"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 2,\n","            \"data_in_frac_width\": 2,\n","            # weight\n","            \"weight_width\": 2,\n","            \"weight_frac_width\": 2,\n","            # bias\n","            \"bias_width\": 2,\n","            \"bias_frac_width\": 2,\n","        }\n","    },\n","    \"relu\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # # weight\n","            # \"weight_width\": 8,\n","            # \"weight_frac_width\": 4,\n","            # # bias\n","            # \"bias_width\": 8,\n","            # \"bias_frac_width\": 4,\n","        }\n","    },\n","}\n","\n","mg = MaseGraph(model=model)\n","mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","\n","mg_trans = MaseGraph(model=model)\n","mg_trans, _ = init_metadata_analysis_pass(mg_trans, None)\n","mg_trans, _ = add_common_metadata_analysis_pass(mg_trans, {\"dummy_in\": dummy_in})\n","mg_trans, _ = quantize_transform_pass(mg_trans, pass_args)\n","summarize_quantization_analysis_pass(mg, mg_trans, save_dir=\"quantize_summary\")\n","\n","\n","for og_node, node in zip(mg.fx_graph.nodes, mg_trans.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original weights:  tensor([[ 0.0146,  0.0996, -0.0316,  0.0403,  0.0685,  0.1840, -0.0285,  0.0622,\n","         -0.0455,  0.0711,  0.0172,  0.0250, -0.1422, -0.1315, -0.5085, -0.0726],\n","        [ 0.0727,  0.1423, -0.3114, -0.0457,  0.0154,  0.1282, -0.0300,  0.0711,\n","         -0.0192,  0.0455,  0.2072, -0.1718, -0.0718, -0.0205, -0.0191,  0.3600]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.2500, -0.0000,  0.0000,\n","         -0.0000,  0.0000,  0.0000,  0.0000, -0.2500, -0.2500, -0.5000, -0.0000],\n","        [ 0.0000,  0.2500, -0.2500, -0.0000,  0.0000,  0.2500, -0.0000,  0.0000,\n","         -0.0000,  0.0000,  0.2500, -0.2500, -0.0000, -0.0000, -0.0000,  0.2500]],\n","       grad_fn=<SliceBackward0>)\n","Original weights:  tensor([[ 0.1181,  0.1461, -0.0558,  0.0524, -0.1136,  0.0183, -0.0927, -0.4486,\n","          0.1665,  0.0404,  0.0298,  0.0455,  0.0197, -0.2387,  0.1373,  0.0412,\n","          0.0274, -0.1670,  0.1275, -0.0862,  0.0818,  0.0348, -0.1340,  0.0905,\n","          0.0457,  0.0464,  0.0630,  0.1591, -0.1446,  0.0342,  0.0556, -0.0173],\n","        [-0.1485, -0.1107, -0.0469,  0.1003,  0.0858, -0.1413, -0.0589,  0.0306,\n","         -0.1351, -0.3232, -0.1903, -0.0761,  0.0301, -0.0115, -0.3036, -0.3615,\n","         -0.4178,  0.0013, -0.0443,  0.0494, -0.1636, -0.0325,  0.1012, -0.1198,\n","         -0.0740, -0.1922, -0.0333,  0.1630,  0.0811, -0.3414, -0.0863,  0.0081]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0000,  0.2500, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.5000,\n","          0.2500,  0.0000,  0.0000,  0.0000,  0.0000, -0.2500,  0.2500,  0.0000,\n","          0.0000, -0.2500,  0.2500, -0.0000,  0.0000,  0.0000, -0.2500,  0.0000,\n","          0.0000,  0.0000,  0.0000,  0.2500, -0.2500,  0.0000,  0.0000, -0.0000],\n","        [-0.2500, -0.0000, -0.0000,  0.0000,  0.0000, -0.2500, -0.0000,  0.0000,\n","         -0.2500, -0.2500, -0.2500, -0.0000,  0.0000, -0.0000, -0.2500, -0.2500,\n","         -0.5000,  0.0000, -0.0000,  0.0000, -0.2500, -0.0000,  0.0000, -0.0000,\n","         -0.0000, -0.2500, -0.0000,  0.2500,  0.0000, -0.2500, -0.0000,  0.0000]],\n","       grad_fn=<SliceBackward0>)\n","Original weights:  tensor([[ 0.0572, -0.2061,  0.1665, -0.3324, -0.1361, -0.1358,  0.0535,  0.0529,\n","          0.0608, -0.2736,  0.1626, -0.3289, -0.1575,  0.1869, -0.0145, -0.1680],\n","        [ 0.0075, -0.1077, -0.0146,  0.1603, -0.1860,  0.1014,  0.0186,  0.0253,\n","         -0.0750,  0.0164,  0.0636, -0.5114, -0.3297, -0.0835,  0.1455,  0.0520]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0000, -0.2500,  0.2500, -0.2500, -0.2500, -0.2500,  0.0000,  0.0000,\n","          0.0000, -0.2500,  0.2500, -0.2500, -0.2500,  0.2500, -0.0000, -0.2500],\n","        [ 0.0000, -0.0000, -0.0000,  0.2500, -0.2500,  0.0000,  0.0000,  0.0000,\n","         -0.0000,  0.0000,  0.0000, -0.5000, -0.2500, -0.0000,  0.2500,  0.0000]],\n","       grad_fn=<SliceBackward0>)\n"]}],"source":["from chop.passes.graph.transforms.quantize.quantized_modules.linear import _LinearBase\n","\n","i = 0\n","for module_name, module_trans_name in zip(mg.modules, mg_trans.modules):\n","    module = mg.modules[module_name]\n","    module_trans = mg_trans.modules[module_trans_name]\n","\n","    if isinstance(module_trans, _LinearBase):\n","        print(\"Original weights: \", module.weight[:2])\n","        print(\"Quantised weights: \", module_trans.w_quantizer(module_trans.weight)[:2])\n","        i += 1\n","        \n","    if i == 3:\n","        break\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computations summary:\n","---------------------\n","| Node name     | Node type    |   Parameters |   Forward FLOPS |   Backward FLOPS |   Forward bitops |   Backward bitops |\n","|---------------|--------------|--------------|-----------------|------------------|------------------|-------------------|\n","| x             | placeholder  |              |                 |                  |                  |                   |\n","| seq_blocks_0  | batch_norm1d |           32 |             512 |              512 | 524288           |  524288           |\n","| seq_blocks_1  | relu         |            0 |             128 |              128 |   4096           |    4096           |\n","| seq_blocks_2  | linear       |          512 |            4096 |             8192 |      4.1943e+06  |       8.38861e+06 |\n","| seq_blocks_3  | batch_norm1d |           64 |            1024 |             1024 |      1.04858e+06 |       1.04858e+06 |\n","| seq_blocks_4  | relu         |            0 |             256 |              256 |   8192           |    8192           |\n","| seq_blocks_5  | dropout      |            0 |               0 |                0 |      0           |       0           |\n","| seq_blocks_6  | linear       |          512 |            4096 |             8192 |      4.1943e+06  |       8.38861e+06 |\n","| seq_blocks_7  | batch_norm1d |           32 |             512 |              512 | 524288           |  524288           |\n","| seq_blocks_8  | relu         |            0 |             128 |              128 |   4096           |    4096           |\n","| seq_blocks_9  | dropout      |            0 |               0 |                0 |      0           |       0           |\n","| seq_blocks_10 | linear       |           80 |             640 |             1280 | 655360           |       1.31072e+06 |\n","| seq_blocks_11 | batch_norm1d |           10 |             160 |              160 | 163840           |  163840           |\n","| seq_blocks_12 | relu         |            0 |              40 |               40 |   1280           |    1280           |\n","| output        | output       |              |                 |                  |                  |                   |\n"]},{"data":{"text/plain":["(<chop.ir.graph.mase_graph.MaseGraph at 0x7f5e145e2090>, {})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from pprint import pprint\n","\n","from chop.passes.graph.analysis.flops.flops_pass import analyse_flops_pass\n","from chop.passes.graph.utils import get_mase_op\n","\n","analyse_flops_pass(mg)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# for node in mg.fx_graph.nodes:\n","#     print(node.meta['mase'].parameters['common'])"]},{"cell_type":"markdown","metadata":{"id":"HhTU3755MerQ"},"source":["\n","\n","# Exercises:\n","\n","We have now seen how to:\n","1. Set up a dataset\n","2. Set up a model\n","3. Generate a `MaseGraph` from the model\n","4. Run Analysis and Transform passes on the `MaseGraph`\n","\n","Now consider the following problems:\n","\n","1. Explain the functionality of `report_graph_analysis_pass` and its printed jargons such as `placeholder`, `get_attr` ... You might find the doc of [torch.fx](https://pytorch.org/docs/stable/fx.html) useful.\n","\n","2. What are the functionalities of `profile_statistics_analysis_pass` and `report_node_meta_param_analysis_pass` respectively?"]},{"cell_type":"markdown","metadata":{},"source":["### Answer 1\n","> Explain the functionality of `report_graph_analysis_pass` and its printed jargons such as `placeholder`, `get_attr` \n","\n","`report_graph_analysis_pass` steps through each node of the FX graph and counts how many of each node fit the following types:\n","- `placeholder`- method inputs\n","- `get_attr`, `call_function`, `call_method`, `call_module` - the operations within the node, whether or not the node is getting an attribute or calling one of a free function, a method or a module\n","- `output` - how many outputs of the graph\n","\n","The pass also reports the layers in the graph along with their settings (example, `Linear(in_features=16, out_features=5, bias=True)`).\n","\n","This pass seems like it would be useful for getting an understanding of how the model is structured.\n","\n","### Answer 2\n","> What are the functionalities of `profile_statistics_analysis_pass` and `report_node_meta_param_analysis_pass` respectively?\n","\n","`profile_statistics_analysis_pass` iterates through each node and checks whether it matches the arguments specified, and if it does then it computes statistics based on the dummy data passed in. Stats can be computed for weight nodes (where only `call_module` nodes are considered) and for activation nodes separately, and they can also be further filtered by a type of node (example `linear` or `relu`) or specifically by the name. Statistics such as the variance, the range, etc. can be computed.\n","\n","`report_node_meta_param_analysis_pass` then iterates through the updated graph (processed by `profile_statistics_analysis_pass`) and outputs the stats computed."]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","## MASE OPs and MASE Types\n","\n","MASE is designed to be a very high-level intermediate representation (IR), this is very different from the classic [LLVM IR](https://llvm.org/docs/LangRef.html) that you might be familiar with.\n","\n","The following MASE Types are available:\n","(Note from Aaron: do we have a page somewhere that have summarized this?)\n","\n","\n","## A deeper dive into the quantisation transform\n","\n","3. Explain why only 1 OP is changed after the `quantize_transform_pass` .\n","\n","4. Write some code to traverse both `mg` and `ori_mg`, check and comment on the nodes in these two graphs. You might find the source code for the implementation of `summarize_quantization_analysis_pass` useful.\n","\n","5. Perform the same quantisation flow to the bigger JSC network that you have trained in lab1. You must be aware that now the `pass_args` for your custom network might be different if you have used more than the `Linear` layer in your network.\n","\n","6. Write code to show and verify that the weights of these layers are indeed quantised. You might need to go through the source code of the implementation of the quantisation pass and also the implementation of the [Quantized Layers](../../machop/chop/passes/transforms/quantize/quantized_modules/linear.py) ."]},{"cell_type":"markdown","metadata":{},"source":["### Answer 3\n","The `pass_args` specified that the quantisation should be done by `type` of `linear`, and there is only one linear layer in the model so only this was changed.\n","\n","### Answer 4\n","The following basic code was written to traverse the nodes of `mg` and `ori_mg` and compare the nodes:\n","```python\n","for og_node, node in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")\n","print(\"----------------------------------------------\")\n","```\n","\n","This code produced the following output:\n","```text\n","----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLU(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: ReLU(inplace=True)\n","transformed seq_blocks_3: ReLU(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n","----------------------------------------------\n","```\n","\n","We can see that all the layers are identical except for `seq_blocks_2`, with the original being of type `Linear` and the new being `LinearInteger` after the quantization pass. This confirms the observations in the answer to Q3 above."]},{"cell_type":"markdown","metadata":{},"source":["\n","## The command line interface\n","\n","The same flow can also be executed on the command line throw the `transform` action.\n","\n","```bash\n","# make sure you have the same printout\n","pwd\n","# it should show\n","# your_dir/mase-tools/machop\n","\n","# enter the following command\n","./ch transform --config configs/examples/jsc_toy_by_type.toml --task cls --cpu=0\n","```\n","7. Load your own pre-trained JSC network, and perform perform the quantisation using the command line interface.\n","\n","## \\[Optional] Write your own pass\n","\n","Many examples of existing passes are in the [source code](../..//machop/chop/passes/__init__.py), the [test files](../../machop/test/passes) for these passes also contain useful information on helping you to understand how these passes are used.\n","\n","Implement a pass to count the number of FLOPs (floating-point operations) and BitOPs (bit-wise operations)."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
