{"cells":[{"cell_type":"markdown","metadata":{"id":"Oa09Had3Ldfq"},"source":["# Installing MASE (again)\n","\n","Run the block below to install MASE in the current Colab runtime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ClqAsevLdJx"},"outputs":[],"source":["git_token = \"YOUR_GIT_TOKEN\"\n","short_code = \"YOUR_SHORT_CODE\"\n","\n","# Check the current python version (It should be using Python 3.10) and update pip to the latest version.\n","!python --version\n","!python -m pip install --user --upgrade pip\n","\n","# Clone MASE from your branch (the branch must already exist)\n","!git clone -b lab1_{short_code} https://{git_token}@github.com/DeepWok/mase.git\n","\n","# Install requirements\n","!python -m pip install -r ./mase/machop/requirements.txt\n","\n","# Change working directory to machop\n","%cd ./mase/machop/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gg2xBbRmYZ1g"},"outputs":[],"source":["!./ch --help"]},{"cell_type":"markdown","metadata":{"id":"VF0krky2N4dr"},"source":["# General introduction\n","\n","In this lab, you will learn how to use the software stack of MASE. There are in total 7 tasks you would need to finish, and 1 optional task."]},{"cell_type":"markdown","metadata":{"id":"DIOZ48aaMqhV"},"source":["# Turning you network to a graph\n","\n","One specific feature of MASE is its capability to transform DL models to a computation graph using the [torch.fx](<https://pytorch.org/docs/stable/fx.html>) framework.\n"]},{"cell_type":"markdown","metadata":{"id":"cjBbOikbLJdN"},"source":["## Use the Transform functionality without CLI\n","\n","This tutorial describes how to use the MASE transform functionality for a pre-trained model."]},{"cell_type":"markdown","metadata":{"id":"j5sg0OpYLJdO"},"source":["## Import related packages and machop"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4KO86-UYLJdP"},"outputs":[],"source":["import sys\n","import logging\n","import os\n","from pathlib import Path\n","from pprint import pprint as pp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd ~/dev/advanced-deep-learning-systems/mase/machop\n","!pwd\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# figure out the correct path\n","machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n","assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n","sys.path.append(str(machop_path))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"l7BE0UToLJdQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"]}],"source":["from chop.dataset import MaseDataModule, get_dataset_info\n","from chop.tools.logger import set_logging_verbosity\n","\n","from chop.passes.graph import (\n","    save_node_meta_param_interface_pass,\n","    report_node_meta_param_analysis_pass,\n","    profile_statistics_analysis_pass,\n","    add_common_metadata_analysis_pass,\n","    init_metadata_analysis_pass,\n","    add_software_metadata_analysis_pass,\n",")\n","from chop.tools.get_input import InputGenerator\n","from chop.tools.checkpoint_load import load_model\n","from chop.ir import MaseGraph\n","\n","from chop.models import get_model_info, get_model\n","\n","set_logging_verbosity(\"info\")"]},{"cell_type":"markdown","metadata":{"id":"q35_tV4QLJdQ"},"source":["## Set up the dataset\n","\n","Here we create a `MaseDataModule` using the `jsc` dataset from lab1. Note the `MaseDataModule` also requires the name of the model you plan to use data module with. In this case it is `jsc-tiny`."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ztEzclWrLJdR"},"outputs":[],"source":["batch_size = 8\n","model_name = \"jsc-tiny\"\n","dataset_name = \"jsc\"\n","\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n",")\n","data_module.prepare_data()\n","data_module.setup()\n"]},{"cell_type":"markdown","metadata":{"id":"08-4XdNYLJdR"},"source":["## Set up the model \n","\n","Here we use the previously trained `jsc-tiny` model in lab 1 as an example."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# If you stored your model checkpoint on Google Drive, remember to mount the drive to the current runtime in order to access it\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gIU4s9CiLJdR"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/jsc-tiny_classification_jsc_2024-01-26/software/training_ckpts/best.ckpt\u001b[0m\n"]}],"source":["# üìùÔ∏è change this CHECKPOINT_PATH to the one you trained in Lab1\n","CHECKPOINT_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/jsc-tiny_classification_jsc_2024-01-26/software/training_ckpts/best.ckpt\"\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False)\n","\n","model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"]},{"cell_type":"markdown","metadata":{"id":"lrIWs8XvLJdR"},"source":["# Get a dummy data in\n","With the dataset module and model information, we can grab an input generator."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ygyzBWJyLJdR"},"outputs":[],"source":["# get the input generator\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","# a demonstration of how to feed an input value to the model\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n"]},{"cell_type":"markdown","metadata":{"id":"-sucUgAVLJdS"},"source":["## Generate a MaseGraph\n","We have two forms of passes: transform passes and analysis passes, both of them would require the model to be transferred into a MaseGraph to allow manipulation."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wSmp6oaGLJdS"},"outputs":[],"source":["# generate the mase graph and initialize node metadata\n","mg = MaseGraph(model=model)"]},{"cell_type":"markdown","metadata":{"id":"SiEehxhNLJdS"},"source":["## Running an Analysis pass\n","Analysis pass DOES NOT change the graph\n","\n","The following analysis passes are essential to prepare the graph for other passes"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"UuXo32cJLJdS"},"outputs":[],"source":["mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","mg, _ = add_software_metadata_analysis_pass(mg, None)"]},{"cell_type":"markdown","metadata":{"id":"bAE-LFypLJdS"},"source":["We will first run a simple graph analysis to understand the structure of the model."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"V4c2sgqdLJdS"},"outputs":[{"name":"stdout","output_type":"stream","text":["graph():\n","    %x : [num_users=1] = placeholder[target=x]\n","    %seq_blocks_0 : [num_users=1] = call_module[target=seq_blocks.0](args = (%x,), kwargs = {})\n","    %seq_blocks_1 : [num_users=1] = call_module[target=seq_blocks.1](args = (%seq_blocks_0,), kwargs = {})\n","    %seq_blocks_2 : [num_users=1] = call_module[target=seq_blocks.2](args = (%seq_blocks_1,), kwargs = {})\n","    %seq_blocks_3 : [num_users=1] = call_module[target=seq_blocks.3](args = (%seq_blocks_2,), kwargs = {})\n","    return seq_blocks_3\n","Network overview:\n","{'placeholder': 1, 'get_attr': 0, 'call_function': 0, 'call_method': 0, 'call_module': 4, 'output': 1}\n","Layer types:\n","[BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), Linear(in_features=16, out_features=5, bias=True), ReLU(inplace=True)]\n"]}],"source":["# report graph is an analysis pass that shows you the detailed information in the graph\n","from chop.passes.graph import report_graph_analysis_pass\n","_ = report_graph_analysis_pass(mg)"]},{"cell_type":"markdown","metadata":{"id":"GjIq-hnWLJdS"},"source":["## Running another Analysis pass: Profile statistics\n","\n","The pass `profile_statistics_analysis_pass` collects statistics of parameters and activations, and save them to node's metadata.\n","\n","Here is a list of all the supported statistics. Refer to the `__init__` of statistic classes in `chop.passes.analysis.statistical_profiler.stat` to check the args each stat class takes.\n","\n","This is a more complex analysis than the previous pass, and thus it would require you to pass in additional arguments for this pass.\n","\n","### Example: the range of weights & input activations of nodes\n","\n","Say we want to collect the tensor-wise min-max range of the 1st `torch.nn.Linear` nodes' weights & bias, and the channel-wise 97% quantile min-max of the 1st `torch.nn.Linear` nodes' input activations. We can do the following:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"wTcTTDV8LJdS"},"outputs":[],"source":["\n","pass_args = {\n","    \"by\": \"type\",                                                            # collect statistics by node name\n","    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n","    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n","    \"weight_statistics\": {\n","        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n","    },\n","    \"activation_statistics\": {\n","        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n","    },\n","    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n","    \"num_samples\": 32,                                                       # feed 32 samples to the model\n","}"]},{"cell_type":"markdown","metadata":{"id":"NhxtJNCVLJdT"},"source":["We can use the `report_node_meta_param_analysis_pass` to inspect the collected statistics."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"OGAXEK29LJdT"},"outputs":[{"name":"stderr","output_type":"stream","text":["Profiling weight statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 9464.39it/s]\n","Profiling act statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 390.84it/s]\n","\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34m\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| Node name    | Fx Node op   | Mase type           | Mase op      | Software Param                                                                          |\n","+==============+==============+=====================+==============+=========================================================================================+\n","| x            | placeholder  | placeholder         | placeholder  | {'results': {'data_out_0': {'stat': {}}}}                                               |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                         |\n","|              |              |                     |              |           'data_in_0': {'stat': {}},                                                    |\n","|              |              |                     |              |           'running_mean': {'stat': {}},                                                 |\n","|              |              |                     |              |           'running_var': {'stat': {}},                                                  |\n","|              |              |                     |              |           'weight': {'stat': {}}},                                                      |\n","|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                               |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 512,                       |\n","|              |              |                     |              |                                                     'max': 2.517944812774658,           |\n","|              |              |                     |              |                                                     'min': -1.6142338514328003,         |\n","|              |              |                     |              |                                                     'range': 4.132178783416748}}}},     |\n","|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                               |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 5,                            |\n","|              |              |                     |              |                                                  'mean': 0.04106813669204712,           |\n","|              |              |                     |              |                                                  'variance': 0.0907774269580841}}},     |\n","|              |              |                     |              |           'data_in_0': {'stat': {}},                                                    |\n","|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 80,                         |\n","|              |              |                     |              |                                                    'mean': 0.011629286222159863,        |\n","|              |              |                     |              |                                                    'variance': 0.03853578865528107}}}}, |\n","|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                               |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| seq_blocks_3 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 160,                       |\n","|              |              |                     |              |                                                     'max': 2.8995959758758545,          |\n","|              |              |                     |              |                                                     'min': -1.806367039680481,          |\n","|              |              |                     |              |                                                     'range': 4.705963134765625}}}},     |\n","|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                               |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\n","| output       | output       | output              | output       | {'args': {'data_in_0': {'stat': {}}}}                                                   |\n","+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------+\u001b[0m\n"]}],"source":["mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n","mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"]},{"cell_type":"markdown","metadata":{"id":"6330lcJfLJdT"},"source":["## Running a Transform pass: Quantisation\n","\n","As its name suggests, the transform pass would modify the `MaseGraph`.\n","Similar to the previous analysis pass example, we would need to first declare the configuration for the pass."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"t3MO3JYQLJdT"},"outputs":[],"source":["pass_args = {\n","    \"by\": \"type\",\n","    \"default\": {\"config\": {\"name\": None}},\n","    \"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # weight\n","            \"weight_width\": 8,\n","            \"weight_frac_width\": 4,\n","            # bias\n","            \"bias_width\": 8,\n","            \"bias_frac_width\": 4,\n","        }\n","    },\n","}"]},{"cell_type":"markdown","metadata":{"id":"OLuqdnuLLJdT"},"source":["We can then proceed to apply the transformation, in this case, we kept the original graph on purpose, so that we can print a `diff`."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"zPiJQvs4LJdT"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34m\n","| Original type   | OP           |   Total |   Changed |   Unchanged |\n","|-----------------+--------------+---------+-----------+-------------|\n","| BatchNorm1d     | batch_norm1d |       1 |         0 |           1 |\n","| Linear          | linear       |       1 |         1 |           0 |\n","| ReLU            | relu         |       2 |         0 |           2 |\n","| output          | output       |       1 |         0 |           1 |\n","| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"]}],"source":["from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","\n","ori_mg = MaseGraph(model=model)\n","ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n","ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n","\n","mg, _ = quantize_transform_pass(mg, pass_args)\n","summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear(in_features=16, out_features=5, bias=True)\n","tensor([-0.1298,  0.2062,  0.4861, -0.2565, -0.1006])\n","tensor([[-0.2332,  0.2832, -0.1115, -0.0295, -0.0072,  0.1444,  0.0797,  0.3395,\n","          0.0553,  0.3004,  0.1721,  0.1641, -0.0056,  0.0201,  0.0698,  0.3321],\n","        [ 0.3941, -0.1131, -0.4779, -0.2654, -0.1232,  0.0928,  0.0162,  0.2843,\n","          0.0254,  0.1038,  0.3021, -0.0592, -0.0999,  0.0907, -0.4290, -0.0821],\n","        [ 0.0346,  0.1561, -0.1502, -0.5660, -0.1753,  0.0592,  0.1440,  0.0482,\n","          0.0399, -0.1276,  0.1169, -0.2150, -0.2085, -0.1641,  0.2179, -0.1539],\n","        [-0.0709, -0.0405,  0.0492,  0.1516,  0.0798, -0.0184,  0.2083, -0.1451,\n","          0.0881, -0.2306, -0.2248, -0.1836,  0.0951,  0.0654, -0.1739, -0.0221],\n","        [-0.1331,  0.0142,  0.2336,  0.2879,  0.3525,  0.4610, -0.2539, -0.0417,\n","          0.0423,  0.0954,  0.0374,  0.1446, -0.0673, -0.1901,  0.1603, -0.1296]])\n","LinearInteger(in_features=16, out_features=5, bias=True)\n","tensor([-0.1298,  0.2062,  0.4861, -0.2565, -0.1006])\n","tensor([[-0.2332,  0.2832, -0.1115, -0.0295, -0.0072,  0.1444,  0.0797,  0.3395,\n","          0.0553,  0.3004,  0.1721,  0.1641, -0.0056,  0.0201,  0.0698,  0.3321],\n","        [ 0.3941, -0.1131, -0.4779, -0.2654, -0.1232,  0.0928,  0.0162,  0.2843,\n","          0.0254,  0.1038,  0.3021, -0.0592, -0.0999,  0.0907, -0.4290, -0.0821],\n","        [ 0.0346,  0.1561, -0.1502, -0.5660, -0.1753,  0.0592,  0.1440,  0.0482,\n","          0.0399, -0.1276,  0.1169, -0.2150, -0.2085, -0.1641,  0.2179, -0.1539],\n","        [-0.0709, -0.0405,  0.0492,  0.1516,  0.0798, -0.0184,  0.2083, -0.1451,\n","          0.0881, -0.2306, -0.2248, -0.1836,  0.0951,  0.0654, -0.1739, -0.0221],\n","        [-0.1331,  0.0142,  0.2336,  0.2879,  0.3525,  0.4610, -0.2539, -0.0417,\n","          0.0423,  0.0954,  0.0374,  0.1446, -0.0673, -0.1901,  0.1603, -0.1296]])\n"]}],"source":["from pprint import pprint\n","\n","pprint(ori_mg.modules['seq_blocks.2'])\n","pprint(ori_mg.modules['seq_blocks.2'].bias.data)\n","pprint(ori_mg.modules['seq_blocks.2'].weight.data)\n","\n","pprint(mg.modules['seq_blocks.2'])\n","pprint(mg.modules['seq_blocks.2'].bias.data)\n","pprint(mg.modules['seq_blocks.2'].weight.data)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLU(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: ReLU(inplace=True)\n","transformed seq_blocks_3: ReLU(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n"]}],"source":["from chop.passes.graph.utils import get_node_actual_target\n","\n","for og_node, node in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/jsc-custom_classification_jsc_2024-01-27/software/training_ckpts/best.ckpt\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34m\n","| Original type   | OP           |   Total |   Changed |   Unchanged |\n","|-----------------+--------------+---------+-----------+-------------|\n","| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n","| Dropout         | dropout      |       2 |         0 |           2 |\n","| Linear          | linear       |       3 |         3 |           0 |\n","| ReLU            | relu         |       4 |         4 |           0 |\n","| output          | output       |       1 |         0 |           1 |\n","| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=32, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=32, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_3: BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_4: ReLU(inplace=True)\n","transformed seq_blocks_4: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_5: Dropout(p=0.2, inplace=False)\n","transformed seq_blocks_5: Dropout(p=0.2, inplace=False)\n","----------------------------------------------\n","original seq_blocks_6: Linear(in_features=32, out_features=16, bias=True)\n","transformed seq_blocks_6: LinearInteger(in_features=32, out_features=16, bias=True)\n","----------------------------------------------\n","original seq_blocks_7: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_7: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_8: ReLU(inplace=True)\n","transformed seq_blocks_8: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original seq_blocks_9: Dropout(p=0.2, inplace=False)\n","transformed seq_blocks_9: Dropout(p=0.2, inplace=False)\n","----------------------------------------------\n","original seq_blocks_10: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_10: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_11: BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_11: BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_12: ReLU(inplace=True)\n","transformed seq_blocks_12: ReLUInteger(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n"]}],"source":["from chop.passes.graph.utils import get_node_actual_target\n","from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","batch_size = 8\n","model_name = \"jsc-custom\"\n","dataset_name = \"jsc\"\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n",")\n","data_module.prepare_data()\n","data_module.setup()\n","\n","LAB1_CUSTOM_PATH = \"/home/bkt123/dev/advanced-deep-learning-systems/mase/mase_output/jsc-custom_classification_jsc_2024-01-27/software/training_ckpts/best.ckpt\"\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False)\n","\n","model = load_model(load_name=LAB1_CUSTOM_PATH, load_type=\"pl\", model=model)\n","\n","# get the input generator\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","# a demonstration of how to feed an input value to the model\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n","\n","pass_args = {\n","    \"by\": \"type\",\n","    \"default\": {\"config\": {\"name\": None}},\n","    \"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # weight\n","            \"weight_width\": 8,\n","            \"weight_frac_width\": 4,\n","            # bias\n","            \"bias_width\": 8,\n","            \"bias_frac_width\": 4,\n","        }\n","    },\n","    \"relu\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # # weight\n","            # \"weight_width\": 8,\n","            # \"weight_frac_width\": 4,\n","            # # bias\n","            # \"bias_width\": 8,\n","            # \"bias_frac_width\": 4,\n","        }\n","    },\n","}\n","\n","mg = MaseGraph(model=model)\n","mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","\n","mg_trans = MaseGraph(model=model)\n","mg_trans, _ = init_metadata_analysis_pass(mg_trans, None)\n","mg_trans, _ = add_common_metadata_analysis_pass(mg_trans, {\"dummy_in\": dummy_in})\n","mg_trans, _ = quantize_transform_pass(mg_trans, pass_args)\n","summarize_quantization_analysis_pass(mg, mg_trans, save_dir=\"quantize_summary\")\n","\n","\n","for og_node, node in zip(mg.fx_graph.nodes, mg_trans.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original weights:  tensor([[ 0.0255,  0.1090,  0.0359,  0.2054,  0.1749,  0.0137, -0.0309,  0.0114,\n","         -0.0637,  0.0512,  0.0183, -0.0041, -0.0681, -0.0890, -0.5769, -0.1234],\n","        [ 0.0558,  0.1819, -0.3261,  0.0708, -0.1033,  0.0756, -0.0145,  0.0285,\n","         -0.0013,  0.0439,  0.1017, -0.2077,  0.0847,  0.0008,  0.0621,  0.3468]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0000,  0.1250,  0.0625,  0.1875,  0.1875,  0.0000, -0.0000,  0.0000,\n","         -0.0625,  0.0625,  0.0000, -0.0000, -0.0625, -0.0625, -0.5625, -0.1250],\n","        [ 0.0625,  0.1875, -0.3125,  0.0625, -0.1250,  0.0625, -0.0000,  0.0000,\n","         -0.0000,  0.0625,  0.1250, -0.1875,  0.0625,  0.0000,  0.0625,  0.3750]],\n","       grad_fn=<SliceBackward0>)\n","Original weights:  tensor([[ 0.0825,  0.1261,  0.0914,  0.0158, -0.2281, -0.2152, -0.1013, -0.4228,\n","          0.1333, -0.1087,  0.0085, -0.0342, -0.3247,  0.0023,  0.0238, -0.1339,\n","         -0.0091, -0.3102,  0.1026, -0.0515,  0.1231, -0.0272, -0.1931,  0.0197,\n","         -0.0331, -0.0491, -0.0282,  0.0100, -0.1544, -0.1985,  0.1280,  0.0411],\n","        [ 0.0239, -0.0592,  0.0365,  0.0344,  0.0577, -0.0604,  0.0182,  0.1241,\n","         -0.0226, -0.3895, -0.1715,  0.0076,  0.0184,  0.2811, -0.1738, -0.2158,\n","         -0.2777,  0.0148,  0.0425,  0.3084, -0.1222, -0.0037,  0.0101, -0.1173,\n","          0.0245, -0.1829,  0.0251,  0.3758,  0.0581, -0.4017, -0.1129, -0.0046]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0625,  0.1250,  0.0625,  0.0000, -0.2500, -0.1875, -0.1250, -0.4375,\n","          0.1250, -0.1250,  0.0000, -0.0625, -0.3125,  0.0000,  0.0000, -0.1250,\n","         -0.0000, -0.3125,  0.1250, -0.0625,  0.1250, -0.0000, -0.1875,  0.0000,\n","         -0.0625, -0.0625, -0.0000,  0.0000, -0.1250, -0.1875,  0.1250,  0.0625],\n","        [ 0.0000, -0.0625,  0.0625,  0.0625,  0.0625, -0.0625,  0.0000,  0.1250,\n","         -0.0000, -0.3750, -0.1875,  0.0000,  0.0000,  0.2500, -0.1875, -0.1875,\n","         -0.2500,  0.0000,  0.0625,  0.3125, -0.1250, -0.0000,  0.0000, -0.1250,\n","          0.0000, -0.1875,  0.0000,  0.3750,  0.0625, -0.3750, -0.1250, -0.0000]],\n","       grad_fn=<SliceBackward0>)\n","Original weights:  tensor([[ 0.0102, -0.0170,  0.1119, -0.2880, -0.2641, -0.0412,  0.0696,  0.0662,\n","          0.0777, -0.3716,  0.1390, -0.4887, -0.2731,  0.1075, -0.0754, -0.2051],\n","        [-0.0367,  0.0315,  0.0134,  0.1614, -0.1598,  0.0765,  0.0509,  0.0754,\n","         -0.0604, -0.2775,  0.0597, -0.3762, -0.3182, -0.1542,  0.1087,  0.0592]],\n","       grad_fn=<SliceBackward0>)\n","Quantised weights:  tensor([[ 0.0000, -0.0000,  0.1250, -0.3125, -0.2500, -0.0625,  0.0625,  0.0625,\n","          0.0625, -0.3750,  0.1250, -0.5000, -0.2500,  0.1250, -0.0625, -0.1875],\n","        [-0.0625,  0.0625,  0.0000,  0.1875, -0.1875,  0.0625,  0.0625,  0.0625,\n","         -0.0625, -0.2500,  0.0625, -0.3750, -0.3125, -0.1250,  0.1250,  0.0625]],\n","       grad_fn=<SliceBackward0>)\n"]}],"source":["from chop.passes.graph.transforms.quantize.quantized_modules.linear import _LinearBase\n","\n","i = 0\n","for module_name, module_trans_name in zip(mg.modules, mg_trans.modules):\n","    module = mg.modules[module_name]\n","    module_trans = mg_trans.modules[module_trans_name]\n","\n","    if isinstance(module_trans, _LinearBase):\n","        print(\"Original weights: \", module.weight[:2])\n","        print(\"Quantised weights: \", module_trans.w_quantizer(module_trans.weight)[:2])\n","        i += 1\n","        \n","    if i == 3:\n","        break\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computations summary:\n","---------------------\n","| Node name     | Node type    |   Parameters |   Forward FLOPS |   Backward FLOPS |   Input buffer size |   Output buffer size |\n","|---------------|--------------|--------------|-----------------|------------------|---------------------|----------------------|\n","| x             | placeholder  |              |                 |                  |                     |                      |\n","| seq_blocks_0  | batch_norm1d |           32 |             512 |              512 |                 128 |                  128 |\n","| seq_blocks_1  | relu         |            0 |             128 |              128 |                 128 |                  128 |\n","| seq_blocks_2  | linear       |          512 |            4096 |             8192 |                 128 |                  256 |\n","| seq_blocks_3  | batch_norm1d |           64 |            1024 |             1024 |                 256 |                  256 |\n","| seq_blocks_4  | relu         |            0 |             256 |              256 |                 256 |                  256 |\n","| seq_blocks_5  | dropout      |            0 |               0 |                0 |                 256 |                  256 |\n","| seq_blocks_6  | linear       |          512 |            4096 |             8192 |                 256 |                  128 |\n","| seq_blocks_7  | batch_norm1d |           32 |             512 |              512 |                 128 |                  128 |\n","| seq_blocks_8  | relu         |            0 |             128 |              128 |                 128 |                  128 |\n","| seq_blocks_9  | dropout      |            0 |               0 |                0 |                 128 |                  128 |\n","| seq_blocks_10 | linear       |           80 |             640 |             1280 |                 128 |                   40 |\n","| seq_blocks_11 | batch_norm1d |           10 |             160 |              160 |                  40 |                   40 |\n","| seq_blocks_12 | relu         |            0 |              40 |               40 |                  40 |                   40 |\n","| output        | output       |              |                 |                  |                     |                      |\n"]}],"source":["from pprint import pprint\n","\n","from chop.passes.graph.analysis.flops.flops_pass import analyse_flops_pass\n","from chop.passes.graph.utils import get_mase_op\n","\n","analyse_flops_pass(mg)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[-0.6870,  0.6464, -0.2211, -0.5086, -0.2880, -0.4539, -0.3727, -0.5476,\n","         -0.3727,  0.0828,  0.2902, -0.1872,  0.0218, -0.4286, -0.2975,  0.4106],\n","        [ 0.5310,  0.2459,  0.0614, -0.0658, -0.3883, -0.3701, -1.1023, -0.8840,\n","         -1.1023, -1.5075, -1.5469, -1.2582, -1.6790, -1.2448,  0.2650, -1.0364],\n","        [-0.2012,  0.3965,  0.9537,  0.9707,  0.1673, -0.3228, -1.0676, -1.1820,\n","         -1.0676, -1.1923, -1.0395, -1.1846, -1.2158, -1.3171,  1.0332,  0.6035],\n","        [ 1.0630, -0.3592, -1.1664, -0.8446, -1.0724, -0.6250, -0.2240, -0.1673,\n","         -0.2240,  0.4029,  0.6315,  0.7814,  0.0869,  0.0549, -1.2494, -0.8917],\n","        [-1.5865,  0.9318,  1.4369,  1.5644,  2.3059,  2.4386,  0.9330,  0.8453,\n","          0.9330,  0.8588,  0.7322,  0.5232,  1.0754,  0.9757,  1.4826,  1.8575],\n","        [ 0.8153, -0.7495, -1.1809, -0.8461, -1.0941, -0.6264, -0.4208, -0.2742,\n","         -0.4208,  0.5012,  0.8880,  1.4151,  0.6015,  0.9140, -1.2530, -0.6023],\n","        [ 0.5671, -0.1916,  0.2416, -0.0074, -0.1003, -0.4123, -0.7554, -1.0181,\n","         -0.7554, -0.9070, -0.6038, -0.7224, -0.8519, -1.0699,  0.2722, -0.7952],\n","        [ 0.9186, -0.6290, -1.1730, -0.8452, -1.0618, -0.6231,  0.1172,  0.6232,\n","          0.1172,  0.8646,  0.8421,  1.1591,  0.5698,  0.7566, -1.2643, -0.9399]])}}}\n","{'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[-0.6870,  0.6464, -0.2211, -0.5086, -0.2880, -0.4539, -0.3727, -0.5476,\n","         -0.3727,  0.0828,  0.2902, -0.1872,  0.0218, -0.4286, -0.2975,  0.4106],\n","        [ 0.5310,  0.2459,  0.0614, -0.0658, -0.3883, -0.3701, -1.1023, -0.8840,\n","         -1.1023, -1.5075, -1.5469, -1.2582, -1.6790, -1.2448,  0.2650, -1.0364],\n","        [-0.2012,  0.3965,  0.9537,  0.9707,  0.1673, -0.3228, -1.0676, -1.1820,\n","         -1.0676, -1.1923, -1.0395, -1.1846, -1.2158, -1.3171,  1.0332,  0.6035],\n","        [ 1.0630, -0.3592, -1.1664, -0.8446, -1.0724, -0.6250, -0.2240, -0.1673,\n","         -0.2240,  0.4029,  0.6315,  0.7814,  0.0869,  0.0549, -1.2494, -0.8917],\n","        [-1.5865,  0.9318,  1.4369,  1.5644,  2.3059,  2.4386,  0.9330,  0.8453,\n","          0.9330,  0.8588,  0.7322,  0.5232,  1.0754,  0.9757,  1.4826,  1.8575],\n","        [ 0.8153, -0.7495, -1.1809, -0.8461, -1.0941, -0.6264, -0.4208, -0.2742,\n","         -0.4208,  0.5012,  0.8880,  1.4151,  0.6015,  0.9140, -1.2530, -0.6023],\n","        [ 0.5671, -0.1916,  0.2416, -0.0074, -0.1003, -0.4123, -0.7554, -1.0181,\n","         -0.7554, -0.9070, -0.6038, -0.7224, -0.8519, -1.0699,  0.2722, -0.7952],\n","        [ 0.9186, -0.6290, -1.1730, -0.8452, -1.0618, -0.6231,  0.1172,  0.6232,\n","          0.1172,  0.8646,  0.8421,  1.1591,  0.5698,  0.7566, -1.2643, -0.9399]])}, 'weight': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n","tensor([0.6499, 0.6326, 0.9923, 1.2061, 0.8360, 0.7412, 0.8345, 0.4282, 0.8453,\n","        0.7053, 0.6434, 0.6145, 0.4374, 0.5981, 1.3043, 0.6870],\n","       requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n","tensor([ 0.4082,  0.4055,  0.3804, -0.0823,  0.8921,  0.4982,  0.0887,  0.1179,\n","         0.1439,  0.0260,  0.1947,  0.3404,  0.9268,  0.1957,  0.1766,  0.9940],\n","       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 1.0803, 0.2854, 0.0000, 0.8150, 0.2479, 0.0738, 0.0000, 0.1288,\n","         0.1806, 0.3868, 0.1823, 1.0208, 0.0271, 0.0000, 1.4093],\n","        [0.6730, 0.6373, 0.5833, 0.0000, 0.7349, 0.3115, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.2037, 0.0000, 0.6840, 0.3818],\n","        [0.1244, 0.8038, 1.5245, 1.4017, 1.1785, 0.3475, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.4262, 0.0000, 1.6797, 1.5463],\n","        [1.0716, 0.0000, 0.0000, 0.0000, 0.1887, 0.1178, 0.2722, 0.2153, 0.3298,\n","         0.4346, 0.6333, 0.7875, 1.0521, 0.3421, 0.0000, 0.4846],\n","        [0.0000, 1.3960, 2.0343, 2.2460, 2.8860, 2.4457, 1.8158, 0.8385, 1.8934,\n","         0.7963, 0.7060, 0.6262, 1.5270, 0.9420, 2.2623, 2.4369],\n","        [0.8860, 0.0000, 0.0000, 0.0000, 0.1714, 0.1168, 0.0097, 0.1495, 0.0639,\n","         0.5126, 0.8185, 1.1835, 1.2993, 0.9018, 0.0000, 0.6901],\n","        [0.7000, 0.1532, 0.7735, 0.0107, 0.9649, 0.2794, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.6010, 0.0000, 0.6933, 0.5531],\n","        [0.9634, 0.0000, 0.0000, 0.0000, 0.1972, 0.1193, 0.7274, 0.7018, 0.7908,\n","         0.8010, 0.7854, 1.0235, 1.2840, 0.7993, 0.0000, 0.4503]],\n","       grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0000, 1.0803, 0.2854, 0.0000, 0.8150, 0.2479, 0.0738, 0.0000, 0.1288,\n","         0.1806, 0.3868, 0.1823, 1.0208, 0.0271, 0.0000, 1.4093],\n","        [0.6730, 0.6373, 0.5833, 0.0000, 0.7349, 0.3115, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.2037, 0.0000, 0.6840, 0.3818],\n","        [0.1244, 0.8038, 1.5245, 1.4017, 1.1785, 0.3475, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.4262, 0.0000, 1.6797, 1.5463],\n","        [1.0716, 0.0000, 0.0000, 0.0000, 0.1887, 0.1178, 0.2722, 0.2153, 0.3298,\n","         0.4346, 0.6333, 0.7875, 1.0521, 0.3421, 0.0000, 0.4846],\n","        [0.0000, 1.3960, 2.0343, 2.2460, 2.8860, 2.4457, 1.8158, 0.8385, 1.8934,\n","         0.7963, 0.7060, 0.6262, 1.5270, 0.9420, 2.2623, 2.4369],\n","        [0.8860, 0.0000, 0.0000, 0.0000, 0.1714, 0.1168, 0.0097, 0.1495, 0.0639,\n","         0.5126, 0.8185, 1.1835, 1.2993, 0.9018, 0.0000, 0.6901],\n","        [0.7000, 0.1532, 0.7735, 0.0107, 0.9649, 0.2794, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.6010, 0.0000, 0.6933, 0.5531],\n","        [0.9634, 0.0000, 0.0000, 0.0000, 0.1972, 0.1193, 0.7274, 0.7018, 0.7908,\n","         0.8010, 0.7854, 1.0235, 1.2840, 0.7993, 0.0000, 0.4503]],\n","       grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 1.0803, 0.2854, 0.0000, 0.8150, 0.2479, 0.0738, 0.0000, 0.1288,\n","         0.1806, 0.3868, 0.1823, 1.0208, 0.0271, 0.0000, 1.4093],\n","        [0.6730, 0.6373, 0.5833, 0.0000, 0.7349, 0.3115, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.2037, 0.0000, 0.6840, 0.3818],\n","        [0.1244, 0.8038, 1.5245, 1.4017, 1.1785, 0.3475, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.4262, 0.0000, 1.6797, 1.5463],\n","        [1.0716, 0.0000, 0.0000, 0.0000, 0.1887, 0.1178, 0.2722, 0.2153, 0.3298,\n","         0.4346, 0.6333, 0.7875, 1.0521, 0.3421, 0.0000, 0.4846],\n","        [0.0000, 1.3960, 2.0343, 2.2460, 2.8860, 2.4457, 1.8158, 0.8385, 1.8934,\n","         0.7963, 0.7060, 0.6262, 1.5270, 0.9420, 2.2623, 2.4369],\n","        [0.8860, 0.0000, 0.0000, 0.0000, 0.1714, 0.1168, 0.0097, 0.1495, 0.0639,\n","         0.5126, 0.8185, 1.1835, 1.2993, 0.9018, 0.0000, 0.6901],\n","        [0.7000, 0.1532, 0.7735, 0.0107, 0.9649, 0.2794, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.6010, 0.0000, 0.6933, 0.5531],\n","        [0.9634, 0.0000, 0.0000, 0.0000, 0.1972, 0.1193, 0.7274, 0.7018, 0.7908,\n","         0.8010, 0.7854, 1.0235, 1.2840, 0.7993, 0.0000, 0.4503]],\n","       grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0000, 1.0803, 0.2854, 0.0000, 0.8150, 0.2479, 0.0738, 0.0000, 0.1288,\n","         0.1806, 0.3868, 0.1823, 1.0208, 0.0271, 0.0000, 1.4093],\n","        [0.6730, 0.6373, 0.5833, 0.0000, 0.7349, 0.3115, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.2037, 0.0000, 0.6840, 0.3818],\n","        [0.1244, 0.8038, 1.5245, 1.4017, 1.1785, 0.3475, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.4262, 0.0000, 1.6797, 1.5463],\n","        [1.0716, 0.0000, 0.0000, 0.0000, 0.1887, 0.1178, 0.2722, 0.2153, 0.3298,\n","         0.4346, 0.6333, 0.7875, 1.0521, 0.3421, 0.0000, 0.4846],\n","        [0.0000, 1.3960, 2.0343, 2.2460, 2.8860, 2.4457, 1.8158, 0.8385, 1.8934,\n","         0.7963, 0.7060, 0.6262, 1.5270, 0.9420, 2.2623, 2.4369],\n","        [0.8860, 0.0000, 0.0000, 0.0000, 0.1714, 0.1168, 0.0097, 0.1495, 0.0639,\n","         0.5126, 0.8185, 1.1835, 1.2993, 0.9018, 0.0000, 0.6901],\n","        [0.7000, 0.1532, 0.7735, 0.0107, 0.9649, 0.2794, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.6010, 0.0000, 0.6933, 0.5531],\n","        [0.9634, 0.0000, 0.0000, 0.0000, 0.1972, 0.1193, 0.7274, 0.7018, 0.7908,\n","         0.8010, 0.7854, 1.0235, 1.2840, 0.7993, 0.0000, 0.4503]],\n","       grad_fn=<ReluBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [32, 16], 'from': None, 'value': Parameter containing:\n","tensor([[ 2.5465e-02,  1.0900e-01,  3.5937e-02,  2.0544e-01,  1.7491e-01,\n","          1.3672e-02, -3.0854e-02,  1.1425e-02, -6.3719e-02,  5.1197e-02,\n","          1.8315e-02, -4.1201e-03, -6.8110e-02, -8.9010e-02, -5.7691e-01,\n","         -1.2345e-01],\n","        [ 5.5802e-02,  1.8185e-01, -3.2607e-01,  7.0786e-02, -1.0326e-01,\n","          7.5588e-02, -1.4527e-02,  2.8503e-02, -1.3385e-03,  4.3884e-02,\n","          1.0166e-01, -2.0768e-01,  8.4658e-02,  7.5627e-04,  6.2070e-02,\n","          3.4681e-01],\n","        [-4.1306e-02, -1.6481e-03, -1.5721e-01, -4.1798e-01, -1.1776e-01,\n","          5.8624e-02,  5.0797e-02, -2.6932e-03, -4.4188e-02, -1.6415e-02,\n","          5.3251e-02, -2.5787e-02, -1.4654e-02,  4.9622e-02,  3.8900e-01,\n","          5.4066e-02],\n","        [-4.3542e-03, -1.7342e-02,  2.3883e-01,  1.5665e-01,  1.2554e-01,\n","          4.4233e-02,  6.2806e-02, -7.5783e-02, -4.4155e-02, -3.1396e-02,\n","          7.3830e-03, -3.7231e-02, -1.4130e-01,  5.9846e-02, -3.6178e-01,\n","          2.7435e-02],\n","        [-2.9354e-02,  6.0747e-02,  6.8532e-03, -1.1165e-01,  1.2931e-01,\n","          1.7682e-01, -2.1831e-01, -1.3745e-01,  6.6865e-02, -7.2002e-03,\n","         -6.7153e-02,  2.7089e-01,  1.2090e-01, -1.4560e-01,  2.0390e-01,\n","         -2.4133e-01],\n","        [ 6.5899e-02,  1.3191e-01,  1.0288e-01, -6.1442e-01,  6.7814e-02,\n","         -2.5995e-01, -7.1195e-02,  4.7712e-02,  6.4884e-02, -1.6864e-01,\n","          9.9301e-02,  5.2477e-03,  1.0722e-01, -2.7128e-02,  1.0134e-01,\n","         -2.0091e-01],\n","        [ 7.8232e-02,  1.0817e-01,  4.0022e-02, -4.9405e-01,  1.8830e-01,\n","         -2.7527e-01,  5.5002e-02, -5.4140e-02, -8.1125e-02,  8.9319e-02,\n","          8.1974e-02, -1.2083e-01,  3.2930e-02,  6.7603e-02,  7.8245e-02,\n","         -1.6778e-01],\n","        [ 4.8672e-02,  3.6819e-02,  1.4918e-01, -5.3384e-01,  2.1075e-01,\n","         -1.4990e-01, -4.9344e-02,  3.6597e-02,  1.7345e-02,  4.6042e-02,\n","         -1.1471e-02, -2.0214e-02, -5.2991e-02,  1.4754e-03,  6.4455e-03,\n","         -7.6697e-02],\n","        [ 1.8036e-02,  1.0785e-01, -2.5681e-01, -4.6300e-02, -1.6089e-01,\n","          5.8199e-02,  7.5769e-02,  2.1286e-02, -9.6097e-02,  4.2963e-03,\n","         -2.6242e-02, -2.1901e-02,  7.4353e-02, -5.9882e-03,  2.7555e-01,\n","          1.3249e-01],\n","        [-6.0573e-02, -3.7526e-02, -7.5065e-02, -3.9348e-01, -1.3162e-01,\n","         -3.0575e-01, -6.2369e-02, -1.3973e-01,  1.0075e-01, -1.7650e-02,\n","          1.3500e-01, -2.3846e-01,  2.1795e-01, -2.1928e-01, -4.0250e-02,\n","         -1.5727e-01],\n","        [-2.7336e-02, -5.0682e-02, -7.9674e-02,  1.3670e-02, -2.4749e-01,\n","          1.2969e-03,  5.9311e-02,  7.2133e-02, -6.3938e-02, -6.1870e-02,\n","          1.9309e-01, -1.2186e-01,  2.5023e-01,  1.8378e-02, -4.1597e-01,\n","         -1.4006e-01],\n","        [-6.4346e-02, -2.8988e-02, -6.7079e-02, -1.0915e-01,  2.4968e-02,\n","          6.4404e-03,  3.8061e-02, -5.7095e-02, -2.1713e-02,  5.7092e-02,\n","         -1.0124e-01, -2.8207e-02, -1.6488e-01,  9.2638e-02,  4.9007e-01,\n","          1.7789e-01],\n","        [-2.3144e-01, -1.7938e-01,  5.7265e-02, -6.1340e-01,  5.0828e-02,\n","         -4.9878e-02, -7.8107e-02, -6.3137e-02,  8.9785e-02,  4.9747e-02,\n","         -7.1577e-02, -2.7558e-02, -1.1243e-01,  1.0324e-01,  1.3635e-02,\n","         -1.1251e-01],\n","        [-3.3229e-04,  7.4552e-03,  8.7113e-02, -2.0801e-01,  1.9469e-01,\n","         -1.1175e-01,  8.6125e-02,  8.8045e-03, -9.9052e-02, -5.2357e-02,\n","          7.4488e-02, -5.8304e-02, -1.2424e-01,  8.4134e-02,  6.2233e-02,\n","         -2.7591e-02],\n","        [-5.3797e-02, -4.7521e-02, -1.6573e-01, -1.7350e-02, -2.4272e-01,\n","         -1.1963e-01,  2.7522e-03,  9.1779e-02,  1.8561e-02,  1.4440e-01,\n","          1.2517e-01, -1.1177e-01,  2.2462e-01, -1.2833e-01, -3.5539e-01,\n","         -1.1897e-01],\n","        [ 5.7472e-02,  1.4420e-01, -3.3391e-02,  2.4637e-01,  3.3166e-02,\n","         -1.4497e-01,  8.7306e-02, -2.9661e-02, -1.0071e-01, -7.6003e-02,\n","         -9.2606e-02,  1.2635e-02,  1.8822e-01, -5.6699e-02, -4.4157e-01,\n","         -1.8486e-01],\n","        [-2.6538e-02, -1.1291e-02, -1.4486e-01, -1.0876e-01, -3.4792e-01,\n","          1.3705e-02,  3.9695e-02,  5.4918e-02, -1.3755e-02, -9.2272e-02,\n","          2.0267e-02,  6.6069e-02,  3.1254e-01, -5.9067e-02, -1.8886e-01,\n","         -1.3739e-01],\n","        [-1.9579e-01, -1.2164e-01,  4.0350e-02, -5.6134e-01,  2.2107e-01,\n","         -3.2969e-01, -3.5661e-02,  7.3416e-02,  1.0017e-02, -4.4083e-02,\n","         -5.7552e-02,  1.1400e-01, -1.3335e-01,  1.5272e-02, -3.4397e-02,\n","         -9.6177e-02],\n","        [-5.0619e-02, -3.5383e-02,  6.5894e-02,  9.4851e-02,  1.4650e-01,\n","         -1.1166e-02, -1.2451e-01, -4.5650e-02,  1.0435e-01, -5.0966e-02,\n","          9.0386e-02, -9.9541e-02, -1.3840e-01,  9.6137e-02, -3.0050e-01,\n","         -1.3379e-02],\n","        [ 1.2299e-02,  4.5988e-03,  1.4575e-01, -1.6133e-01,  1.8501e-01,\n","         -7.1795e-02, -1.5949e-01,  5.3178e-03,  1.4692e-01, -4.0827e-02,\n","         -7.7019e-04,  9.0827e-03, -1.3390e-01,  2.9091e-02, -2.3741e-02,\n","         -3.0538e-03],\n","        [ 2.3901e-01,  1.7191e-01, -8.7651e-02,  1.5374e-01,  1.4422e-01,\n","          8.9166e-02, -6.0960e-03, -1.1840e-01, -5.3946e-02, -1.2139e-02,\n","         -3.5703e-03, -4.8683e-02,  3.2771e-01,  2.4507e-02, -3.2748e-01,\n","         -7.4024e-02],\n","        [-3.4665e-02,  4.3233e-02, -1.3848e-01,  1.9900e-01,  2.3376e-02,\n","          5.0643e-02,  1.8004e-01, -5.4953e-03, -1.7496e-01,  3.8871e-02,\n","         -1.3320e-01,  7.5403e-02, -2.1708e-01,  2.8432e-02,  5.7308e-01,\n","          2.1760e-01],\n","        [-1.6817e-01,  8.5859e-02,  2.5180e-01, -1.4865e-01, -3.9585e-02,\n","          2.0817e-01, -5.7691e-02,  3.1414e-03, -5.4299e-02, -2.0680e-01,\n","         -1.7001e-01,  2.5066e-01, -1.5247e-01,  6.2013e-02, -3.2611e-02,\n","         -2.1019e-01],\n","        [ 3.1685e-02,  1.8367e-02, -3.8556e-01,  2.7292e-01, -2.3262e-01,\n","          5.2352e-02, -2.0643e-01,  5.4488e-03,  2.3274e-01,  6.7421e-02,\n","         -4.5090e-03,  2.6492e-02,  9.8944e-02, -6.0096e-02,  1.2555e-01,\n","          7.7154e-02],\n","        [ 4.9636e-02,  4.0012e-02,  2.1499e-01,  4.9156e-02,  1.8269e-01,\n","          1.1042e-01,  8.3310e-02, -1.3438e-01, -7.4771e-02,  6.4991e-02,\n","         -1.8000e-01,  9.4625e-02, -2.2603e-01, -1.9832e-02, -2.8844e-01,\n","          7.6347e-02],\n","        [ 2.8446e-02,  3.1486e-02, -8.9107e-02,  3.8921e-01, -3.1211e-02,\n","         -1.4124e-02,  1.5756e-01,  2.2849e-02, -1.6888e-01,  5.1577e-02,\n","         -2.3984e-02, -1.7563e-02,  8.1085e-02, -5.5338e-02, -4.4670e-01,\n","          3.8605e-02],\n","        [-1.7853e-02, -3.6443e-02,  1.9716e-02,  3.2392e-01,  5.5187e-02,\n","          4.2250e-02, -6.3142e-02, -2.9938e-03,  4.6211e-02, -2.3000e-01,\n","          1.3695e-02, -1.2307e-01, -1.0252e-01,  1.4218e-02, -2.4407e-01,\n","          4.4666e-02],\n","        [ 1.8290e-01,  2.9053e-01, -2.9243e-01,  3.5660e-01, -2.4853e-01,\n","          2.1237e-02,  1.9738e-01,  2.5528e-02, -1.7199e-01, -1.0003e-01,\n","          7.5288e-02, -1.4514e-02,  1.2693e-01,  1.6075e-03, -3.5286e-01,\n","          9.6130e-02],\n","        [-8.2909e-02, -1.9383e-02,  2.8219e-01, -1.3203e-01,  1.6959e-01,\n","          8.4521e-02, -1.5870e-01,  6.7985e-02,  2.4805e-02,  2.1783e-02,\n","         -1.2824e-01,  1.4339e-01, -4.2083e-01, -2.7157e-02, -1.3953e-01,\n","         -4.0431e-02],\n","        [-4.3069e-02,  1.4003e-02, -1.5222e-01, -3.8285e-01, -1.8173e-01,\n","         -8.1889e-02,  1.4468e-02,  6.2765e-02,  3.8714e-02, -1.9429e-01,\n","          9.3848e-02, -1.4794e-01, -3.3606e-02,  5.8916e-02, -3.5972e-01,\n","         -3.1463e-01],\n","        [ 3.8499e-02,  1.1114e-01, -3.6240e-01,  1.0338e-01, -1.0672e-01,\n","          2.8415e-02,  6.4245e-02,  3.2755e-02, -8.2564e-02, -1.2097e-03,\n","         -4.2123e-02,  3.3899e-03,  1.2313e-01, -7.4904e-02,  1.6690e-01,\n","          1.6146e-01],\n","        [-1.6484e-01, -8.4108e-02, -1.5677e-02,  1.0382e-01, -3.8364e-01,\n","          2.3694e-01,  8.6645e-03, -2.4851e-02,  1.0282e-01, -2.4928e-02,\n","          3.9266e-02,  5.2803e-02, -1.4529e-01,  1.9941e-02,  1.1712e-02,\n","          3.3057e-01]], requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [32], 'from': None, 'value': Parameter containing:\n","tensor([-0.0557, -0.1041,  0.0782,  0.1282, -0.1335,  0.0100,  0.1255, -0.0578,\n","         0.0658, -0.0103,  0.0530, -0.1177, -0.1602, -0.1773,  0.2122, -0.0727,\n","        -0.0074, -0.1288,  0.2547,  0.2312, -0.1523, -0.1947, -0.1806, -0.0086,\n","        -0.0462, -0.1504, -0.0850,  0.0722, -0.1210,  0.0513, -0.0198, -0.0975],\n","       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 32], 'torch_dtype': torch.float32, 'value': tensor([[-2.2595e-02,  5.1723e-01,  2.3712e-02,  1.7629e-01, -1.2274e-01,\n","          1.0236e-02,  1.5743e-01, -4.2273e-03,  2.3468e-01, -2.4649e-01,\n","         -1.2994e-01, -9.5253e-02, -5.9701e-01, -1.7454e-01,  9.0902e-04,\n","         -5.9014e-02, -2.1289e-01, -4.3231e-01,  2.0619e-01,  2.7169e-01,\n","          3.5905e-01, -1.1009e-01, -5.1547e-01, -3.7295e-02,  6.6841e-02,\n","         -4.8395e-02, -1.6196e-01,  3.7126e-01, -4.1756e-01, -6.4121e-01,\n","          2.4633e-01, -9.4435e-02],\n","        [-2.7094e-01, -1.0782e-03,  1.7312e-01,  9.3804e-02,  1.1152e-01,\n","          1.8170e-01,  3.1925e-01,  1.5795e-01,  1.5101e-01, -3.5389e-01,\n","         -5.1271e-01,  1.7131e-01, -4.3158e-01, -6.9804e-03, -4.0940e-01,\n","         -3.1661e-01, -4.8634e-01, -3.4223e-01,  1.0182e-01,  3.9635e-01,\n","          1.5239e-02,  1.9250e-01, -1.9003e-01, -2.1965e-01,  9.2570e-02,\n","         -4.6481e-01, -2.2575e-01, -1.4494e-01, -7.0156e-02, -5.8958e-01,\n","         -3.1543e-03, -3.7468e-01],\n","        [-6.0025e-01,  2.3233e-01, -1.4144e-01,  2.3523e-01,  2.9723e-04,\n","         -6.8536e-01, -3.9702e-01, -4.7709e-01,  2.2840e-01, -1.1932e+00,\n","         -1.1933e+00,  6.5539e-01, -1.2621e+00, -1.3060e-01, -1.1225e+00,\n","         -6.1379e-01, -1.1948e+00, -1.0936e+00,  3.7662e-02,  3.2391e-01,\n","         -2.2644e-01,  1.1552e+00, -3.7607e-01, -7.8741e-02,  1.7967e-01,\n","         -4.0963e-01,  6.2743e-02, -2.9293e-01, -1.4875e-01, -2.0592e+00,\n","          1.3333e-01,  3.5156e-02],\n","        [-1.5207e-01,  1.2414e-01,  5.1358e-02, -1.4534e-02, -5.8564e-02,\n","          7.4937e-02,  1.6107e-01, -7.8965e-02,  1.6356e-01, -1.8177e-01,\n","          1.8881e-01, -3.0733e-01, -5.9261e-01, -2.9822e-01,  3.1001e-01,\n","         -3.0399e-02,  1.8501e-01, -4.7386e-01,  5.4932e-02,  1.3354e-01,\n","          3.6801e-01, -3.5267e-01, -6.1786e-01,  1.7757e-01, -1.9526e-01,\n","         -5.6908e-02, -3.6085e-01,  3.9977e-01, -6.1869e-01, -3.1771e-01,\n","          1.5959e-01, -2.1792e-01],\n","        [-7.4056e-01,  6.1948e-01, -3.2831e-01,  4.2499e-01,  1.7216e-01,\n","         -1.5661e+00, -1.0452e+00, -9.2234e-01,  2.6680e-01, -2.6825e+00,\n","         -1.6853e+00,  8.6216e-01, -2.0178e+00, -2.5459e-01, -1.8447e+00,\n","         -1.0352e+00, -1.7989e+00, -2.1357e+00,  8.7356e-03,  2.5758e-01,\n","          2.3605e-01,  1.7194e+00, -5.8053e-01,  6.3720e-03,  4.0535e-01,\n","         -3.8433e-01,  2.7716e-02, -3.3158e-01, -4.2433e-01, -3.4286e+00,\n","          2.3952e-01,  3.1817e-01],\n","        [-2.2182e-01,  1.5044e-01,  9.3230e-02, -2.7338e-02, -1.3903e-02,\n","          3.7452e-02,  1.4006e-01, -1.2014e-01,  1.9627e-01, -3.4111e-01,\n","          2.2091e-01, -2.7413e-01, -5.6315e-01, -3.0095e-01,  2.6209e-01,\n","         -7.6946e-02,  2.2428e-01, -4.5231e-01,  5.9920e-02,  1.1339e-01,\n","          4.0343e-01, -3.3190e-01, -5.5136e-01,  1.8922e-01, -2.4300e-01,\n","         -6.9952e-02, -4.2640e-01,  4.1480e-01, -6.6857e-01, -4.2104e-01,\n","          1.7235e-01, -1.3949e-01],\n","        [-3.2777e-01, -8.1416e-02,  1.1654e-01,  1.2182e-01,  1.1411e-01,\n","          1.6570e-01,  3.0855e-01,  1.8325e-01,  6.5887e-02, -3.1702e-01,\n","         -4.8931e-01,  1.4473e-01, -3.9717e-01, -1.4012e-03, -4.0597e-01,\n","         -3.3729e-01, -4.9187e-01, -2.9531e-01,  1.0510e-01,  4.1136e-01,\n","          6.8245e-02,  1.0653e-01, -3.0249e-01, -2.9958e-01,  7.5011e-02,\n","         -4.6413e-01, -2.2540e-01, -3.2667e-01, -1.4989e-01, -7.4031e-01,\n","         -7.1055e-02, -4.3712e-01],\n","        [-2.2288e-01,  1.1462e-01,  6.9788e-02, -6.7102e-02, -1.6863e-01,\n","          6.2634e-02,  1.7605e-01, -7.7967e-02,  1.6327e-01, -3.1320e-01,\n","          2.7148e-01, -3.2375e-01, -5.6629e-01, -3.0991e-01,  4.1115e-01,\n","         -7.2542e-02,  2.5848e-01, -4.4586e-01,  1.4742e-02,  1.0081e-01,\n","          3.3153e-01, -3.8308e-01, -6.9175e-01,  2.1135e-01, -3.0621e-01,\n","         -5.2007e-02, -4.9730e-01,  3.9915e-01, -7.2222e-01, -3.2163e-01,\n","          1.4442e-01, -1.9033e-01]], grad_fn=<AddmmBackward0>)}}}\n","{'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [8, 32], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[-2.2595e-02,  5.1723e-01,  2.3712e-02,  1.7629e-01, -1.2274e-01,\n","          1.0236e-02,  1.5743e-01, -4.2273e-03,  2.3468e-01, -2.4649e-01,\n","         -1.2994e-01, -9.5253e-02, -5.9701e-01, -1.7454e-01,  9.0902e-04,\n","         -5.9014e-02, -2.1289e-01, -4.3231e-01,  2.0619e-01,  2.7169e-01,\n","          3.5905e-01, -1.1009e-01, -5.1547e-01, -3.7295e-02,  6.6841e-02,\n","         -4.8395e-02, -1.6196e-01,  3.7126e-01, -4.1756e-01, -6.4121e-01,\n","          2.4633e-01, -9.4435e-02],\n","        [-2.7094e-01, -1.0782e-03,  1.7312e-01,  9.3804e-02,  1.1152e-01,\n","          1.8170e-01,  3.1925e-01,  1.5795e-01,  1.5101e-01, -3.5389e-01,\n","         -5.1271e-01,  1.7131e-01, -4.3158e-01, -6.9804e-03, -4.0940e-01,\n","         -3.1661e-01, -4.8634e-01, -3.4223e-01,  1.0182e-01,  3.9635e-01,\n","          1.5239e-02,  1.9250e-01, -1.9003e-01, -2.1965e-01,  9.2570e-02,\n","         -4.6481e-01, -2.2575e-01, -1.4494e-01, -7.0156e-02, -5.8958e-01,\n","         -3.1543e-03, -3.7468e-01],\n","        [-6.0025e-01,  2.3233e-01, -1.4144e-01,  2.3523e-01,  2.9723e-04,\n","         -6.8536e-01, -3.9702e-01, -4.7709e-01,  2.2840e-01, -1.1932e+00,\n","         -1.1933e+00,  6.5539e-01, -1.2621e+00, -1.3060e-01, -1.1225e+00,\n","         -6.1379e-01, -1.1948e+00, -1.0936e+00,  3.7662e-02,  3.2391e-01,\n","         -2.2644e-01,  1.1552e+00, -3.7607e-01, -7.8741e-02,  1.7967e-01,\n","         -4.0963e-01,  6.2743e-02, -2.9293e-01, -1.4875e-01, -2.0592e+00,\n","          1.3333e-01,  3.5156e-02],\n","        [-1.5207e-01,  1.2414e-01,  5.1358e-02, -1.4534e-02, -5.8564e-02,\n","          7.4937e-02,  1.6107e-01, -7.8965e-02,  1.6356e-01, -1.8177e-01,\n","          1.8881e-01, -3.0733e-01, -5.9261e-01, -2.9822e-01,  3.1001e-01,\n","         -3.0399e-02,  1.8501e-01, -4.7386e-01,  5.4932e-02,  1.3354e-01,\n","          3.6801e-01, -3.5267e-01, -6.1786e-01,  1.7757e-01, -1.9526e-01,\n","         -5.6908e-02, -3.6085e-01,  3.9977e-01, -6.1869e-01, -3.1771e-01,\n","          1.5959e-01, -2.1792e-01],\n","        [-7.4056e-01,  6.1948e-01, -3.2831e-01,  4.2499e-01,  1.7216e-01,\n","         -1.5661e+00, -1.0452e+00, -9.2234e-01,  2.6680e-01, -2.6825e+00,\n","         -1.6853e+00,  8.6216e-01, -2.0178e+00, -2.5459e-01, -1.8447e+00,\n","         -1.0352e+00, -1.7989e+00, -2.1357e+00,  8.7356e-03,  2.5758e-01,\n","          2.3605e-01,  1.7194e+00, -5.8053e-01,  6.3720e-03,  4.0535e-01,\n","         -3.8433e-01,  2.7716e-02, -3.3158e-01, -4.2433e-01, -3.4286e+00,\n","          2.3952e-01,  3.1817e-01],\n","        [-2.2182e-01,  1.5044e-01,  9.3230e-02, -2.7338e-02, -1.3903e-02,\n","          3.7452e-02,  1.4006e-01, -1.2014e-01,  1.9627e-01, -3.4111e-01,\n","          2.2091e-01, -2.7413e-01, -5.6315e-01, -3.0095e-01,  2.6209e-01,\n","         -7.6946e-02,  2.2428e-01, -4.5231e-01,  5.9920e-02,  1.1339e-01,\n","          4.0343e-01, -3.3190e-01, -5.5136e-01,  1.8922e-01, -2.4300e-01,\n","         -6.9952e-02, -4.2640e-01,  4.1480e-01, -6.6857e-01, -4.2104e-01,\n","          1.7235e-01, -1.3949e-01],\n","        [-3.2777e-01, -8.1416e-02,  1.1654e-01,  1.2182e-01,  1.1411e-01,\n","          1.6570e-01,  3.0855e-01,  1.8325e-01,  6.5887e-02, -3.1702e-01,\n","         -4.8931e-01,  1.4473e-01, -3.9717e-01, -1.4012e-03, -4.0597e-01,\n","         -3.3729e-01, -4.9187e-01, -2.9531e-01,  1.0510e-01,  4.1136e-01,\n","          6.8245e-02,  1.0653e-01, -3.0249e-01, -2.9958e-01,  7.5011e-02,\n","         -4.6413e-01, -2.2540e-01, -3.2667e-01, -1.4989e-01, -7.4031e-01,\n","         -7.1055e-02, -4.3712e-01],\n","        [-2.2288e-01,  1.1462e-01,  6.9788e-02, -6.7102e-02, -1.6863e-01,\n","          6.2634e-02,  1.7605e-01, -7.7967e-02,  1.6327e-01, -3.1320e-01,\n","          2.7148e-01, -3.2375e-01, -5.6629e-01, -3.0991e-01,  4.1115e-01,\n","         -7.2542e-02,  2.5848e-01, -4.4586e-01,  1.4742e-02,  1.0081e-01,\n","          3.3153e-01, -3.8308e-01, -6.9175e-01,  2.1135e-01, -3.0621e-01,\n","         -5.2007e-02, -4.9730e-01,  3.9915e-01, -7.2222e-01, -3.2163e-01,\n","          1.4442e-01, -1.9033e-01]], grad_fn=<AddmmBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [32], 'from': None, 'value': Parameter containing:\n","tensor([0.9331, 0.8323, 0.8508, 0.9282, 0.7183, 0.9347, 0.8385, 0.9666, 0.8621,\n","        0.9143, 0.9633, 0.9199, 0.9489, 0.7433, 0.8435, 0.9560, 0.9370, 0.9641,\n","        0.8465, 0.7527, 0.7311, 0.8696, 0.8492, 0.9184, 0.8128, 0.9521, 1.0206,\n","        0.9148, 0.8402, 0.8913, 0.8861, 0.8171], requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [32], 'from': None, 'value': Parameter containing:\n","tensor([-0.2897, -0.3373, -0.2873, -0.2339, -0.7109, -0.4166, -0.3315, -0.5181,\n","        -0.1605, -0.3884, -0.0584, -0.2339, -0.3211, -0.7258,  0.0039, -0.3690,\n","        -0.0026, -0.3436, -0.4347, -0.6235, -0.2941,  0.0243, -0.2849, -0.0649,\n","        -0.2392, -0.4345, -0.0666, -0.3910, -0.4413, -0.4306, -0.2189,  0.0860],\n","       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 32], 'torch_dtype': torch.float32, 'value': tensor([[9.6061e-01, 7.9130e-01, 0.0000e+00, 1.2248e-01, 0.0000e+00, 0.0000e+00,\n","         1.1775e-02, 0.0000e+00, 5.8855e-01, 1.3039e-01, 3.5518e-01, 0.0000e+00,\n","         5.3394e-02, 0.0000e+00, 4.0503e-01, 3.8082e-01, 3.0599e-01, 1.1072e-01,\n","         1.4306e+00, 0.0000e+00, 2.8412e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.5131e-01, 2.7982e-01, 4.4445e-01, 0.0000e+00, 0.0000e+00,\n","         7.9163e-01, 2.4473e-01],\n","        [0.0000e+00, 0.0000e+00, 6.3382e-01, 0.0000e+00, 0.0000e+00, 2.3045e-01,\n","         3.2058e-01, 3.9977e-01, 0.0000e+00, 8.5134e-03, 0.0000e+00, 0.0000e+00,\n","         3.5347e-01, 3.7445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5869e-01,\n","         0.0000e+00, 3.1764e-01, 0.0000e+00, 0.0000e+00, 1.2373e+00, 0.0000e+00,\n","         6.1122e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2421e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8224e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 4.9611e-01, 0.0000e+00, 0.0000e+00, 9.6979e-01,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1069e+00, 2.5455e-01, 0.0000e+00,\n","         3.7554e-01, 0.0000e+00, 1.4972e+00, 0.0000e+00, 4.4858e-01, 0.0000e+00,\n","         0.0000e+00, 7.2148e-01],\n","        [4.1602e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6230e-02,\n","         1.8735e-02, 0.0000e+00, 0.0000e+00, 2.0383e-01, 8.1571e-01, 0.0000e+00,\n","         6.1368e-02, 0.0000e+00, 7.5858e-01, 4.6375e-01, 8.4749e-01, 4.2466e-02,\n","         0.0000e+00, 0.0000e+00, 3.1561e-01, 0.0000e+00, 0.0000e+00, 8.7674e-01,\n","         0.0000e+00, 5.0836e-01, 0.0000e+00, 5.2125e-01, 0.0000e+00, 2.1123e-01,\n","         5.2919e-02, 0.0000e+00],\n","        [0.0000e+00, 1.1662e+00, 0.0000e+00, 1.6404e+00, 3.5626e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.0607e+00, 0.0000e+00, 0.0000e+00, 1.4213e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7812e+00, 0.0000e+00, 1.9248e-04,\n","         1.1902e+00, 0.0000e+00, 1.3074e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.3366e-01, 1.7626e+00],\n","        [1.2264e-01, 0.0000e+00, 1.9017e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.3853e-02, 2.3017e-02, 8.6209e-01, 0.0000e+00,\n","         1.1482e-01, 0.0000e+00, 7.0377e-01, 3.2885e-01, 9.0093e-01, 7.7870e-02,\n","         0.0000e+00, 0.0000e+00, 4.4000e-01, 0.0000e+00, 0.0000e+00, 9.3639e-01,\n","         0.0000e+00, 4.4255e-01, 0.0000e+00, 5.6173e-01, 0.0000e+00, 1.2246e-01,\n","         1.6162e-01, 7.8999e-02],\n","        [0.0000e+00, 0.0000e+00, 3.1961e-01, 0.0000e+00, 0.0000e+00, 2.0434e-01,\n","         3.0016e-01, 4.7116e-01, 0.0000e+00, 5.0356e-02, 0.0000e+00, 0.0000e+00,\n","         4.1588e-01, 4.0901e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3575e-01,\n","         8.0471e-03, 4.1487e-01, 0.0000e+00, 0.0000e+00, 6.4327e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4459e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1817e-01, 0.0000e+00, 5.9984e-02, 0.0000e+00, 0.0000e+00, 3.6155e-02,\n","         4.7304e-02, 0.0000e+00, 0.0000e+00, 5.4684e-02, 9.3514e-01, 0.0000e+00,\n","         1.0911e-01, 0.0000e+00, 8.7426e-01, 3.4161e-01, 9.4748e-01, 8.8469e-02,\n","         0.0000e+00, 0.0000e+00, 1.8749e-01, 0.0000e+00, 0.0000e+00, 1.0497e+00,\n","         0.0000e+00, 5.3309e-01, 0.0000e+00, 5.1958e-01, 0.0000e+00, 2.0786e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [8, 32], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[9.6061e-01, 7.9130e-01, 0.0000e+00, 1.2248e-01, 0.0000e+00, 0.0000e+00,\n","         1.1775e-02, 0.0000e+00, 5.8855e-01, 1.3039e-01, 3.5518e-01, 0.0000e+00,\n","         5.3394e-02, 0.0000e+00, 4.0503e-01, 3.8082e-01, 3.0599e-01, 1.1072e-01,\n","         1.4306e+00, 0.0000e+00, 2.8412e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.5131e-01, 2.7982e-01, 4.4445e-01, 0.0000e+00, 0.0000e+00,\n","         7.9163e-01, 2.4473e-01],\n","        [0.0000e+00, 0.0000e+00, 6.3382e-01, 0.0000e+00, 0.0000e+00, 2.3045e-01,\n","         3.2058e-01, 3.9977e-01, 0.0000e+00, 8.5134e-03, 0.0000e+00, 0.0000e+00,\n","         3.5347e-01, 3.7445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5869e-01,\n","         0.0000e+00, 3.1764e-01, 0.0000e+00, 0.0000e+00, 1.2373e+00, 0.0000e+00,\n","         6.1122e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2421e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8224e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 4.9611e-01, 0.0000e+00, 0.0000e+00, 9.6979e-01,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1069e+00, 2.5455e-01, 0.0000e+00,\n","         3.7554e-01, 0.0000e+00, 1.4972e+00, 0.0000e+00, 4.4858e-01, 0.0000e+00,\n","         0.0000e+00, 7.2148e-01],\n","        [4.1602e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6230e-02,\n","         1.8735e-02, 0.0000e+00, 0.0000e+00, 2.0383e-01, 8.1571e-01, 0.0000e+00,\n","         6.1368e-02, 0.0000e+00, 7.5858e-01, 4.6375e-01, 8.4749e-01, 4.2466e-02,\n","         0.0000e+00, 0.0000e+00, 3.1561e-01, 0.0000e+00, 0.0000e+00, 8.7674e-01,\n","         0.0000e+00, 5.0836e-01, 0.0000e+00, 5.2125e-01, 0.0000e+00, 2.1123e-01,\n","         5.2919e-02, 0.0000e+00],\n","        [0.0000e+00, 1.1662e+00, 0.0000e+00, 1.6404e+00, 3.5626e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.0607e+00, 0.0000e+00, 0.0000e+00, 1.4213e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7812e+00, 0.0000e+00, 1.9248e-04,\n","         1.1902e+00, 0.0000e+00, 1.3074e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.3366e-01, 1.7626e+00],\n","        [1.2264e-01, 0.0000e+00, 1.9017e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.3853e-02, 2.3017e-02, 8.6209e-01, 0.0000e+00,\n","         1.1482e-01, 0.0000e+00, 7.0377e-01, 3.2885e-01, 9.0093e-01, 7.7870e-02,\n","         0.0000e+00, 0.0000e+00, 4.4000e-01, 0.0000e+00, 0.0000e+00, 9.3639e-01,\n","         0.0000e+00, 4.4255e-01, 0.0000e+00, 5.6173e-01, 0.0000e+00, 1.2246e-01,\n","         1.6162e-01, 7.8999e-02],\n","        [0.0000e+00, 0.0000e+00, 3.1961e-01, 0.0000e+00, 0.0000e+00, 2.0434e-01,\n","         3.0016e-01, 4.7116e-01, 0.0000e+00, 5.0356e-02, 0.0000e+00, 0.0000e+00,\n","         4.1588e-01, 4.0901e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3575e-01,\n","         8.0471e-03, 4.1487e-01, 0.0000e+00, 0.0000e+00, 6.4327e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4459e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1817e-01, 0.0000e+00, 5.9984e-02, 0.0000e+00, 0.0000e+00, 3.6155e-02,\n","         4.7304e-02, 0.0000e+00, 0.0000e+00, 5.4684e-02, 9.3514e-01, 0.0000e+00,\n","         1.0911e-01, 0.0000e+00, 8.7426e-01, 3.4161e-01, 9.4748e-01, 8.8469e-02,\n","         0.0000e+00, 0.0000e+00, 1.8749e-01, 0.0000e+00, 0.0000e+00, 1.0497e+00,\n","         0.0000e+00, 5.3309e-01, 0.0000e+00, 5.1958e-01, 0.0000e+00, 2.0786e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 32], 'torch_dtype': torch.float32, 'value': tensor([[9.6061e-01, 7.9130e-01, 0.0000e+00, 1.2248e-01, 0.0000e+00, 0.0000e+00,\n","         1.1775e-02, 0.0000e+00, 5.8855e-01, 1.3039e-01, 3.5518e-01, 0.0000e+00,\n","         5.3394e-02, 0.0000e+00, 4.0503e-01, 3.8082e-01, 3.0599e-01, 1.1072e-01,\n","         1.4306e+00, 0.0000e+00, 2.8412e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.5131e-01, 2.7982e-01, 4.4445e-01, 0.0000e+00, 0.0000e+00,\n","         7.9163e-01, 2.4473e-01],\n","        [0.0000e+00, 0.0000e+00, 6.3382e-01, 0.0000e+00, 0.0000e+00, 2.3045e-01,\n","         3.2058e-01, 3.9977e-01, 0.0000e+00, 8.5134e-03, 0.0000e+00, 0.0000e+00,\n","         3.5347e-01, 3.7445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5869e-01,\n","         0.0000e+00, 3.1764e-01, 0.0000e+00, 0.0000e+00, 1.2373e+00, 0.0000e+00,\n","         6.1122e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2421e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8224e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 4.9611e-01, 0.0000e+00, 0.0000e+00, 9.6979e-01,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1069e+00, 2.5455e-01, 0.0000e+00,\n","         3.7554e-01, 0.0000e+00, 1.4972e+00, 0.0000e+00, 4.4858e-01, 0.0000e+00,\n","         0.0000e+00, 7.2148e-01],\n","        [4.1602e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6230e-02,\n","         1.8735e-02, 0.0000e+00, 0.0000e+00, 2.0383e-01, 8.1571e-01, 0.0000e+00,\n","         6.1368e-02, 0.0000e+00, 7.5858e-01, 4.6375e-01, 8.4749e-01, 4.2466e-02,\n","         0.0000e+00, 0.0000e+00, 3.1561e-01, 0.0000e+00, 0.0000e+00, 8.7674e-01,\n","         0.0000e+00, 5.0836e-01, 0.0000e+00, 5.2125e-01, 0.0000e+00, 2.1123e-01,\n","         5.2919e-02, 0.0000e+00],\n","        [0.0000e+00, 1.1662e+00, 0.0000e+00, 1.6404e+00, 3.5626e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.0607e+00, 0.0000e+00, 0.0000e+00, 1.4213e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7812e+00, 0.0000e+00, 1.9248e-04,\n","         1.1902e+00, 0.0000e+00, 1.3074e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.3366e-01, 1.7626e+00],\n","        [1.2264e-01, 0.0000e+00, 1.9017e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.3853e-02, 2.3017e-02, 8.6209e-01, 0.0000e+00,\n","         1.1482e-01, 0.0000e+00, 7.0377e-01, 3.2885e-01, 9.0093e-01, 7.7870e-02,\n","         0.0000e+00, 0.0000e+00, 4.4000e-01, 0.0000e+00, 0.0000e+00, 9.3639e-01,\n","         0.0000e+00, 4.4255e-01, 0.0000e+00, 5.6173e-01, 0.0000e+00, 1.2246e-01,\n","         1.6162e-01, 7.8999e-02],\n","        [0.0000e+00, 0.0000e+00, 3.1961e-01, 0.0000e+00, 0.0000e+00, 2.0434e-01,\n","         3.0016e-01, 4.7116e-01, 0.0000e+00, 5.0356e-02, 0.0000e+00, 0.0000e+00,\n","         4.1588e-01, 4.0901e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3575e-01,\n","         8.0471e-03, 4.1487e-01, 0.0000e+00, 0.0000e+00, 6.4327e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4459e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1817e-01, 0.0000e+00, 5.9984e-02, 0.0000e+00, 0.0000e+00, 3.6155e-02,\n","         4.7304e-02, 0.0000e+00, 0.0000e+00, 5.4684e-02, 9.3514e-01, 0.0000e+00,\n","         1.0911e-01, 0.0000e+00, 8.7426e-01, 3.4161e-01, 9.4748e-01, 8.8469e-02,\n","         0.0000e+00, 0.0000e+00, 1.8749e-01, 0.0000e+00, 0.0000e+00, 1.0497e+00,\n","         0.0000e+00, 5.3309e-01, 0.0000e+00, 5.1958e-01, 0.0000e+00, 2.0786e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': {'data_in_0': {'shape': [8, 32], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[9.6061e-01, 7.9130e-01, 0.0000e+00, 1.2248e-01, 0.0000e+00, 0.0000e+00,\n","         1.1775e-02, 0.0000e+00, 5.8855e-01, 1.3039e-01, 3.5518e-01, 0.0000e+00,\n","         5.3394e-02, 0.0000e+00, 4.0503e-01, 3.8082e-01, 3.0599e-01, 1.1072e-01,\n","         1.4306e+00, 0.0000e+00, 2.8412e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.5131e-01, 2.7982e-01, 4.4445e-01, 0.0000e+00, 0.0000e+00,\n","         7.9163e-01, 2.4473e-01],\n","        [0.0000e+00, 0.0000e+00, 6.3382e-01, 0.0000e+00, 0.0000e+00, 2.3045e-01,\n","         3.2058e-01, 3.9977e-01, 0.0000e+00, 8.5134e-03, 0.0000e+00, 0.0000e+00,\n","         3.5347e-01, 3.7445e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5869e-01,\n","         0.0000e+00, 3.1764e-01, 0.0000e+00, 0.0000e+00, 1.2373e+00, 0.0000e+00,\n","         6.1122e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2421e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8224e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 4.9611e-01, 0.0000e+00, 0.0000e+00, 9.6979e-01,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1069e+00, 2.5455e-01, 0.0000e+00,\n","         3.7554e-01, 0.0000e+00, 1.4972e+00, 0.0000e+00, 4.4858e-01, 0.0000e+00,\n","         0.0000e+00, 7.2148e-01],\n","        [4.1602e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6230e-02,\n","         1.8735e-02, 0.0000e+00, 0.0000e+00, 2.0383e-01, 8.1571e-01, 0.0000e+00,\n","         6.1368e-02, 0.0000e+00, 7.5858e-01, 4.6375e-01, 8.4749e-01, 4.2466e-02,\n","         0.0000e+00, 0.0000e+00, 3.1561e-01, 0.0000e+00, 0.0000e+00, 8.7674e-01,\n","         0.0000e+00, 5.0836e-01, 0.0000e+00, 5.2125e-01, 0.0000e+00, 2.1123e-01,\n","         5.2919e-02, 0.0000e+00],\n","        [0.0000e+00, 1.1662e+00, 0.0000e+00, 1.6404e+00, 3.5626e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.0607e+00, 0.0000e+00, 0.0000e+00, 1.4213e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7812e+00, 0.0000e+00, 1.9248e-04,\n","         1.1902e+00, 0.0000e+00, 1.3074e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.3366e-01, 1.7626e+00],\n","        [1.2264e-01, 0.0000e+00, 1.9017e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.3853e-02, 2.3017e-02, 8.6209e-01, 0.0000e+00,\n","         1.1482e-01, 0.0000e+00, 7.0377e-01, 3.2885e-01, 9.0093e-01, 7.7870e-02,\n","         0.0000e+00, 0.0000e+00, 4.4000e-01, 0.0000e+00, 0.0000e+00, 9.3639e-01,\n","         0.0000e+00, 4.4255e-01, 0.0000e+00, 5.6173e-01, 0.0000e+00, 1.2246e-01,\n","         1.6162e-01, 7.8999e-02],\n","        [0.0000e+00, 0.0000e+00, 3.1961e-01, 0.0000e+00, 0.0000e+00, 2.0434e-01,\n","         3.0016e-01, 4.7116e-01, 0.0000e+00, 5.0356e-02, 0.0000e+00, 0.0000e+00,\n","         4.1588e-01, 4.0901e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3575e-01,\n","         8.0471e-03, 4.1487e-01, 0.0000e+00, 0.0000e+00, 6.4327e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4459e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1817e-01, 0.0000e+00, 5.9984e-02, 0.0000e+00, 0.0000e+00, 3.6155e-02,\n","         4.7304e-02, 0.0000e+00, 0.0000e+00, 5.4684e-02, 9.3514e-01, 0.0000e+00,\n","         1.0911e-01, 0.0000e+00, 8.7426e-01, 3.4161e-01, 9.4748e-01, 8.8469e-02,\n","         0.0000e+00, 0.0000e+00, 1.8749e-01, 0.0000e+00, 0.0000e+00, 1.0497e+00,\n","         0.0000e+00, 5.3309e-01, 0.0000e+00, 5.1958e-01, 0.0000e+00, 2.0786e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 32], 'torch_dtype': torch.float32, 'value': tensor([[1.2008e+00, 0.0000e+00, 0.0000e+00, 1.5309e-01, 0.0000e+00, 0.0000e+00,\n","         1.4719e-02, 0.0000e+00, 7.3568e-01, 1.6299e-01, 4.4397e-01, 0.0000e+00,\n","         6.6743e-02, 0.0000e+00, 5.0629e-01, 4.7602e-01, 3.8249e-01, 1.3840e-01,\n","         0.0000e+00, 0.0000e+00, 3.5515e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 6.8914e-01, 3.4977e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         9.8954e-01, 3.0591e-01],\n","        [0.0000e+00, 0.0000e+00, 7.9228e-01, 0.0000e+00, 0.0000e+00, 2.8806e-01,\n","         4.0073e-01, 4.9971e-01, 0.0000e+00, 1.0642e-02, 0.0000e+00, 0.0000e+00,\n","         4.4184e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2336e-01,\n","         0.0000e+00, 3.9705e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.6402e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0526e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 6.2014e-01, 0.0000e+00, 0.0000e+00, 1.2122e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3836e+00, 3.1818e-01, 0.0000e+00,\n","         4.6943e-01, 0.0000e+00, 1.8715e+00, 0.0000e+00, 5.6072e-01, 0.0000e+00,\n","         0.0000e+00, 9.0185e-01],\n","        [5.2002e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0287e-02,\n","         2.3419e-02, 0.0000e+00, 0.0000e+00, 2.5479e-01, 1.0196e+00, 0.0000e+00,\n","         7.6710e-02, 0.0000e+00, 9.4823e-01, 0.0000e+00, 1.0594e+00, 5.3082e-02,\n","         0.0000e+00, 0.0000e+00, 3.9451e-01, 0.0000e+00, 0.0000e+00, 1.0959e+00,\n","         0.0000e+00, 6.3545e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6403e-01,\n","         6.6149e-02, 0.0000e+00],\n","        [0.0000e+00, 1.4578e+00, 0.0000e+00, 2.0505e+00, 4.4532e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.3259e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2265e+00, 0.0000e+00, 2.4060e-04,\n","         1.4877e+00, 0.0000e+00, 1.6343e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 2.2033e+00],\n","        [1.5330e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.9816e-02, 2.8771e-02, 1.0776e+00, 0.0000e+00,\n","         1.4352e-01, 0.0000e+00, 8.7972e-01, 4.1106e-01, 1.1262e+00, 9.7337e-02,\n","         0.0000e+00, 0.0000e+00, 5.5000e-01, 0.0000e+00, 0.0000e+00, 1.1705e+00,\n","         0.0000e+00, 5.5318e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 9.8748e-02],\n","        [0.0000e+00, 0.0000e+00, 3.9951e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         3.7520e-01, 5.8895e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.1126e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1969e-01,\n","         1.0059e-02, 5.1859e-01, 0.0000e+00, 0.0000e+00, 8.0409e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5574e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.4771e-01, 0.0000e+00, 7.4980e-02, 0.0000e+00, 0.0000e+00, 4.5194e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8355e-02, 1.1689e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2701e-01, 1.1843e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3121e+00,\n","         0.0000e+00, 6.6636e-01, 0.0000e+00, 6.4947e-01, 0.0000e+00, 2.5982e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<MulBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': {'data_in_0': {'shape': [8, 32], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[1.2008e+00, 0.0000e+00, 0.0000e+00, 1.5309e-01, 0.0000e+00, 0.0000e+00,\n","         1.4719e-02, 0.0000e+00, 7.3568e-01, 1.6299e-01, 4.4397e-01, 0.0000e+00,\n","         6.6743e-02, 0.0000e+00, 5.0629e-01, 4.7602e-01, 3.8249e-01, 1.3840e-01,\n","         0.0000e+00, 0.0000e+00, 3.5515e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 6.8914e-01, 3.4977e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         9.8954e-01, 3.0591e-01],\n","        [0.0000e+00, 0.0000e+00, 7.9228e-01, 0.0000e+00, 0.0000e+00, 2.8806e-01,\n","         4.0073e-01, 4.9971e-01, 0.0000e+00, 1.0642e-02, 0.0000e+00, 0.0000e+00,\n","         4.4184e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2336e-01,\n","         0.0000e+00, 3.9705e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         7.6402e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0526e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 6.2014e-01, 0.0000e+00, 0.0000e+00, 1.2122e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3836e+00, 3.1818e-01, 0.0000e+00,\n","         4.6943e-01, 0.0000e+00, 1.8715e+00, 0.0000e+00, 5.6072e-01, 0.0000e+00,\n","         0.0000e+00, 9.0185e-01],\n","        [5.2002e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0287e-02,\n","         2.3419e-02, 0.0000e+00, 0.0000e+00, 2.5479e-01, 1.0196e+00, 0.0000e+00,\n","         7.6710e-02, 0.0000e+00, 9.4823e-01, 0.0000e+00, 1.0594e+00, 5.3082e-02,\n","         0.0000e+00, 0.0000e+00, 3.9451e-01, 0.0000e+00, 0.0000e+00, 1.0959e+00,\n","         0.0000e+00, 6.3545e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6403e-01,\n","         6.6149e-02, 0.0000e+00],\n","        [0.0000e+00, 1.4578e+00, 0.0000e+00, 2.0505e+00, 4.4532e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.3259e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2265e+00, 0.0000e+00, 2.4060e-04,\n","         1.4877e+00, 0.0000e+00, 1.6343e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 2.2033e+00],\n","        [1.5330e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.9816e-02, 2.8771e-02, 1.0776e+00, 0.0000e+00,\n","         1.4352e-01, 0.0000e+00, 8.7972e-01, 4.1106e-01, 1.1262e+00, 9.7337e-02,\n","         0.0000e+00, 0.0000e+00, 5.5000e-01, 0.0000e+00, 0.0000e+00, 1.1705e+00,\n","         0.0000e+00, 5.5318e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 9.8748e-02],\n","        [0.0000e+00, 0.0000e+00, 3.9951e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         3.7520e-01, 5.8895e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 5.1126e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1969e-01,\n","         1.0059e-02, 5.1859e-01, 0.0000e+00, 0.0000e+00, 8.0409e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5574e-01, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.4771e-01, 0.0000e+00, 7.4980e-02, 0.0000e+00, 0.0000e+00, 4.5194e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8355e-02, 1.1689e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2701e-01, 1.1843e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3121e+00,\n","         0.0000e+00, 6.6636e-01, 0.0000e+00, 6.4947e-01, 0.0000e+00, 2.5982e-01,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<MulBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [16, 32], 'from': None, 'value': Parameter containing:\n","tensor([[ 8.2521e-02,  1.2608e-01,  9.1352e-02,  1.5776e-02, -2.2807e-01,\n","         -2.1520e-01, -1.0133e-01, -4.2282e-01,  1.3329e-01, -1.0873e-01,\n","          8.4763e-03, -3.4248e-02, -3.2473e-01,  2.3328e-03,  2.3752e-02,\n","         -1.3391e-01, -9.1384e-03, -3.1016e-01,  1.0256e-01, -5.1479e-02,\n","          1.2305e-01, -2.7206e-02, -1.9309e-01,  1.9676e-02, -3.3067e-02,\n","         -4.9099e-02, -2.8208e-02,  1.0046e-02, -1.5444e-01, -1.9851e-01,\n","          1.2797e-01,  4.1136e-02],\n","        [ 2.3900e-02, -5.9152e-02,  3.6498e-02,  3.4405e-02,  5.7699e-02,\n","         -6.0386e-02,  1.8244e-02,  1.2412e-01, -2.2601e-02, -3.8948e-01,\n","         -1.7154e-01,  7.6281e-03,  1.8410e-02,  2.8112e-01, -1.7375e-01,\n","         -2.1577e-01, -2.7773e-01,  1.4789e-02,  4.2492e-02,  3.0839e-01,\n","         -1.2218e-01, -3.6621e-03,  1.0110e-02, -1.1732e-01,  2.4513e-02,\n","         -1.8287e-01,  2.5135e-02,  3.7577e-01,  5.8077e-02, -4.0172e-01,\n","         -1.1294e-01, -4.6427e-03],\n","        [-3.2864e-02,  2.2103e-02,  5.7414e-02,  2.5287e-02,  2.4927e-02,\n","         -3.6676e-01, -2.0859e-01, -2.2418e-02,  5.1536e-02, -3.7424e-01,\n","          1.1795e-02,  4.1850e-02, -7.7472e-02,  9.7445e-02,  9.3029e-03,\n","         -1.6890e-01, -9.0297e-04, -1.4262e-01,  1.2619e-01,  1.0497e-01,\n","         -6.5068e-02,  2.6553e-02,  2.3907e-02,  5.8713e-03,  5.3812e-02,\n","         -2.6891e-02,  2.1670e-03,  6.9331e-02,  7.3832e-02, -5.2093e-01,\n","          2.6280e-02,  2.5785e-02],\n","        [-3.0460e-02, -1.5992e-01, -7.3232e-02, -3.8234e-01, -2.9247e-02,\n","          1.8570e-01,  4.7315e-03,  6.9716e-02, -2.8517e-01,  1.0877e-01,\n","         -5.9290e-03, -4.4159e-02,  5.2984e-02,  5.2875e-02, -1.4118e-02,\n","         -2.2039e-03, -3.2332e-03,  1.2674e-03, -6.8786e-02, -4.3241e-02,\n","         -8.5114e-03, -4.5393e-02,  1.8797e-02, -1.1799e-02, -3.1869e-01,\n","         -6.7557e-02, -7.0905e-02, -6.2342e-03, -2.7147e-02,  1.2638e-01,\n","         -2.7391e-01, -2.3843e-01],\n","        [-1.5191e-02, -5.8979e-02, -1.2481e-01,  3.1852e-03,  6.0318e-02,\n","          2.2322e-01,  2.8054e-01,  2.3647e-01, -1.1774e-01,  7.8879e-02,\n","         -3.9257e-02, -1.7493e-02,  1.7412e-01, -2.0386e-01, -1.7720e-02,\n","         -6.4583e-02, -2.5341e-02,  1.7272e-01, -1.8791e-02, -1.2840e-01,\n","         -4.9810e-02, -9.4160e-03,  4.9247e-02, -1.5856e-01, -2.0541e-03,\n","         -1.3571e-01, -2.3675e-03, -1.8090e-01,  4.5356e-02, -3.1709e-02,\n","         -1.2793e-01, -3.3916e-03],\n","        [ 4.0015e-02, -1.4174e-01, -1.1173e-01,  5.3159e-03,  2.5498e-02,\n","          1.2359e-01,  1.4424e-01, -8.9420e-01, -5.0776e-02, -2.0872e-02,\n","         -1.4490e-04,  6.9607e-03, -4.2651e-01, -9.6201e-02, -6.9925e-04,\n","          3.1367e-02, -3.5936e-03, -4.1617e-01, -7.2126e-02, -4.0800e-02,\n","          2.5416e-02,  1.2616e-02,  4.2949e-02, -1.0856e-02,  2.9329e-03,\n","          1.4029e-02,  9.5283e-03,  3.4308e-03,  5.2095e-02,  1.3793e-02,\n","         -5.0073e-02, -3.7636e-02],\n","        [ 1.9151e-02,  9.1220e-03,  4.1831e-02, -7.9198e-02, -1.8289e-01,\n","          6.8930e-02,  1.9712e-01, -6.0204e-01, -2.3588e-03,  6.4947e-02,\n","          2.6133e-02,  1.1075e-02, -4.6208e-01, -1.0625e-01,  1.6507e-02,\n","          2.8085e-02,  2.7374e-02, -4.1651e-01, -1.0135e-01, -6.0728e-02,\n","          7.4698e-02,  1.1677e-02, -2.3453e-01,  6.8082e-02, -6.6822e-02,\n","         -5.2165e-03,  5.3422e-03,  6.4369e-02, -3.9829e-01,  8.3384e-02,\n","          2.6329e-02,  5.2475e-03],\n","        [-7.5932e-02, -3.5676e-03, -1.4344e-02, -2.5532e-01, -3.3351e-01,\n","          2.9438e-01,  3.1352e-01, -4.6434e-02, -2.6178e-02,  6.9044e-02,\n","          1.9911e-02,  2.5620e-03, -1.5154e-01,  1.9548e-01,  1.3380e-02,\n","          4.7467e-02,  3.1363e-02, -1.4478e-01, -1.9310e-01,  7.1078e-02,\n","          4.6193e-02, -9.6740e-03, -1.2836e-01,  1.8342e-02, -8.1728e-02,\n","          1.7840e-02, -9.2735e-02,  8.9766e-02, -1.4495e-01,  1.6686e-01,\n","         -7.4483e-04, -5.5291e-02],\n","        [-7.2091e-02,  2.6855e-02,  4.7264e-02,  1.1235e-02,  9.7227e-02,\n","          1.3707e-01,  1.4667e-01,  1.0818e-01,  2.5571e-02, -1.2300e-01,\n","         -2.6464e-01, -9.0267e-03,  6.3145e-02,  9.9694e-02, -1.5008e-01,\n","         -3.8472e-01, -1.8424e-01,  6.7488e-02, -2.0396e-02,  8.2699e-02,\n","         -6.2605e-02, -4.4532e-03,  4.3760e-02, -1.2033e-01,  1.8186e-02,\n","         -1.1484e-03, -1.4334e-02,  1.7095e-01,  5.9951e-02, -1.6711e-01,\n","          3.6750e-02,  2.7007e-02],\n","        [ 2.9323e-02, -2.0458e-03, -1.1817e-01,  5.3514e-04,  6.9100e-02,\n","         -1.7874e-02,  2.0435e-03, -3.0628e-02, -2.3646e-02,  3.9969e-02,\n","          2.7162e-02,  6.8640e-03, -8.4406e-03, -2.1475e-01,  2.3357e-02,\n","          4.3881e-02, -2.5912e-03,  4.6092e-03,  1.1645e-02, -1.5444e-01,\n","         -3.1422e-03,  7.0429e-03,  9.2331e-03, -2.3528e-01, -4.9873e-03,\n","         -3.6104e-01,  2.9542e-03, -3.3706e-01,  6.7307e-03,  6.7806e-03,\n","         -4.5633e-02,  1.5852e-03],\n","        [-5.1888e-02,  1.5461e-02,  1.2445e-02,  4.4835e-02, -1.1066e-01,\n","         -4.5124e-01, -3.3826e-01, -4.5530e-01,  2.3622e-02, -1.0524e-01,\n","         -1.1700e-03,  3.9189e-02, -4.6805e-01,  6.5079e-02, -1.7723e-03,\n","         -3.2163e-02,  3.1669e-03, -4.9314e-01, -3.7338e-02,  5.5208e-02,\n","         -2.6541e-03,  3.2873e-02,  1.8896e-02, -2.0372e-03,  4.8537e-02,\n","          3.7437e-02,  2.1715e-02,  6.1448e-03,  5.7512e-02, -1.9487e-01,\n","          7.3673e-03,  1.4994e-02],\n","        [-9.4836e-02, -2.8618e-03,  4.2696e-02, -1.7840e-01, -3.9797e-02,\n","          1.2925e-01,  6.9359e-02, -1.0048e-02, -9.7931e-03,  1.8065e-01,\n","         -1.7828e-01, -2.5519e-01,  2.3212e-02,  3.9432e-02, -8.7591e-02,\n","         -1.6567e-01, -6.8502e-02,  5.6541e-02, -1.1404e-01,  9.0449e-02,\n","         -2.3937e-02, -3.4474e-01,  2.1919e-02, -5.8540e-03, -6.2234e-02,\n","         -2.6077e-02, -2.7482e-01, -1.0939e-01,  1.8387e-02,  4.6782e-02,\n","         -3.2545e-02, -2.9548e-02],\n","        [-1.5283e-02,  1.0511e-03, -7.6675e-02, -2.3391e-01, -2.9065e-02,\n","          1.5114e-01,  1.5081e-01,  1.6032e-01, -2.5733e-02,  7.5212e-02,\n","         -4.4849e-02, -2.1891e-01,  3.9771e-02, -1.5620e-01, -3.8339e-02,\n","         -6.0805e-02, -3.4284e-02,  6.9041e-02, -1.1976e-02, -1.7288e-01,\n","         -2.7049e-02, -1.7529e-01,  4.9241e-02, -8.3537e-02, -2.4325e-01,\n","         -2.0108e-01, -4.8815e-02, -1.6847e-01,  8.2493e-02, -5.8163e-02,\n","         -4.0167e-02, -3.9858e-02],\n","        [-1.7821e-01,  4.8710e-02,  5.4403e-02, -2.9898e-01, -2.2751e-01,\n","          9.7393e-02,  5.3240e-02,  1.7941e-01,  1.1411e-02,  1.9720e-02,\n","         -1.3944e-02, -7.2132e-02,  6.9993e-02,  8.8884e-02, -1.1481e-02,\n","         -2.2594e-01, -5.5823e-03,  6.7100e-02, -1.9396e-01,  3.8026e-02,\n","         -1.3439e-01, -9.0425e-02,  3.4153e-02,  8.0936e-03, -1.5631e-01,\n","          3.4492e-02, -3.7315e-01,  8.4395e-03, -1.1921e-02, -2.3826e-01,\n","          2.3312e-02,  3.6125e-02],\n","        [-1.2610e-01, -3.0993e-02, -4.6792e-02, -2.1555e-04, -1.8875e-02,\n","          9.3091e-03, -7.4153e-03,  1.5209e-02, -3.6674e-02, -3.4106e-01,\n","         -2.2387e-01, -2.9911e-03, -2.9092e-02,  1.0398e-01, -2.2903e-01,\n","         -2.8290e-01, -2.3130e-01, -2.8994e-02, -3.3585e-02,  6.1735e-02,\n","         -3.7166e-02,  1.3132e-03,  2.1249e-02, -1.5713e-02,  6.5945e-03,\n","          1.2367e-02,  7.9844e-03,  2.1028e-01,  4.2471e-02, -4.0737e-01,\n","         -6.4975e-02,  1.5094e-03],\n","        [ 2.1400e-02, -3.6011e-02, -2.1967e-01, -1.6028e-01, -2.9727e-02,\n","          1.9594e-01,  1.6490e-01, -1.9778e-01, -5.2339e-02,  1.0280e-02,\n","         -7.8229e-04, -6.4153e-02, -5.4348e-04, -5.5980e-01,  4.9073e-04,\n","         -4.1302e-03, -1.0635e-03,  1.2858e-02,  8.0323e-03, -5.5507e-01,\n","          1.9075e-02, -1.0474e-01,  1.7572e-02, -4.0273e-03, -2.4765e-01,\n","         -4.2936e-02, -2.3720e-02, -1.4389e-02, -3.0065e-02,  4.4087e-02,\n","         -2.4891e-02, -4.1404e-02]], requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n","tensor([ 0.1525,  0.0653,  0.1816, -0.0461, -0.0964,  0.1613,  0.0504,  0.1695,\n","        -0.0202, -0.1245, -0.0268, -0.1666,  0.0076,  0.1176,  0.0503,  0.0025],\n","       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[ 0.3560, -0.6242,  0.0171, -0.7599, -0.4548,  0.0595,  0.0808,  0.0345,\n","         -0.5211, -0.3498, -0.1577, -0.6676, -0.3374, -0.3579, -0.6940, -0.0999],\n","        [-0.4967,  0.3318,  0.0549, -0.0550,  0.2232, -0.5728, -0.8464,  0.1230,\n","          0.3064, -0.2952, -0.7997,  0.0055,  0.1590,  0.3449,  0.0581, -0.4104],\n","        [-0.0233,  0.1456,  0.4026, -0.8458, -0.1710,  0.1838, -0.2360, -0.2410,\n","          0.0321, -0.1098,  0.1960, -1.5119, -0.6959, -0.8229,  0.0757, -0.4619],\n","        [ 0.1253, -1.0635, -0.1273, -0.0837, -0.4196,  0.1368,  0.2247,  0.3162,\n","         -0.8739, -0.5434, -0.2123, -0.5141, -0.3268, -0.0676, -0.9318,  0.0188],\n","        [ 0.3786,  0.1045,  0.5446, -2.6707, -0.3405, -0.1253, -0.2363, -0.9590,\n","          0.1723, -0.1105,  0.2836, -1.9417, -1.4374, -1.4748, -0.0233, -1.1929],\n","        [ 0.1215, -0.9842,  0.0515, -0.1512, -0.4595,  0.0770,  0.1518,  0.2625,\n","         -0.9745, -0.5321, -0.1464, -0.6192, -0.3544, -0.0583, -0.8383, -0.0197],\n","        [-0.4938,  0.5105,  0.2189, -0.0280,  0.0646, -0.5381, -0.8850,  0.1443,\n","          0.3079, -0.3657, -0.5152, -0.0120,  0.0727,  0.3772,  0.1511, -0.7111],\n","        [ 0.0443, -0.7155, -0.0211, -0.0837, -0.6202,  0.1728,  0.2882,  0.3935,\n","         -0.8124, -0.8462, -0.0969, -0.6035, -0.4756, -0.0411, -0.6328, -0.0370]],\n","       grad_fn=<AddmmBackward0>)}}}\n","{'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[ 0.3560, -0.6242,  0.0171, -0.7599, -0.4548,  0.0595,  0.0808,  0.0345,\n","         -0.5211, -0.3498, -0.1577, -0.6676, -0.3374, -0.3579, -0.6940, -0.0999],\n","        [-0.4967,  0.3318,  0.0549, -0.0550,  0.2232, -0.5728, -0.8464,  0.1230,\n","          0.3064, -0.2952, -0.7997,  0.0055,  0.1590,  0.3449,  0.0581, -0.4104],\n","        [-0.0233,  0.1456,  0.4026, -0.8458, -0.1710,  0.1838, -0.2360, -0.2410,\n","          0.0321, -0.1098,  0.1960, -1.5119, -0.6959, -0.8229,  0.0757, -0.4619],\n","        [ 0.1253, -1.0635, -0.1273, -0.0837, -0.4196,  0.1368,  0.2247,  0.3162,\n","         -0.8739, -0.5434, -0.2123, -0.5141, -0.3268, -0.0676, -0.9318,  0.0188],\n","        [ 0.3786,  0.1045,  0.5446, -2.6707, -0.3405, -0.1253, -0.2363, -0.9590,\n","          0.1723, -0.1105,  0.2836, -1.9417, -1.4374, -1.4748, -0.0233, -1.1929],\n","        [ 0.1215, -0.9842,  0.0515, -0.1512, -0.4595,  0.0770,  0.1518,  0.2625,\n","         -0.9745, -0.5321, -0.1464, -0.6192, -0.3544, -0.0583, -0.8383, -0.0197],\n","        [-0.4938,  0.5105,  0.2189, -0.0280,  0.0646, -0.5381, -0.8850,  0.1443,\n","          0.3079, -0.3657, -0.5152, -0.0120,  0.0727,  0.3772,  0.1511, -0.7111],\n","        [ 0.0443, -0.7155, -0.0211, -0.0837, -0.6202,  0.1728,  0.2882,  0.3935,\n","         -0.8124, -0.8462, -0.0969, -0.6035, -0.4756, -0.0411, -0.6328, -0.0370]],\n","       grad_fn=<AddmmBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n","tensor([0.8370, 0.8209, 0.7475, 0.9053, 0.9687, 0.8863, 0.7917, 0.8917, 0.9040,\n","        0.8417, 0.9399, 0.9011, 1.0737, 0.8870, 0.7668, 0.9075],\n","       requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [16], 'from': None, 'value': Parameter containing:\n","tensor([-0.0390, -0.4339, -0.1033, -0.3881, -0.3079, -0.3110, -0.1304, -0.0305,\n","        -0.4131, -0.5177, -0.1904, -0.5757, -0.5617, -0.3627, -0.5692, -0.3695],\n","       requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.9032, 0.0000, 0.0000, 0.0000, 0.0000, 0.1006, 0.3493, 0.0245, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2347],\n","        [0.0000, 0.4330, 0.0000, 0.1785, 1.4666, 0.0000, 0.0000, 0.2176, 0.6324,\n","         0.0000, 0.0000, 0.4741, 0.7926, 0.5650, 0.1660, 0.0000],\n","        [0.0000, 0.1720, 0.8045, 0.0000, 0.0547, 0.4786, 0.0000, 0.0000, 0.1559,\n","         0.5271, 0.8890, 0.0000, 0.0000, 0.0000, 0.1974, 0.0000],\n","        [0.2900, 0.0000, 0.0000, 0.1478, 0.0000, 0.3355, 0.6115, 0.6387, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5062],\n","        [0.9631, 0.1144, 1.3005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3995,\n","         0.5246, 1.1398, 0.0000, 0.0000, 0.0000, 0.0210, 0.0000],\n","        [0.2800, 0.0000, 0.0000, 0.0756, 0.0000, 0.1536, 0.4786, 0.5217, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4180],\n","        [0.0000, 0.6834, 0.1632, 0.2073, 0.8986, 0.0000, 0.0000, 0.2640, 0.6349,\n","         0.0000, 0.0000, 0.4493, 0.5922, 0.6142, 0.3318, 0.0000],\n","        [0.0749, 0.0000, 0.0000, 0.1478, 0.0000, 0.4452, 0.7274, 0.8073, 0.0000,\n","         0.0000, 0.0506, 0.0000, 0.0000, 0.0000, 0.0000, 0.3785]],\n","       grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.9032, 0.0000, 0.0000, 0.0000, 0.0000, 0.1006, 0.3493, 0.0245, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2347],\n","        [0.0000, 0.4330, 0.0000, 0.1785, 1.4666, 0.0000, 0.0000, 0.2176, 0.6324,\n","         0.0000, 0.0000, 0.4741, 0.7926, 0.5650, 0.1660, 0.0000],\n","        [0.0000, 0.1720, 0.8045, 0.0000, 0.0547, 0.4786, 0.0000, 0.0000, 0.1559,\n","         0.5271, 0.8890, 0.0000, 0.0000, 0.0000, 0.1974, 0.0000],\n","        [0.2900, 0.0000, 0.0000, 0.1478, 0.0000, 0.3355, 0.6115, 0.6387, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5062],\n","        [0.9631, 0.1144, 1.3005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3995,\n","         0.5246, 1.1398, 0.0000, 0.0000, 0.0000, 0.0210, 0.0000],\n","        [0.2800, 0.0000, 0.0000, 0.0756, 0.0000, 0.1536, 0.4786, 0.5217, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4180],\n","        [0.0000, 0.6834, 0.1632, 0.2073, 0.8986, 0.0000, 0.0000, 0.2640, 0.6349,\n","         0.0000, 0.0000, 0.4493, 0.5922, 0.6142, 0.3318, 0.0000],\n","        [0.0749, 0.0000, 0.0000, 0.1478, 0.0000, 0.4452, 0.7274, 0.8073, 0.0000,\n","         0.0000, 0.0506, 0.0000, 0.0000, 0.0000, 0.0000, 0.3785]],\n","       grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[0.9032, 0.0000, 0.0000, 0.0000, 0.0000, 0.1006, 0.3493, 0.0245, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2347],\n","        [0.0000, 0.4330, 0.0000, 0.1785, 1.4666, 0.0000, 0.0000, 0.2176, 0.6324,\n","         0.0000, 0.0000, 0.4741, 0.7926, 0.5650, 0.1660, 0.0000],\n","        [0.0000, 0.1720, 0.8045, 0.0000, 0.0547, 0.4786, 0.0000, 0.0000, 0.1559,\n","         0.5271, 0.8890, 0.0000, 0.0000, 0.0000, 0.1974, 0.0000],\n","        [0.2900, 0.0000, 0.0000, 0.1478, 0.0000, 0.3355, 0.6115, 0.6387, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5062],\n","        [0.9631, 0.1144, 1.3005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3995,\n","         0.5246, 1.1398, 0.0000, 0.0000, 0.0000, 0.0210, 0.0000],\n","        [0.2800, 0.0000, 0.0000, 0.0756, 0.0000, 0.1536, 0.4786, 0.5217, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4180],\n","        [0.0000, 0.6834, 0.1632, 0.2073, 0.8986, 0.0000, 0.0000, 0.2640, 0.6349,\n","         0.0000, 0.0000, 0.4493, 0.5922, 0.6142, 0.3318, 0.0000],\n","        [0.0749, 0.0000, 0.0000, 0.1478, 0.0000, 0.4452, 0.7274, 0.8073, 0.0000,\n","         0.0000, 0.0506, 0.0000, 0.0000, 0.0000, 0.0000, 0.3785]],\n","       grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.9032, 0.0000, 0.0000, 0.0000, 0.0000, 0.1006, 0.3493, 0.0245, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2347],\n","        [0.0000, 0.4330, 0.0000, 0.1785, 1.4666, 0.0000, 0.0000, 0.2176, 0.6324,\n","         0.0000, 0.0000, 0.4741, 0.7926, 0.5650, 0.1660, 0.0000],\n","        [0.0000, 0.1720, 0.8045, 0.0000, 0.0547, 0.4786, 0.0000, 0.0000, 0.1559,\n","         0.5271, 0.8890, 0.0000, 0.0000, 0.0000, 0.1974, 0.0000],\n","        [0.2900, 0.0000, 0.0000, 0.1478, 0.0000, 0.3355, 0.6115, 0.6387, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5062],\n","        [0.9631, 0.1144, 1.3005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3995,\n","         0.5246, 1.1398, 0.0000, 0.0000, 0.0000, 0.0210, 0.0000],\n","        [0.2800, 0.0000, 0.0000, 0.0756, 0.0000, 0.1536, 0.4786, 0.5217, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4180],\n","        [0.0000, 0.6834, 0.1632, 0.2073, 0.8986, 0.0000, 0.0000, 0.2640, 0.6349,\n","         0.0000, 0.0000, 0.4493, 0.5922, 0.6142, 0.3318, 0.0000],\n","        [0.0749, 0.0000, 0.0000, 0.1478, 0.0000, 0.4452, 0.7274, 0.8073, 0.0000,\n","         0.0000, 0.0506, 0.0000, 0.0000, 0.0000, 0.0000, 0.3785]],\n","       grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 16], 'torch_dtype': torch.float32, 'value': tensor([[1.1289, 0.0000, 0.0000, 0.0000, 0.0000, 0.1257, 0.4366, 0.0306, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2934],\n","        [0.0000, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7905,\n","         0.0000, 0.0000, 0.0000, 0.9907, 0.7062, 0.2076, 0.0000],\n","        [0.0000, 0.2151, 1.0056, 0.0000, 0.0684, 0.5982, 0.0000, 0.0000, 0.1948,\n","         0.6588, 1.1113, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3625, 0.0000, 0.0000, 0.1847, 0.0000, 0.4194, 0.7644, 0.7984, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6327],\n","        [1.2039, 0.0000, 1.6257, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4993,\n","         0.6558, 1.4247, 0.0000, 0.0000, 0.0000, 0.0262, 0.0000],\n","        [0.3499, 0.0000, 0.0000, 0.0946, 0.0000, 0.1920, 0.5982, 0.6522, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.2039, 0.0000, 1.1232, 0.0000, 0.0000, 0.3300, 0.7936,\n","         0.0000, 0.0000, 0.5616, 0.0000, 0.7678, 0.4147, 0.0000],\n","        [0.0936, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9093, 0.0000, 0.0000,\n","         0.0000, 0.0633, 0.0000, 0.0000, 0.0000, 0.0000, 0.4731]],\n","       grad_fn=<MulBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': {'data_in_0': {'shape': [8, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[1.1289, 0.0000, 0.0000, 0.0000, 0.0000, 0.1257, 0.4366, 0.0306, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2934],\n","        [0.0000, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7905,\n","         0.0000, 0.0000, 0.0000, 0.9907, 0.7062, 0.2076, 0.0000],\n","        [0.0000, 0.2151, 1.0056, 0.0000, 0.0684, 0.5982, 0.0000, 0.0000, 0.1948,\n","         0.6588, 1.1113, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3625, 0.0000, 0.0000, 0.1847, 0.0000, 0.4194, 0.7644, 0.7984, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6327],\n","        [1.2039, 0.0000, 1.6257, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4993,\n","         0.6558, 1.4247, 0.0000, 0.0000, 0.0000, 0.0262, 0.0000],\n","        [0.3499, 0.0000, 0.0000, 0.0946, 0.0000, 0.1920, 0.5982, 0.6522, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.2039, 0.0000, 1.1232, 0.0000, 0.0000, 0.3300, 0.7936,\n","         0.0000, 0.0000, 0.5616, 0.0000, 0.7678, 0.4147, 0.0000],\n","        [0.0936, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9093, 0.0000, 0.0000,\n","         0.0000, 0.0633, 0.0000, 0.0000, 0.0000, 0.0000, 0.4731]],\n","       grad_fn=<MulBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [5, 16], 'from': None, 'value': Parameter containing:\n","tensor([[ 0.0102, -0.0170,  0.1119, -0.2880, -0.2641, -0.0412,  0.0696,  0.0662,\n","          0.0777, -0.3716,  0.1390, -0.4887, -0.2731,  0.1075, -0.0754, -0.2051],\n","        [-0.0367,  0.0315,  0.0134,  0.1614, -0.1598,  0.0765,  0.0509,  0.0754,\n","         -0.0604, -0.2775,  0.0597, -0.3762, -0.3182, -0.1542,  0.1087,  0.0592],\n","        [-0.0575, -0.2346, -0.0770,  0.1623,  0.1442, -0.0239, -0.0111,  0.0189,\n","         -0.1151,  0.0818, -0.0414, -0.1174,  0.2106, -0.1535, -0.5312,  0.0402],\n","        [-0.0483,  0.0357, -0.1049,  0.1297,  0.0930,  0.0066,  0.0142,  0.0394,\n","          0.0710, -0.5057, -0.0740,  0.1781,  0.1342,  0.0514,  0.0423, -0.0525],\n","        [-0.0582,  0.1082,  0.0826, -0.1969,  0.1286,  0.0933, -0.1814, -0.2157,\n","          0.0892,  0.0087,  0.1039, -0.2857,  0.0420, -0.3564,  0.1775, -0.2471]],\n","       requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n","tensor([-0.2568, -0.0360,  0.2144, -0.1998, -0.1100], requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 5], 'torch_dtype': torch.float32, 'value': tensor([[-0.2782, -0.0259,  0.1540, -0.2615, -0.3223],\n","        [-0.4149, -0.4683, -0.0136,  0.0537, -0.1542],\n","        [-0.2659, -0.1093,  0.0676, -0.6888,  0.1995],\n","        [-0.3472,  0.1491,  0.2455, -0.1815, -0.5956],\n","        [-0.0715, -0.1827, -0.0566, -0.8290,  0.1572],\n","        [-0.2035,  0.0607,  0.2107, -0.1690, -0.3803],\n","        [-0.6703, -0.5205, -0.1285,  0.1097, -0.3097],\n","        [-0.2807,  0.0386,  0.2153, -0.2209, -0.3908]],\n","       grad_fn=<AddmmBackward0>)}}}\n","{'mase_type': 'module', 'mase_op': 'batch_norm1d', 'args': {'data_in_0': {'shape': [8, 5], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[-0.2782, -0.0259,  0.1540, -0.2615, -0.3223],\n","        [-0.4149, -0.4683, -0.0136,  0.0537, -0.1542],\n","        [-0.2659, -0.1093,  0.0676, -0.6888,  0.1995],\n","        [-0.3472,  0.1491,  0.2455, -0.1815, -0.5956],\n","        [-0.0715, -0.1827, -0.0566, -0.8290,  0.1572],\n","        [-0.2035,  0.0607,  0.2107, -0.1690, -0.3803],\n","        [-0.6703, -0.5205, -0.1285,  0.1097, -0.3097],\n","        [-0.2807,  0.0386,  0.2153, -0.2209, -0.3908]],\n","       grad_fn=<AddmmBackward0>)}, 'weight': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n","tensor([2.1910, 2.0147, 2.5960, 2.4834, 2.6620], requires_grad=True)}, 'bias': {'type': 'float', 'precision': [32], 'shape': [5], 'from': None, 'value': Parameter containing:\n","tensor([0.9538, 1.0879, 0.7378, 1.0604, 0.9132], requires_grad=True)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 5], 'torch_dtype': torch.float32, 'value': tensor([[1.4671, 2.0193, 2.0610, 1.1568, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 3.7010, 1.6354],\n","        [1.6326, 1.2895, 0.3599, 0.0000, 5.2703],\n","        [0.5428, 3.5511, 3.8634, 1.8022, 0.0000],\n","        [4.2361, 0.6467, 0.0000, 0.0000, 4.8353],\n","        [2.4679, 2.7774, 3.1774, 1.9032, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 4.1526, 0.0381],\n","        [1.4336, 2.5838, 3.2686, 1.4841, 0.0000]], grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'module_related_func', 'mase_op': 'relu', 'args': {'data_in_0': {'shape': [8, 5], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[1.4671, 2.0193, 2.0610, 1.1568, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 3.7010, 1.6354],\n","        [1.6326, 1.2895, 0.3599, 0.0000, 5.2703],\n","        [0.5428, 3.5511, 3.8634, 1.8022, 0.0000],\n","        [4.2361, 0.6467, 0.0000, 0.0000, 4.8353],\n","        [2.4679, 2.7774, 3.1774, 1.9032, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 4.1526, 0.0381],\n","        [1.4336, 2.5838, 3.2686, 1.4841, 0.0000]], grad_fn=<ReluBackward0>)}}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 5], 'torch_dtype': torch.float32, 'value': tensor([[1.4671, 2.0193, 2.0610, 1.1568, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 3.7010, 1.6354],\n","        [1.6326, 1.2895, 0.3599, 0.0000, 5.2703],\n","        [0.5428, 3.5511, 3.8634, 1.8022, 0.0000],\n","        [4.2361, 0.6467, 0.0000, 0.0000, 4.8353],\n","        [2.4679, 2.7774, 3.1774, 1.9032, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 4.1526, 0.0381],\n","        [1.4336, 2.5838, 3.2686, 1.4841, 0.0000]], grad_fn=<ReluBackward0>)}}}\n","{'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': {'data_out_0': {'type': 'float', 'precision': [32], 'shape': [8, 5], 'torch_dtype': torch.float32, 'value': tensor([[1.4671, 2.0193, 2.0610, 1.1568, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 3.7010, 1.6354],\n","        [1.6326, 1.2895, 0.3599, 0.0000, 5.2703],\n","        [0.5428, 3.5511, 3.8634, 1.8022, 0.0000],\n","        [4.2361, 0.6467, 0.0000, 0.0000, 4.8353],\n","        [2.4679, 2.7774, 3.1774, 1.9032, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 4.1526, 0.0381],\n","        [1.4336, 2.5838, 3.2686, 1.4841, 0.0000]], grad_fn=<ReluBackward0>)}}}\n"]}],"source":["for node in mg.fx_graph.nodes:\n","    print(node.meta['mase'].parameters['common'])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computations summary:\n","---------------------\n","| Node name     | Node type    |   Parameters |   Forward FLOPS |   Backward FLOPS |   Input buffer size |   Output buffer size |\n","|---------------|--------------|--------------|-----------------|------------------|---------------------|----------------------|\n","| x             | placeholder  |              |                 |                  |                     |                      |\n","| seq_blocks_0  | batch_norm1d |           32 |             512 |              512 |                 128 |                  128 |\n","| seq_blocks_1  | relu         |            0 |             128 |              128 |                 128 |                  128 |\n","| seq_blocks_2  | linear       |          512 |            4096 |             8192 |                 128 |                  256 |\n","| seq_blocks_3  | batch_norm1d |           64 |            1024 |             1024 |                 256 |                  256 |\n","| seq_blocks_4  | relu         |            0 |             256 |              256 |                 256 |                  256 |\n","| seq_blocks_5  | dropout      |            0 |               0 |                0 |                 256 |                  256 |\n","| seq_blocks_6  | linear       |          512 |            4096 |             8192 |                 256 |                  128 |\n","| seq_blocks_7  | batch_norm1d |           32 |             512 |              512 |                 128 |                  128 |\n","| seq_blocks_8  | relu         |            0 |             128 |              128 |                 128 |                  128 |\n","| seq_blocks_9  | dropout      |            0 |               0 |                0 |                 128 |                  128 |\n","| seq_blocks_10 | linear       |           80 |             640 |             1280 |                 128 |                   40 |\n","| seq_blocks_11 | batch_norm1d |           10 |             160 |              160 |                  40 |                   40 |\n","| seq_blocks_12 | relu         |            0 |              40 |               40 |                  40 |                   40 |\n","| output        | output       |              |                 |                  |                     |                      |\n"]}],"source":["from chop.passes.graph.analysis.flops.flops_pass import analyse_flops_pass\n","\n","analyse_flops_pass(mg)"]},{"cell_type":"markdown","metadata":{"id":"HhTU3755MerQ"},"source":["\n","\n","# Exercises:\n","\n","We have now seen how to:\n","1. Set up a dataset\n","2. Set up a model\n","3. Generate a `MaseGraph` from the model\n","4. Run Analysis and Transform passes on the `MaseGraph`\n","\n","Now consider the following problems:\n","\n","1. Explain the functionality of `report_graph_analysis_pass` and its printed jargons such as `placeholder`, `get_attr` ... You might find the doc of [torch.fx](https://pytorch.org/docs/stable/fx.html) useful.\n","\n","2. What are the functionalities of `profile_statistics_analysis_pass` and `report_node_meta_param_analysis_pass` respectively?"]},{"cell_type":"markdown","metadata":{},"source":["### Answer 1\n","> Explain the functionality of `report_graph_analysis_pass` and its printed jargons such as `placeholder`, `get_attr` \n","\n","`report_graph_analysis_pass` steps through each node of the FX graph and counts how many of each node fit the following types:\n","- `placeholder`- method inputs\n","- `get_attr`, `call_function`, `call_method`, `call_module` - the operations within the node, whether or not the node is getting an attribute or calling one of a free function, a method or a module\n","- `output` - how many outputs of the graph\n","\n","The pass also reports the layers in the graph along with their settings (example, `Linear(in_features=16, out_features=5, bias=True)`).\n","\n","This pass seems like it would be useful for getting an understanding of how the model is structured.\n","\n","### Answer 2\n","> What are the functionalities of `profile_statistics_analysis_pass` and `report_node_meta_param_analysis_pass` respectively?\n","\n","`profile_statistics_analysis_pass` iterates through each node and checks whether it matches the arguments specified, and if it does then it computes statistics based on the dummy data passed in. Stats can be computed for weight nodes (where only `call_module` nodes are considered) and for activation nodes separately, and they can also be further filtered by a type of node (example `linear` or `relu`) or specifically by the name. Statistics such as the variance, the range, etc. can be computed.\n","\n","`report_node_meta_param_analysis_pass` then iterates through the updated graph (processed by `profile_statistics_analysis_pass`) and outputs the stats computed."]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","## MASE OPs and MASE Types\n","\n","MASE is designed to be a very high-level intermediate representation (IR), this is very different from the classic [LLVM IR](https://llvm.org/docs/LangRef.html) that you might be familiar with.\n","\n","The following MASE Types are available:\n","(Note from Aaron: do we have a page somewhere that have summarized this?)\n","\n","\n","## A deeper dive into the quantisation transform\n","\n","3. Explain why only 1 OP is changed after the `quantize_transform_pass` .\n","\n","4. Write some code to traverse both `mg` and `ori_mg`, check and comment on the nodes in these two graphs. You might find the source code for the implementation of `summarize_quantization_analysis_pass` useful.\n","\n","5. Perform the same quantisation flow to the bigger JSC network that you have trained in lab1. You must be aware that now the `pass_args` for your custom network might be different if you have used more than the `Linear` layer in your network.\n","\n","6. Write code to show and verify that the weights of these layers are indeed quantised. You might need to go through the source code of the implementation of the quantisation pass and also the implementation of the [Quantized Layers](../../machop/chop/passes/transforms/quantize/quantized_modules/linear.py) ."]},{"cell_type":"markdown","metadata":{},"source":["### Answer 3\n","The `pass_args` specified that the quantisation should be done by `type` of `linear`, and there is only one linear layer in the model so only this was changed.\n","\n","### Answer 4\n","The following basic code was written to traverse the nodes of `mg` and `ori_mg` and compare the nodes:\n","```python\n","for og_node, node in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n","    print(\"----------------------------------------------\")\n","    print(f\"original {og_node.name}: {get_node_actual_target(og_node)}\")\n","    print(f\"transformed {node.name}: {get_node_actual_target(node)}\")\n","print(\"----------------------------------------------\")\n","```\n","\n","This code produced the following output:\n","```text\n","----------------------------------------------\n","original x: x\n","transformed x: x\n","----------------------------------------------\n","original seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","transformed seq_blocks_0: BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","----------------------------------------------\n","original seq_blocks_1: ReLU(inplace=True)\n","transformed seq_blocks_1: ReLU(inplace=True)\n","----------------------------------------------\n","original seq_blocks_2: Linear(in_features=16, out_features=5, bias=True)\n","transformed seq_blocks_2: LinearInteger(in_features=16, out_features=5, bias=True)\n","----------------------------------------------\n","original seq_blocks_3: ReLU(inplace=True)\n","transformed seq_blocks_3: ReLU(inplace=True)\n","----------------------------------------------\n","original output: output\n","transformed output: output\n","----------------------------------------------\n","```\n","\n","We can see that all the layers are identical except for `seq_blocks_2`, with the original being of type `Linear` and the new being `LinearInteger` after the quantization pass. This confirms the observations in the answer to Q3 above."]},{"cell_type":"markdown","metadata":{},"source":["\n","## The command line interface\n","\n","The same flow can also be executed on the command line throw the `transform` action.\n","\n","```bash\n","# make sure you have the same printout\n","pwd\n","# it should show\n","# your_dir/mase-tools/machop\n","\n","# enter the following command\n","./ch transform --config configs/examples/jsc_toy_by_type.toml --task cls --cpu=0\n","```\n","7. Load your own pre-trained JSC network, and perform perform the quantisation using the command line interface.\n","\n","## \\[Optional] Write your own pass\n","\n","Many examples of existing passes are in the [source code](../..//machop/chop/passes/__init__.py), the [test files](../../machop/test/passes) for these passes also contain useful information on helping you to understand how these passes are used.\n","\n","Implement a pass to count the number of FLOPs (floating-point operations) and BitOPs (bit-wise operations)."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
